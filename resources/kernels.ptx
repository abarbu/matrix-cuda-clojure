	.version 1.4
	.target sm_10, map_f64_to_f32
	// compiled with /opt/cuda/open64/lib//be
	// nvopencc 4.1 built on 2013-07-17

	//-----------------------------------------------------------
	// Compiling /tmp/tmpxft_000076db_00000000-9_kernels.cpp3.i (/tmp/ccBI#.4hFlYj)
	//-----------------------------------------------------------

	//-----------------------------------------------------------
	// Options:
	//-----------------------------------------------------------
	//  Target:ptx, ISA:sm_10, Endian:little, Pointer Size:64
	//  -O3	(Optimization level)
	//  -g0	(Debug level)
	//  -m2	(Report advisories)
	//-----------------------------------------------------------

	.file	1	"<command-line>"
	.file	2	"/usr/include/stdc-predef.h"
	.file	3	"/tmp/tmpxft_000076db_00000000-8_kernels.cudafe2.gpu"
	.file	4	"/usr/lib/gcc/x86_64-pc-linux-gnu/4.8.1/include/stddef.h"
	.file	5	"/opt/cuda/bin/..//include/crt/device_runtime.h"
	.file	6	"/opt/cuda/bin/..//include/host_defines.h"
	.file	7	"/opt/cuda/bin/..//include/builtin_types.h"
	.file	8	"/opt/cuda/include/device_types.h"
	.file	9	"/opt/cuda/include/driver_types.h"
	.file	10	"/opt/cuda/include/surface_types.h"
	.file	11	"/opt/cuda/include/texture_types.h"
	.file	12	"/opt/cuda/include/vector_types.h"
	.file	13	"/opt/cuda/bin/..//include/device_launch_parameters.h"
	.file	14	"/opt/cuda/include/crt/storage_class.h"
	.file	15	"kernels.cu"
	.file	16	"/opt/cuda/bin/..//include/common_functions.h"
	.file	17	"/opt/cuda/include/math_functions.h"
	.file	18	"/opt/cuda/include/math_constants.h"
	.file	19	"/opt/cuda/include/device_functions.h"
	.file	20	"/opt/cuda/include/sm_11_atomic_functions.h"
	.file	21	"/opt/cuda/include/sm_12_atomic_functions.h"
	.file	22	"/opt/cuda/include/sm_13_double_functions.h"
	.file	23	"/opt/cuda/include/sm_20_atomic_functions.h"
	.file	24	"/opt/cuda/include/sm_32_atomic_functions.h"
	.file	25	"/opt/cuda/include/sm_35_atomic_functions.h"
	.file	26	"/opt/cuda/include/sm_20_intrinsics.h"
	.file	27	"/opt/cuda/include/sm_30_intrinsics.h"
	.file	28	"/opt/cuda/include/sm_32_intrinsics.h"
	.file	29	"/opt/cuda/include/sm_35_intrinsics.h"
	.file	30	"/opt/cuda/include/surface_functions.h"
	.file	31	"/opt/cuda/include/texture_fetch_functions.h"
	.file	32	"/opt/cuda/include/texture_indirect_functions.h"
	.file	33	"/opt/cuda/include/surface_indirect_functions.h"
	.file	34	"/opt/cuda/include/math_functions_dbl_ptx1.h"


	.entry efill_vsf (
		.param .u64 __cudaparm_efill_vsf_n,
		.param .u64 __cudaparm_efill_vsf_x,
		.param .s32 __cudaparm_efill_vsf_lx,
		.param .f32 __cudaparm_efill_vsf_y,
		.param .u64 __cudaparm_efill_vsf_result,
		.param .s32 __cudaparm_efill_vsf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<7>;
	.reg .u64 %rd<8>;
	.reg .f32 %f<3>;
	.reg .pred %p<3>;
	.loc	15	140	0
$LDWbegin_efill_vsf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_efill_vsf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_0_1026;
	ld.param.f32 	%f1, [__cudaparm_efill_vsf_y];
	ld.param.u64 	%rd3, [__cudaparm_efill_vsf_result];
	ld.param.s32 	%r4, [__cudaparm_efill_vsf_lr];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	st.global.f32 	[%rd6+0], %f1;
$Lt_0_1026:
	exit;
$LDWend_efill_vsf:
	} // efill_vsf

	.entry efill_msf (
		.param .s32 __cudaparm_efill_msf_rs,
		.param .s32 __cudaparm_efill_msf_cs,
		.param .u64 __cudaparm_efill_msf_A,
		.param .s32 __cudaparm_efill_msf_lda,
		.param .f32 __cudaparm_efill_msf_B,
		.param .u64 __cudaparm_efill_msf_C,
		.param .s32 __cudaparm_efill_msf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<19>;
	.reg .u64 %rd<6>;
	.reg .f32 %f<3>;
	.reg .pred %p<3>;
$LDWbegin_efill_msf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_efill_msf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_efill_msf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_1_1282;
	ld.param.f32 	%f1, [__cudaparm_efill_msf_B];
	ld.param.u64 	%rd1, [__cudaparm_efill_msf_C];
	ld.param.s32 	%r15, [__cudaparm_efill_msf_ldc];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	st.global.f32 	[%rd4+0], %f1;
$Lt_1_1282:
	exit;
$LDWend_efill_msf:
	} // efill_msf

	.entry efill_svf (
		.param .u64 __cudaparm_efill_svf_n,
		.param .f32 __cudaparm_efill_svf_x,
		.param .u64 __cudaparm_efill_svf_y,
		.param .s32 __cudaparm_efill_svf_ly,
		.param .u64 __cudaparm_efill_svf_result,
		.param .s32 __cudaparm_efill_svf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<7>;
	.reg .u64 %rd<8>;
	.reg .f32 %f<3>;
	.reg .pred %p<3>;
	.loc	15	141	0
$LDWbegin_efill_svf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_efill_svf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_2_1026;
	ld.param.f32 	%f1, [__cudaparm_efill_svf_x];
	ld.param.u64 	%rd3, [__cudaparm_efill_svf_result];
	ld.param.s32 	%r4, [__cudaparm_efill_svf_lr];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	st.global.f32 	[%rd6+0], %f1;
$Lt_2_1026:
	exit;
$LDWend_efill_svf:
	} // efill_svf

	.entry efill_smf (
		.param .s32 __cudaparm_efill_smf_rs,
		.param .s32 __cudaparm_efill_smf_cs,
		.param .f32 __cudaparm_efill_smf_A,
		.param .u64 __cudaparm_efill_smf_B,
		.param .s32 __cudaparm_efill_smf_ldb,
		.param .u64 __cudaparm_efill_smf_C,
		.param .s32 __cudaparm_efill_smf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<19>;
	.reg .u64 %rd<6>;
	.reg .f32 %f<3>;
	.reg .pred %p<3>;
$LDWbegin_efill_smf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_efill_smf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_efill_smf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_3_1282;
	ld.param.f32 	%f1, [__cudaparm_efill_smf_A];
	ld.param.u64 	%rd1, [__cudaparm_efill_smf_C];
	ld.param.s32 	%r15, [__cudaparm_efill_smf_ldc];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	st.global.f32 	[%rd4+0], %f1;
$Lt_3_1282:
	exit;
$LDWend_efill_smf:
	} // efill_smf

	.entry efill_vvf (
		.param .u64 __cudaparm_efill_vvf_n,
		.param .u64 __cudaparm_efill_vvf_x,
		.param .s32 __cudaparm_efill_vvf_lx,
		.param .u64 __cudaparm_efill_vvf_y,
		.param .s32 __cudaparm_efill_vvf_ly,
		.param .u64 __cudaparm_efill_vvf_result,
		.param .s32 __cudaparm_efill_vvf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<3>;
	.reg .pred %p<3>;
	.loc	15	142	0
$LDWbegin_efill_vvf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_efill_vvf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_4_1026;
	ld.param.u64 	%rd3, [__cudaparm_efill_vvf_x];
	ld.param.s32 	%r4, [__cudaparm_efill_vvf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_efill_vvf_result];
	ld.param.s32 	%r6, [__cudaparm_efill_vvf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f1;
$Lt_4_1026:
	exit;
$LDWend_efill_vvf:
	} // efill_vvf

	.entry efill_vmf (
		.param .s32 __cudaparm_efill_vmf_rs,
		.param .s32 __cudaparm_efill_vmf_cs,
		.param .u64 __cudaparm_efill_vmf_x,
		.param .s32 __cudaparm_efill_vmf_lx,
		.param .u64 __cudaparm_efill_vmf_B,
		.param .s32 __cudaparm_efill_vmf_ldb,
		.param .u64 __cudaparm_efill_vmf_C,
		.param .s32 __cudaparm_efill_vmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<21>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<3>;
	.reg .pred %p<3>;
$LDWbegin_efill_vmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_efill_vmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_efill_vmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_5_1282;
	ld.param.u64 	%rd1, [__cudaparm_efill_vmf_x];
	ld.param.s32 	%r15, [__cudaparm_efill_vmf_lx];
	mul.lo.s32 	%r16, %r15, %r6;
	cvt.s64.s32 	%rd2, %r16;
	mul.wide.s32 	%rd3, %r16, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_efill_vmf_C];
	ld.param.s32 	%r17, [__cudaparm_efill_vmf_ldc];
	mul.lo.s32 	%r18, %r17, %r4;
	add.s32 	%r19, %r6, %r18;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f1;
$Lt_5_1282:
	exit;
$LDWend_efill_vmf:
	} // efill_vmf

	.entry efill_mvf (
		.param .s32 __cudaparm_efill_mvf_rs,
		.param .s32 __cudaparm_efill_mvf_cs,
		.param .u64 __cudaparm_efill_mvf_A,
		.param .s32 __cudaparm_efill_mvf_lda,
		.param .u64 __cudaparm_efill_mvf_y,
		.param .s32 __cudaparm_efill_mvf_ly,
		.param .u64 __cudaparm_efill_mvf_C,
		.param .s32 __cudaparm_efill_mvf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<3>;
	.reg .pred %p<3>;
$LDWbegin_efill_mvf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_efill_mvf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_efill_mvf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_6_1282;
	ld.param.u64 	%rd1, [__cudaparm_efill_mvf_A];
	ld.param.s32 	%r15, [__cudaparm_efill_mvf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_efill_mvf_C];
	ld.param.s32 	%r18, [__cudaparm_efill_mvf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f1;
$Lt_6_1282:
	exit;
$LDWend_efill_mvf:
	} // efill_mvf

	.entry efill_mmf (
		.param .s32 __cudaparm_efill_mmf_rs,
		.param .s32 __cudaparm_efill_mmf_cs,
		.param .u64 __cudaparm_efill_mmf_A,
		.param .s32 __cudaparm_efill_mmf_lda,
		.param .u64 __cudaparm_efill_mmf_B,
		.param .s32 __cudaparm_efill_mmf_ldb,
		.param .u64 __cudaparm_efill_mmf_C,
		.param .s32 __cudaparm_efill_mmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<3>;
	.reg .pred %p<3>;
$LDWbegin_efill_mmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_efill_mmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_efill_mmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_7_1282;
	ld.param.u64 	%rd1, [__cudaparm_efill_mmf_A];
	ld.param.s32 	%r15, [__cudaparm_efill_mmf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_efill_mmf_C];
	ld.param.s32 	%r18, [__cudaparm_efill_mmf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f1;
$Lt_7_1282:
	exit;
$LDWend_efill_mmf:
	} // efill_mmf

	.entry eadd_vsf (
		.param .u64 __cudaparm_eadd_vsf_n,
		.param .u64 __cudaparm_eadd_vsf_x,
		.param .s32 __cudaparm_eadd_vsf_lx,
		.param .f32 __cudaparm_eadd_vsf_y,
		.param .u64 __cudaparm_eadd_vsf_result,
		.param .s32 __cudaparm_eadd_vsf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
	.loc	15	144	0
$LDWbegin_eadd_vsf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eadd_vsf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_8_1026;
	ld.param.u64 	%rd3, [__cudaparm_eadd_vsf_x];
	ld.param.s32 	%r4, [__cudaparm_eadd_vsf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.f32 	%f2, [__cudaparm_eadd_vsf_y];
	add.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_eadd_vsf_result];
	ld.param.s32 	%r6, [__cudaparm_eadd_vsf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f3;
$Lt_8_1026:
	exit;
$LDWend_eadd_vsf:
	} // eadd_vsf

	.entry eadd_msf (
		.param .s32 __cudaparm_eadd_msf_rs,
		.param .s32 __cudaparm_eadd_msf_cs,
		.param .u64 __cudaparm_eadd_msf_A,
		.param .s32 __cudaparm_eadd_msf_lda,
		.param .f32 __cudaparm_eadd_msf_B,
		.param .u64 __cudaparm_eadd_msf_C,
		.param .s32 __cudaparm_eadd_msf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_eadd_msf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eadd_msf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eadd_msf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_9_1282;
	ld.param.u64 	%rd1, [__cudaparm_eadd_msf_A];
	ld.param.s32 	%r15, [__cudaparm_eadd_msf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.f32 	%f2, [__cudaparm_eadd_msf_B];
	add.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd5, [__cudaparm_eadd_msf_C];
	ld.param.s32 	%r18, [__cudaparm_eadd_msf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f3;
$Lt_9_1282:
	exit;
$LDWend_eadd_msf:
	} // eadd_msf

	.entry eadd_svf (
		.param .u64 __cudaparm_eadd_svf_n,
		.param .f32 __cudaparm_eadd_svf_x,
		.param .u64 __cudaparm_eadd_svf_y,
		.param .s32 __cudaparm_eadd_svf_ly,
		.param .u64 __cudaparm_eadd_svf_result,
		.param .s32 __cudaparm_eadd_svf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_eadd_svf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eadd_svf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_10_1026;
	ld.param.u64 	%rd3, [__cudaparm_eadd_svf_y];
	ld.param.s32 	%r4, [__cudaparm_eadd_svf_ly];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.f32 	%f2, [__cudaparm_eadd_svf_x];
	add.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_eadd_svf_result];
	ld.param.s32 	%r6, [__cudaparm_eadd_svf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f3;
$Lt_10_1026:
	exit;
$LDWend_eadd_svf:
	} // eadd_svf

	.entry eadd_smf (
		.param .s32 __cudaparm_eadd_smf_rs,
		.param .s32 __cudaparm_eadd_smf_cs,
		.param .f32 __cudaparm_eadd_smf_A,
		.param .u64 __cudaparm_eadd_smf_B,
		.param .s32 __cudaparm_eadd_smf_ldb,
		.param .u64 __cudaparm_eadd_smf_C,
		.param .s32 __cudaparm_eadd_smf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_eadd_smf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eadd_smf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eadd_smf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_11_1282;
	ld.param.u64 	%rd1, [__cudaparm_eadd_smf_B];
	ld.param.s32 	%r15, [__cudaparm_eadd_smf_ldb];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.f32 	%f2, [__cudaparm_eadd_smf_A];
	add.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd5, [__cudaparm_eadd_smf_C];
	ld.param.s32 	%r18, [__cudaparm_eadd_smf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f3;
$Lt_11_1282:
	exit;
$LDWend_eadd_smf:
	} // eadd_smf

	.entry eadd_vvf (
		.param .u64 __cudaparm_eadd_vvf_n,
		.param .u64 __cudaparm_eadd_vvf_x,
		.param .s32 __cudaparm_eadd_vvf_lx,
		.param .u64 __cudaparm_eadd_vvf_y,
		.param .s32 __cudaparm_eadd_vvf_ly,
		.param .u64 __cudaparm_eadd_vvf_result,
		.param .s32 __cudaparm_eadd_vvf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<11>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_eadd_vvf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eadd_vvf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_12_1026;
	ld.param.u64 	%rd3, [__cudaparm_eadd_vvf_x];
	ld.param.s32 	%r4, [__cudaparm_eadd_vvf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_eadd_vvf_y];
	ld.param.s32 	%r6, [__cudaparm_eadd_vvf_ly];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.global.f32 	%f2, [%rd10+0];
	add.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd11, [__cudaparm_eadd_vvf_result];
	ld.param.s32 	%r8, [__cudaparm_eadd_vvf_lr];
	mul.lo.s32 	%r9, %r8, %r3;
	cvt.s64.s32 	%rd12, %r9;
	mul.wide.s32 	%rd13, %r9, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f3;
$Lt_12_1026:
	exit;
$LDWend_eadd_vvf:
	} // eadd_vvf

	.entry eadd_vmf (
		.param .s32 __cudaparm_eadd_vmf_rs,
		.param .s32 __cudaparm_eadd_vmf_cs,
		.param .u64 __cudaparm_eadd_vmf_x,
		.param .s32 __cudaparm_eadd_vmf_lx,
		.param .u64 __cudaparm_eadd_vmf_B,
		.param .s32 __cudaparm_eadd_vmf_ldb,
		.param .u64 __cudaparm_eadd_vmf_C,
		.param .s32 __cudaparm_eadd_vmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_eadd_vmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eadd_vmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eadd_vmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_13_1282;
	ld.param.u64 	%rd1, [__cudaparm_eadd_vmf_x];
	ld.param.s32 	%r15, [__cudaparm_eadd_vmf_lx];
	mul.lo.s32 	%r16, %r15, %r6;
	cvt.s64.s32 	%rd2, %r16;
	mul.wide.s32 	%rd3, %r16, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_eadd_vmf_B];
	ld.param.s32 	%r17, [__cudaparm_eadd_vmf_ldb];
	mul.lo.s32 	%r18, %r17, %r4;
	add.s32 	%r19, %r6, %r18;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	add.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_eadd_vmf_C];
	ld.param.s32 	%r20, [__cudaparm_eadd_vmf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_13_1282:
	exit;
$LDWend_eadd_vmf:
	} // eadd_vmf

	.entry eadd_mvf (
		.param .s32 __cudaparm_eadd_mvf_rs,
		.param .s32 __cudaparm_eadd_mvf_cs,
		.param .u64 __cudaparm_eadd_mvf_A,
		.param .s32 __cudaparm_eadd_mvf_lda,
		.param .u64 __cudaparm_eadd_mvf_y,
		.param .s32 __cudaparm_eadd_mvf_ly,
		.param .u64 __cudaparm_eadd_mvf_C,
		.param .s32 __cudaparm_eadd_mvf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_eadd_mvf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eadd_mvf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eadd_mvf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_14_1282;
	ld.param.u64 	%rd1, [__cudaparm_eadd_mvf_A];
	ld.param.s32 	%r15, [__cudaparm_eadd_mvf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_eadd_mvf_y];
	ld.param.s32 	%r18, [__cudaparm_eadd_mvf_ly];
	mul.lo.s32 	%r19, %r18, %r6;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	add.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_eadd_mvf_C];
	ld.param.s32 	%r20, [__cudaparm_eadd_mvf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_14_1282:
	exit;
$LDWend_eadd_mvf:
	} // eadd_mvf

	.entry eadd_mmf (
		.param .s32 __cudaparm_eadd_mmf_rs,
		.param .s32 __cudaparm_eadd_mmf_cs,
		.param .u64 __cudaparm_eadd_mmf_A,
		.param .s32 __cudaparm_eadd_mmf_lda,
		.param .u64 __cudaparm_eadd_mmf_B,
		.param .s32 __cudaparm_eadd_mmf_ldb,
		.param .u64 __cudaparm_eadd_mmf_C,
		.param .s32 __cudaparm_eadd_mmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<25>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_eadd_mmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eadd_mmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eadd_mmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_15_1282;
	ld.param.u64 	%rd1, [__cudaparm_eadd_mmf_A];
	ld.param.s32 	%r15, [__cudaparm_eadd_mmf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_eadd_mmf_B];
	ld.param.s32 	%r18, [__cudaparm_eadd_mmf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	add.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_eadd_mmf_C];
	ld.param.s32 	%r21, [__cudaparm_eadd_mmf_ldc];
	mul.lo.s32 	%r22, %r21, %r4;
	add.s32 	%r23, %r6, %r22;
	cvt.s64.s32 	%rd10, %r23;
	mul.wide.s32 	%rd11, %r23, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_15_1282:
	exit;
$LDWend_eadd_mmf:
	} // eadd_mmf

	.entry esub_vsf (
		.param .u64 __cudaparm_esub_vsf_n,
		.param .u64 __cudaparm_esub_vsf_x,
		.param .s32 __cudaparm_esub_vsf_lx,
		.param .f32 __cudaparm_esub_vsf_y,
		.param .u64 __cudaparm_esub_vsf_result,
		.param .s32 __cudaparm_esub_vsf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
	.loc	15	145	0
$LDWbegin_esub_vsf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_esub_vsf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_16_1026;
	ld.param.u64 	%rd3, [__cudaparm_esub_vsf_x];
	ld.param.s32 	%r4, [__cudaparm_esub_vsf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.f32 	%f2, [__cudaparm_esub_vsf_y];
	sub.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_esub_vsf_result];
	ld.param.s32 	%r6, [__cudaparm_esub_vsf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f3;
$Lt_16_1026:
	exit;
$LDWend_esub_vsf:
	} // esub_vsf

	.entry esub_msf (
		.param .s32 __cudaparm_esub_msf_rs,
		.param .s32 __cudaparm_esub_msf_cs,
		.param .u64 __cudaparm_esub_msf_A,
		.param .s32 __cudaparm_esub_msf_lda,
		.param .f32 __cudaparm_esub_msf_B,
		.param .u64 __cudaparm_esub_msf_C,
		.param .s32 __cudaparm_esub_msf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_esub_msf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_esub_msf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_esub_msf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_17_1282;
	ld.param.u64 	%rd1, [__cudaparm_esub_msf_A];
	ld.param.s32 	%r15, [__cudaparm_esub_msf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.f32 	%f2, [__cudaparm_esub_msf_B];
	sub.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd5, [__cudaparm_esub_msf_C];
	ld.param.s32 	%r18, [__cudaparm_esub_msf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f3;
$Lt_17_1282:
	exit;
$LDWend_esub_msf:
	} // esub_msf

	.entry esub_svf (
		.param .u64 __cudaparm_esub_svf_n,
		.param .f32 __cudaparm_esub_svf_x,
		.param .u64 __cudaparm_esub_svf_y,
		.param .s32 __cudaparm_esub_svf_ly,
		.param .u64 __cudaparm_esub_svf_result,
		.param .s32 __cudaparm_esub_svf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_esub_svf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_esub_svf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_18_1026;
	ld.param.f32 	%f1, [__cudaparm_esub_svf_x];
	ld.param.u64 	%rd3, [__cudaparm_esub_svf_y];
	ld.param.s32 	%r4, [__cudaparm_esub_svf_ly];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f2, [%rd6+0];
	sub.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_esub_svf_result];
	ld.param.s32 	%r6, [__cudaparm_esub_svf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f3;
$Lt_18_1026:
	exit;
$LDWend_esub_svf:
	} // esub_svf

	.entry esub_smf (
		.param .s32 __cudaparm_esub_smf_rs,
		.param .s32 __cudaparm_esub_smf_cs,
		.param .f32 __cudaparm_esub_smf_A,
		.param .u64 __cudaparm_esub_smf_B,
		.param .s32 __cudaparm_esub_smf_ldb,
		.param .u64 __cudaparm_esub_smf_C,
		.param .s32 __cudaparm_esub_smf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_esub_smf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_esub_smf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_esub_smf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_19_1282;
	ld.param.f32 	%f1, [__cudaparm_esub_smf_A];
	ld.param.u64 	%rd1, [__cudaparm_esub_smf_B];
	ld.param.s32 	%r15, [__cudaparm_esub_smf_ldb];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f2, [%rd4+0];
	sub.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd5, [__cudaparm_esub_smf_C];
	ld.param.s32 	%r18, [__cudaparm_esub_smf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f3;
$Lt_19_1282:
	exit;
$LDWend_esub_smf:
	} // esub_smf

	.entry esub_vvf (
		.param .u64 __cudaparm_esub_vvf_n,
		.param .u64 __cudaparm_esub_vvf_x,
		.param .s32 __cudaparm_esub_vvf_lx,
		.param .u64 __cudaparm_esub_vvf_y,
		.param .s32 __cudaparm_esub_vvf_ly,
		.param .u64 __cudaparm_esub_vvf_result,
		.param .s32 __cudaparm_esub_vvf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<11>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_esub_vvf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_esub_vvf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_20_1026;
	ld.param.u64 	%rd3, [__cudaparm_esub_vvf_x];
	ld.param.s32 	%r4, [__cudaparm_esub_vvf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_esub_vvf_y];
	ld.param.s32 	%r6, [__cudaparm_esub_vvf_ly];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.global.f32 	%f2, [%rd10+0];
	sub.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd11, [__cudaparm_esub_vvf_result];
	ld.param.s32 	%r8, [__cudaparm_esub_vvf_lr];
	mul.lo.s32 	%r9, %r8, %r3;
	cvt.s64.s32 	%rd12, %r9;
	mul.wide.s32 	%rd13, %r9, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f3;
$Lt_20_1026:
	exit;
$LDWend_esub_vvf:
	} // esub_vvf

	.entry esub_vmf (
		.param .s32 __cudaparm_esub_vmf_rs,
		.param .s32 __cudaparm_esub_vmf_cs,
		.param .u64 __cudaparm_esub_vmf_x,
		.param .s32 __cudaparm_esub_vmf_lx,
		.param .u64 __cudaparm_esub_vmf_B,
		.param .s32 __cudaparm_esub_vmf_ldb,
		.param .u64 __cudaparm_esub_vmf_C,
		.param .s32 __cudaparm_esub_vmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_esub_vmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_esub_vmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_esub_vmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_21_1282;
	ld.param.u64 	%rd1, [__cudaparm_esub_vmf_x];
	ld.param.s32 	%r15, [__cudaparm_esub_vmf_lx];
	mul.lo.s32 	%r16, %r15, %r6;
	cvt.s64.s32 	%rd2, %r16;
	mul.wide.s32 	%rd3, %r16, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_esub_vmf_B];
	ld.param.s32 	%r17, [__cudaparm_esub_vmf_ldb];
	mul.lo.s32 	%r18, %r17, %r4;
	add.s32 	%r19, %r6, %r18;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	sub.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_esub_vmf_C];
	ld.param.s32 	%r20, [__cudaparm_esub_vmf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_21_1282:
	exit;
$LDWend_esub_vmf:
	} // esub_vmf

	.entry esub_mvf (
		.param .s32 __cudaparm_esub_mvf_rs,
		.param .s32 __cudaparm_esub_mvf_cs,
		.param .u64 __cudaparm_esub_mvf_A,
		.param .s32 __cudaparm_esub_mvf_lda,
		.param .u64 __cudaparm_esub_mvf_y,
		.param .s32 __cudaparm_esub_mvf_ly,
		.param .u64 __cudaparm_esub_mvf_C,
		.param .s32 __cudaparm_esub_mvf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_esub_mvf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_esub_mvf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_esub_mvf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_22_1282;
	ld.param.u64 	%rd1, [__cudaparm_esub_mvf_A];
	ld.param.s32 	%r15, [__cudaparm_esub_mvf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_esub_mvf_y];
	ld.param.s32 	%r18, [__cudaparm_esub_mvf_ly];
	mul.lo.s32 	%r19, %r18, %r6;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	sub.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_esub_mvf_C];
	ld.param.s32 	%r20, [__cudaparm_esub_mvf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_22_1282:
	exit;
$LDWend_esub_mvf:
	} // esub_mvf

	.entry esub_mmf (
		.param .s32 __cudaparm_esub_mmf_rs,
		.param .s32 __cudaparm_esub_mmf_cs,
		.param .u64 __cudaparm_esub_mmf_A,
		.param .s32 __cudaparm_esub_mmf_lda,
		.param .u64 __cudaparm_esub_mmf_B,
		.param .s32 __cudaparm_esub_mmf_ldb,
		.param .u64 __cudaparm_esub_mmf_C,
		.param .s32 __cudaparm_esub_mmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<25>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_esub_mmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_esub_mmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_esub_mmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_23_1282;
	ld.param.u64 	%rd1, [__cudaparm_esub_mmf_A];
	ld.param.s32 	%r15, [__cudaparm_esub_mmf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_esub_mmf_B];
	ld.param.s32 	%r18, [__cudaparm_esub_mmf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	sub.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_esub_mmf_C];
	ld.param.s32 	%r21, [__cudaparm_esub_mmf_ldc];
	mul.lo.s32 	%r22, %r21, %r4;
	add.s32 	%r23, %r6, %r22;
	cvt.s64.s32 	%rd10, %r23;
	mul.wide.s32 	%rd11, %r23, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_23_1282:
	exit;
$LDWend_esub_mmf:
	} // esub_mmf

	.entry emul_vsf (
		.param .u64 __cudaparm_emul_vsf_n,
		.param .u64 __cudaparm_emul_vsf_x,
		.param .s32 __cudaparm_emul_vsf_lx,
		.param .f32 __cudaparm_emul_vsf_y,
		.param .u64 __cudaparm_emul_vsf_result,
		.param .s32 __cudaparm_emul_vsf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
	.loc	15	146	0
$LDWbegin_emul_vsf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_emul_vsf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_24_1026;
	ld.param.u64 	%rd3, [__cudaparm_emul_vsf_x];
	ld.param.s32 	%r4, [__cudaparm_emul_vsf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.f32 	%f2, [__cudaparm_emul_vsf_y];
	mul.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_emul_vsf_result];
	ld.param.s32 	%r6, [__cudaparm_emul_vsf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f3;
$Lt_24_1026:
	exit;
$LDWend_emul_vsf:
	} // emul_vsf

	.entry emul_msf (
		.param .s32 __cudaparm_emul_msf_rs,
		.param .s32 __cudaparm_emul_msf_cs,
		.param .u64 __cudaparm_emul_msf_A,
		.param .s32 __cudaparm_emul_msf_lda,
		.param .f32 __cudaparm_emul_msf_B,
		.param .u64 __cudaparm_emul_msf_C,
		.param .s32 __cudaparm_emul_msf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emul_msf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emul_msf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emul_msf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_25_1282;
	ld.param.u64 	%rd1, [__cudaparm_emul_msf_A];
	ld.param.s32 	%r15, [__cudaparm_emul_msf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.f32 	%f2, [__cudaparm_emul_msf_B];
	mul.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd5, [__cudaparm_emul_msf_C];
	ld.param.s32 	%r18, [__cudaparm_emul_msf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f3;
$Lt_25_1282:
	exit;
$LDWend_emul_msf:
	} // emul_msf

	.entry emul_svf (
		.param .u64 __cudaparm_emul_svf_n,
		.param .f32 __cudaparm_emul_svf_x,
		.param .u64 __cudaparm_emul_svf_y,
		.param .s32 __cudaparm_emul_svf_ly,
		.param .u64 __cudaparm_emul_svf_result,
		.param .s32 __cudaparm_emul_svf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emul_svf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_emul_svf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_26_1026;
	ld.param.u64 	%rd3, [__cudaparm_emul_svf_y];
	ld.param.s32 	%r4, [__cudaparm_emul_svf_ly];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.f32 	%f2, [__cudaparm_emul_svf_x];
	mul.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_emul_svf_result];
	ld.param.s32 	%r6, [__cudaparm_emul_svf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f3;
$Lt_26_1026:
	exit;
$LDWend_emul_svf:
	} // emul_svf

	.entry emul_smf (
		.param .s32 __cudaparm_emul_smf_rs,
		.param .s32 __cudaparm_emul_smf_cs,
		.param .f32 __cudaparm_emul_smf_A,
		.param .u64 __cudaparm_emul_smf_B,
		.param .s32 __cudaparm_emul_smf_ldb,
		.param .u64 __cudaparm_emul_smf_C,
		.param .s32 __cudaparm_emul_smf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emul_smf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emul_smf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emul_smf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_27_1282;
	ld.param.u64 	%rd1, [__cudaparm_emul_smf_B];
	ld.param.s32 	%r15, [__cudaparm_emul_smf_ldb];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.f32 	%f2, [__cudaparm_emul_smf_A];
	mul.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd5, [__cudaparm_emul_smf_C];
	ld.param.s32 	%r18, [__cudaparm_emul_smf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f3;
$Lt_27_1282:
	exit;
$LDWend_emul_smf:
	} // emul_smf

	.entry emul_vvf (
		.param .u64 __cudaparm_emul_vvf_n,
		.param .u64 __cudaparm_emul_vvf_x,
		.param .s32 __cudaparm_emul_vvf_lx,
		.param .u64 __cudaparm_emul_vvf_y,
		.param .s32 __cudaparm_emul_vvf_ly,
		.param .u64 __cudaparm_emul_vvf_result,
		.param .s32 __cudaparm_emul_vvf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<11>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emul_vvf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_emul_vvf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_28_1026;
	ld.param.u64 	%rd3, [__cudaparm_emul_vvf_x];
	ld.param.s32 	%r4, [__cudaparm_emul_vvf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_emul_vvf_y];
	ld.param.s32 	%r6, [__cudaparm_emul_vvf_ly];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.global.f32 	%f2, [%rd10+0];
	mul.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd11, [__cudaparm_emul_vvf_result];
	ld.param.s32 	%r8, [__cudaparm_emul_vvf_lr];
	mul.lo.s32 	%r9, %r8, %r3;
	cvt.s64.s32 	%rd12, %r9;
	mul.wide.s32 	%rd13, %r9, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f3;
$Lt_28_1026:
	exit;
$LDWend_emul_vvf:
	} // emul_vvf

	.entry emul_vmf (
		.param .s32 __cudaparm_emul_vmf_rs,
		.param .s32 __cudaparm_emul_vmf_cs,
		.param .u64 __cudaparm_emul_vmf_x,
		.param .s32 __cudaparm_emul_vmf_lx,
		.param .u64 __cudaparm_emul_vmf_B,
		.param .s32 __cudaparm_emul_vmf_ldb,
		.param .u64 __cudaparm_emul_vmf_C,
		.param .s32 __cudaparm_emul_vmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emul_vmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emul_vmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emul_vmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_29_1282;
	ld.param.u64 	%rd1, [__cudaparm_emul_vmf_x];
	ld.param.s32 	%r15, [__cudaparm_emul_vmf_lx];
	mul.lo.s32 	%r16, %r15, %r6;
	cvt.s64.s32 	%rd2, %r16;
	mul.wide.s32 	%rd3, %r16, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_emul_vmf_B];
	ld.param.s32 	%r17, [__cudaparm_emul_vmf_ldb];
	mul.lo.s32 	%r18, %r17, %r4;
	add.s32 	%r19, %r6, %r18;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	mul.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_emul_vmf_C];
	ld.param.s32 	%r20, [__cudaparm_emul_vmf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_29_1282:
	exit;
$LDWend_emul_vmf:
	} // emul_vmf

	.entry emul_mvf (
		.param .s32 __cudaparm_emul_mvf_rs,
		.param .s32 __cudaparm_emul_mvf_cs,
		.param .u64 __cudaparm_emul_mvf_A,
		.param .s32 __cudaparm_emul_mvf_lda,
		.param .u64 __cudaparm_emul_mvf_y,
		.param .s32 __cudaparm_emul_mvf_ly,
		.param .u64 __cudaparm_emul_mvf_C,
		.param .s32 __cudaparm_emul_mvf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emul_mvf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emul_mvf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emul_mvf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_30_1282;
	ld.param.u64 	%rd1, [__cudaparm_emul_mvf_A];
	ld.param.s32 	%r15, [__cudaparm_emul_mvf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_emul_mvf_y];
	ld.param.s32 	%r18, [__cudaparm_emul_mvf_ly];
	mul.lo.s32 	%r19, %r18, %r6;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	mul.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_emul_mvf_C];
	ld.param.s32 	%r20, [__cudaparm_emul_mvf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_30_1282:
	exit;
$LDWend_emul_mvf:
	} // emul_mvf

	.entry emul_mmf (
		.param .s32 __cudaparm_emul_mmf_rs,
		.param .s32 __cudaparm_emul_mmf_cs,
		.param .u64 __cudaparm_emul_mmf_A,
		.param .s32 __cudaparm_emul_mmf_lda,
		.param .u64 __cudaparm_emul_mmf_B,
		.param .s32 __cudaparm_emul_mmf_ldb,
		.param .u64 __cudaparm_emul_mmf_C,
		.param .s32 __cudaparm_emul_mmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<25>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emul_mmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emul_mmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emul_mmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_31_1282;
	ld.param.u64 	%rd1, [__cudaparm_emul_mmf_A];
	ld.param.s32 	%r15, [__cudaparm_emul_mmf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_emul_mmf_B];
	ld.param.s32 	%r18, [__cudaparm_emul_mmf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	mul.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_emul_mmf_C];
	ld.param.s32 	%r21, [__cudaparm_emul_mmf_ldc];
	mul.lo.s32 	%r22, %r21, %r4;
	add.s32 	%r23, %r6, %r22;
	cvt.s64.s32 	%rd10, %r23;
	mul.wide.s32 	%rd11, %r23, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_31_1282:
	exit;
$LDWend_emul_mmf:
	} // emul_mmf

	.entry ediv_vsf (
		.param .u64 __cudaparm_ediv_vsf_n,
		.param .u64 __cudaparm_ediv_vsf_x,
		.param .s32 __cudaparm_ediv_vsf_lx,
		.param .f32 __cudaparm_ediv_vsf_y,
		.param .u64 __cudaparm_ediv_vsf_result,
		.param .s32 __cudaparm_ediv_vsf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
	.loc	15	147	0
$LDWbegin_ediv_vsf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_ediv_vsf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_32_1026;
	ld.param.u64 	%rd3, [__cudaparm_ediv_vsf_x];
	ld.param.s32 	%r4, [__cudaparm_ediv_vsf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.f32 	%f2, [__cudaparm_ediv_vsf_y];
	div.full.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_ediv_vsf_result];
	ld.param.s32 	%r6, [__cudaparm_ediv_vsf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f3;
$Lt_32_1026:
	exit;
$LDWend_ediv_vsf:
	} // ediv_vsf

	.entry ediv_msf (
		.param .s32 __cudaparm_ediv_msf_rs,
		.param .s32 __cudaparm_ediv_msf_cs,
		.param .u64 __cudaparm_ediv_msf_A,
		.param .s32 __cudaparm_ediv_msf_lda,
		.param .f32 __cudaparm_ediv_msf_B,
		.param .u64 __cudaparm_ediv_msf_C,
		.param .s32 __cudaparm_ediv_msf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_ediv_msf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_ediv_msf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_ediv_msf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_33_1282;
	ld.param.u64 	%rd1, [__cudaparm_ediv_msf_A];
	ld.param.s32 	%r15, [__cudaparm_ediv_msf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.f32 	%f2, [__cudaparm_ediv_msf_B];
	div.full.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd5, [__cudaparm_ediv_msf_C];
	ld.param.s32 	%r18, [__cudaparm_ediv_msf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f3;
$Lt_33_1282:
	exit;
$LDWend_ediv_msf:
	} // ediv_msf

	.entry ediv_svf (
		.param .u64 __cudaparm_ediv_svf_n,
		.param .f32 __cudaparm_ediv_svf_x,
		.param .u64 __cudaparm_ediv_svf_y,
		.param .s32 __cudaparm_ediv_svf_ly,
		.param .u64 __cudaparm_ediv_svf_result,
		.param .s32 __cudaparm_ediv_svf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_ediv_svf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_ediv_svf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_34_1026;
	ld.param.f32 	%f1, [__cudaparm_ediv_svf_x];
	ld.param.u64 	%rd3, [__cudaparm_ediv_svf_y];
	ld.param.s32 	%r4, [__cudaparm_ediv_svf_ly];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f2, [%rd6+0];
	div.full.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_ediv_svf_result];
	ld.param.s32 	%r6, [__cudaparm_ediv_svf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f3;
$Lt_34_1026:
	exit;
$LDWend_ediv_svf:
	} // ediv_svf

	.entry ediv_smf (
		.param .s32 __cudaparm_ediv_smf_rs,
		.param .s32 __cudaparm_ediv_smf_cs,
		.param .f32 __cudaparm_ediv_smf_A,
		.param .u64 __cudaparm_ediv_smf_B,
		.param .s32 __cudaparm_ediv_smf_ldb,
		.param .u64 __cudaparm_ediv_smf_C,
		.param .s32 __cudaparm_ediv_smf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_ediv_smf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_ediv_smf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_ediv_smf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_35_1282;
	ld.param.f32 	%f1, [__cudaparm_ediv_smf_A];
	ld.param.u64 	%rd1, [__cudaparm_ediv_smf_B];
	ld.param.s32 	%r15, [__cudaparm_ediv_smf_ldb];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f2, [%rd4+0];
	div.full.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd5, [__cudaparm_ediv_smf_C];
	ld.param.s32 	%r18, [__cudaparm_ediv_smf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f3;
$Lt_35_1282:
	exit;
$LDWend_ediv_smf:
	} // ediv_smf

	.entry ediv_vvf (
		.param .u64 __cudaparm_ediv_vvf_n,
		.param .u64 __cudaparm_ediv_vvf_x,
		.param .s32 __cudaparm_ediv_vvf_lx,
		.param .u64 __cudaparm_ediv_vvf_y,
		.param .s32 __cudaparm_ediv_vvf_ly,
		.param .u64 __cudaparm_ediv_vvf_result,
		.param .s32 __cudaparm_ediv_vvf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<11>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_ediv_vvf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_ediv_vvf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_36_1026;
	ld.param.u64 	%rd3, [__cudaparm_ediv_vvf_x];
	ld.param.s32 	%r4, [__cudaparm_ediv_vvf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_ediv_vvf_y];
	ld.param.s32 	%r6, [__cudaparm_ediv_vvf_ly];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.global.f32 	%f2, [%rd10+0];
	div.full.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd11, [__cudaparm_ediv_vvf_result];
	ld.param.s32 	%r8, [__cudaparm_ediv_vvf_lr];
	mul.lo.s32 	%r9, %r8, %r3;
	cvt.s64.s32 	%rd12, %r9;
	mul.wide.s32 	%rd13, %r9, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f3;
$Lt_36_1026:
	exit;
$LDWend_ediv_vvf:
	} // ediv_vvf

	.entry ediv_vmf (
		.param .s32 __cudaparm_ediv_vmf_rs,
		.param .s32 __cudaparm_ediv_vmf_cs,
		.param .u64 __cudaparm_ediv_vmf_x,
		.param .s32 __cudaparm_ediv_vmf_lx,
		.param .u64 __cudaparm_ediv_vmf_B,
		.param .s32 __cudaparm_ediv_vmf_ldb,
		.param .u64 __cudaparm_ediv_vmf_C,
		.param .s32 __cudaparm_ediv_vmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_ediv_vmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_ediv_vmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_ediv_vmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_37_1282;
	ld.param.u64 	%rd1, [__cudaparm_ediv_vmf_x];
	ld.param.s32 	%r15, [__cudaparm_ediv_vmf_lx];
	mul.lo.s32 	%r16, %r15, %r6;
	cvt.s64.s32 	%rd2, %r16;
	mul.wide.s32 	%rd3, %r16, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_ediv_vmf_B];
	ld.param.s32 	%r17, [__cudaparm_ediv_vmf_ldb];
	mul.lo.s32 	%r18, %r17, %r4;
	add.s32 	%r19, %r6, %r18;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	div.full.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_ediv_vmf_C];
	ld.param.s32 	%r20, [__cudaparm_ediv_vmf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_37_1282:
	exit;
$LDWend_ediv_vmf:
	} // ediv_vmf

	.entry ediv_mvf (
		.param .s32 __cudaparm_ediv_mvf_rs,
		.param .s32 __cudaparm_ediv_mvf_cs,
		.param .u64 __cudaparm_ediv_mvf_A,
		.param .s32 __cudaparm_ediv_mvf_lda,
		.param .u64 __cudaparm_ediv_mvf_y,
		.param .s32 __cudaparm_ediv_mvf_ly,
		.param .u64 __cudaparm_ediv_mvf_C,
		.param .s32 __cudaparm_ediv_mvf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_ediv_mvf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_ediv_mvf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_ediv_mvf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_38_1282;
	ld.param.u64 	%rd1, [__cudaparm_ediv_mvf_A];
	ld.param.s32 	%r15, [__cudaparm_ediv_mvf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_ediv_mvf_y];
	ld.param.s32 	%r18, [__cudaparm_ediv_mvf_ly];
	mul.lo.s32 	%r19, %r18, %r6;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	div.full.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_ediv_mvf_C];
	ld.param.s32 	%r20, [__cudaparm_ediv_mvf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_38_1282:
	exit;
$LDWend_ediv_mvf:
	} // ediv_mvf

	.entry ediv_mmf (
		.param .s32 __cudaparm_ediv_mmf_rs,
		.param .s32 __cudaparm_ediv_mmf_cs,
		.param .u64 __cudaparm_ediv_mmf_A,
		.param .s32 __cudaparm_ediv_mmf_lda,
		.param .u64 __cudaparm_ediv_mmf_B,
		.param .s32 __cudaparm_ediv_mmf_ldb,
		.param .u64 __cudaparm_ediv_mmf_C,
		.param .s32 __cudaparm_ediv_mmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<25>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_ediv_mmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_ediv_mmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_ediv_mmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_39_1282;
	ld.param.u64 	%rd1, [__cudaparm_ediv_mmf_A];
	ld.param.s32 	%r15, [__cudaparm_ediv_mmf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_ediv_mmf_B];
	ld.param.s32 	%r18, [__cudaparm_ediv_mmf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	div.full.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_ediv_mmf_C];
	ld.param.s32 	%r21, [__cudaparm_ediv_mmf_ldc];
	mul.lo.s32 	%r22, %r21, %r4;
	add.s32 	%r23, %r6, %r22;
	cvt.s64.s32 	%rd10, %r23;
	mul.wide.s32 	%rd11, %r23, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_39_1282:
	exit;
$LDWend_ediv_mmf:
	} // ediv_mmf

	.entry epow_vsf (
		.param .u64 __cudaparm_epow_vsf_n,
		.param .u64 __cudaparm_epow_vsf_x,
		.param .s32 __cudaparm_epow_vsf_lx,
		.param .f32 __cudaparm_epow_vsf_y,
		.param .u64 __cudaparm_epow_vsf_result,
		.param .s32 __cudaparm_epow_vsf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<52>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<212>;
	.reg .pred %p<28>;
	.loc	15	149	0
$LDWbegin_epow_vsf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_epow_vsf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_40_18434;
	ld.param.u64 	%rd3, [__cudaparm_epow_vsf_x];
	ld.param.s32 	%r4, [__cudaparm_epow_vsf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.f32 	%f2, [__cudaparm_epow_vsf_y];
	mov.f32 	%f3, 0f3f800000;     	// 1
	set.eq.u32.f32 	%r6, %f1, %f3;
	neg.s32 	%r7, %r6;
	mov.f32 	%f4, 0f00000000;     	// 0
	set.eq.u32.f32 	%r8, %f2, %f4;
	neg.s32 	%r9, %r8;
	or.b32 	%r10, %r7, %r9;
	mov.u32 	%r11, 0;
	setp.eq.s32 	%p2, %r10, %r11;
	@%p2 bra 	$Lt_40_19202;
	mov.f32 	%f5, 0f3f800000;     	// 1
	bra.uni 	$Lt_40_18946;
$Lt_40_19202:
	.loc	17	11223	0
	abs.f32 	%f6, %f1;
	mov.f32 	%f7, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.le.f32 	%p3, %f6, %f7;
	@!%p3 bra 	$Lt_40_10242;
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_vsf_y];
	.loc	17	11223	0
	abs.f32 	%f8, %f2;
	mov.f32 	%f9, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.le.f32 	%p4, %f8, %f9;
	@%p4 bra 	$Lt_40_10498;
$Lt_40_10242:
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_vsf_y];
	.loc	17	11224	0
	add.f32 	%f5, %f1, %f2;
	.loc	17	11223	0
	bra.uni 	$Lt_40_11010;
$Lt_40_10498:
	.loc	17	11225	0
	mov.f32 	%f10, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p5, %f8, %f10;
	@!%p5 bra 	$Lt_40_19714;
	.loc	17	11230	0
	mov.f32 	%f11, 0f3f800000;    	// 1
	setp.gt.f32 	%p6, %f6, %f11;
	mov.s32 	%r12, 1065353216;
	mov.s32 	%r13, 0;
	mov.s32 	%r14, 2139095040;
	selp.s32 	%r15, %r13, %r14, %p6;
	mov.s32 	%r16, 2139095040;
	mov.s32 	%r17, 0;
	selp.s32 	%r18, %r16, %r17, %p6;
	mov.f32 	%f12, 0f00000000;    	// 0
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_vsf_y];
	.loc	17	11230	0
	setp.lt.f32 	%p7, %f2, %f12;
	selp.s32 	%r19, %r15, %r18, %p7;
	mov.f32 	%f13, 0fbf800000;    	// -1
	setp.eq.f32 	%p8, %f1, %f13;
	selp.s32 	%r20, %r12, %r19, %p8;
	mov.b32 	%f5, %r20;
	bra.uni 	$Lt_40_19458;
$Lt_40_19714:
	.loc	17	11231	0
	mov.f32 	%f14, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p9, %f6, %f14;
	@!%p9 bra 	$Lt_40_20226;
	.loc	17	11232	0
	mov.s32 	%r21, 2139095040;
	mov.s32 	%r22, 0;
	mov.f32 	%f15, 0f00000000;    	// 0
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_vsf_y];
	.loc	17	11232	0
	setp.ge.f32 	%p10, %f2, %f15;
	selp.s32 	%r23, %r21, %r22, %p10;
	mov.f32 	%f16, 0f3f000000;    	// 0.5
	mul.f32 	%f17, %f2, %f16;
	cvt.rzi.f32.f32 	%f18, %f17;
	add.f32 	%f19, %f18, %f18;
	sub.f32 	%f20, %f2, %f19;
	abs.f32 	%f21, %f20;
	mov.f32 	%f22, 0f3f800000;    	// 1
	set.eq.u32.f32 	%r24, %f21, %f22;
	neg.s32 	%r25, %r24;
	mov.f32 	%f23, 0f00000000;    	// 0
	set.lt.u32.f32 	%r26, %f1, %f23;
	neg.s32 	%r27, %r26;
	and.b32 	%r28, %r25, %r27;
	mov.u32 	%r29, 0;
	setp.eq.s32 	%p11, %r28, %r29;
	@%p11 bra 	$Lt_40_20482;
	.loc	17	11234	0
	xor.b32 	%r23, %r23, -2147483648;
$Lt_40_20482:
	.loc	17	11235	0
	mov.b32 	%f5, %r23;
	bra.uni 	$Lt_40_19970;
$Lt_40_20226:
	mov.f32 	%f24, 0f00000000;    	// 0
	setp.eq.f32 	%p12, %f1, %f24;
	@!%p12 bra 	$Lt_40_21250;
	mov.f32 	%f25, 0f3f000000;    	// 0.5
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_vsf_y];
	.loc	17	11235	0
	mul.f32 	%f26, %f2, %f25;
	cvt.rzi.f32.f32 	%f27, %f26;
	add.f32 	%f28, %f27, %f27;
	sub.f32 	%f29, %f2, %f28;
	abs.f32 	%f30, %f29;
	mov.f32 	%f31, 0f3f800000;    	// 1
	setp.eq.f32 	%p13, %f30, %f31;
	@!%p13 bra 	$Lt_40_21762;
	.loc	17	11238	0
	add.f32 	%f32, %f1, %f1;
	mov.b32 	%r23, %f32;
	bra.uni 	$Lt_40_21506;
$Lt_40_21762:
	mov.s32 	%r23, 0;
$Lt_40_21506:
	.loc	17	11239	0
	or.b32 	%r30, %r23, 2139095040;
	mov.f32 	%f33, 0f00000000;    	// 0
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_vsf_y];
	.loc	17	11239	0
	setp.lt.f32 	%p14, %f2, %f33;
	selp.s32 	%r23, %r30, %r23, %p14;
	.loc	17	11240	0
	mov.b32 	%f5, %r23;
	bra.uni 	$Lt_40_20994;
$Lt_40_21250:
	.loc	17	11241	0
	mov.f32 	%f34, 0f00000000;    	// 0
	setp.lt.f32 	%p15, %f1, %f34;
	mov.pred 	%p16, %p15;
	mov.pred 	%p17, %p18;
	@!%p15 bra 	$Lt_40_24322;
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_vsf_y];
	.loc	17	11241	0
	cvt.rzi.f32.f32 	%f35, %f2;
	setp.neu.f32 	%p19, %f2, %f35;
	@!%p19 bra 	$L_40_17922;
	.loc	17	11242	0
	mov.f32 	%f5, 0f7fffffff;     	// nan
	bra.uni 	$L_40_17666;
$Lt_40_24322:
$L_40_17922:
	.loc	17	9078	0
	mov.b32 	%r31, %f6;
	and.b32 	%r32, %r31, 8388607;
	or.b32 	%r33, %r32, 1065353216;
	mov.b32 	%f36, %r33;
	mov.f32 	%f37, %f36;
	.loc	17	9079	0
	shr.u32 	%r34, %r31, 23;
	cvt.rn.f32.u32 	%f38, %r34;
	mov.f32 	%f39, 0fc2fe0000;    	// -127
	add.f32 	%f40, %f38, %f39;
	mov.f32 	%f41, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p20, %f36, %f41;
	@!%p20 bra 	$Lt_40_22018;
	.loc	17	9081	0
	mov.f32 	%f42, 0f3f000000;    	// 0.5
	mul.f32 	%f37, %f36, %f42;
	.loc	17	9082	0
	mov.f32 	%f43, 0f3f800000;    	// 1
	add.f32 	%f40, %f40, %f43;
$Lt_40_22018:
	.loc	17	8944	0
	mov.f32 	%f44, 0f3f800000;    	// 1
	add.f32 	%f45, %f37, %f44;
	mov.f32 	%f46, %f45;
	rcp.approx.ftz.f32 %f47,%f46;
	mov.f32 	%f48, %f47;
	.loc	17	8936	0
	mov.f32 	%f49, 0fbf800000;    	// -1
	add.f32 	%f50, %f37, %f49;
	add.f32 	%f51, %f50, %f50;
	mul.f32 	%f52, %f51, %f48;
	mul.f32 	%f53, %f52, %f52;
	mov.f32 	%f54, 0f3b18f0fe;    	// 0.0023337
	mov.f32 	%f55, %f54;
	mov.f32 	%f56, %f53;
	mov.f32 	%f57, 0f3c4caf63;    	// 0.012493
	mov.f32 	%f58, %f57;
	mad.f32 %f59, %f55, %f56, %f58;
	mov.f32 	%f60, %f59;
	mov.f32 	%f61, %f60;
	mov.f32 	%f62, %f53;
	mov.f32 	%f63, 0f3daaaabd;    	// 0.0833335
	mov.f32 	%f64, %f63;
	mad.f32 %f65, %f61, %f62, %f64;
	mov.f32 	%f66, %f65;
	.loc	17	9099	0
	mul.rn.f32 	%f67, %f66, %f53;
	mul.rn.f32 	%f68, %f67, %f52;
	.loc	17	8936	0
	mov.b32 	%r35, %f50;
	mov.b32 	%r36, %f52;
	and.b32 	%r37, %r35, -4096;
	mov.b32 	%f69, %r37;
	and.b32 	%r38, %r36, -4096;
	mov.b32 	%f70, %r38;
	neg.f32 	%f71, %f70;
	sub.f32 	%f72, %f50, %f70;
	mov.f32 	%f73, %f71;
	mov.f32 	%f74, %f69;
	add.f32 	%f75, %f72, %f72;
	mov.f32 	%f76, %f75;
	mad.f32 %f77, %f73, %f74, %f76;
	mov.f32 	%f78, %f77;
	mov.f32 	%f79, %f71;
	sub.f32 	%f80, %f50, %f69;
	mov.f32 	%f81, %f80;
	mov.f32 	%f82, %f78;
	mad.f32 %f83, %f79, %f81, %f82;
	mov.f32 	%f84, %f83;
	.loc	17	9122	0
	mul.rn.f32 	%f85, %f48, %f84;
	add.f32 	%f86, %f85, %f70;
	add.f32 	%f87, %f86, %f68;
	sub.f32 	%f88, %f70, %f86;
	sub.f32 	%f89, %f86, %f87;
	add.f32 	%f90, %f85, %f88;
	add.f32 	%f91, %f89, %f68;
	add.f32 	%f92, %f90, %f91;
	add.f32 	%f93, %f87, %f92;
	.loc	17	9123	0
	sub.f32 	%f94, %f87, %f93;
	add.f32 	%f95, %f92, %f94;
	.loc	17	9130	0
	mov.f32 	%f96, 0f3f317200;    	// 0.693146
	mul.rn.f32 	%f97, %f40, %f96;
	add.f32 	%f98, %f97, %f93;
	.loc	17	9131	0
	mov.f32 	%f99, 0f35bfbe8e;    	// 1.42861e-06
	mul.rn.f32 	%f100, %f40, %f99;
	sub.f32 	%f101, %f97, %f98;
	add.f32 	%f102, %f101, %f93;
	add.f32 	%f103, %f102, %f95;
	add.f32 	%f104, %f100, %f103;
	.loc	17	9132	0
	add.f32 	%f105, %f104, %f98;
	.loc	17	8936	0
	mov.f32 	%f106, 0f39000000;   	// 0.00012207
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_vsf_y];
	.loc	17	8936	0
	mul.f32 	%f107, %f2, %f106;
	mov.f32 	%f108, 0f77f684df;   	// 1e+34
	setp.gt.f32 	%p21, %f8, %f108;
	selp.f32 	%f109, %f107, %f2, %p21;
	neg.f32 	%f110, %f109;
	mov.f32 	%f111, %f110;
	mov.f32 	%f112, 0f45800800;   	// 4097
	mov.f32 	%f113, %f112;
	mov.f32 	%f114, %f109;
	mad.f32 %f115, %f111, %f113, %f114;
	mov.f32 	%f116, %f115;
	mov.f32 	%f117, %f109;
	mov.f32 	%f118, 0f45800800;   	// 4097
	mov.f32 	%f119, %f118;
	mov.f32 	%f120, %f116;
	mad.f32 %f121, %f117, %f119, %f120;
	mov.f32 	%f122, %f121;
	.loc	17	9150	0
	mov.f32 	%f123, %f122;
	.loc	17	8936	0
	neg.f32 	%f124, %f105;
	mov.f32 	%f125, %f124;
	mov.f32 	%f126, 0f45800800;   	// 4097
	mov.f32 	%f127, %f126;
	mov.f32 	%f128, %f105;
	mad.f32 %f129, %f125, %f127, %f128;
	mov.f32 	%f116, %f129;
	mov.f32 	%f130, %f105;
	mov.f32 	%f131, 0f45800800;   	// 4097
	mov.f32 	%f132, %f131;
	mov.f32 	%f133, %f116;
	mad.f32 %f134, %f130, %f132, %f133;
	mov.f32 	%f116, %f134;
	.loc	17	9151	0
	mov.f32 	%f135, %f116;
	.loc	17	9153	0
	sub.f32 	%f136, %f105, %f116;
	.loc	17	8936	0
	mul.rn.f32 	%f137, %f109, %f105;
	mov.f32 	%f138, %f123;
	mov.f32 	%f139, %f116;
	neg.f32 	%f140, %f137;
	mov.f32 	%f141, %f140;
	mad.f32 %f142, %f138, %f139, %f141;
	mov.f32 	%f116, %f142;
	mov.f32 	%f143, %f123;
	mov.f32 	%f144, %f136;
	mov.f32 	%f145, %f116;
	mad.f32 %f146, %f143, %f144, %f145;
	mov.f32 	%f116, %f146;
	sub.f32 	%f147, %f109, %f122;
	mov.f32 	%f148, %f135;
	mov.f32 	%f149, %f147;
	mov.f32 	%f150, %f116;
	mad.f32 %f151, %f148, %f149, %f150;
	mov.f32 	%f116, %f151;
	mov.f32 	%f152, %f147;
	mov.f32 	%f153, %f136;
	mov.f32 	%f154, %f116;
	mad.f32 %f155, %f152, %f153, %f154;
	mov.f32 	%f116, %f155;
	.loc	17	9159	0
	sub.f32 	%f156, %f98, %f105;
	mov.f32 	%f157, 0f00000000;   	// 0
	mul.rn.f32 	%f158, %f157, %f105;
	add.f32 	%f159, %f156, %f104;
	mul.rn.f32 	%f160, %f109, %f159;
	add.f32 	%f161, %f158, %f160;
	add.f32 	%f162, %f161, %f116;
	add.rn.f32 	%f163, %f137, %f162;
	sub.f32 	%f164, %f137, %f163;
	add.rn.f32 	%f165, %f164, %f162;
	.loc	17	11157	0
	mov.f32 	%f166, %f165;
	mov.f32 	%f167, %f163;
	mov.b32 	%r39, %f163;
	mov.u32 	%r40, 1118925336;
	setp.ne.s32 	%p22, %r39, %r40;
	@%p22 bra 	$Lt_40_22530;
	.loc	17	11161	0
	sub.s32 	%r41, %r39, 1;
	mov.b32 	%f167, %r41;
	.loc	17	11162	0
	mov.f32 	%f168, 0f37000000;   	// 7.62939e-06
	add.f32 	%f166, %f165, %f168;
$Lt_40_22530:
	.loc	17	8936	0
	mov.f32 	%f169, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f170, %f167, %f169;
	cvt.rzi.f32.f32 	%f171, %f170;
	mov.f32 	%f172, %f171;
	mov.f32 	%f173, 0fbf317200;   	// -0.693146
	mov.f32 	%f174, %f173;
	mov.f32 	%f175, %f167;
	mad.f32 %f176, %f172, %f174, %f175;
	mov.f32 	%f177, %f176;
	mov.f32 	%f178, %f171;
	mov.f32 	%f179, 0fb5bfbe8e;   	// -1.42861e-06
	mov.f32 	%f180, %f179;
	mov.f32 	%f181, %f177;
	mad.f32 %f182, %f178, %f180, %f181;
	mov.f32 	%f183, %f182;
	.loc	17	8965	0
	mov.f32 	%f184, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f185, %f183, %f184;
	mov.f32 	%f186, %f185;
	ex2.approx.ftz.f32 %f187,%f186;
	mov.f32 	%f188, %f187;
	.loc	17	11166	0
	mov.f32 	%f189, 0f42d20000;   	// 105
	setp.gt.f32 	%p23, %f167, %f189;
	mov.f32 	%f190, 0fc2d20000;   	// -105
	setp.lt.f32 	%p24, %f167, %f190;
	ex2.approx.f32 	%f191, %f171;
	mul.f32 	%f192, %f191, %f188;
	mov.f32 	%f193, 0f00000000;   	// 0
	selp.f32 	%f194, %f193, %f192, %p24;
	mov.f32 	%f195, 0f7f800000;   	// ((1.0F)/(0.0F))
	selp.f32 	%f196, %f195, %f194, %p23;
	mov.f32 	%f197, %f196;
	mov.f32 	%f198, 0f7f800000;   	// ((1.0F)/(0.0F))
	setp.neu.f32 	%p25, %f196, %f198;
	@!%p25 bra 	$Lt_40_23042;
	.loc	17	8936	0
	mov.f32 	%f199, %f197;
	mov.f32 	%f200, %f166;
	mov.f32 	%f201, %f197;
	mad.f32 %f202, %f199, %f200, %f201;
	mov.f32 	%f203, %f202;
	.loc	17	11172	0
	mov.f32 	%f197, %f203;
$Lt_40_23042:
	.loc	17	11244	0
	mov.f32 	%f5, %f197;
	mov.f32 	%f204, 0f3f000000;   	// 0.5
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_vsf_y];
	.loc	17	11244	0
	mul.f32 	%f205, %f2, %f204;
	cvt.rzi.f32.f32 	%f206, %f205;
	selp.s32 	%r42, 1, 0, %p16;
	add.f32 	%f207, %f206, %f206;
	sub.f32 	%f208, %f2, %f207;
	abs.f32 	%f209, %f208;
	mov.f32 	%f210, 0f3f800000;   	// 1
	set.eq.u32.f32 	%r43, %f209, %f210;
	neg.s32 	%r44, %r43;
	and.b32 	%r45, %r42, %r44;
	mov.u32 	%r46, 0;
	setp.eq.s32 	%p26, %r45, %r46;
	@%p26 bra 	$Lt_40_23554;
	.loc	17	11246	0
	mov.b32 	%r47, %f5;
	xor.b32 	%r48, %r47, -2147483648;
	mov.b32 	%f5, %r48;
$Lt_40_23554:
$L_40_17666:
$Lt_40_20994:
$Lt_40_19970:
$Lt_40_19458:
$Lt_40_11010:
$Lt_40_18946:
	.loc	15	149	0
	ld.param.u64 	%rd7, [__cudaparm_epow_vsf_result];
	ld.param.s32 	%r49, [__cudaparm_epow_vsf_lr];
	mul.lo.s32 	%r50, %r49, %r3;
	cvt.s64.s32 	%rd8, %r50;
	mul.wide.s32 	%rd9, %r50, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f5;
$Lt_40_18434:
	exit;
$LDWend_epow_vsf:
	} // epow_vsf

	.entry epow_msf (
		.param .s32 __cudaparm_epow_msf_rs,
		.param .s32 __cudaparm_epow_msf_cs,
		.param .u64 __cudaparm_epow_msf_A,
		.param .s32 __cudaparm_epow_msf_lda,
		.param .f32 __cudaparm_epow_msf_B,
		.param .u64 __cudaparm_epow_msf_C,
		.param .s32 __cudaparm_epow_msf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<65>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<212>;
	.reg .pred %p<28>;
$LDWbegin_epow_msf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_epow_msf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_epow_msf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_41_18690;
	ld.param.u64 	%rd1, [__cudaparm_epow_msf_A];
	ld.param.s32 	%r15, [__cudaparm_epow_msf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.f32 	%f2, [__cudaparm_epow_msf_B];
	mov.f32 	%f3, 0f3f800000;     	// 1
	set.eq.u32.f32 	%r18, %f1, %f3;
	neg.s32 	%r19, %r18;
	mov.f32 	%f4, 0f00000000;     	// 0
	set.eq.u32.f32 	%r20, %f2, %f4;
	neg.s32 	%r21, %r20;
	or.b32 	%r22, %r19, %r21;
	mov.u32 	%r23, 0;
	setp.eq.s32 	%p2, %r22, %r23;
	@%p2 bra 	$Lt_41_19458;
	mov.f32 	%f5, 0f3f800000;     	// 1
	bra.uni 	$Lt_41_19202;
$Lt_41_19458:
	.loc	17	11223	0
	abs.f32 	%f6, %f1;
	mov.f32 	%f7, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.le.f32 	%p3, %f6, %f7;
	@!%p3 bra 	$Lt_41_10242;
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_msf_B];
	.loc	17	11223	0
	abs.f32 	%f8, %f2;
	mov.f32 	%f9, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.le.f32 	%p4, %f8, %f9;
	@%p4 bra 	$Lt_41_10498;
$Lt_41_10242:
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_msf_B];
	.loc	17	11224	0
	add.f32 	%f5, %f1, %f2;
	.loc	17	11223	0
	bra.uni 	$Lt_41_11010;
$Lt_41_10498:
	.loc	17	11225	0
	mov.f32 	%f10, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p5, %f8, %f10;
	@!%p5 bra 	$Lt_41_19970;
	.loc	17	11230	0
	mov.f32 	%f11, 0f3f800000;    	// 1
	setp.gt.f32 	%p6, %f6, %f11;
	mov.s32 	%r24, 1065353216;
	mov.s32 	%r25, 0;
	mov.s32 	%r26, 2139095040;
	selp.s32 	%r27, %r25, %r26, %p6;
	mov.s32 	%r28, 2139095040;
	mov.s32 	%r29, 0;
	selp.s32 	%r30, %r28, %r29, %p6;
	mov.f32 	%f12, 0f00000000;    	// 0
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_msf_B];
	.loc	17	11230	0
	setp.lt.f32 	%p7, %f2, %f12;
	selp.s32 	%r31, %r27, %r30, %p7;
	mov.f32 	%f13, 0fbf800000;    	// -1
	setp.eq.f32 	%p8, %f1, %f13;
	selp.s32 	%r32, %r24, %r31, %p8;
	mov.b32 	%f5, %r32;
	bra.uni 	$Lt_41_19714;
$Lt_41_19970:
	.loc	17	11231	0
	mov.f32 	%f14, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p9, %f6, %f14;
	@!%p9 bra 	$Lt_41_20482;
	.loc	17	11232	0
	mov.s32 	%r33, 2139095040;
	mov.s32 	%r34, 0;
	mov.f32 	%f15, 0f00000000;    	// 0
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_msf_B];
	.loc	17	11232	0
	setp.ge.f32 	%p10, %f2, %f15;
	selp.s32 	%r35, %r33, %r34, %p10;
	mov.f32 	%f16, 0f3f000000;    	// 0.5
	mul.f32 	%f17, %f2, %f16;
	cvt.rzi.f32.f32 	%f18, %f17;
	add.f32 	%f19, %f18, %f18;
	sub.f32 	%f20, %f2, %f19;
	abs.f32 	%f21, %f20;
	mov.f32 	%f22, 0f3f800000;    	// 1
	set.eq.u32.f32 	%r36, %f21, %f22;
	neg.s32 	%r37, %r36;
	mov.f32 	%f23, 0f00000000;    	// 0
	set.lt.u32.f32 	%r38, %f1, %f23;
	neg.s32 	%r39, %r38;
	and.b32 	%r40, %r37, %r39;
	mov.u32 	%r41, 0;
	setp.eq.s32 	%p11, %r40, %r41;
	@%p11 bra 	$Lt_41_20738;
	.loc	17	11234	0
	xor.b32 	%r35, %r35, -2147483648;
$Lt_41_20738:
	.loc	17	11235	0
	mov.b32 	%f5, %r35;
	bra.uni 	$Lt_41_20226;
$Lt_41_20482:
	mov.f32 	%f24, 0f00000000;    	// 0
	setp.eq.f32 	%p12, %f1, %f24;
	@!%p12 bra 	$Lt_41_21506;
	mov.f32 	%f25, 0f3f000000;    	// 0.5
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_msf_B];
	.loc	17	11235	0
	mul.f32 	%f26, %f2, %f25;
	cvt.rzi.f32.f32 	%f27, %f26;
	add.f32 	%f28, %f27, %f27;
	sub.f32 	%f29, %f2, %f28;
	abs.f32 	%f30, %f29;
	mov.f32 	%f31, 0f3f800000;    	// 1
	setp.eq.f32 	%p13, %f30, %f31;
	@!%p13 bra 	$Lt_41_22018;
	.loc	17	11238	0
	add.f32 	%f32, %f1, %f1;
	mov.b32 	%r35, %f32;
	bra.uni 	$Lt_41_21762;
$Lt_41_22018:
	mov.s32 	%r35, 0;
$Lt_41_21762:
	.loc	17	11239	0
	or.b32 	%r42, %r35, 2139095040;
	mov.f32 	%f33, 0f00000000;    	// 0
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_msf_B];
	.loc	17	11239	0
	setp.lt.f32 	%p14, %f2, %f33;
	selp.s32 	%r35, %r42, %r35, %p14;
	.loc	17	11240	0
	mov.b32 	%f5, %r35;
	bra.uni 	$Lt_41_21250;
$Lt_41_21506:
	.loc	17	11241	0
	mov.f32 	%f34, 0f00000000;    	// 0
	setp.lt.f32 	%p15, %f1, %f34;
	mov.pred 	%p16, %p15;
	mov.pred 	%p17, %p18;
	@!%p15 bra 	$Lt_41_24578;
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_msf_B];
	.loc	17	11241	0
	cvt.rzi.f32.f32 	%f35, %f2;
	setp.neu.f32 	%p19, %f2, %f35;
	@!%p19 bra 	$L_41_18178;
	.loc	17	11242	0
	mov.f32 	%f5, 0f7fffffff;     	// nan
	bra.uni 	$L_41_17922;
$Lt_41_24578:
$L_41_18178:
	.loc	17	9078	0
	mov.b32 	%r43, %f6;
	and.b32 	%r44, %r43, 8388607;
	or.b32 	%r45, %r44, 1065353216;
	mov.b32 	%f36, %r45;
	mov.f32 	%f37, %f36;
	.loc	17	9079	0
	shr.u32 	%r46, %r43, 23;
	cvt.rn.f32.u32 	%f38, %r46;
	mov.f32 	%f39, 0fc2fe0000;    	// -127
	add.f32 	%f40, %f38, %f39;
	mov.f32 	%f41, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p20, %f36, %f41;
	@!%p20 bra 	$Lt_41_22274;
	.loc	17	9081	0
	mov.f32 	%f42, 0f3f000000;    	// 0.5
	mul.f32 	%f37, %f36, %f42;
	.loc	17	9082	0
	mov.f32 	%f43, 0f3f800000;    	// 1
	add.f32 	%f40, %f40, %f43;
$Lt_41_22274:
	.loc	17	8944	0
	mov.f32 	%f44, 0f3f800000;    	// 1
	add.f32 	%f45, %f37, %f44;
	mov.f32 	%f46, %f45;
	rcp.approx.ftz.f32 %f47,%f46;
	mov.f32 	%f48, %f47;
	.loc	17	8936	0
	mov.f32 	%f49, 0fbf800000;    	// -1
	add.f32 	%f50, %f37, %f49;
	add.f32 	%f51, %f50, %f50;
	mul.f32 	%f52, %f51, %f48;
	mul.f32 	%f53, %f52, %f52;
	mov.f32 	%f54, 0f3b18f0fe;    	// 0.0023337
	mov.f32 	%f55, %f54;
	mov.f32 	%f56, %f53;
	mov.f32 	%f57, 0f3c4caf63;    	// 0.012493
	mov.f32 	%f58, %f57;
	mad.f32 %f59, %f55, %f56, %f58;
	mov.f32 	%f60, %f59;
	mov.f32 	%f61, %f60;
	mov.f32 	%f62, %f53;
	mov.f32 	%f63, 0f3daaaabd;    	// 0.0833335
	mov.f32 	%f64, %f63;
	mad.f32 %f65, %f61, %f62, %f64;
	mov.f32 	%f66, %f65;
	.loc	17	9099	0
	mul.rn.f32 	%f67, %f66, %f53;
	mul.rn.f32 	%f68, %f67, %f52;
	.loc	17	8936	0
	mov.b32 	%r47, %f50;
	mov.b32 	%r48, %f52;
	and.b32 	%r49, %r47, -4096;
	mov.b32 	%f69, %r49;
	and.b32 	%r50, %r48, -4096;
	mov.b32 	%f70, %r50;
	neg.f32 	%f71, %f70;
	sub.f32 	%f72, %f50, %f70;
	mov.f32 	%f73, %f71;
	mov.f32 	%f74, %f69;
	add.f32 	%f75, %f72, %f72;
	mov.f32 	%f76, %f75;
	mad.f32 %f77, %f73, %f74, %f76;
	mov.f32 	%f78, %f77;
	mov.f32 	%f79, %f71;
	sub.f32 	%f80, %f50, %f69;
	mov.f32 	%f81, %f80;
	mov.f32 	%f82, %f78;
	mad.f32 %f83, %f79, %f81, %f82;
	mov.f32 	%f84, %f83;
	.loc	17	9122	0
	mul.rn.f32 	%f85, %f48, %f84;
	add.f32 	%f86, %f85, %f70;
	add.f32 	%f87, %f86, %f68;
	sub.f32 	%f88, %f70, %f86;
	sub.f32 	%f89, %f86, %f87;
	add.f32 	%f90, %f85, %f88;
	add.f32 	%f91, %f89, %f68;
	add.f32 	%f92, %f90, %f91;
	add.f32 	%f93, %f87, %f92;
	.loc	17	9123	0
	sub.f32 	%f94, %f87, %f93;
	add.f32 	%f95, %f92, %f94;
	.loc	17	9130	0
	mov.f32 	%f96, 0f3f317200;    	// 0.693146
	mul.rn.f32 	%f97, %f40, %f96;
	add.f32 	%f98, %f97, %f93;
	.loc	17	9131	0
	mov.f32 	%f99, 0f35bfbe8e;    	// 1.42861e-06
	mul.rn.f32 	%f100, %f40, %f99;
	sub.f32 	%f101, %f97, %f98;
	add.f32 	%f102, %f101, %f93;
	add.f32 	%f103, %f102, %f95;
	add.f32 	%f104, %f100, %f103;
	.loc	17	9132	0
	add.f32 	%f105, %f104, %f98;
	.loc	17	8936	0
	mov.f32 	%f106, 0f39000000;   	// 0.00012207
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_msf_B];
	.loc	17	8936	0
	mul.f32 	%f107, %f2, %f106;
	mov.f32 	%f108, 0f77f684df;   	// 1e+34
	setp.gt.f32 	%p21, %f8, %f108;
	selp.f32 	%f109, %f107, %f2, %p21;
	neg.f32 	%f110, %f109;
	mov.f32 	%f111, %f110;
	mov.f32 	%f112, 0f45800800;   	// 4097
	mov.f32 	%f113, %f112;
	mov.f32 	%f114, %f109;
	mad.f32 %f115, %f111, %f113, %f114;
	mov.f32 	%f116, %f115;
	mov.f32 	%f117, %f109;
	mov.f32 	%f118, 0f45800800;   	// 4097
	mov.f32 	%f119, %f118;
	mov.f32 	%f120, %f116;
	mad.f32 %f121, %f117, %f119, %f120;
	mov.f32 	%f122, %f121;
	.loc	17	9150	0
	mov.f32 	%f123, %f122;
	.loc	17	8936	0
	neg.f32 	%f124, %f105;
	mov.f32 	%f125, %f124;
	mov.f32 	%f126, 0f45800800;   	// 4097
	mov.f32 	%f127, %f126;
	mov.f32 	%f128, %f105;
	mad.f32 %f129, %f125, %f127, %f128;
	mov.f32 	%f116, %f129;
	mov.f32 	%f130, %f105;
	mov.f32 	%f131, 0f45800800;   	// 4097
	mov.f32 	%f132, %f131;
	mov.f32 	%f133, %f116;
	mad.f32 %f134, %f130, %f132, %f133;
	mov.f32 	%f116, %f134;
	.loc	17	9151	0
	mov.f32 	%f135, %f116;
	.loc	17	9153	0
	sub.f32 	%f136, %f105, %f116;
	.loc	17	8936	0
	mul.rn.f32 	%f137, %f109, %f105;
	mov.f32 	%f138, %f123;
	mov.f32 	%f139, %f116;
	neg.f32 	%f140, %f137;
	mov.f32 	%f141, %f140;
	mad.f32 %f142, %f138, %f139, %f141;
	mov.f32 	%f116, %f142;
	mov.f32 	%f143, %f123;
	mov.f32 	%f144, %f136;
	mov.f32 	%f145, %f116;
	mad.f32 %f146, %f143, %f144, %f145;
	mov.f32 	%f116, %f146;
	sub.f32 	%f147, %f109, %f122;
	mov.f32 	%f148, %f135;
	mov.f32 	%f149, %f147;
	mov.f32 	%f150, %f116;
	mad.f32 %f151, %f148, %f149, %f150;
	mov.f32 	%f116, %f151;
	mov.f32 	%f152, %f147;
	mov.f32 	%f153, %f136;
	mov.f32 	%f154, %f116;
	mad.f32 %f155, %f152, %f153, %f154;
	mov.f32 	%f116, %f155;
	.loc	17	9159	0
	sub.f32 	%f156, %f98, %f105;
	mov.f32 	%f157, 0f00000000;   	// 0
	mul.rn.f32 	%f158, %f157, %f105;
	add.f32 	%f159, %f156, %f104;
	mul.rn.f32 	%f160, %f109, %f159;
	add.f32 	%f161, %f158, %f160;
	add.f32 	%f162, %f161, %f116;
	add.rn.f32 	%f163, %f137, %f162;
	sub.f32 	%f164, %f137, %f163;
	add.rn.f32 	%f165, %f164, %f162;
	.loc	17	11157	0
	mov.f32 	%f166, %f165;
	mov.f32 	%f167, %f163;
	mov.b32 	%r51, %f163;
	mov.u32 	%r52, 1118925336;
	setp.ne.s32 	%p22, %r51, %r52;
	@%p22 bra 	$Lt_41_22786;
	.loc	17	11161	0
	sub.s32 	%r53, %r51, 1;
	mov.b32 	%f167, %r53;
	.loc	17	11162	0
	mov.f32 	%f168, 0f37000000;   	// 7.62939e-06
	add.f32 	%f166, %f165, %f168;
$Lt_41_22786:
	.loc	17	8936	0
	mov.f32 	%f169, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f170, %f167, %f169;
	cvt.rzi.f32.f32 	%f171, %f170;
	mov.f32 	%f172, %f171;
	mov.f32 	%f173, 0fbf317200;   	// -0.693146
	mov.f32 	%f174, %f173;
	mov.f32 	%f175, %f167;
	mad.f32 %f176, %f172, %f174, %f175;
	mov.f32 	%f177, %f176;
	mov.f32 	%f178, %f171;
	mov.f32 	%f179, 0fb5bfbe8e;   	// -1.42861e-06
	mov.f32 	%f180, %f179;
	mov.f32 	%f181, %f177;
	mad.f32 %f182, %f178, %f180, %f181;
	mov.f32 	%f183, %f182;
	.loc	17	8965	0
	mov.f32 	%f184, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f185, %f183, %f184;
	mov.f32 	%f186, %f185;
	ex2.approx.ftz.f32 %f187,%f186;
	mov.f32 	%f188, %f187;
	.loc	17	11166	0
	mov.f32 	%f189, 0f42d20000;   	// 105
	setp.gt.f32 	%p23, %f167, %f189;
	mov.f32 	%f190, 0fc2d20000;   	// -105
	setp.lt.f32 	%p24, %f167, %f190;
	ex2.approx.f32 	%f191, %f171;
	mul.f32 	%f192, %f191, %f188;
	mov.f32 	%f193, 0f00000000;   	// 0
	selp.f32 	%f194, %f193, %f192, %p24;
	mov.f32 	%f195, 0f7f800000;   	// ((1.0F)/(0.0F))
	selp.f32 	%f196, %f195, %f194, %p23;
	mov.f32 	%f197, %f196;
	mov.f32 	%f198, 0f7f800000;   	// ((1.0F)/(0.0F))
	setp.neu.f32 	%p25, %f196, %f198;
	@!%p25 bra 	$Lt_41_23298;
	.loc	17	8936	0
	mov.f32 	%f199, %f197;
	mov.f32 	%f200, %f166;
	mov.f32 	%f201, %f197;
	mad.f32 %f202, %f199, %f200, %f201;
	mov.f32 	%f203, %f202;
	.loc	17	11172	0
	mov.f32 	%f197, %f203;
$Lt_41_23298:
	.loc	17	11244	0
	mov.f32 	%f5, %f197;
	mov.f32 	%f204, 0f3f000000;   	// 0.5
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_msf_B];
	.loc	17	11244	0
	mul.f32 	%f205, %f2, %f204;
	cvt.rzi.f32.f32 	%f206, %f205;
	selp.s32 	%r54, 1, 0, %p16;
	add.f32 	%f207, %f206, %f206;
	sub.f32 	%f208, %f2, %f207;
	abs.f32 	%f209, %f208;
	mov.f32 	%f210, 0f3f800000;   	// 1
	set.eq.u32.f32 	%r55, %f209, %f210;
	neg.s32 	%r56, %r55;
	and.b32 	%r57, %r54, %r56;
	mov.u32 	%r58, 0;
	setp.eq.s32 	%p26, %r57, %r58;
	@%p26 bra 	$Lt_41_23810;
	.loc	17	11246	0
	mov.b32 	%r59, %f5;
	xor.b32 	%r60, %r59, -2147483648;
	mov.b32 	%f5, %r60;
$Lt_41_23810:
$L_41_17922:
$Lt_41_21250:
$Lt_41_20226:
$Lt_41_19714:
$Lt_41_11010:
$Lt_41_19202:
	.loc	15	149	0
	ld.param.u64 	%rd5, [__cudaparm_epow_msf_C];
	ld.param.s32 	%r61, [__cudaparm_epow_msf_ldc];
	mul.lo.s32 	%r62, %r61, %r4;
	add.s32 	%r63, %r6, %r62;
	cvt.s64.s32 	%rd6, %r63;
	mul.wide.s32 	%rd7, %r63, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f5;
$Lt_41_18690:
	exit;
$LDWend_epow_msf:
	} // epow_msf

	.entry epow_svf (
		.param .u64 __cudaparm_epow_svf_n,
		.param .f32 __cudaparm_epow_svf_x,
		.param .u64 __cudaparm_epow_svf_y,
		.param .s32 __cudaparm_epow_svf_ly,
		.param .u64 __cudaparm_epow_svf_result,
		.param .s32 __cudaparm_epow_svf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<52>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<212>;
	.reg .pred %p<28>;
$LDWbegin_epow_svf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_epow_svf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_42_18434;
	ld.param.u64 	%rd3, [__cudaparm_epow_svf_y];
	ld.param.s32 	%r4, [__cudaparm_epow_svf_ly];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.f32 	%f2, [__cudaparm_epow_svf_x];
	mov.f32 	%f3, 0f00000000;     	// 0
	set.eq.u32.f32 	%r6, %f1, %f3;
	neg.s32 	%r7, %r6;
	mov.f32 	%f4, 0f3f800000;     	// 1
	set.eq.u32.f32 	%r8, %f2, %f4;
	neg.s32 	%r9, %r8;
	or.b32 	%r10, %r7, %r9;
	mov.u32 	%r11, 0;
	setp.eq.s32 	%p2, %r10, %r11;
	@%p2 bra 	$Lt_42_19202;
	mov.f32 	%f5, 0f3f800000;     	// 1
	bra.uni 	$Lt_42_18946;
$Lt_42_19202:
	ld.param.f32 	%f2, [__cudaparm_epow_svf_x];
	.loc	17	11223	0
	abs.f32 	%f6, %f2;
	mov.f32 	%f7, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.le.f32 	%p3, %f6, %f7;
	@!%p3 bra 	$Lt_42_10242;
	abs.f32 	%f8, %f1;
	mov.f32 	%f9, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.le.f32 	%p4, %f8, %f9;
	@%p4 bra 	$Lt_42_10498;
$Lt_42_10242:
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_svf_x];
	.loc	17	11224	0
	add.f32 	%f5, %f1, %f2;
	.loc	17	11223	0
	bra.uni 	$Lt_42_11010;
$Lt_42_10498:
	.loc	17	11225	0
	mov.f32 	%f10, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p5, %f8, %f10;
	@!%p5 bra 	$Lt_42_19714;
	.loc	17	11230	0
	mov.f32 	%f11, 0f3f800000;    	// 1
	setp.gt.f32 	%p6, %f6, %f11;
	mov.s32 	%r12, 1065353216;
	mov.s32 	%r13, 0;
	mov.s32 	%r14, 2139095040;
	selp.s32 	%r15, %r13, %r14, %p6;
	mov.s32 	%r16, 2139095040;
	mov.s32 	%r17, 0;
	selp.s32 	%r18, %r16, %r17, %p6;
	mov.f32 	%f12, 0f00000000;    	// 0
	setp.lt.f32 	%p7, %f1, %f12;
	selp.s32 	%r19, %r15, %r18, %p7;
	mov.f32 	%f13, 0fbf800000;    	// -1
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_svf_x];
	.loc	17	11230	0
	setp.eq.f32 	%p8, %f2, %f13;
	selp.s32 	%r20, %r12, %r19, %p8;
	mov.b32 	%f5, %r20;
	bra.uni 	$Lt_42_19458;
$Lt_42_19714:
	.loc	17	11231	0
	mov.f32 	%f14, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p9, %f6, %f14;
	@!%p9 bra 	$Lt_42_20226;
	.loc	17	11232	0
	mov.s32 	%r21, 2139095040;
	mov.s32 	%r22, 0;
	mov.f32 	%f15, 0f00000000;    	// 0
	setp.ge.f32 	%p10, %f1, %f15;
	selp.s32 	%r23, %r21, %r22, %p10;
	mov.f32 	%f16, 0f3f000000;    	// 0.5
	mul.f32 	%f17, %f1, %f16;
	cvt.rzi.f32.f32 	%f18, %f17;
	add.f32 	%f19, %f18, %f18;
	sub.f32 	%f20, %f1, %f19;
	abs.f32 	%f21, %f20;
	mov.f32 	%f22, 0f3f800000;    	// 1
	set.eq.u32.f32 	%r24, %f21, %f22;
	neg.s32 	%r25, %r24;
	mov.f32 	%f23, 0f00000000;    	// 0
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_svf_x];
	.loc	17	11232	0
	set.lt.u32.f32 	%r26, %f2, %f23;
	neg.s32 	%r27, %r26;
	and.b32 	%r28, %r25, %r27;
	mov.u32 	%r29, 0;
	setp.eq.s32 	%p11, %r28, %r29;
	@%p11 bra 	$Lt_42_20482;
	.loc	17	11234	0
	xor.b32 	%r23, %r23, -2147483648;
$Lt_42_20482:
	.loc	17	11235	0
	mov.b32 	%f5, %r23;
	bra.uni 	$Lt_42_19970;
$Lt_42_20226:
	mov.f32 	%f24, 0f00000000;    	// 0
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_svf_x];
	.loc	17	11235	0
	setp.eq.f32 	%p12, %f2, %f24;
	@!%p12 bra 	$Lt_42_21250;
	mov.f32 	%f25, 0f3f000000;    	// 0.5
	mul.f32 	%f26, %f1, %f25;
	cvt.rzi.f32.f32 	%f27, %f26;
	add.f32 	%f28, %f27, %f27;
	sub.f32 	%f29, %f1, %f28;
	abs.f32 	%f30, %f29;
	mov.f32 	%f31, 0f3f800000;    	// 1
	setp.eq.f32 	%p13, %f30, %f31;
	@!%p13 bra 	$Lt_42_21762;
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_svf_x];
	.loc	17	11238	0
	add.f32 	%f32, %f2, %f2;
	mov.b32 	%r23, %f32;
	bra.uni 	$Lt_42_21506;
$Lt_42_21762:
	mov.s32 	%r23, 0;
$Lt_42_21506:
	.loc	17	11239	0
	or.b32 	%r30, %r23, 2139095040;
	mov.f32 	%f33, 0f00000000;    	// 0
	setp.lt.f32 	%p14, %f1, %f33;
	selp.s32 	%r23, %r30, %r23, %p14;
	.loc	17	11240	0
	mov.b32 	%f5, %r23;
	bra.uni 	$Lt_42_20994;
$Lt_42_21250:
	.loc	17	11241	0
	mov.f32 	%f34, 0f00000000;    	// 0
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_svf_x];
	.loc	17	11241	0
	setp.lt.f32 	%p15, %f2, %f34;
	mov.pred 	%p16, %p15;
	mov.pred 	%p17, %p18;
	@!%p15 bra 	$Lt_42_24322;
	cvt.rzi.f32.f32 	%f35, %f1;
	setp.neu.f32 	%p19, %f1, %f35;
	@!%p19 bra 	$L_42_17922;
	.loc	17	11242	0
	mov.f32 	%f5, 0f7fffffff;     	// nan
	bra.uni 	$L_42_17666;
$Lt_42_24322:
$L_42_17922:
	.loc	17	9078	0
	mov.b32 	%r31, %f6;
	and.b32 	%r32, %r31, 8388607;
	or.b32 	%r33, %r32, 1065353216;
	mov.b32 	%f36, %r33;
	mov.f32 	%f37, %f36;
	.loc	17	9079	0
	shr.u32 	%r34, %r31, 23;
	cvt.rn.f32.u32 	%f38, %r34;
	mov.f32 	%f39, 0fc2fe0000;    	// -127
	add.f32 	%f40, %f38, %f39;
	mov.f32 	%f41, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p20, %f36, %f41;
	@!%p20 bra 	$Lt_42_22018;
	.loc	17	9081	0
	mov.f32 	%f42, 0f3f000000;    	// 0.5
	mul.f32 	%f37, %f36, %f42;
	.loc	17	9082	0
	mov.f32 	%f43, 0f3f800000;    	// 1
	add.f32 	%f40, %f40, %f43;
$Lt_42_22018:
	.loc	17	8944	0
	mov.f32 	%f44, 0f3f800000;    	// 1
	add.f32 	%f45, %f37, %f44;
	mov.f32 	%f46, %f45;
	rcp.approx.ftz.f32 %f47,%f46;
	mov.f32 	%f48, %f47;
	.loc	17	8936	0
	mov.f32 	%f49, 0fbf800000;    	// -1
	add.f32 	%f50, %f37, %f49;
	add.f32 	%f51, %f50, %f50;
	mul.f32 	%f52, %f51, %f48;
	mul.f32 	%f53, %f52, %f52;
	mov.f32 	%f54, 0f3b18f0fe;    	// 0.0023337
	mov.f32 	%f55, %f54;
	mov.f32 	%f56, %f53;
	mov.f32 	%f57, 0f3c4caf63;    	// 0.012493
	mov.f32 	%f58, %f57;
	mad.f32 %f59, %f55, %f56, %f58;
	mov.f32 	%f60, %f59;
	mov.f32 	%f61, %f60;
	mov.f32 	%f62, %f53;
	mov.f32 	%f63, 0f3daaaabd;    	// 0.0833335
	mov.f32 	%f64, %f63;
	mad.f32 %f65, %f61, %f62, %f64;
	mov.f32 	%f66, %f65;
	.loc	17	9099	0
	mul.rn.f32 	%f67, %f66, %f53;
	mul.rn.f32 	%f68, %f67, %f52;
	.loc	17	8936	0
	mov.b32 	%r35, %f50;
	mov.b32 	%r36, %f52;
	and.b32 	%r37, %r35, -4096;
	mov.b32 	%f69, %r37;
	and.b32 	%r38, %r36, -4096;
	mov.b32 	%f70, %r38;
	neg.f32 	%f71, %f70;
	sub.f32 	%f72, %f50, %f70;
	mov.f32 	%f73, %f71;
	mov.f32 	%f74, %f69;
	add.f32 	%f75, %f72, %f72;
	mov.f32 	%f76, %f75;
	mad.f32 %f77, %f73, %f74, %f76;
	mov.f32 	%f78, %f77;
	mov.f32 	%f79, %f71;
	sub.f32 	%f80, %f50, %f69;
	mov.f32 	%f81, %f80;
	mov.f32 	%f82, %f78;
	mad.f32 %f83, %f79, %f81, %f82;
	mov.f32 	%f84, %f83;
	.loc	17	9122	0
	mul.rn.f32 	%f85, %f48, %f84;
	add.f32 	%f86, %f85, %f70;
	add.f32 	%f87, %f86, %f68;
	sub.f32 	%f88, %f70, %f86;
	sub.f32 	%f89, %f86, %f87;
	add.f32 	%f90, %f85, %f88;
	add.f32 	%f91, %f89, %f68;
	add.f32 	%f92, %f90, %f91;
	add.f32 	%f93, %f87, %f92;
	.loc	17	9123	0
	sub.f32 	%f94, %f87, %f93;
	add.f32 	%f95, %f92, %f94;
	.loc	17	9130	0
	mov.f32 	%f96, 0f3f317200;    	// 0.693146
	mul.rn.f32 	%f97, %f40, %f96;
	add.f32 	%f98, %f97, %f93;
	.loc	17	9131	0
	mov.f32 	%f99, 0f35bfbe8e;    	// 1.42861e-06
	mul.rn.f32 	%f100, %f40, %f99;
	sub.f32 	%f101, %f97, %f98;
	add.f32 	%f102, %f101, %f93;
	add.f32 	%f103, %f102, %f95;
	add.f32 	%f104, %f100, %f103;
	.loc	17	9132	0
	add.f32 	%f105, %f104, %f98;
	.loc	17	8936	0
	mov.f32 	%f106, 0f39000000;   	// 0.00012207
	mul.f32 	%f107, %f1, %f106;
	mov.f32 	%f108, 0f77f684df;   	// 1e+34
	setp.gt.f32 	%p21, %f8, %f108;
	selp.f32 	%f109, %f107, %f1, %p21;
	neg.f32 	%f110, %f109;
	mov.f32 	%f111, %f110;
	mov.f32 	%f112, 0f45800800;   	// 4097
	mov.f32 	%f113, %f112;
	mov.f32 	%f114, %f109;
	mad.f32 %f115, %f111, %f113, %f114;
	mov.f32 	%f116, %f115;
	mov.f32 	%f117, %f109;
	mov.f32 	%f118, 0f45800800;   	// 4097
	mov.f32 	%f119, %f118;
	mov.f32 	%f120, %f116;
	mad.f32 %f121, %f117, %f119, %f120;
	mov.f32 	%f122, %f121;
	.loc	17	9150	0
	mov.f32 	%f123, %f122;
	.loc	17	8936	0
	neg.f32 	%f124, %f105;
	mov.f32 	%f125, %f124;
	mov.f32 	%f126, 0f45800800;   	// 4097
	mov.f32 	%f127, %f126;
	mov.f32 	%f128, %f105;
	mad.f32 %f129, %f125, %f127, %f128;
	mov.f32 	%f116, %f129;
	mov.f32 	%f130, %f105;
	mov.f32 	%f131, 0f45800800;   	// 4097
	mov.f32 	%f132, %f131;
	mov.f32 	%f133, %f116;
	mad.f32 %f134, %f130, %f132, %f133;
	mov.f32 	%f116, %f134;
	.loc	17	9151	0
	mov.f32 	%f135, %f116;
	.loc	17	9153	0
	sub.f32 	%f136, %f105, %f116;
	.loc	17	8936	0
	mul.rn.f32 	%f137, %f109, %f105;
	mov.f32 	%f138, %f123;
	mov.f32 	%f139, %f116;
	neg.f32 	%f140, %f137;
	mov.f32 	%f141, %f140;
	mad.f32 %f142, %f138, %f139, %f141;
	mov.f32 	%f116, %f142;
	mov.f32 	%f143, %f123;
	mov.f32 	%f144, %f136;
	mov.f32 	%f145, %f116;
	mad.f32 %f146, %f143, %f144, %f145;
	mov.f32 	%f116, %f146;
	sub.f32 	%f147, %f109, %f122;
	mov.f32 	%f148, %f135;
	mov.f32 	%f149, %f147;
	mov.f32 	%f150, %f116;
	mad.f32 %f151, %f148, %f149, %f150;
	mov.f32 	%f116, %f151;
	mov.f32 	%f152, %f147;
	mov.f32 	%f153, %f136;
	mov.f32 	%f154, %f116;
	mad.f32 %f155, %f152, %f153, %f154;
	mov.f32 	%f116, %f155;
	.loc	17	9159	0
	sub.f32 	%f156, %f98, %f105;
	mov.f32 	%f157, 0f00000000;   	// 0
	mul.rn.f32 	%f158, %f157, %f105;
	add.f32 	%f159, %f156, %f104;
	mul.rn.f32 	%f160, %f109, %f159;
	add.f32 	%f161, %f158, %f160;
	add.f32 	%f162, %f161, %f116;
	add.rn.f32 	%f163, %f137, %f162;
	sub.f32 	%f164, %f137, %f163;
	add.rn.f32 	%f165, %f164, %f162;
	.loc	17	11157	0
	mov.f32 	%f166, %f165;
	mov.f32 	%f167, %f163;
	mov.b32 	%r39, %f163;
	mov.u32 	%r40, 1118925336;
	setp.ne.s32 	%p22, %r39, %r40;
	@%p22 bra 	$Lt_42_22530;
	.loc	17	11161	0
	sub.s32 	%r41, %r39, 1;
	mov.b32 	%f167, %r41;
	.loc	17	11162	0
	mov.f32 	%f168, 0f37000000;   	// 7.62939e-06
	add.f32 	%f166, %f165, %f168;
$Lt_42_22530:
	.loc	17	8936	0
	mov.f32 	%f169, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f170, %f167, %f169;
	cvt.rzi.f32.f32 	%f171, %f170;
	mov.f32 	%f172, %f171;
	mov.f32 	%f173, 0fbf317200;   	// -0.693146
	mov.f32 	%f174, %f173;
	mov.f32 	%f175, %f167;
	mad.f32 %f176, %f172, %f174, %f175;
	mov.f32 	%f177, %f176;
	mov.f32 	%f178, %f171;
	mov.f32 	%f179, 0fb5bfbe8e;   	// -1.42861e-06
	mov.f32 	%f180, %f179;
	mov.f32 	%f181, %f177;
	mad.f32 %f182, %f178, %f180, %f181;
	mov.f32 	%f183, %f182;
	.loc	17	8965	0
	mov.f32 	%f184, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f185, %f183, %f184;
	mov.f32 	%f186, %f185;
	ex2.approx.ftz.f32 %f187,%f186;
	mov.f32 	%f188, %f187;
	.loc	17	11166	0
	mov.f32 	%f189, 0f42d20000;   	// 105
	setp.gt.f32 	%p23, %f167, %f189;
	mov.f32 	%f190, 0fc2d20000;   	// -105
	setp.lt.f32 	%p24, %f167, %f190;
	ex2.approx.f32 	%f191, %f171;
	mul.f32 	%f192, %f191, %f188;
	mov.f32 	%f193, 0f00000000;   	// 0
	selp.f32 	%f194, %f193, %f192, %p24;
	mov.f32 	%f195, 0f7f800000;   	// ((1.0F)/(0.0F))
	selp.f32 	%f196, %f195, %f194, %p23;
	mov.f32 	%f197, %f196;
	mov.f32 	%f198, 0f7f800000;   	// ((1.0F)/(0.0F))
	setp.neu.f32 	%p25, %f196, %f198;
	@!%p25 bra 	$Lt_42_23042;
	.loc	17	8936	0
	mov.f32 	%f199, %f197;
	mov.f32 	%f200, %f166;
	mov.f32 	%f201, %f197;
	mad.f32 %f202, %f199, %f200, %f201;
	mov.f32 	%f203, %f202;
	.loc	17	11172	0
	mov.f32 	%f197, %f203;
$Lt_42_23042:
	.loc	17	11244	0
	mov.f32 	%f5, %f197;
	mov.f32 	%f204, 0f3f000000;   	// 0.5
	mul.f32 	%f205, %f1, %f204;
	cvt.rzi.f32.f32 	%f206, %f205;
	selp.s32 	%r42, 1, 0, %p16;
	add.f32 	%f207, %f206, %f206;
	sub.f32 	%f208, %f1, %f207;
	abs.f32 	%f209, %f208;
	mov.f32 	%f210, 0f3f800000;   	// 1
	set.eq.u32.f32 	%r43, %f209, %f210;
	neg.s32 	%r44, %r43;
	and.b32 	%r45, %r42, %r44;
	mov.u32 	%r46, 0;
	setp.eq.s32 	%p26, %r45, %r46;
	@%p26 bra 	$Lt_42_23554;
	.loc	17	11246	0
	mov.b32 	%r47, %f5;
	xor.b32 	%r48, %r47, -2147483648;
	mov.b32 	%f5, %r48;
$Lt_42_23554:
$L_42_17666:
$Lt_42_20994:
$Lt_42_19970:
$Lt_42_19458:
$Lt_42_11010:
$Lt_42_18946:
	.loc	15	149	0
	ld.param.u64 	%rd7, [__cudaparm_epow_svf_result];
	ld.param.s32 	%r49, [__cudaparm_epow_svf_lr];
	mul.lo.s32 	%r50, %r49, %r3;
	cvt.s64.s32 	%rd8, %r50;
	mul.wide.s32 	%rd9, %r50, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f5;
$Lt_42_18434:
	exit;
$LDWend_epow_svf:
	} // epow_svf

	.entry epow_smf (
		.param .s32 __cudaparm_epow_smf_rs,
		.param .s32 __cudaparm_epow_smf_cs,
		.param .f32 __cudaparm_epow_smf_A,
		.param .u64 __cudaparm_epow_smf_B,
		.param .s32 __cudaparm_epow_smf_ldb,
		.param .u64 __cudaparm_epow_smf_C,
		.param .s32 __cudaparm_epow_smf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<65>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<212>;
	.reg .pred %p<28>;
$LDWbegin_epow_smf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_epow_smf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_epow_smf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_43_18690;
	ld.param.u64 	%rd1, [__cudaparm_epow_smf_B];
	ld.param.s32 	%r15, [__cudaparm_epow_smf_ldb];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.f32 	%f2, [__cudaparm_epow_smf_A];
	mov.f32 	%f3, 0f00000000;     	// 0
	set.eq.u32.f32 	%r18, %f1, %f3;
	neg.s32 	%r19, %r18;
	mov.f32 	%f4, 0f3f800000;     	// 1
	set.eq.u32.f32 	%r20, %f2, %f4;
	neg.s32 	%r21, %r20;
	or.b32 	%r22, %r19, %r21;
	mov.u32 	%r23, 0;
	setp.eq.s32 	%p2, %r22, %r23;
	@%p2 bra 	$Lt_43_19458;
	mov.f32 	%f5, 0f3f800000;     	// 1
	bra.uni 	$Lt_43_19202;
$Lt_43_19458:
	ld.param.f32 	%f2, [__cudaparm_epow_smf_A];
	.loc	17	11223	0
	abs.f32 	%f6, %f2;
	mov.f32 	%f7, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.le.f32 	%p3, %f6, %f7;
	@!%p3 bra 	$Lt_43_10242;
	abs.f32 	%f8, %f1;
	mov.f32 	%f9, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.le.f32 	%p4, %f8, %f9;
	@%p4 bra 	$Lt_43_10498;
$Lt_43_10242:
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_smf_A];
	.loc	17	11224	0
	add.f32 	%f5, %f1, %f2;
	.loc	17	11223	0
	bra.uni 	$Lt_43_11010;
$Lt_43_10498:
	.loc	17	11225	0
	mov.f32 	%f10, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p5, %f8, %f10;
	@!%p5 bra 	$Lt_43_19970;
	.loc	17	11230	0
	mov.f32 	%f11, 0f3f800000;    	// 1
	setp.gt.f32 	%p6, %f6, %f11;
	mov.s32 	%r24, 1065353216;
	mov.s32 	%r25, 0;
	mov.s32 	%r26, 2139095040;
	selp.s32 	%r27, %r25, %r26, %p6;
	mov.s32 	%r28, 2139095040;
	mov.s32 	%r29, 0;
	selp.s32 	%r30, %r28, %r29, %p6;
	mov.f32 	%f12, 0f00000000;    	// 0
	setp.lt.f32 	%p7, %f1, %f12;
	selp.s32 	%r31, %r27, %r30, %p7;
	mov.f32 	%f13, 0fbf800000;    	// -1
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_smf_A];
	.loc	17	11230	0
	setp.eq.f32 	%p8, %f2, %f13;
	selp.s32 	%r32, %r24, %r31, %p8;
	mov.b32 	%f5, %r32;
	bra.uni 	$Lt_43_19714;
$Lt_43_19970:
	.loc	17	11231	0
	mov.f32 	%f14, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p9, %f6, %f14;
	@!%p9 bra 	$Lt_43_20482;
	.loc	17	11232	0
	mov.s32 	%r33, 2139095040;
	mov.s32 	%r34, 0;
	mov.f32 	%f15, 0f00000000;    	// 0
	setp.ge.f32 	%p10, %f1, %f15;
	selp.s32 	%r35, %r33, %r34, %p10;
	mov.f32 	%f16, 0f3f000000;    	// 0.5
	mul.f32 	%f17, %f1, %f16;
	cvt.rzi.f32.f32 	%f18, %f17;
	add.f32 	%f19, %f18, %f18;
	sub.f32 	%f20, %f1, %f19;
	abs.f32 	%f21, %f20;
	mov.f32 	%f22, 0f3f800000;    	// 1
	set.eq.u32.f32 	%r36, %f21, %f22;
	neg.s32 	%r37, %r36;
	mov.f32 	%f23, 0f00000000;    	// 0
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_smf_A];
	.loc	17	11232	0
	set.lt.u32.f32 	%r38, %f2, %f23;
	neg.s32 	%r39, %r38;
	and.b32 	%r40, %r37, %r39;
	mov.u32 	%r41, 0;
	setp.eq.s32 	%p11, %r40, %r41;
	@%p11 bra 	$Lt_43_20738;
	.loc	17	11234	0
	xor.b32 	%r35, %r35, -2147483648;
$Lt_43_20738:
	.loc	17	11235	0
	mov.b32 	%f5, %r35;
	bra.uni 	$Lt_43_20226;
$Lt_43_20482:
	mov.f32 	%f24, 0f00000000;    	// 0
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_smf_A];
	.loc	17	11235	0
	setp.eq.f32 	%p12, %f2, %f24;
	@!%p12 bra 	$Lt_43_21506;
	mov.f32 	%f25, 0f3f000000;    	// 0.5
	mul.f32 	%f26, %f1, %f25;
	cvt.rzi.f32.f32 	%f27, %f26;
	add.f32 	%f28, %f27, %f27;
	sub.f32 	%f29, %f1, %f28;
	abs.f32 	%f30, %f29;
	mov.f32 	%f31, 0f3f800000;    	// 1
	setp.eq.f32 	%p13, %f30, %f31;
	@!%p13 bra 	$Lt_43_22018;
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_smf_A];
	.loc	17	11238	0
	add.f32 	%f32, %f2, %f2;
	mov.b32 	%r35, %f32;
	bra.uni 	$Lt_43_21762;
$Lt_43_22018:
	mov.s32 	%r35, 0;
$Lt_43_21762:
	.loc	17	11239	0
	or.b32 	%r42, %r35, 2139095040;
	mov.f32 	%f33, 0f00000000;    	// 0
	setp.lt.f32 	%p14, %f1, %f33;
	selp.s32 	%r35, %r42, %r35, %p14;
	.loc	17	11240	0
	mov.b32 	%f5, %r35;
	bra.uni 	$Lt_43_21250;
$Lt_43_21506:
	.loc	17	11241	0
	mov.f32 	%f34, 0f00000000;    	// 0
	.loc	15	149	0
	ld.param.f32 	%f2, [__cudaparm_epow_smf_A];
	.loc	17	11241	0
	setp.lt.f32 	%p15, %f2, %f34;
	mov.pred 	%p16, %p15;
	mov.pred 	%p17, %p18;
	@!%p15 bra 	$Lt_43_24578;
	cvt.rzi.f32.f32 	%f35, %f1;
	setp.neu.f32 	%p19, %f1, %f35;
	@!%p19 bra 	$L_43_18178;
	.loc	17	11242	0
	mov.f32 	%f5, 0f7fffffff;     	// nan
	bra.uni 	$L_43_17922;
$Lt_43_24578:
$L_43_18178:
	.loc	17	9078	0
	mov.b32 	%r43, %f6;
	and.b32 	%r44, %r43, 8388607;
	or.b32 	%r45, %r44, 1065353216;
	mov.b32 	%f36, %r45;
	mov.f32 	%f37, %f36;
	.loc	17	9079	0
	shr.u32 	%r46, %r43, 23;
	cvt.rn.f32.u32 	%f38, %r46;
	mov.f32 	%f39, 0fc2fe0000;    	// -127
	add.f32 	%f40, %f38, %f39;
	mov.f32 	%f41, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p20, %f36, %f41;
	@!%p20 bra 	$Lt_43_22274;
	.loc	17	9081	0
	mov.f32 	%f42, 0f3f000000;    	// 0.5
	mul.f32 	%f37, %f36, %f42;
	.loc	17	9082	0
	mov.f32 	%f43, 0f3f800000;    	// 1
	add.f32 	%f40, %f40, %f43;
$Lt_43_22274:
	.loc	17	8944	0
	mov.f32 	%f44, 0f3f800000;    	// 1
	add.f32 	%f45, %f37, %f44;
	mov.f32 	%f46, %f45;
	rcp.approx.ftz.f32 %f47,%f46;
	mov.f32 	%f48, %f47;
	.loc	17	8936	0
	mov.f32 	%f49, 0fbf800000;    	// -1
	add.f32 	%f50, %f37, %f49;
	add.f32 	%f51, %f50, %f50;
	mul.f32 	%f52, %f51, %f48;
	mul.f32 	%f53, %f52, %f52;
	mov.f32 	%f54, 0f3b18f0fe;    	// 0.0023337
	mov.f32 	%f55, %f54;
	mov.f32 	%f56, %f53;
	mov.f32 	%f57, 0f3c4caf63;    	// 0.012493
	mov.f32 	%f58, %f57;
	mad.f32 %f59, %f55, %f56, %f58;
	mov.f32 	%f60, %f59;
	mov.f32 	%f61, %f60;
	mov.f32 	%f62, %f53;
	mov.f32 	%f63, 0f3daaaabd;    	// 0.0833335
	mov.f32 	%f64, %f63;
	mad.f32 %f65, %f61, %f62, %f64;
	mov.f32 	%f66, %f65;
	.loc	17	9099	0
	mul.rn.f32 	%f67, %f66, %f53;
	mul.rn.f32 	%f68, %f67, %f52;
	.loc	17	8936	0
	mov.b32 	%r47, %f50;
	mov.b32 	%r48, %f52;
	and.b32 	%r49, %r47, -4096;
	mov.b32 	%f69, %r49;
	and.b32 	%r50, %r48, -4096;
	mov.b32 	%f70, %r50;
	neg.f32 	%f71, %f70;
	sub.f32 	%f72, %f50, %f70;
	mov.f32 	%f73, %f71;
	mov.f32 	%f74, %f69;
	add.f32 	%f75, %f72, %f72;
	mov.f32 	%f76, %f75;
	mad.f32 %f77, %f73, %f74, %f76;
	mov.f32 	%f78, %f77;
	mov.f32 	%f79, %f71;
	sub.f32 	%f80, %f50, %f69;
	mov.f32 	%f81, %f80;
	mov.f32 	%f82, %f78;
	mad.f32 %f83, %f79, %f81, %f82;
	mov.f32 	%f84, %f83;
	.loc	17	9122	0
	mul.rn.f32 	%f85, %f48, %f84;
	add.f32 	%f86, %f85, %f70;
	add.f32 	%f87, %f86, %f68;
	sub.f32 	%f88, %f70, %f86;
	sub.f32 	%f89, %f86, %f87;
	add.f32 	%f90, %f85, %f88;
	add.f32 	%f91, %f89, %f68;
	add.f32 	%f92, %f90, %f91;
	add.f32 	%f93, %f87, %f92;
	.loc	17	9123	0
	sub.f32 	%f94, %f87, %f93;
	add.f32 	%f95, %f92, %f94;
	.loc	17	9130	0
	mov.f32 	%f96, 0f3f317200;    	// 0.693146
	mul.rn.f32 	%f97, %f40, %f96;
	add.f32 	%f98, %f97, %f93;
	.loc	17	9131	0
	mov.f32 	%f99, 0f35bfbe8e;    	// 1.42861e-06
	mul.rn.f32 	%f100, %f40, %f99;
	sub.f32 	%f101, %f97, %f98;
	add.f32 	%f102, %f101, %f93;
	add.f32 	%f103, %f102, %f95;
	add.f32 	%f104, %f100, %f103;
	.loc	17	9132	0
	add.f32 	%f105, %f104, %f98;
	.loc	17	8936	0
	mov.f32 	%f106, 0f39000000;   	// 0.00012207
	mul.f32 	%f107, %f1, %f106;
	mov.f32 	%f108, 0f77f684df;   	// 1e+34
	setp.gt.f32 	%p21, %f8, %f108;
	selp.f32 	%f109, %f107, %f1, %p21;
	neg.f32 	%f110, %f109;
	mov.f32 	%f111, %f110;
	mov.f32 	%f112, 0f45800800;   	// 4097
	mov.f32 	%f113, %f112;
	mov.f32 	%f114, %f109;
	mad.f32 %f115, %f111, %f113, %f114;
	mov.f32 	%f116, %f115;
	mov.f32 	%f117, %f109;
	mov.f32 	%f118, 0f45800800;   	// 4097
	mov.f32 	%f119, %f118;
	mov.f32 	%f120, %f116;
	mad.f32 %f121, %f117, %f119, %f120;
	mov.f32 	%f122, %f121;
	.loc	17	9150	0
	mov.f32 	%f123, %f122;
	.loc	17	8936	0
	neg.f32 	%f124, %f105;
	mov.f32 	%f125, %f124;
	mov.f32 	%f126, 0f45800800;   	// 4097
	mov.f32 	%f127, %f126;
	mov.f32 	%f128, %f105;
	mad.f32 %f129, %f125, %f127, %f128;
	mov.f32 	%f116, %f129;
	mov.f32 	%f130, %f105;
	mov.f32 	%f131, 0f45800800;   	// 4097
	mov.f32 	%f132, %f131;
	mov.f32 	%f133, %f116;
	mad.f32 %f134, %f130, %f132, %f133;
	mov.f32 	%f116, %f134;
	.loc	17	9151	0
	mov.f32 	%f135, %f116;
	.loc	17	9153	0
	sub.f32 	%f136, %f105, %f116;
	.loc	17	8936	0
	mul.rn.f32 	%f137, %f109, %f105;
	mov.f32 	%f138, %f123;
	mov.f32 	%f139, %f116;
	neg.f32 	%f140, %f137;
	mov.f32 	%f141, %f140;
	mad.f32 %f142, %f138, %f139, %f141;
	mov.f32 	%f116, %f142;
	mov.f32 	%f143, %f123;
	mov.f32 	%f144, %f136;
	mov.f32 	%f145, %f116;
	mad.f32 %f146, %f143, %f144, %f145;
	mov.f32 	%f116, %f146;
	sub.f32 	%f147, %f109, %f122;
	mov.f32 	%f148, %f135;
	mov.f32 	%f149, %f147;
	mov.f32 	%f150, %f116;
	mad.f32 %f151, %f148, %f149, %f150;
	mov.f32 	%f116, %f151;
	mov.f32 	%f152, %f147;
	mov.f32 	%f153, %f136;
	mov.f32 	%f154, %f116;
	mad.f32 %f155, %f152, %f153, %f154;
	mov.f32 	%f116, %f155;
	.loc	17	9159	0
	sub.f32 	%f156, %f98, %f105;
	mov.f32 	%f157, 0f00000000;   	// 0
	mul.rn.f32 	%f158, %f157, %f105;
	add.f32 	%f159, %f156, %f104;
	mul.rn.f32 	%f160, %f109, %f159;
	add.f32 	%f161, %f158, %f160;
	add.f32 	%f162, %f161, %f116;
	add.rn.f32 	%f163, %f137, %f162;
	sub.f32 	%f164, %f137, %f163;
	add.rn.f32 	%f165, %f164, %f162;
	.loc	17	11157	0
	mov.f32 	%f166, %f165;
	mov.f32 	%f167, %f163;
	mov.b32 	%r51, %f163;
	mov.u32 	%r52, 1118925336;
	setp.ne.s32 	%p22, %r51, %r52;
	@%p22 bra 	$Lt_43_22786;
	.loc	17	11161	0
	sub.s32 	%r53, %r51, 1;
	mov.b32 	%f167, %r53;
	.loc	17	11162	0
	mov.f32 	%f168, 0f37000000;   	// 7.62939e-06
	add.f32 	%f166, %f165, %f168;
$Lt_43_22786:
	.loc	17	8936	0
	mov.f32 	%f169, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f170, %f167, %f169;
	cvt.rzi.f32.f32 	%f171, %f170;
	mov.f32 	%f172, %f171;
	mov.f32 	%f173, 0fbf317200;   	// -0.693146
	mov.f32 	%f174, %f173;
	mov.f32 	%f175, %f167;
	mad.f32 %f176, %f172, %f174, %f175;
	mov.f32 	%f177, %f176;
	mov.f32 	%f178, %f171;
	mov.f32 	%f179, 0fb5bfbe8e;   	// -1.42861e-06
	mov.f32 	%f180, %f179;
	mov.f32 	%f181, %f177;
	mad.f32 %f182, %f178, %f180, %f181;
	mov.f32 	%f183, %f182;
	.loc	17	8965	0
	mov.f32 	%f184, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f185, %f183, %f184;
	mov.f32 	%f186, %f185;
	ex2.approx.ftz.f32 %f187,%f186;
	mov.f32 	%f188, %f187;
	.loc	17	11166	0
	mov.f32 	%f189, 0f42d20000;   	// 105
	setp.gt.f32 	%p23, %f167, %f189;
	mov.f32 	%f190, 0fc2d20000;   	// -105
	setp.lt.f32 	%p24, %f167, %f190;
	ex2.approx.f32 	%f191, %f171;
	mul.f32 	%f192, %f191, %f188;
	mov.f32 	%f193, 0f00000000;   	// 0
	selp.f32 	%f194, %f193, %f192, %p24;
	mov.f32 	%f195, 0f7f800000;   	// ((1.0F)/(0.0F))
	selp.f32 	%f196, %f195, %f194, %p23;
	mov.f32 	%f197, %f196;
	mov.f32 	%f198, 0f7f800000;   	// ((1.0F)/(0.0F))
	setp.neu.f32 	%p25, %f196, %f198;
	@!%p25 bra 	$Lt_43_23298;
	.loc	17	8936	0
	mov.f32 	%f199, %f197;
	mov.f32 	%f200, %f166;
	mov.f32 	%f201, %f197;
	mad.f32 %f202, %f199, %f200, %f201;
	mov.f32 	%f203, %f202;
	.loc	17	11172	0
	mov.f32 	%f197, %f203;
$Lt_43_23298:
	.loc	17	11244	0
	mov.f32 	%f5, %f197;
	mov.f32 	%f204, 0f3f000000;   	// 0.5
	mul.f32 	%f205, %f1, %f204;
	cvt.rzi.f32.f32 	%f206, %f205;
	selp.s32 	%r54, 1, 0, %p16;
	add.f32 	%f207, %f206, %f206;
	sub.f32 	%f208, %f1, %f207;
	abs.f32 	%f209, %f208;
	mov.f32 	%f210, 0f3f800000;   	// 1
	set.eq.u32.f32 	%r55, %f209, %f210;
	neg.s32 	%r56, %r55;
	and.b32 	%r57, %r54, %r56;
	mov.u32 	%r58, 0;
	setp.eq.s32 	%p26, %r57, %r58;
	@%p26 bra 	$Lt_43_23810;
	.loc	17	11246	0
	mov.b32 	%r59, %f5;
	xor.b32 	%r60, %r59, -2147483648;
	mov.b32 	%f5, %r60;
$Lt_43_23810:
$L_43_17922:
$Lt_43_21250:
$Lt_43_20226:
$Lt_43_19714:
$Lt_43_11010:
$Lt_43_19202:
	.loc	15	149	0
	ld.param.u64 	%rd5, [__cudaparm_epow_smf_C];
	ld.param.s32 	%r61, [__cudaparm_epow_smf_ldc];
	mul.lo.s32 	%r62, %r61, %r4;
	add.s32 	%r63, %r6, %r62;
	cvt.s64.s32 	%rd6, %r63;
	mul.wide.s32 	%rd7, %r63, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f5;
$Lt_43_18690:
	exit;
$LDWend_epow_smf:
	} // epow_smf

	.entry epow_vvf (
		.param .u64 __cudaparm_epow_vvf_n,
		.param .u64 __cudaparm_epow_vvf_x,
		.param .s32 __cudaparm_epow_vvf_lx,
		.param .u64 __cudaparm_epow_vvf_y,
		.param .s32 __cudaparm_epow_vvf_ly,
		.param .u64 __cudaparm_epow_vvf_result,
		.param .s32 __cudaparm_epow_vvf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<54>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<212>;
	.reg .pred %p<28>;
$LDWbegin_epow_vvf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_epow_vvf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_44_18434;
	ld.param.u64 	%rd3, [__cudaparm_epow_vvf_x];
	ld.param.s32 	%r4, [__cudaparm_epow_vvf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_epow_vvf_y];
	ld.param.s32 	%r6, [__cudaparm_epow_vvf_ly];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.global.f32 	%f2, [%rd10+0];
	mov.f32 	%f3, 0f3f800000;     	// 1
	set.eq.u32.f32 	%r8, %f1, %f3;
	neg.s32 	%r9, %r8;
	mov.f32 	%f4, 0f00000000;     	// 0
	set.eq.u32.f32 	%r10, %f2, %f4;
	neg.s32 	%r11, %r10;
	or.b32 	%r12, %r9, %r11;
	mov.u32 	%r13, 0;
	setp.eq.s32 	%p2, %r12, %r13;
	@%p2 bra 	$Lt_44_19202;
	mov.f32 	%f5, 0f3f800000;     	// 1
	bra.uni 	$Lt_44_18946;
$Lt_44_19202:
	.loc	17	11223	0
	abs.f32 	%f6, %f1;
	mov.f32 	%f7, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.le.f32 	%p3, %f6, %f7;
	@!%p3 bra 	$Lt_44_10242;
	abs.f32 	%f8, %f2;
	mov.f32 	%f9, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.le.f32 	%p4, %f8, %f9;
	@%p4 bra 	$Lt_44_10498;
$Lt_44_10242:
	.loc	17	11224	0
	add.f32 	%f5, %f1, %f2;
	.loc	17	11223	0
	bra.uni 	$Lt_44_11010;
$Lt_44_10498:
	.loc	17	11225	0
	mov.f32 	%f10, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p5, %f8, %f10;
	@!%p5 bra 	$Lt_44_19714;
	.loc	17	11230	0
	mov.f32 	%f11, 0f3f800000;    	// 1
	setp.gt.f32 	%p6, %f6, %f11;
	mov.s32 	%r14, 1065353216;
	mov.s32 	%r15, 0;
	mov.s32 	%r16, 2139095040;
	selp.s32 	%r17, %r15, %r16, %p6;
	mov.s32 	%r18, 2139095040;
	mov.s32 	%r19, 0;
	selp.s32 	%r20, %r18, %r19, %p6;
	mov.f32 	%f12, 0f00000000;    	// 0
	setp.lt.f32 	%p7, %f2, %f12;
	selp.s32 	%r21, %r17, %r20, %p7;
	mov.f32 	%f13, 0fbf800000;    	// -1
	setp.eq.f32 	%p8, %f1, %f13;
	selp.s32 	%r22, %r14, %r21, %p8;
	mov.b32 	%f5, %r22;
	bra.uni 	$Lt_44_19458;
$Lt_44_19714:
	.loc	17	11231	0
	mov.f32 	%f14, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p9, %f6, %f14;
	@!%p9 bra 	$Lt_44_20226;
	.loc	17	11232	0
	mov.s32 	%r23, 2139095040;
	mov.s32 	%r24, 0;
	mov.f32 	%f15, 0f00000000;    	// 0
	setp.ge.f32 	%p10, %f2, %f15;
	selp.s32 	%r25, %r23, %r24, %p10;
	mov.f32 	%f16, 0f3f000000;    	// 0.5
	mul.f32 	%f17, %f2, %f16;
	cvt.rzi.f32.f32 	%f18, %f17;
	add.f32 	%f19, %f18, %f18;
	sub.f32 	%f20, %f2, %f19;
	abs.f32 	%f21, %f20;
	mov.f32 	%f22, 0f3f800000;    	// 1
	set.eq.u32.f32 	%r26, %f21, %f22;
	neg.s32 	%r27, %r26;
	mov.f32 	%f23, 0f00000000;    	// 0
	set.lt.u32.f32 	%r28, %f1, %f23;
	neg.s32 	%r29, %r28;
	and.b32 	%r30, %r27, %r29;
	mov.u32 	%r31, 0;
	setp.eq.s32 	%p11, %r30, %r31;
	@%p11 bra 	$Lt_44_20482;
	.loc	17	11234	0
	xor.b32 	%r25, %r25, -2147483648;
$Lt_44_20482:
	.loc	17	11235	0
	mov.b32 	%f5, %r25;
	bra.uni 	$Lt_44_19970;
$Lt_44_20226:
	mov.f32 	%f24, 0f00000000;    	// 0
	setp.eq.f32 	%p12, %f1, %f24;
	@!%p12 bra 	$Lt_44_21250;
	mov.f32 	%f25, 0f3f000000;    	// 0.5
	mul.f32 	%f26, %f2, %f25;
	cvt.rzi.f32.f32 	%f27, %f26;
	add.f32 	%f28, %f27, %f27;
	sub.f32 	%f29, %f2, %f28;
	abs.f32 	%f30, %f29;
	mov.f32 	%f31, 0f3f800000;    	// 1
	setp.eq.f32 	%p13, %f30, %f31;
	@!%p13 bra 	$Lt_44_21762;
	.loc	17	11238	0
	add.f32 	%f32, %f1, %f1;
	mov.b32 	%r25, %f32;
	bra.uni 	$Lt_44_21506;
$Lt_44_21762:
	mov.s32 	%r25, 0;
$Lt_44_21506:
	.loc	17	11239	0
	or.b32 	%r32, %r25, 2139095040;
	mov.f32 	%f33, 0f00000000;    	// 0
	setp.lt.f32 	%p14, %f2, %f33;
	selp.s32 	%r25, %r32, %r25, %p14;
	.loc	17	11240	0
	mov.b32 	%f5, %r25;
	bra.uni 	$Lt_44_20994;
$Lt_44_21250:
	.loc	17	11241	0
	mov.f32 	%f34, 0f00000000;    	// 0
	setp.lt.f32 	%p15, %f1, %f34;
	mov.pred 	%p16, %p15;
	mov.pred 	%p17, %p18;
	@!%p15 bra 	$Lt_44_24322;
	cvt.rzi.f32.f32 	%f35, %f2;
	setp.neu.f32 	%p19, %f2, %f35;
	@!%p19 bra 	$L_44_17922;
	.loc	17	11242	0
	mov.f32 	%f5, 0f7fffffff;     	// nan
	bra.uni 	$L_44_17666;
$Lt_44_24322:
$L_44_17922:
	.loc	17	9078	0
	mov.b32 	%r33, %f6;
	and.b32 	%r34, %r33, 8388607;
	or.b32 	%r35, %r34, 1065353216;
	mov.b32 	%f36, %r35;
	mov.f32 	%f37, %f36;
	.loc	17	9079	0
	shr.u32 	%r36, %r33, 23;
	cvt.rn.f32.u32 	%f38, %r36;
	mov.f32 	%f39, 0fc2fe0000;    	// -127
	add.f32 	%f40, %f38, %f39;
	mov.f32 	%f41, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p20, %f36, %f41;
	@!%p20 bra 	$Lt_44_22018;
	.loc	17	9081	0
	mov.f32 	%f42, 0f3f000000;    	// 0.5
	mul.f32 	%f37, %f36, %f42;
	.loc	17	9082	0
	mov.f32 	%f43, 0f3f800000;    	// 1
	add.f32 	%f40, %f40, %f43;
$Lt_44_22018:
	.loc	17	8944	0
	mov.f32 	%f44, 0f3f800000;    	// 1
	add.f32 	%f45, %f37, %f44;
	mov.f32 	%f46, %f45;
	rcp.approx.ftz.f32 %f47,%f46;
	mov.f32 	%f48, %f47;
	.loc	17	8936	0
	mov.f32 	%f49, 0fbf800000;    	// -1
	add.f32 	%f50, %f37, %f49;
	add.f32 	%f51, %f50, %f50;
	mul.f32 	%f52, %f51, %f48;
	mul.f32 	%f53, %f52, %f52;
	mov.f32 	%f54, 0f3b18f0fe;    	// 0.0023337
	mov.f32 	%f55, %f54;
	mov.f32 	%f56, %f53;
	mov.f32 	%f57, 0f3c4caf63;    	// 0.012493
	mov.f32 	%f58, %f57;
	mad.f32 %f59, %f55, %f56, %f58;
	mov.f32 	%f60, %f59;
	mov.f32 	%f61, %f60;
	mov.f32 	%f62, %f53;
	mov.f32 	%f63, 0f3daaaabd;    	// 0.0833335
	mov.f32 	%f64, %f63;
	mad.f32 %f65, %f61, %f62, %f64;
	mov.f32 	%f66, %f65;
	.loc	17	9099	0
	mul.rn.f32 	%f67, %f66, %f53;
	mul.rn.f32 	%f68, %f67, %f52;
	.loc	17	8936	0
	mov.b32 	%r37, %f50;
	mov.b32 	%r38, %f52;
	and.b32 	%r39, %r37, -4096;
	mov.b32 	%f69, %r39;
	and.b32 	%r40, %r38, -4096;
	mov.b32 	%f70, %r40;
	neg.f32 	%f71, %f70;
	sub.f32 	%f72, %f50, %f70;
	mov.f32 	%f73, %f71;
	mov.f32 	%f74, %f69;
	add.f32 	%f75, %f72, %f72;
	mov.f32 	%f76, %f75;
	mad.f32 %f77, %f73, %f74, %f76;
	mov.f32 	%f78, %f77;
	mov.f32 	%f79, %f71;
	sub.f32 	%f80, %f50, %f69;
	mov.f32 	%f81, %f80;
	mov.f32 	%f82, %f78;
	mad.f32 %f83, %f79, %f81, %f82;
	mov.f32 	%f84, %f83;
	.loc	17	9122	0
	mul.rn.f32 	%f85, %f48, %f84;
	add.f32 	%f86, %f85, %f70;
	add.f32 	%f87, %f86, %f68;
	sub.f32 	%f88, %f70, %f86;
	sub.f32 	%f89, %f86, %f87;
	add.f32 	%f90, %f85, %f88;
	add.f32 	%f91, %f89, %f68;
	add.f32 	%f92, %f90, %f91;
	add.f32 	%f93, %f87, %f92;
	.loc	17	9123	0
	sub.f32 	%f94, %f87, %f93;
	add.f32 	%f95, %f92, %f94;
	.loc	17	9130	0
	mov.f32 	%f96, 0f3f317200;    	// 0.693146
	mul.rn.f32 	%f97, %f40, %f96;
	add.f32 	%f98, %f97, %f93;
	.loc	17	9131	0
	mov.f32 	%f99, 0f35bfbe8e;    	// 1.42861e-06
	mul.rn.f32 	%f100, %f40, %f99;
	sub.f32 	%f101, %f97, %f98;
	add.f32 	%f102, %f101, %f93;
	add.f32 	%f103, %f102, %f95;
	add.f32 	%f104, %f100, %f103;
	.loc	17	9132	0
	add.f32 	%f105, %f104, %f98;
	.loc	17	8936	0
	mov.f32 	%f106, 0f39000000;   	// 0.00012207
	mul.f32 	%f107, %f2, %f106;
	mov.f32 	%f108, 0f77f684df;   	// 1e+34
	setp.gt.f32 	%p21, %f8, %f108;
	selp.f32 	%f109, %f107, %f2, %p21;
	neg.f32 	%f110, %f109;
	mov.f32 	%f111, %f110;
	mov.f32 	%f112, 0f45800800;   	// 4097
	mov.f32 	%f113, %f112;
	mov.f32 	%f114, %f109;
	mad.f32 %f115, %f111, %f113, %f114;
	mov.f32 	%f116, %f115;
	mov.f32 	%f117, %f109;
	mov.f32 	%f118, 0f45800800;   	// 4097
	mov.f32 	%f119, %f118;
	mov.f32 	%f120, %f116;
	mad.f32 %f121, %f117, %f119, %f120;
	mov.f32 	%f122, %f121;
	.loc	17	9150	0
	mov.f32 	%f123, %f122;
	.loc	17	8936	0
	neg.f32 	%f124, %f105;
	mov.f32 	%f125, %f124;
	mov.f32 	%f126, 0f45800800;   	// 4097
	mov.f32 	%f127, %f126;
	mov.f32 	%f128, %f105;
	mad.f32 %f129, %f125, %f127, %f128;
	mov.f32 	%f116, %f129;
	mov.f32 	%f130, %f105;
	mov.f32 	%f131, 0f45800800;   	// 4097
	mov.f32 	%f132, %f131;
	mov.f32 	%f133, %f116;
	mad.f32 %f134, %f130, %f132, %f133;
	mov.f32 	%f116, %f134;
	.loc	17	9151	0
	mov.f32 	%f135, %f116;
	.loc	17	9153	0
	sub.f32 	%f136, %f105, %f116;
	.loc	17	8936	0
	mul.rn.f32 	%f137, %f109, %f105;
	mov.f32 	%f138, %f123;
	mov.f32 	%f139, %f116;
	neg.f32 	%f140, %f137;
	mov.f32 	%f141, %f140;
	mad.f32 %f142, %f138, %f139, %f141;
	mov.f32 	%f116, %f142;
	mov.f32 	%f143, %f123;
	mov.f32 	%f144, %f136;
	mov.f32 	%f145, %f116;
	mad.f32 %f146, %f143, %f144, %f145;
	mov.f32 	%f116, %f146;
	sub.f32 	%f147, %f109, %f122;
	mov.f32 	%f148, %f135;
	mov.f32 	%f149, %f147;
	mov.f32 	%f150, %f116;
	mad.f32 %f151, %f148, %f149, %f150;
	mov.f32 	%f116, %f151;
	mov.f32 	%f152, %f147;
	mov.f32 	%f153, %f136;
	mov.f32 	%f154, %f116;
	mad.f32 %f155, %f152, %f153, %f154;
	mov.f32 	%f116, %f155;
	.loc	17	9159	0
	sub.f32 	%f156, %f98, %f105;
	mov.f32 	%f157, 0f00000000;   	// 0
	mul.rn.f32 	%f158, %f157, %f105;
	add.f32 	%f159, %f156, %f104;
	mul.rn.f32 	%f160, %f109, %f159;
	add.f32 	%f161, %f158, %f160;
	add.f32 	%f162, %f161, %f116;
	add.rn.f32 	%f163, %f137, %f162;
	sub.f32 	%f164, %f137, %f163;
	add.rn.f32 	%f165, %f164, %f162;
	.loc	17	11157	0
	mov.f32 	%f166, %f165;
	mov.f32 	%f167, %f163;
	mov.b32 	%r41, %f163;
	mov.u32 	%r42, 1118925336;
	setp.ne.s32 	%p22, %r41, %r42;
	@%p22 bra 	$Lt_44_22530;
	.loc	17	11161	0
	sub.s32 	%r43, %r41, 1;
	mov.b32 	%f167, %r43;
	.loc	17	11162	0
	mov.f32 	%f168, 0f37000000;   	// 7.62939e-06
	add.f32 	%f166, %f165, %f168;
$Lt_44_22530:
	.loc	17	8936	0
	mov.f32 	%f169, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f170, %f167, %f169;
	cvt.rzi.f32.f32 	%f171, %f170;
	mov.f32 	%f172, %f171;
	mov.f32 	%f173, 0fbf317200;   	// -0.693146
	mov.f32 	%f174, %f173;
	mov.f32 	%f175, %f167;
	mad.f32 %f176, %f172, %f174, %f175;
	mov.f32 	%f177, %f176;
	mov.f32 	%f178, %f171;
	mov.f32 	%f179, 0fb5bfbe8e;   	// -1.42861e-06
	mov.f32 	%f180, %f179;
	mov.f32 	%f181, %f177;
	mad.f32 %f182, %f178, %f180, %f181;
	mov.f32 	%f183, %f182;
	.loc	17	8965	0
	mov.f32 	%f184, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f185, %f183, %f184;
	mov.f32 	%f186, %f185;
	ex2.approx.ftz.f32 %f187,%f186;
	mov.f32 	%f188, %f187;
	.loc	17	11166	0
	mov.f32 	%f189, 0f42d20000;   	// 105
	setp.gt.f32 	%p23, %f167, %f189;
	mov.f32 	%f190, 0fc2d20000;   	// -105
	setp.lt.f32 	%p24, %f167, %f190;
	ex2.approx.f32 	%f191, %f171;
	mul.f32 	%f192, %f191, %f188;
	mov.f32 	%f193, 0f00000000;   	// 0
	selp.f32 	%f194, %f193, %f192, %p24;
	mov.f32 	%f195, 0f7f800000;   	// ((1.0F)/(0.0F))
	selp.f32 	%f196, %f195, %f194, %p23;
	mov.f32 	%f197, %f196;
	mov.f32 	%f198, 0f7f800000;   	// ((1.0F)/(0.0F))
	setp.neu.f32 	%p25, %f196, %f198;
	@!%p25 bra 	$Lt_44_23042;
	.loc	17	8936	0
	mov.f32 	%f199, %f197;
	mov.f32 	%f200, %f166;
	mov.f32 	%f201, %f197;
	mad.f32 %f202, %f199, %f200, %f201;
	mov.f32 	%f203, %f202;
	.loc	17	11172	0
	mov.f32 	%f197, %f203;
$Lt_44_23042:
	.loc	17	11244	0
	mov.f32 	%f5, %f197;
	mov.f32 	%f204, 0f3f000000;   	// 0.5
	mul.f32 	%f205, %f2, %f204;
	cvt.rzi.f32.f32 	%f206, %f205;
	selp.s32 	%r44, 1, 0, %p16;
	add.f32 	%f207, %f206, %f206;
	sub.f32 	%f208, %f2, %f207;
	abs.f32 	%f209, %f208;
	mov.f32 	%f210, 0f3f800000;   	// 1
	set.eq.u32.f32 	%r45, %f209, %f210;
	neg.s32 	%r46, %r45;
	and.b32 	%r47, %r44, %r46;
	mov.u32 	%r48, 0;
	setp.eq.s32 	%p26, %r47, %r48;
	@%p26 bra 	$Lt_44_23554;
	.loc	17	11246	0
	mov.b32 	%r49, %f5;
	xor.b32 	%r50, %r49, -2147483648;
	mov.b32 	%f5, %r50;
$Lt_44_23554:
$L_44_17666:
$Lt_44_20994:
$Lt_44_19970:
$Lt_44_19458:
$Lt_44_11010:
$Lt_44_18946:
	.loc	15	149	0
	ld.param.u64 	%rd11, [__cudaparm_epow_vvf_result];
	ld.param.s32 	%r51, [__cudaparm_epow_vvf_lr];
	mul.lo.s32 	%r52, %r51, %r3;
	cvt.s64.s32 	%rd12, %r52;
	mul.wide.s32 	%rd13, %r52, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f5;
$Lt_44_18434:
	exit;
$LDWend_epow_vvf:
	} // epow_vvf

	.entry epow_vmf (
		.param .s32 __cudaparm_epow_vmf_rs,
		.param .s32 __cudaparm_epow_vmf_cs,
		.param .u64 __cudaparm_epow_vmf_x,
		.param .s32 __cudaparm_epow_vmf_lx,
		.param .u64 __cudaparm_epow_vmf_B,
		.param .s32 __cudaparm_epow_vmf_ldb,
		.param .u64 __cudaparm_epow_vmf_C,
		.param .s32 __cudaparm_epow_vmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<67>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<212>;
	.reg .pred %p<28>;
$LDWbegin_epow_vmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_epow_vmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_epow_vmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_45_18690;
	ld.param.u64 	%rd1, [__cudaparm_epow_vmf_x];
	ld.param.s32 	%r15, [__cudaparm_epow_vmf_lx];
	mul.lo.s32 	%r16, %r15, %r6;
	cvt.s64.s32 	%rd2, %r16;
	mul.wide.s32 	%rd3, %r16, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_epow_vmf_B];
	ld.param.s32 	%r17, [__cudaparm_epow_vmf_ldb];
	mul.lo.s32 	%r18, %r17, %r4;
	add.s32 	%r19, %r6, %r18;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	mov.f32 	%f3, 0f3f800000;     	// 1
	set.eq.u32.f32 	%r20, %f1, %f3;
	neg.s32 	%r21, %r20;
	mov.f32 	%f4, 0f00000000;     	// 0
	set.eq.u32.f32 	%r22, %f2, %f4;
	neg.s32 	%r23, %r22;
	or.b32 	%r24, %r21, %r23;
	mov.u32 	%r25, 0;
	setp.eq.s32 	%p2, %r24, %r25;
	@%p2 bra 	$Lt_45_19458;
	mov.f32 	%f5, 0f3f800000;     	// 1
	bra.uni 	$Lt_45_19202;
$Lt_45_19458:
	.loc	17	11223	0
	abs.f32 	%f6, %f1;
	mov.f32 	%f7, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.le.f32 	%p3, %f6, %f7;
	@!%p3 bra 	$Lt_45_10242;
	abs.f32 	%f8, %f2;
	mov.f32 	%f9, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.le.f32 	%p4, %f8, %f9;
	@%p4 bra 	$Lt_45_10498;
$Lt_45_10242:
	.loc	17	11224	0
	add.f32 	%f5, %f1, %f2;
	.loc	17	11223	0
	bra.uni 	$Lt_45_11010;
$Lt_45_10498:
	.loc	17	11225	0
	mov.f32 	%f10, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p5, %f8, %f10;
	@!%p5 bra 	$Lt_45_19970;
	.loc	17	11230	0
	mov.f32 	%f11, 0f3f800000;    	// 1
	setp.gt.f32 	%p6, %f6, %f11;
	mov.s32 	%r26, 1065353216;
	mov.s32 	%r27, 0;
	mov.s32 	%r28, 2139095040;
	selp.s32 	%r29, %r27, %r28, %p6;
	mov.s32 	%r30, 2139095040;
	mov.s32 	%r31, 0;
	selp.s32 	%r32, %r30, %r31, %p6;
	mov.f32 	%f12, 0f00000000;    	// 0
	setp.lt.f32 	%p7, %f2, %f12;
	selp.s32 	%r33, %r29, %r32, %p7;
	mov.f32 	%f13, 0fbf800000;    	// -1
	setp.eq.f32 	%p8, %f1, %f13;
	selp.s32 	%r34, %r26, %r33, %p8;
	mov.b32 	%f5, %r34;
	bra.uni 	$Lt_45_19714;
$Lt_45_19970:
	.loc	17	11231	0
	mov.f32 	%f14, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p9, %f6, %f14;
	@!%p9 bra 	$Lt_45_20482;
	.loc	17	11232	0
	mov.s32 	%r35, 2139095040;
	mov.s32 	%r36, 0;
	mov.f32 	%f15, 0f00000000;    	// 0
	setp.ge.f32 	%p10, %f2, %f15;
	selp.s32 	%r37, %r35, %r36, %p10;
	mov.f32 	%f16, 0f3f000000;    	// 0.5
	mul.f32 	%f17, %f2, %f16;
	cvt.rzi.f32.f32 	%f18, %f17;
	add.f32 	%f19, %f18, %f18;
	sub.f32 	%f20, %f2, %f19;
	abs.f32 	%f21, %f20;
	mov.f32 	%f22, 0f3f800000;    	// 1
	set.eq.u32.f32 	%r38, %f21, %f22;
	neg.s32 	%r39, %r38;
	mov.f32 	%f23, 0f00000000;    	// 0
	set.lt.u32.f32 	%r40, %f1, %f23;
	neg.s32 	%r41, %r40;
	and.b32 	%r42, %r39, %r41;
	mov.u32 	%r43, 0;
	setp.eq.s32 	%p11, %r42, %r43;
	@%p11 bra 	$Lt_45_20738;
	.loc	17	11234	0
	xor.b32 	%r37, %r37, -2147483648;
$Lt_45_20738:
	.loc	17	11235	0
	mov.b32 	%f5, %r37;
	bra.uni 	$Lt_45_20226;
$Lt_45_20482:
	mov.f32 	%f24, 0f00000000;    	// 0
	setp.eq.f32 	%p12, %f1, %f24;
	@!%p12 bra 	$Lt_45_21506;
	mov.f32 	%f25, 0f3f000000;    	// 0.5
	mul.f32 	%f26, %f2, %f25;
	cvt.rzi.f32.f32 	%f27, %f26;
	add.f32 	%f28, %f27, %f27;
	sub.f32 	%f29, %f2, %f28;
	abs.f32 	%f30, %f29;
	mov.f32 	%f31, 0f3f800000;    	// 1
	setp.eq.f32 	%p13, %f30, %f31;
	@!%p13 bra 	$Lt_45_22018;
	.loc	17	11238	0
	add.f32 	%f32, %f1, %f1;
	mov.b32 	%r37, %f32;
	bra.uni 	$Lt_45_21762;
$Lt_45_22018:
	mov.s32 	%r37, 0;
$Lt_45_21762:
	.loc	17	11239	0
	or.b32 	%r44, %r37, 2139095040;
	mov.f32 	%f33, 0f00000000;    	// 0
	setp.lt.f32 	%p14, %f2, %f33;
	selp.s32 	%r37, %r44, %r37, %p14;
	.loc	17	11240	0
	mov.b32 	%f5, %r37;
	bra.uni 	$Lt_45_21250;
$Lt_45_21506:
	.loc	17	11241	0
	mov.f32 	%f34, 0f00000000;    	// 0
	setp.lt.f32 	%p15, %f1, %f34;
	mov.pred 	%p16, %p15;
	mov.pred 	%p17, %p18;
	@!%p15 bra 	$Lt_45_24578;
	cvt.rzi.f32.f32 	%f35, %f2;
	setp.neu.f32 	%p19, %f2, %f35;
	@!%p19 bra 	$L_45_18178;
	.loc	17	11242	0
	mov.f32 	%f5, 0f7fffffff;     	// nan
	bra.uni 	$L_45_17922;
$Lt_45_24578:
$L_45_18178:
	.loc	17	9078	0
	mov.b32 	%r45, %f6;
	and.b32 	%r46, %r45, 8388607;
	or.b32 	%r47, %r46, 1065353216;
	mov.b32 	%f36, %r47;
	mov.f32 	%f37, %f36;
	.loc	17	9079	0
	shr.u32 	%r48, %r45, 23;
	cvt.rn.f32.u32 	%f38, %r48;
	mov.f32 	%f39, 0fc2fe0000;    	// -127
	add.f32 	%f40, %f38, %f39;
	mov.f32 	%f41, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p20, %f36, %f41;
	@!%p20 bra 	$Lt_45_22274;
	.loc	17	9081	0
	mov.f32 	%f42, 0f3f000000;    	// 0.5
	mul.f32 	%f37, %f36, %f42;
	.loc	17	9082	0
	mov.f32 	%f43, 0f3f800000;    	// 1
	add.f32 	%f40, %f40, %f43;
$Lt_45_22274:
	.loc	17	8944	0
	mov.f32 	%f44, 0f3f800000;    	// 1
	add.f32 	%f45, %f37, %f44;
	mov.f32 	%f46, %f45;
	rcp.approx.ftz.f32 %f47,%f46;
	mov.f32 	%f48, %f47;
	.loc	17	8936	0
	mov.f32 	%f49, 0fbf800000;    	// -1
	add.f32 	%f50, %f37, %f49;
	add.f32 	%f51, %f50, %f50;
	mul.f32 	%f52, %f51, %f48;
	mul.f32 	%f53, %f52, %f52;
	mov.f32 	%f54, 0f3b18f0fe;    	// 0.0023337
	mov.f32 	%f55, %f54;
	mov.f32 	%f56, %f53;
	mov.f32 	%f57, 0f3c4caf63;    	// 0.012493
	mov.f32 	%f58, %f57;
	mad.f32 %f59, %f55, %f56, %f58;
	mov.f32 	%f60, %f59;
	mov.f32 	%f61, %f60;
	mov.f32 	%f62, %f53;
	mov.f32 	%f63, 0f3daaaabd;    	// 0.0833335
	mov.f32 	%f64, %f63;
	mad.f32 %f65, %f61, %f62, %f64;
	mov.f32 	%f66, %f65;
	.loc	17	9099	0
	mul.rn.f32 	%f67, %f66, %f53;
	mul.rn.f32 	%f68, %f67, %f52;
	.loc	17	8936	0
	mov.b32 	%r49, %f50;
	mov.b32 	%r50, %f52;
	and.b32 	%r51, %r49, -4096;
	mov.b32 	%f69, %r51;
	and.b32 	%r52, %r50, -4096;
	mov.b32 	%f70, %r52;
	neg.f32 	%f71, %f70;
	sub.f32 	%f72, %f50, %f70;
	mov.f32 	%f73, %f71;
	mov.f32 	%f74, %f69;
	add.f32 	%f75, %f72, %f72;
	mov.f32 	%f76, %f75;
	mad.f32 %f77, %f73, %f74, %f76;
	mov.f32 	%f78, %f77;
	mov.f32 	%f79, %f71;
	sub.f32 	%f80, %f50, %f69;
	mov.f32 	%f81, %f80;
	mov.f32 	%f82, %f78;
	mad.f32 %f83, %f79, %f81, %f82;
	mov.f32 	%f84, %f83;
	.loc	17	9122	0
	mul.rn.f32 	%f85, %f48, %f84;
	add.f32 	%f86, %f85, %f70;
	add.f32 	%f87, %f86, %f68;
	sub.f32 	%f88, %f70, %f86;
	sub.f32 	%f89, %f86, %f87;
	add.f32 	%f90, %f85, %f88;
	add.f32 	%f91, %f89, %f68;
	add.f32 	%f92, %f90, %f91;
	add.f32 	%f93, %f87, %f92;
	.loc	17	9123	0
	sub.f32 	%f94, %f87, %f93;
	add.f32 	%f95, %f92, %f94;
	.loc	17	9130	0
	mov.f32 	%f96, 0f3f317200;    	// 0.693146
	mul.rn.f32 	%f97, %f40, %f96;
	add.f32 	%f98, %f97, %f93;
	.loc	17	9131	0
	mov.f32 	%f99, 0f35bfbe8e;    	// 1.42861e-06
	mul.rn.f32 	%f100, %f40, %f99;
	sub.f32 	%f101, %f97, %f98;
	add.f32 	%f102, %f101, %f93;
	add.f32 	%f103, %f102, %f95;
	add.f32 	%f104, %f100, %f103;
	.loc	17	9132	0
	add.f32 	%f105, %f104, %f98;
	.loc	17	8936	0
	mov.f32 	%f106, 0f39000000;   	// 0.00012207
	mul.f32 	%f107, %f2, %f106;
	mov.f32 	%f108, 0f77f684df;   	// 1e+34
	setp.gt.f32 	%p21, %f8, %f108;
	selp.f32 	%f109, %f107, %f2, %p21;
	neg.f32 	%f110, %f109;
	mov.f32 	%f111, %f110;
	mov.f32 	%f112, 0f45800800;   	// 4097
	mov.f32 	%f113, %f112;
	mov.f32 	%f114, %f109;
	mad.f32 %f115, %f111, %f113, %f114;
	mov.f32 	%f116, %f115;
	mov.f32 	%f117, %f109;
	mov.f32 	%f118, 0f45800800;   	// 4097
	mov.f32 	%f119, %f118;
	mov.f32 	%f120, %f116;
	mad.f32 %f121, %f117, %f119, %f120;
	mov.f32 	%f122, %f121;
	.loc	17	9150	0
	mov.f32 	%f123, %f122;
	.loc	17	8936	0
	neg.f32 	%f124, %f105;
	mov.f32 	%f125, %f124;
	mov.f32 	%f126, 0f45800800;   	// 4097
	mov.f32 	%f127, %f126;
	mov.f32 	%f128, %f105;
	mad.f32 %f129, %f125, %f127, %f128;
	mov.f32 	%f116, %f129;
	mov.f32 	%f130, %f105;
	mov.f32 	%f131, 0f45800800;   	// 4097
	mov.f32 	%f132, %f131;
	mov.f32 	%f133, %f116;
	mad.f32 %f134, %f130, %f132, %f133;
	mov.f32 	%f116, %f134;
	.loc	17	9151	0
	mov.f32 	%f135, %f116;
	.loc	17	9153	0
	sub.f32 	%f136, %f105, %f116;
	.loc	17	8936	0
	mul.rn.f32 	%f137, %f109, %f105;
	mov.f32 	%f138, %f123;
	mov.f32 	%f139, %f116;
	neg.f32 	%f140, %f137;
	mov.f32 	%f141, %f140;
	mad.f32 %f142, %f138, %f139, %f141;
	mov.f32 	%f116, %f142;
	mov.f32 	%f143, %f123;
	mov.f32 	%f144, %f136;
	mov.f32 	%f145, %f116;
	mad.f32 %f146, %f143, %f144, %f145;
	mov.f32 	%f116, %f146;
	sub.f32 	%f147, %f109, %f122;
	mov.f32 	%f148, %f135;
	mov.f32 	%f149, %f147;
	mov.f32 	%f150, %f116;
	mad.f32 %f151, %f148, %f149, %f150;
	mov.f32 	%f116, %f151;
	mov.f32 	%f152, %f147;
	mov.f32 	%f153, %f136;
	mov.f32 	%f154, %f116;
	mad.f32 %f155, %f152, %f153, %f154;
	mov.f32 	%f116, %f155;
	.loc	17	9159	0
	sub.f32 	%f156, %f98, %f105;
	mov.f32 	%f157, 0f00000000;   	// 0
	mul.rn.f32 	%f158, %f157, %f105;
	add.f32 	%f159, %f156, %f104;
	mul.rn.f32 	%f160, %f109, %f159;
	add.f32 	%f161, %f158, %f160;
	add.f32 	%f162, %f161, %f116;
	add.rn.f32 	%f163, %f137, %f162;
	sub.f32 	%f164, %f137, %f163;
	add.rn.f32 	%f165, %f164, %f162;
	.loc	17	11157	0
	mov.f32 	%f166, %f165;
	mov.f32 	%f167, %f163;
	mov.b32 	%r53, %f163;
	mov.u32 	%r54, 1118925336;
	setp.ne.s32 	%p22, %r53, %r54;
	@%p22 bra 	$Lt_45_22786;
	.loc	17	11161	0
	sub.s32 	%r55, %r53, 1;
	mov.b32 	%f167, %r55;
	.loc	17	11162	0
	mov.f32 	%f168, 0f37000000;   	// 7.62939e-06
	add.f32 	%f166, %f165, %f168;
$Lt_45_22786:
	.loc	17	8936	0
	mov.f32 	%f169, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f170, %f167, %f169;
	cvt.rzi.f32.f32 	%f171, %f170;
	mov.f32 	%f172, %f171;
	mov.f32 	%f173, 0fbf317200;   	// -0.693146
	mov.f32 	%f174, %f173;
	mov.f32 	%f175, %f167;
	mad.f32 %f176, %f172, %f174, %f175;
	mov.f32 	%f177, %f176;
	mov.f32 	%f178, %f171;
	mov.f32 	%f179, 0fb5bfbe8e;   	// -1.42861e-06
	mov.f32 	%f180, %f179;
	mov.f32 	%f181, %f177;
	mad.f32 %f182, %f178, %f180, %f181;
	mov.f32 	%f183, %f182;
	.loc	17	8965	0
	mov.f32 	%f184, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f185, %f183, %f184;
	mov.f32 	%f186, %f185;
	ex2.approx.ftz.f32 %f187,%f186;
	mov.f32 	%f188, %f187;
	.loc	17	11166	0
	mov.f32 	%f189, 0f42d20000;   	// 105
	setp.gt.f32 	%p23, %f167, %f189;
	mov.f32 	%f190, 0fc2d20000;   	// -105
	setp.lt.f32 	%p24, %f167, %f190;
	ex2.approx.f32 	%f191, %f171;
	mul.f32 	%f192, %f191, %f188;
	mov.f32 	%f193, 0f00000000;   	// 0
	selp.f32 	%f194, %f193, %f192, %p24;
	mov.f32 	%f195, 0f7f800000;   	// ((1.0F)/(0.0F))
	selp.f32 	%f196, %f195, %f194, %p23;
	mov.f32 	%f197, %f196;
	mov.f32 	%f198, 0f7f800000;   	// ((1.0F)/(0.0F))
	setp.neu.f32 	%p25, %f196, %f198;
	@!%p25 bra 	$Lt_45_23298;
	.loc	17	8936	0
	mov.f32 	%f199, %f197;
	mov.f32 	%f200, %f166;
	mov.f32 	%f201, %f197;
	mad.f32 %f202, %f199, %f200, %f201;
	mov.f32 	%f203, %f202;
	.loc	17	11172	0
	mov.f32 	%f197, %f203;
$Lt_45_23298:
	.loc	17	11244	0
	mov.f32 	%f5, %f197;
	mov.f32 	%f204, 0f3f000000;   	// 0.5
	mul.f32 	%f205, %f2, %f204;
	cvt.rzi.f32.f32 	%f206, %f205;
	selp.s32 	%r56, 1, 0, %p16;
	add.f32 	%f207, %f206, %f206;
	sub.f32 	%f208, %f2, %f207;
	abs.f32 	%f209, %f208;
	mov.f32 	%f210, 0f3f800000;   	// 1
	set.eq.u32.f32 	%r57, %f209, %f210;
	neg.s32 	%r58, %r57;
	and.b32 	%r59, %r56, %r58;
	mov.u32 	%r60, 0;
	setp.eq.s32 	%p26, %r59, %r60;
	@%p26 bra 	$Lt_45_23810;
	.loc	17	11246	0
	mov.b32 	%r61, %f5;
	xor.b32 	%r62, %r61, -2147483648;
	mov.b32 	%f5, %r62;
$Lt_45_23810:
$L_45_17922:
$Lt_45_21250:
$Lt_45_20226:
$Lt_45_19714:
$Lt_45_11010:
$Lt_45_19202:
	.loc	15	149	0
	ld.param.u64 	%rd9, [__cudaparm_epow_vmf_C];
	ld.param.s32 	%r63, [__cudaparm_epow_vmf_ldc];
	mul.lo.s32 	%r64, %r63, %r4;
	add.s32 	%r65, %r6, %r64;
	cvt.s64.s32 	%rd10, %r65;
	mul.wide.s32 	%rd11, %r65, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_45_18690:
	exit;
$LDWend_epow_vmf:
	} // epow_vmf

	.entry epow_mvf (
		.param .s32 __cudaparm_epow_mvf_rs,
		.param .s32 __cudaparm_epow_mvf_cs,
		.param .u64 __cudaparm_epow_mvf_A,
		.param .s32 __cudaparm_epow_mvf_lda,
		.param .u64 __cudaparm_epow_mvf_y,
		.param .s32 __cudaparm_epow_mvf_ly,
		.param .u64 __cudaparm_epow_mvf_C,
		.param .s32 __cudaparm_epow_mvf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<67>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<212>;
	.reg .pred %p<28>;
$LDWbegin_epow_mvf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_epow_mvf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_epow_mvf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_46_18690;
	ld.param.u64 	%rd1, [__cudaparm_epow_mvf_A];
	ld.param.s32 	%r15, [__cudaparm_epow_mvf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_epow_mvf_y];
	ld.param.s32 	%r18, [__cudaparm_epow_mvf_ly];
	mul.lo.s32 	%r19, %r18, %r6;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	mov.f32 	%f3, 0f3f800000;     	// 1
	set.eq.u32.f32 	%r20, %f1, %f3;
	neg.s32 	%r21, %r20;
	mov.f32 	%f4, 0f00000000;     	// 0
	set.eq.u32.f32 	%r22, %f2, %f4;
	neg.s32 	%r23, %r22;
	or.b32 	%r24, %r21, %r23;
	mov.u32 	%r25, 0;
	setp.eq.s32 	%p2, %r24, %r25;
	@%p2 bra 	$Lt_46_19458;
	mov.f32 	%f5, 0f3f800000;     	// 1
	bra.uni 	$Lt_46_19202;
$Lt_46_19458:
	.loc	17	11223	0
	abs.f32 	%f6, %f1;
	mov.f32 	%f7, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.le.f32 	%p3, %f6, %f7;
	@!%p3 bra 	$Lt_46_10242;
	abs.f32 	%f8, %f2;
	mov.f32 	%f9, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.le.f32 	%p4, %f8, %f9;
	@%p4 bra 	$Lt_46_10498;
$Lt_46_10242:
	.loc	17	11224	0
	add.f32 	%f5, %f1, %f2;
	.loc	17	11223	0
	bra.uni 	$Lt_46_11010;
$Lt_46_10498:
	.loc	17	11225	0
	mov.f32 	%f10, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p5, %f8, %f10;
	@!%p5 bra 	$Lt_46_19970;
	.loc	17	11230	0
	mov.f32 	%f11, 0f3f800000;    	// 1
	setp.gt.f32 	%p6, %f6, %f11;
	mov.s32 	%r26, 1065353216;
	mov.s32 	%r27, 0;
	mov.s32 	%r28, 2139095040;
	selp.s32 	%r29, %r27, %r28, %p6;
	mov.s32 	%r30, 2139095040;
	mov.s32 	%r31, 0;
	selp.s32 	%r32, %r30, %r31, %p6;
	mov.f32 	%f12, 0f00000000;    	// 0
	setp.lt.f32 	%p7, %f2, %f12;
	selp.s32 	%r33, %r29, %r32, %p7;
	mov.f32 	%f13, 0fbf800000;    	// -1
	setp.eq.f32 	%p8, %f1, %f13;
	selp.s32 	%r34, %r26, %r33, %p8;
	mov.b32 	%f5, %r34;
	bra.uni 	$Lt_46_19714;
$Lt_46_19970:
	.loc	17	11231	0
	mov.f32 	%f14, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p9, %f6, %f14;
	@!%p9 bra 	$Lt_46_20482;
	.loc	17	11232	0
	mov.s32 	%r35, 2139095040;
	mov.s32 	%r36, 0;
	mov.f32 	%f15, 0f00000000;    	// 0
	setp.ge.f32 	%p10, %f2, %f15;
	selp.s32 	%r37, %r35, %r36, %p10;
	mov.f32 	%f16, 0f3f000000;    	// 0.5
	mul.f32 	%f17, %f2, %f16;
	cvt.rzi.f32.f32 	%f18, %f17;
	add.f32 	%f19, %f18, %f18;
	sub.f32 	%f20, %f2, %f19;
	abs.f32 	%f21, %f20;
	mov.f32 	%f22, 0f3f800000;    	// 1
	set.eq.u32.f32 	%r38, %f21, %f22;
	neg.s32 	%r39, %r38;
	mov.f32 	%f23, 0f00000000;    	// 0
	set.lt.u32.f32 	%r40, %f1, %f23;
	neg.s32 	%r41, %r40;
	and.b32 	%r42, %r39, %r41;
	mov.u32 	%r43, 0;
	setp.eq.s32 	%p11, %r42, %r43;
	@%p11 bra 	$Lt_46_20738;
	.loc	17	11234	0
	xor.b32 	%r37, %r37, -2147483648;
$Lt_46_20738:
	.loc	17	11235	0
	mov.b32 	%f5, %r37;
	bra.uni 	$Lt_46_20226;
$Lt_46_20482:
	mov.f32 	%f24, 0f00000000;    	// 0
	setp.eq.f32 	%p12, %f1, %f24;
	@!%p12 bra 	$Lt_46_21506;
	mov.f32 	%f25, 0f3f000000;    	// 0.5
	mul.f32 	%f26, %f2, %f25;
	cvt.rzi.f32.f32 	%f27, %f26;
	add.f32 	%f28, %f27, %f27;
	sub.f32 	%f29, %f2, %f28;
	abs.f32 	%f30, %f29;
	mov.f32 	%f31, 0f3f800000;    	// 1
	setp.eq.f32 	%p13, %f30, %f31;
	@!%p13 bra 	$Lt_46_22018;
	.loc	17	11238	0
	add.f32 	%f32, %f1, %f1;
	mov.b32 	%r37, %f32;
	bra.uni 	$Lt_46_21762;
$Lt_46_22018:
	mov.s32 	%r37, 0;
$Lt_46_21762:
	.loc	17	11239	0
	or.b32 	%r44, %r37, 2139095040;
	mov.f32 	%f33, 0f00000000;    	// 0
	setp.lt.f32 	%p14, %f2, %f33;
	selp.s32 	%r37, %r44, %r37, %p14;
	.loc	17	11240	0
	mov.b32 	%f5, %r37;
	bra.uni 	$Lt_46_21250;
$Lt_46_21506:
	.loc	17	11241	0
	mov.f32 	%f34, 0f00000000;    	// 0
	setp.lt.f32 	%p15, %f1, %f34;
	mov.pred 	%p16, %p15;
	mov.pred 	%p17, %p18;
	@!%p15 bra 	$Lt_46_24578;
	cvt.rzi.f32.f32 	%f35, %f2;
	setp.neu.f32 	%p19, %f2, %f35;
	@!%p19 bra 	$L_46_18178;
	.loc	17	11242	0
	mov.f32 	%f5, 0f7fffffff;     	// nan
	bra.uni 	$L_46_17922;
$Lt_46_24578:
$L_46_18178:
	.loc	17	9078	0
	mov.b32 	%r45, %f6;
	and.b32 	%r46, %r45, 8388607;
	or.b32 	%r47, %r46, 1065353216;
	mov.b32 	%f36, %r47;
	mov.f32 	%f37, %f36;
	.loc	17	9079	0
	shr.u32 	%r48, %r45, 23;
	cvt.rn.f32.u32 	%f38, %r48;
	mov.f32 	%f39, 0fc2fe0000;    	// -127
	add.f32 	%f40, %f38, %f39;
	mov.f32 	%f41, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p20, %f36, %f41;
	@!%p20 bra 	$Lt_46_22274;
	.loc	17	9081	0
	mov.f32 	%f42, 0f3f000000;    	// 0.5
	mul.f32 	%f37, %f36, %f42;
	.loc	17	9082	0
	mov.f32 	%f43, 0f3f800000;    	// 1
	add.f32 	%f40, %f40, %f43;
$Lt_46_22274:
	.loc	17	8944	0
	mov.f32 	%f44, 0f3f800000;    	// 1
	add.f32 	%f45, %f37, %f44;
	mov.f32 	%f46, %f45;
	rcp.approx.ftz.f32 %f47,%f46;
	mov.f32 	%f48, %f47;
	.loc	17	8936	0
	mov.f32 	%f49, 0fbf800000;    	// -1
	add.f32 	%f50, %f37, %f49;
	add.f32 	%f51, %f50, %f50;
	mul.f32 	%f52, %f51, %f48;
	mul.f32 	%f53, %f52, %f52;
	mov.f32 	%f54, 0f3b18f0fe;    	// 0.0023337
	mov.f32 	%f55, %f54;
	mov.f32 	%f56, %f53;
	mov.f32 	%f57, 0f3c4caf63;    	// 0.012493
	mov.f32 	%f58, %f57;
	mad.f32 %f59, %f55, %f56, %f58;
	mov.f32 	%f60, %f59;
	mov.f32 	%f61, %f60;
	mov.f32 	%f62, %f53;
	mov.f32 	%f63, 0f3daaaabd;    	// 0.0833335
	mov.f32 	%f64, %f63;
	mad.f32 %f65, %f61, %f62, %f64;
	mov.f32 	%f66, %f65;
	.loc	17	9099	0
	mul.rn.f32 	%f67, %f66, %f53;
	mul.rn.f32 	%f68, %f67, %f52;
	.loc	17	8936	0
	mov.b32 	%r49, %f50;
	mov.b32 	%r50, %f52;
	and.b32 	%r51, %r49, -4096;
	mov.b32 	%f69, %r51;
	and.b32 	%r52, %r50, -4096;
	mov.b32 	%f70, %r52;
	neg.f32 	%f71, %f70;
	sub.f32 	%f72, %f50, %f70;
	mov.f32 	%f73, %f71;
	mov.f32 	%f74, %f69;
	add.f32 	%f75, %f72, %f72;
	mov.f32 	%f76, %f75;
	mad.f32 %f77, %f73, %f74, %f76;
	mov.f32 	%f78, %f77;
	mov.f32 	%f79, %f71;
	sub.f32 	%f80, %f50, %f69;
	mov.f32 	%f81, %f80;
	mov.f32 	%f82, %f78;
	mad.f32 %f83, %f79, %f81, %f82;
	mov.f32 	%f84, %f83;
	.loc	17	9122	0
	mul.rn.f32 	%f85, %f48, %f84;
	add.f32 	%f86, %f85, %f70;
	add.f32 	%f87, %f86, %f68;
	sub.f32 	%f88, %f70, %f86;
	sub.f32 	%f89, %f86, %f87;
	add.f32 	%f90, %f85, %f88;
	add.f32 	%f91, %f89, %f68;
	add.f32 	%f92, %f90, %f91;
	add.f32 	%f93, %f87, %f92;
	.loc	17	9123	0
	sub.f32 	%f94, %f87, %f93;
	add.f32 	%f95, %f92, %f94;
	.loc	17	9130	0
	mov.f32 	%f96, 0f3f317200;    	// 0.693146
	mul.rn.f32 	%f97, %f40, %f96;
	add.f32 	%f98, %f97, %f93;
	.loc	17	9131	0
	mov.f32 	%f99, 0f35bfbe8e;    	// 1.42861e-06
	mul.rn.f32 	%f100, %f40, %f99;
	sub.f32 	%f101, %f97, %f98;
	add.f32 	%f102, %f101, %f93;
	add.f32 	%f103, %f102, %f95;
	add.f32 	%f104, %f100, %f103;
	.loc	17	9132	0
	add.f32 	%f105, %f104, %f98;
	.loc	17	8936	0
	mov.f32 	%f106, 0f39000000;   	// 0.00012207
	mul.f32 	%f107, %f2, %f106;
	mov.f32 	%f108, 0f77f684df;   	// 1e+34
	setp.gt.f32 	%p21, %f8, %f108;
	selp.f32 	%f109, %f107, %f2, %p21;
	neg.f32 	%f110, %f109;
	mov.f32 	%f111, %f110;
	mov.f32 	%f112, 0f45800800;   	// 4097
	mov.f32 	%f113, %f112;
	mov.f32 	%f114, %f109;
	mad.f32 %f115, %f111, %f113, %f114;
	mov.f32 	%f116, %f115;
	mov.f32 	%f117, %f109;
	mov.f32 	%f118, 0f45800800;   	// 4097
	mov.f32 	%f119, %f118;
	mov.f32 	%f120, %f116;
	mad.f32 %f121, %f117, %f119, %f120;
	mov.f32 	%f122, %f121;
	.loc	17	9150	0
	mov.f32 	%f123, %f122;
	.loc	17	8936	0
	neg.f32 	%f124, %f105;
	mov.f32 	%f125, %f124;
	mov.f32 	%f126, 0f45800800;   	// 4097
	mov.f32 	%f127, %f126;
	mov.f32 	%f128, %f105;
	mad.f32 %f129, %f125, %f127, %f128;
	mov.f32 	%f116, %f129;
	mov.f32 	%f130, %f105;
	mov.f32 	%f131, 0f45800800;   	// 4097
	mov.f32 	%f132, %f131;
	mov.f32 	%f133, %f116;
	mad.f32 %f134, %f130, %f132, %f133;
	mov.f32 	%f116, %f134;
	.loc	17	9151	0
	mov.f32 	%f135, %f116;
	.loc	17	9153	0
	sub.f32 	%f136, %f105, %f116;
	.loc	17	8936	0
	mul.rn.f32 	%f137, %f109, %f105;
	mov.f32 	%f138, %f123;
	mov.f32 	%f139, %f116;
	neg.f32 	%f140, %f137;
	mov.f32 	%f141, %f140;
	mad.f32 %f142, %f138, %f139, %f141;
	mov.f32 	%f116, %f142;
	mov.f32 	%f143, %f123;
	mov.f32 	%f144, %f136;
	mov.f32 	%f145, %f116;
	mad.f32 %f146, %f143, %f144, %f145;
	mov.f32 	%f116, %f146;
	sub.f32 	%f147, %f109, %f122;
	mov.f32 	%f148, %f135;
	mov.f32 	%f149, %f147;
	mov.f32 	%f150, %f116;
	mad.f32 %f151, %f148, %f149, %f150;
	mov.f32 	%f116, %f151;
	mov.f32 	%f152, %f147;
	mov.f32 	%f153, %f136;
	mov.f32 	%f154, %f116;
	mad.f32 %f155, %f152, %f153, %f154;
	mov.f32 	%f116, %f155;
	.loc	17	9159	0
	sub.f32 	%f156, %f98, %f105;
	mov.f32 	%f157, 0f00000000;   	// 0
	mul.rn.f32 	%f158, %f157, %f105;
	add.f32 	%f159, %f156, %f104;
	mul.rn.f32 	%f160, %f109, %f159;
	add.f32 	%f161, %f158, %f160;
	add.f32 	%f162, %f161, %f116;
	add.rn.f32 	%f163, %f137, %f162;
	sub.f32 	%f164, %f137, %f163;
	add.rn.f32 	%f165, %f164, %f162;
	.loc	17	11157	0
	mov.f32 	%f166, %f165;
	mov.f32 	%f167, %f163;
	mov.b32 	%r53, %f163;
	mov.u32 	%r54, 1118925336;
	setp.ne.s32 	%p22, %r53, %r54;
	@%p22 bra 	$Lt_46_22786;
	.loc	17	11161	0
	sub.s32 	%r55, %r53, 1;
	mov.b32 	%f167, %r55;
	.loc	17	11162	0
	mov.f32 	%f168, 0f37000000;   	// 7.62939e-06
	add.f32 	%f166, %f165, %f168;
$Lt_46_22786:
	.loc	17	8936	0
	mov.f32 	%f169, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f170, %f167, %f169;
	cvt.rzi.f32.f32 	%f171, %f170;
	mov.f32 	%f172, %f171;
	mov.f32 	%f173, 0fbf317200;   	// -0.693146
	mov.f32 	%f174, %f173;
	mov.f32 	%f175, %f167;
	mad.f32 %f176, %f172, %f174, %f175;
	mov.f32 	%f177, %f176;
	mov.f32 	%f178, %f171;
	mov.f32 	%f179, 0fb5bfbe8e;   	// -1.42861e-06
	mov.f32 	%f180, %f179;
	mov.f32 	%f181, %f177;
	mad.f32 %f182, %f178, %f180, %f181;
	mov.f32 	%f183, %f182;
	.loc	17	8965	0
	mov.f32 	%f184, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f185, %f183, %f184;
	mov.f32 	%f186, %f185;
	ex2.approx.ftz.f32 %f187,%f186;
	mov.f32 	%f188, %f187;
	.loc	17	11166	0
	mov.f32 	%f189, 0f42d20000;   	// 105
	setp.gt.f32 	%p23, %f167, %f189;
	mov.f32 	%f190, 0fc2d20000;   	// -105
	setp.lt.f32 	%p24, %f167, %f190;
	ex2.approx.f32 	%f191, %f171;
	mul.f32 	%f192, %f191, %f188;
	mov.f32 	%f193, 0f00000000;   	// 0
	selp.f32 	%f194, %f193, %f192, %p24;
	mov.f32 	%f195, 0f7f800000;   	// ((1.0F)/(0.0F))
	selp.f32 	%f196, %f195, %f194, %p23;
	mov.f32 	%f197, %f196;
	mov.f32 	%f198, 0f7f800000;   	// ((1.0F)/(0.0F))
	setp.neu.f32 	%p25, %f196, %f198;
	@!%p25 bra 	$Lt_46_23298;
	.loc	17	8936	0
	mov.f32 	%f199, %f197;
	mov.f32 	%f200, %f166;
	mov.f32 	%f201, %f197;
	mad.f32 %f202, %f199, %f200, %f201;
	mov.f32 	%f203, %f202;
	.loc	17	11172	0
	mov.f32 	%f197, %f203;
$Lt_46_23298:
	.loc	17	11244	0
	mov.f32 	%f5, %f197;
	mov.f32 	%f204, 0f3f000000;   	// 0.5
	mul.f32 	%f205, %f2, %f204;
	cvt.rzi.f32.f32 	%f206, %f205;
	selp.s32 	%r56, 1, 0, %p16;
	add.f32 	%f207, %f206, %f206;
	sub.f32 	%f208, %f2, %f207;
	abs.f32 	%f209, %f208;
	mov.f32 	%f210, 0f3f800000;   	// 1
	set.eq.u32.f32 	%r57, %f209, %f210;
	neg.s32 	%r58, %r57;
	and.b32 	%r59, %r56, %r58;
	mov.u32 	%r60, 0;
	setp.eq.s32 	%p26, %r59, %r60;
	@%p26 bra 	$Lt_46_23810;
	.loc	17	11246	0
	mov.b32 	%r61, %f5;
	xor.b32 	%r62, %r61, -2147483648;
	mov.b32 	%f5, %r62;
$Lt_46_23810:
$L_46_17922:
$Lt_46_21250:
$Lt_46_20226:
$Lt_46_19714:
$Lt_46_11010:
$Lt_46_19202:
	.loc	15	149	0
	ld.param.u64 	%rd9, [__cudaparm_epow_mvf_C];
	ld.param.s32 	%r63, [__cudaparm_epow_mvf_ldc];
	mul.lo.s32 	%r64, %r63, %r4;
	add.s32 	%r65, %r6, %r64;
	cvt.s64.s32 	%rd10, %r65;
	mul.wide.s32 	%rd11, %r65, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_46_18690:
	exit;
$LDWend_epow_mvf:
	} // epow_mvf

	.entry epow_mmf (
		.param .s32 __cudaparm_epow_mmf_rs,
		.param .s32 __cudaparm_epow_mmf_cs,
		.param .u64 __cudaparm_epow_mmf_A,
		.param .s32 __cudaparm_epow_mmf_lda,
		.param .u64 __cudaparm_epow_mmf_B,
		.param .s32 __cudaparm_epow_mmf_ldb,
		.param .u64 __cudaparm_epow_mmf_C,
		.param .s32 __cudaparm_epow_mmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<68>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<212>;
	.reg .pred %p<28>;
$LDWbegin_epow_mmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_epow_mmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_epow_mmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_47_18690;
	ld.param.u64 	%rd1, [__cudaparm_epow_mmf_A];
	ld.param.s32 	%r15, [__cudaparm_epow_mmf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_epow_mmf_B];
	ld.param.s32 	%r18, [__cudaparm_epow_mmf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	mov.f32 	%f3, 0f3f800000;     	// 1
	set.eq.u32.f32 	%r21, %f1, %f3;
	neg.s32 	%r22, %r21;
	mov.f32 	%f4, 0f00000000;     	// 0
	set.eq.u32.f32 	%r23, %f2, %f4;
	neg.s32 	%r24, %r23;
	or.b32 	%r25, %r22, %r24;
	mov.u32 	%r26, 0;
	setp.eq.s32 	%p2, %r25, %r26;
	@%p2 bra 	$Lt_47_19458;
	mov.f32 	%f5, 0f3f800000;     	// 1
	bra.uni 	$Lt_47_19202;
$Lt_47_19458:
	.loc	17	11223	0
	abs.f32 	%f6, %f1;
	mov.f32 	%f7, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.le.f32 	%p3, %f6, %f7;
	@!%p3 bra 	$Lt_47_10242;
	abs.f32 	%f8, %f2;
	mov.f32 	%f9, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.le.f32 	%p4, %f8, %f9;
	@%p4 bra 	$Lt_47_10498;
$Lt_47_10242:
	.loc	17	11224	0
	add.f32 	%f5, %f1, %f2;
	.loc	17	11223	0
	bra.uni 	$Lt_47_11010;
$Lt_47_10498:
	.loc	17	11225	0
	mov.f32 	%f10, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p5, %f8, %f10;
	@!%p5 bra 	$Lt_47_19970;
	.loc	17	11230	0
	mov.f32 	%f11, 0f3f800000;    	// 1
	setp.gt.f32 	%p6, %f6, %f11;
	mov.s32 	%r27, 1065353216;
	mov.s32 	%r28, 0;
	mov.s32 	%r29, 2139095040;
	selp.s32 	%r30, %r28, %r29, %p6;
	mov.s32 	%r31, 2139095040;
	mov.s32 	%r32, 0;
	selp.s32 	%r33, %r31, %r32, %p6;
	mov.f32 	%f12, 0f00000000;    	// 0
	setp.lt.f32 	%p7, %f2, %f12;
	selp.s32 	%r34, %r30, %r33, %p7;
	mov.f32 	%f13, 0fbf800000;    	// -1
	setp.eq.f32 	%p8, %f1, %f13;
	selp.s32 	%r35, %r27, %r34, %p8;
	mov.b32 	%f5, %r35;
	bra.uni 	$Lt_47_19714;
$Lt_47_19970:
	.loc	17	11231	0
	mov.f32 	%f14, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p9, %f6, %f14;
	@!%p9 bra 	$Lt_47_20482;
	.loc	17	11232	0
	mov.s32 	%r36, 2139095040;
	mov.s32 	%r37, 0;
	mov.f32 	%f15, 0f00000000;    	// 0
	setp.ge.f32 	%p10, %f2, %f15;
	selp.s32 	%r38, %r36, %r37, %p10;
	mov.f32 	%f16, 0f3f000000;    	// 0.5
	mul.f32 	%f17, %f2, %f16;
	cvt.rzi.f32.f32 	%f18, %f17;
	add.f32 	%f19, %f18, %f18;
	sub.f32 	%f20, %f2, %f19;
	abs.f32 	%f21, %f20;
	mov.f32 	%f22, 0f3f800000;    	// 1
	set.eq.u32.f32 	%r39, %f21, %f22;
	neg.s32 	%r40, %r39;
	mov.f32 	%f23, 0f00000000;    	// 0
	set.lt.u32.f32 	%r41, %f1, %f23;
	neg.s32 	%r42, %r41;
	and.b32 	%r43, %r40, %r42;
	mov.u32 	%r44, 0;
	setp.eq.s32 	%p11, %r43, %r44;
	@%p11 bra 	$Lt_47_20738;
	.loc	17	11234	0
	xor.b32 	%r38, %r38, -2147483648;
$Lt_47_20738:
	.loc	17	11235	0
	mov.b32 	%f5, %r38;
	bra.uni 	$Lt_47_20226;
$Lt_47_20482:
	mov.f32 	%f24, 0f00000000;    	// 0
	setp.eq.f32 	%p12, %f1, %f24;
	@!%p12 bra 	$Lt_47_21506;
	mov.f32 	%f25, 0f3f000000;    	// 0.5
	mul.f32 	%f26, %f2, %f25;
	cvt.rzi.f32.f32 	%f27, %f26;
	add.f32 	%f28, %f27, %f27;
	sub.f32 	%f29, %f2, %f28;
	abs.f32 	%f30, %f29;
	mov.f32 	%f31, 0f3f800000;    	// 1
	setp.eq.f32 	%p13, %f30, %f31;
	@!%p13 bra 	$Lt_47_22018;
	.loc	17	11238	0
	add.f32 	%f32, %f1, %f1;
	mov.b32 	%r38, %f32;
	bra.uni 	$Lt_47_21762;
$Lt_47_22018:
	mov.s32 	%r38, 0;
$Lt_47_21762:
	.loc	17	11239	0
	or.b32 	%r45, %r38, 2139095040;
	mov.f32 	%f33, 0f00000000;    	// 0
	setp.lt.f32 	%p14, %f2, %f33;
	selp.s32 	%r38, %r45, %r38, %p14;
	.loc	17	11240	0
	mov.b32 	%f5, %r38;
	bra.uni 	$Lt_47_21250;
$Lt_47_21506:
	.loc	17	11241	0
	mov.f32 	%f34, 0f00000000;    	// 0
	setp.lt.f32 	%p15, %f1, %f34;
	mov.pred 	%p16, %p15;
	mov.pred 	%p17, %p18;
	@!%p15 bra 	$Lt_47_24578;
	cvt.rzi.f32.f32 	%f35, %f2;
	setp.neu.f32 	%p19, %f2, %f35;
	@!%p19 bra 	$L_47_18178;
	.loc	17	11242	0
	mov.f32 	%f5, 0f7fffffff;     	// nan
	bra.uni 	$L_47_17922;
$Lt_47_24578:
$L_47_18178:
	.loc	17	9078	0
	mov.b32 	%r46, %f6;
	and.b32 	%r47, %r46, 8388607;
	or.b32 	%r48, %r47, 1065353216;
	mov.b32 	%f36, %r48;
	mov.f32 	%f37, %f36;
	.loc	17	9079	0
	shr.u32 	%r49, %r46, 23;
	cvt.rn.f32.u32 	%f38, %r49;
	mov.f32 	%f39, 0fc2fe0000;    	// -127
	add.f32 	%f40, %f38, %f39;
	mov.f32 	%f41, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p20, %f36, %f41;
	@!%p20 bra 	$Lt_47_22274;
	.loc	17	9081	0
	mov.f32 	%f42, 0f3f000000;    	// 0.5
	mul.f32 	%f37, %f36, %f42;
	.loc	17	9082	0
	mov.f32 	%f43, 0f3f800000;    	// 1
	add.f32 	%f40, %f40, %f43;
$Lt_47_22274:
	.loc	17	8944	0
	mov.f32 	%f44, 0f3f800000;    	// 1
	add.f32 	%f45, %f37, %f44;
	mov.f32 	%f46, %f45;
	rcp.approx.ftz.f32 %f47,%f46;
	mov.f32 	%f48, %f47;
	.loc	17	8936	0
	mov.f32 	%f49, 0fbf800000;    	// -1
	add.f32 	%f50, %f37, %f49;
	add.f32 	%f51, %f50, %f50;
	mul.f32 	%f52, %f51, %f48;
	mul.f32 	%f53, %f52, %f52;
	mov.f32 	%f54, 0f3b18f0fe;    	// 0.0023337
	mov.f32 	%f55, %f54;
	mov.f32 	%f56, %f53;
	mov.f32 	%f57, 0f3c4caf63;    	// 0.012493
	mov.f32 	%f58, %f57;
	mad.f32 %f59, %f55, %f56, %f58;
	mov.f32 	%f60, %f59;
	mov.f32 	%f61, %f60;
	mov.f32 	%f62, %f53;
	mov.f32 	%f63, 0f3daaaabd;    	// 0.0833335
	mov.f32 	%f64, %f63;
	mad.f32 %f65, %f61, %f62, %f64;
	mov.f32 	%f66, %f65;
	.loc	17	9099	0
	mul.rn.f32 	%f67, %f66, %f53;
	mul.rn.f32 	%f68, %f67, %f52;
	.loc	17	8936	0
	mov.b32 	%r50, %f50;
	mov.b32 	%r51, %f52;
	and.b32 	%r52, %r50, -4096;
	mov.b32 	%f69, %r52;
	and.b32 	%r53, %r51, -4096;
	mov.b32 	%f70, %r53;
	neg.f32 	%f71, %f70;
	sub.f32 	%f72, %f50, %f70;
	mov.f32 	%f73, %f71;
	mov.f32 	%f74, %f69;
	add.f32 	%f75, %f72, %f72;
	mov.f32 	%f76, %f75;
	mad.f32 %f77, %f73, %f74, %f76;
	mov.f32 	%f78, %f77;
	mov.f32 	%f79, %f71;
	sub.f32 	%f80, %f50, %f69;
	mov.f32 	%f81, %f80;
	mov.f32 	%f82, %f78;
	mad.f32 %f83, %f79, %f81, %f82;
	mov.f32 	%f84, %f83;
	.loc	17	9122	0
	mul.rn.f32 	%f85, %f48, %f84;
	add.f32 	%f86, %f85, %f70;
	add.f32 	%f87, %f86, %f68;
	sub.f32 	%f88, %f70, %f86;
	sub.f32 	%f89, %f86, %f87;
	add.f32 	%f90, %f85, %f88;
	add.f32 	%f91, %f89, %f68;
	add.f32 	%f92, %f90, %f91;
	add.f32 	%f93, %f87, %f92;
	.loc	17	9123	0
	sub.f32 	%f94, %f87, %f93;
	add.f32 	%f95, %f92, %f94;
	.loc	17	9130	0
	mov.f32 	%f96, 0f3f317200;    	// 0.693146
	mul.rn.f32 	%f97, %f40, %f96;
	add.f32 	%f98, %f97, %f93;
	.loc	17	9131	0
	mov.f32 	%f99, 0f35bfbe8e;    	// 1.42861e-06
	mul.rn.f32 	%f100, %f40, %f99;
	sub.f32 	%f101, %f97, %f98;
	add.f32 	%f102, %f101, %f93;
	add.f32 	%f103, %f102, %f95;
	add.f32 	%f104, %f100, %f103;
	.loc	17	9132	0
	add.f32 	%f105, %f104, %f98;
	.loc	17	8936	0
	mov.f32 	%f106, 0f39000000;   	// 0.00012207
	mul.f32 	%f107, %f2, %f106;
	mov.f32 	%f108, 0f77f684df;   	// 1e+34
	setp.gt.f32 	%p21, %f8, %f108;
	selp.f32 	%f109, %f107, %f2, %p21;
	neg.f32 	%f110, %f109;
	mov.f32 	%f111, %f110;
	mov.f32 	%f112, 0f45800800;   	// 4097
	mov.f32 	%f113, %f112;
	mov.f32 	%f114, %f109;
	mad.f32 %f115, %f111, %f113, %f114;
	mov.f32 	%f116, %f115;
	mov.f32 	%f117, %f109;
	mov.f32 	%f118, 0f45800800;   	// 4097
	mov.f32 	%f119, %f118;
	mov.f32 	%f120, %f116;
	mad.f32 %f121, %f117, %f119, %f120;
	mov.f32 	%f122, %f121;
	.loc	17	9150	0
	mov.f32 	%f123, %f122;
	.loc	17	8936	0
	neg.f32 	%f124, %f105;
	mov.f32 	%f125, %f124;
	mov.f32 	%f126, 0f45800800;   	// 4097
	mov.f32 	%f127, %f126;
	mov.f32 	%f128, %f105;
	mad.f32 %f129, %f125, %f127, %f128;
	mov.f32 	%f116, %f129;
	mov.f32 	%f130, %f105;
	mov.f32 	%f131, 0f45800800;   	// 4097
	mov.f32 	%f132, %f131;
	mov.f32 	%f133, %f116;
	mad.f32 %f134, %f130, %f132, %f133;
	mov.f32 	%f116, %f134;
	.loc	17	9151	0
	mov.f32 	%f135, %f116;
	.loc	17	9153	0
	sub.f32 	%f136, %f105, %f116;
	.loc	17	8936	0
	mul.rn.f32 	%f137, %f109, %f105;
	mov.f32 	%f138, %f123;
	mov.f32 	%f139, %f116;
	neg.f32 	%f140, %f137;
	mov.f32 	%f141, %f140;
	mad.f32 %f142, %f138, %f139, %f141;
	mov.f32 	%f116, %f142;
	mov.f32 	%f143, %f123;
	mov.f32 	%f144, %f136;
	mov.f32 	%f145, %f116;
	mad.f32 %f146, %f143, %f144, %f145;
	mov.f32 	%f116, %f146;
	sub.f32 	%f147, %f109, %f122;
	mov.f32 	%f148, %f135;
	mov.f32 	%f149, %f147;
	mov.f32 	%f150, %f116;
	mad.f32 %f151, %f148, %f149, %f150;
	mov.f32 	%f116, %f151;
	mov.f32 	%f152, %f147;
	mov.f32 	%f153, %f136;
	mov.f32 	%f154, %f116;
	mad.f32 %f155, %f152, %f153, %f154;
	mov.f32 	%f116, %f155;
	.loc	17	9159	0
	sub.f32 	%f156, %f98, %f105;
	mov.f32 	%f157, 0f00000000;   	// 0
	mul.rn.f32 	%f158, %f157, %f105;
	add.f32 	%f159, %f156, %f104;
	mul.rn.f32 	%f160, %f109, %f159;
	add.f32 	%f161, %f158, %f160;
	add.f32 	%f162, %f161, %f116;
	add.rn.f32 	%f163, %f137, %f162;
	sub.f32 	%f164, %f137, %f163;
	add.rn.f32 	%f165, %f164, %f162;
	.loc	17	11157	0
	mov.f32 	%f166, %f165;
	mov.f32 	%f167, %f163;
	mov.b32 	%r54, %f163;
	mov.u32 	%r55, 1118925336;
	setp.ne.s32 	%p22, %r54, %r55;
	@%p22 bra 	$Lt_47_22786;
	.loc	17	11161	0
	sub.s32 	%r56, %r54, 1;
	mov.b32 	%f167, %r56;
	.loc	17	11162	0
	mov.f32 	%f168, 0f37000000;   	// 7.62939e-06
	add.f32 	%f166, %f165, %f168;
$Lt_47_22786:
	.loc	17	8936	0
	mov.f32 	%f169, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f170, %f167, %f169;
	cvt.rzi.f32.f32 	%f171, %f170;
	mov.f32 	%f172, %f171;
	mov.f32 	%f173, 0fbf317200;   	// -0.693146
	mov.f32 	%f174, %f173;
	mov.f32 	%f175, %f167;
	mad.f32 %f176, %f172, %f174, %f175;
	mov.f32 	%f177, %f176;
	mov.f32 	%f178, %f171;
	mov.f32 	%f179, 0fb5bfbe8e;   	// -1.42861e-06
	mov.f32 	%f180, %f179;
	mov.f32 	%f181, %f177;
	mad.f32 %f182, %f178, %f180, %f181;
	mov.f32 	%f183, %f182;
	.loc	17	8965	0
	mov.f32 	%f184, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f185, %f183, %f184;
	mov.f32 	%f186, %f185;
	ex2.approx.ftz.f32 %f187,%f186;
	mov.f32 	%f188, %f187;
	.loc	17	11166	0
	mov.f32 	%f189, 0f42d20000;   	// 105
	setp.gt.f32 	%p23, %f167, %f189;
	mov.f32 	%f190, 0fc2d20000;   	// -105
	setp.lt.f32 	%p24, %f167, %f190;
	ex2.approx.f32 	%f191, %f171;
	mul.f32 	%f192, %f191, %f188;
	mov.f32 	%f193, 0f00000000;   	// 0
	selp.f32 	%f194, %f193, %f192, %p24;
	mov.f32 	%f195, 0f7f800000;   	// ((1.0F)/(0.0F))
	selp.f32 	%f196, %f195, %f194, %p23;
	mov.f32 	%f197, %f196;
	mov.f32 	%f198, 0f7f800000;   	// ((1.0F)/(0.0F))
	setp.neu.f32 	%p25, %f196, %f198;
	@!%p25 bra 	$Lt_47_23298;
	.loc	17	8936	0
	mov.f32 	%f199, %f197;
	mov.f32 	%f200, %f166;
	mov.f32 	%f201, %f197;
	mad.f32 %f202, %f199, %f200, %f201;
	mov.f32 	%f203, %f202;
	.loc	17	11172	0
	mov.f32 	%f197, %f203;
$Lt_47_23298:
	.loc	17	11244	0
	mov.f32 	%f5, %f197;
	mov.f32 	%f204, 0f3f000000;   	// 0.5
	mul.f32 	%f205, %f2, %f204;
	cvt.rzi.f32.f32 	%f206, %f205;
	selp.s32 	%r57, 1, 0, %p16;
	add.f32 	%f207, %f206, %f206;
	sub.f32 	%f208, %f2, %f207;
	abs.f32 	%f209, %f208;
	mov.f32 	%f210, 0f3f800000;   	// 1
	set.eq.u32.f32 	%r58, %f209, %f210;
	neg.s32 	%r59, %r58;
	and.b32 	%r60, %r57, %r59;
	mov.u32 	%r61, 0;
	setp.eq.s32 	%p26, %r60, %r61;
	@%p26 bra 	$Lt_47_23810;
	.loc	17	11246	0
	mov.b32 	%r62, %f5;
	xor.b32 	%r63, %r62, -2147483648;
	mov.b32 	%f5, %r63;
$Lt_47_23810:
$L_47_17922:
$Lt_47_21250:
$Lt_47_20226:
$Lt_47_19714:
$Lt_47_11010:
$Lt_47_19202:
	.loc	15	149	0
	ld.param.u64 	%rd9, [__cudaparm_epow_mmf_C];
	ld.param.s32 	%r64, [__cudaparm_epow_mmf_ldc];
	mul.lo.s32 	%r65, %r64, %r4;
	add.s32 	%r66, %r6, %r65;
	cvt.s64.s32 	%rd10, %r66;
	mul.wide.s32 	%rd11, %r66, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_47_18690:
	exit;
$LDWend_epow_mmf:
	} // epow_mmf

	.entry edim_vsf (
		.param .u64 __cudaparm_edim_vsf_n,
		.param .u64 __cudaparm_edim_vsf_x,
		.param .s32 __cudaparm_edim_vsf_lx,
		.param .f32 __cudaparm_edim_vsf_y,
		.param .u64 __cudaparm_edim_vsf_result,
		.param .s32 __cudaparm_edim_vsf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
	.loc	15	150	0
$LDWbegin_edim_vsf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_edim_vsf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_48_1794;
	ld.param.u64 	%rd3, [__cudaparm_edim_vsf_x];
	ld.param.s32 	%r4, [__cudaparm_edim_vsf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.f32 	%f2, [__cudaparm_edim_vsf_y];
	mov.f32 	%f3, 0f00000000;     	// 0
	sub.f32 	%f4, %f1, %f2;
	setp.le.f32 	%p2, %f1, %f2;
	selp.f32 	%f5, %f3, %f4, %p2;
	ld.param.u64 	%rd7, [__cudaparm_edim_vsf_result];
	ld.param.s32 	%r6, [__cudaparm_edim_vsf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f5;
$Lt_48_1794:
	exit;
$LDWend_edim_vsf:
	} // edim_vsf

	.entry edim_msf (
		.param .s32 __cudaparm_edim_msf_rs,
		.param .s32 __cudaparm_edim_msf_cs,
		.param .u64 __cudaparm_edim_msf_A,
		.param .s32 __cudaparm_edim_msf_lda,
		.param .f32 __cudaparm_edim_msf_B,
		.param .u64 __cudaparm_edim_msf_C,
		.param .s32 __cudaparm_edim_msf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_edim_msf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_edim_msf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_edim_msf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_49_2050;
	ld.param.u64 	%rd1, [__cudaparm_edim_msf_A];
	ld.param.s32 	%r15, [__cudaparm_edim_msf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.f32 	%f2, [__cudaparm_edim_msf_B];
	mov.f32 	%f3, 0f00000000;     	// 0
	sub.f32 	%f4, %f1, %f2;
	setp.le.f32 	%p2, %f1, %f2;
	selp.f32 	%f5, %f3, %f4, %p2;
	ld.param.u64 	%rd5, [__cudaparm_edim_msf_C];
	ld.param.s32 	%r18, [__cudaparm_edim_msf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f5;
$Lt_49_2050:
	exit;
$LDWend_edim_msf:
	} // edim_msf

	.entry edim_svf (
		.param .u64 __cudaparm_edim_svf_n,
		.param .f32 __cudaparm_edim_svf_x,
		.param .u64 __cudaparm_edim_svf_y,
		.param .s32 __cudaparm_edim_svf_ly,
		.param .u64 __cudaparm_edim_svf_result,
		.param .s32 __cudaparm_edim_svf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_edim_svf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_edim_svf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_50_1794;
	ld.param.u64 	%rd3, [__cudaparm_edim_svf_y];
	ld.param.s32 	%r4, [__cudaparm_edim_svf_ly];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.f32 	%f2, [__cudaparm_edim_svf_x];
	mov.f32 	%f3, 0f00000000;     	// 0
	sub.f32 	%f4, %f2, %f1;
	setp.ge.f32 	%p2, %f1, %f2;
	selp.f32 	%f5, %f3, %f4, %p2;
	ld.param.u64 	%rd7, [__cudaparm_edim_svf_result];
	ld.param.s32 	%r6, [__cudaparm_edim_svf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f5;
$Lt_50_1794:
	exit;
$LDWend_edim_svf:
	} // edim_svf

	.entry edim_smf (
		.param .s32 __cudaparm_edim_smf_rs,
		.param .s32 __cudaparm_edim_smf_cs,
		.param .f32 __cudaparm_edim_smf_A,
		.param .u64 __cudaparm_edim_smf_B,
		.param .s32 __cudaparm_edim_smf_ldb,
		.param .u64 __cudaparm_edim_smf_C,
		.param .s32 __cudaparm_edim_smf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_edim_smf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_edim_smf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_edim_smf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_51_2050;
	ld.param.u64 	%rd1, [__cudaparm_edim_smf_B];
	ld.param.s32 	%r15, [__cudaparm_edim_smf_ldb];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.f32 	%f2, [__cudaparm_edim_smf_A];
	mov.f32 	%f3, 0f00000000;     	// 0
	sub.f32 	%f4, %f2, %f1;
	setp.ge.f32 	%p2, %f1, %f2;
	selp.f32 	%f5, %f3, %f4, %p2;
	ld.param.u64 	%rd5, [__cudaparm_edim_smf_C];
	ld.param.s32 	%r18, [__cudaparm_edim_smf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f5;
$Lt_51_2050:
	exit;
$LDWend_edim_smf:
	} // edim_smf

	.entry edim_vvf (
		.param .u64 __cudaparm_edim_vvf_n,
		.param .u64 __cudaparm_edim_vvf_x,
		.param .s32 __cudaparm_edim_vvf_lx,
		.param .u64 __cudaparm_edim_vvf_y,
		.param .s32 __cudaparm_edim_vvf_ly,
		.param .u64 __cudaparm_edim_vvf_result,
		.param .s32 __cudaparm_edim_vvf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<11>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_edim_vvf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_edim_vvf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_52_1794;
	ld.param.u64 	%rd3, [__cudaparm_edim_vvf_x];
	ld.param.s32 	%r4, [__cudaparm_edim_vvf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_edim_vvf_y];
	ld.param.s32 	%r6, [__cudaparm_edim_vvf_ly];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.global.f32 	%f2, [%rd10+0];
	mov.f32 	%f3, 0f00000000;     	// 0
	sub.f32 	%f4, %f1, %f2;
	setp.le.f32 	%p2, %f1, %f2;
	selp.f32 	%f5, %f3, %f4, %p2;
	ld.param.u64 	%rd11, [__cudaparm_edim_vvf_result];
	ld.param.s32 	%r8, [__cudaparm_edim_vvf_lr];
	mul.lo.s32 	%r9, %r8, %r3;
	cvt.s64.s32 	%rd12, %r9;
	mul.wide.s32 	%rd13, %r9, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f5;
$Lt_52_1794:
	exit;
$LDWend_edim_vvf:
	} // edim_vvf

	.entry edim_vmf (
		.param .s32 __cudaparm_edim_vmf_rs,
		.param .s32 __cudaparm_edim_vmf_cs,
		.param .u64 __cudaparm_edim_vmf_x,
		.param .s32 __cudaparm_edim_vmf_lx,
		.param .u64 __cudaparm_edim_vmf_B,
		.param .s32 __cudaparm_edim_vmf_ldb,
		.param .u64 __cudaparm_edim_vmf_C,
		.param .s32 __cudaparm_edim_vmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_edim_vmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_edim_vmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_edim_vmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_53_2050;
	ld.param.u64 	%rd1, [__cudaparm_edim_vmf_x];
	ld.param.s32 	%r15, [__cudaparm_edim_vmf_lx];
	mul.lo.s32 	%r16, %r15, %r6;
	cvt.s64.s32 	%rd2, %r16;
	mul.wide.s32 	%rd3, %r16, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_edim_vmf_B];
	ld.param.s32 	%r17, [__cudaparm_edim_vmf_ldb];
	mul.lo.s32 	%r18, %r17, %r4;
	add.s32 	%r19, %r6, %r18;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	mov.f32 	%f3, 0f00000000;     	// 0
	sub.f32 	%f4, %f1, %f2;
	setp.le.f32 	%p2, %f1, %f2;
	selp.f32 	%f5, %f3, %f4, %p2;
	ld.param.u64 	%rd9, [__cudaparm_edim_vmf_C];
	ld.param.s32 	%r20, [__cudaparm_edim_vmf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_53_2050:
	exit;
$LDWend_edim_vmf:
	} // edim_vmf

	.entry edim_mvf (
		.param .s32 __cudaparm_edim_mvf_rs,
		.param .s32 __cudaparm_edim_mvf_cs,
		.param .u64 __cudaparm_edim_mvf_A,
		.param .s32 __cudaparm_edim_mvf_lda,
		.param .u64 __cudaparm_edim_mvf_y,
		.param .s32 __cudaparm_edim_mvf_ly,
		.param .u64 __cudaparm_edim_mvf_C,
		.param .s32 __cudaparm_edim_mvf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_edim_mvf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_edim_mvf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_edim_mvf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_54_2050;
	ld.param.u64 	%rd1, [__cudaparm_edim_mvf_A];
	ld.param.s32 	%r15, [__cudaparm_edim_mvf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_edim_mvf_y];
	ld.param.s32 	%r18, [__cudaparm_edim_mvf_ly];
	mul.lo.s32 	%r19, %r18, %r6;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	mov.f32 	%f3, 0f00000000;     	// 0
	sub.f32 	%f4, %f1, %f2;
	setp.le.f32 	%p2, %f1, %f2;
	selp.f32 	%f5, %f3, %f4, %p2;
	ld.param.u64 	%rd9, [__cudaparm_edim_mvf_C];
	ld.param.s32 	%r20, [__cudaparm_edim_mvf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_54_2050:
	exit;
$LDWend_edim_mvf:
	} // edim_mvf

	.entry edim_mmf (
		.param .s32 __cudaparm_edim_mmf_rs,
		.param .s32 __cudaparm_edim_mmf_cs,
		.param .u64 __cudaparm_edim_mmf_A,
		.param .s32 __cudaparm_edim_mmf_lda,
		.param .u64 __cudaparm_edim_mmf_B,
		.param .s32 __cudaparm_edim_mmf_ldb,
		.param .u64 __cudaparm_edim_mmf_C,
		.param .s32 __cudaparm_edim_mmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<25>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_edim_mmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_edim_mmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_edim_mmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_55_2050;
	ld.param.u64 	%rd1, [__cudaparm_edim_mmf_A];
	ld.param.s32 	%r15, [__cudaparm_edim_mmf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_edim_mmf_B];
	ld.param.s32 	%r18, [__cudaparm_edim_mmf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	mov.f32 	%f3, 0f00000000;     	// 0
	sub.f32 	%f4, %f1, %f2;
	setp.le.f32 	%p2, %f1, %f2;
	selp.f32 	%f5, %f3, %f4, %p2;
	ld.param.u64 	%rd9, [__cudaparm_edim_mmf_C];
	ld.param.s32 	%r21, [__cudaparm_edim_mmf_ldc];
	mul.lo.s32 	%r22, %r21, %r4;
	add.s32 	%r23, %r6, %r22;
	cvt.s64.s32 	%rd10, %r23;
	mul.wide.s32 	%rd11, %r23, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_55_2050:
	exit;
$LDWend_edim_mmf:
	} // edim_mmf

	.entry emax_vsf (
		.param .u64 __cudaparm_emax_vsf_n,
		.param .u64 __cudaparm_emax_vsf_x,
		.param .s32 __cudaparm_emax_vsf_lx,
		.param .f32 __cudaparm_emax_vsf_y,
		.param .u64 __cudaparm_emax_vsf_result,
		.param .s32 __cudaparm_emax_vsf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
	.loc	15	151	0
$LDWbegin_emax_vsf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_emax_vsf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_56_1026;
	ld.param.u64 	%rd3, [__cudaparm_emax_vsf_x];
	ld.param.s32 	%r4, [__cudaparm_emax_vsf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.f32 	%f2, [__cudaparm_emax_vsf_y];
	max.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_emax_vsf_result];
	ld.param.s32 	%r6, [__cudaparm_emax_vsf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f3;
$Lt_56_1026:
	exit;
$LDWend_emax_vsf:
	} // emax_vsf

	.entry emax_msf (
		.param .s32 __cudaparm_emax_msf_rs,
		.param .s32 __cudaparm_emax_msf_cs,
		.param .u64 __cudaparm_emax_msf_A,
		.param .s32 __cudaparm_emax_msf_lda,
		.param .f32 __cudaparm_emax_msf_B,
		.param .u64 __cudaparm_emax_msf_C,
		.param .s32 __cudaparm_emax_msf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emax_msf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emax_msf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emax_msf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_57_1282;
	ld.param.u64 	%rd1, [__cudaparm_emax_msf_A];
	ld.param.s32 	%r15, [__cudaparm_emax_msf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.f32 	%f2, [__cudaparm_emax_msf_B];
	max.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd5, [__cudaparm_emax_msf_C];
	ld.param.s32 	%r18, [__cudaparm_emax_msf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f3;
$Lt_57_1282:
	exit;
$LDWend_emax_msf:
	} // emax_msf

	.entry emax_svf (
		.param .u64 __cudaparm_emax_svf_n,
		.param .f32 __cudaparm_emax_svf_x,
		.param .u64 __cudaparm_emax_svf_y,
		.param .s32 __cudaparm_emax_svf_ly,
		.param .u64 __cudaparm_emax_svf_result,
		.param .s32 __cudaparm_emax_svf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emax_svf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_emax_svf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_58_1026;
	ld.param.u64 	%rd3, [__cudaparm_emax_svf_y];
	ld.param.s32 	%r4, [__cudaparm_emax_svf_ly];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.f32 	%f2, [__cudaparm_emax_svf_x];
	max.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_emax_svf_result];
	ld.param.s32 	%r6, [__cudaparm_emax_svf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f3;
$Lt_58_1026:
	exit;
$LDWend_emax_svf:
	} // emax_svf

	.entry emax_smf (
		.param .s32 __cudaparm_emax_smf_rs,
		.param .s32 __cudaparm_emax_smf_cs,
		.param .f32 __cudaparm_emax_smf_A,
		.param .u64 __cudaparm_emax_smf_B,
		.param .s32 __cudaparm_emax_smf_ldb,
		.param .u64 __cudaparm_emax_smf_C,
		.param .s32 __cudaparm_emax_smf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emax_smf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emax_smf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emax_smf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_59_1282;
	ld.param.u64 	%rd1, [__cudaparm_emax_smf_B];
	ld.param.s32 	%r15, [__cudaparm_emax_smf_ldb];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.f32 	%f2, [__cudaparm_emax_smf_A];
	max.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd5, [__cudaparm_emax_smf_C];
	ld.param.s32 	%r18, [__cudaparm_emax_smf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f3;
$Lt_59_1282:
	exit;
$LDWend_emax_smf:
	} // emax_smf

	.entry emax_vvf (
		.param .u64 __cudaparm_emax_vvf_n,
		.param .u64 __cudaparm_emax_vvf_x,
		.param .s32 __cudaparm_emax_vvf_lx,
		.param .u64 __cudaparm_emax_vvf_y,
		.param .s32 __cudaparm_emax_vvf_ly,
		.param .u64 __cudaparm_emax_vvf_result,
		.param .s32 __cudaparm_emax_vvf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<11>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emax_vvf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_emax_vvf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_60_1026;
	ld.param.u64 	%rd3, [__cudaparm_emax_vvf_x];
	ld.param.s32 	%r4, [__cudaparm_emax_vvf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_emax_vvf_y];
	ld.param.s32 	%r6, [__cudaparm_emax_vvf_ly];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.global.f32 	%f2, [%rd10+0];
	max.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd11, [__cudaparm_emax_vvf_result];
	ld.param.s32 	%r8, [__cudaparm_emax_vvf_lr];
	mul.lo.s32 	%r9, %r8, %r3;
	cvt.s64.s32 	%rd12, %r9;
	mul.wide.s32 	%rd13, %r9, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f3;
$Lt_60_1026:
	exit;
$LDWend_emax_vvf:
	} // emax_vvf

	.entry emax_vmf (
		.param .s32 __cudaparm_emax_vmf_rs,
		.param .s32 __cudaparm_emax_vmf_cs,
		.param .u64 __cudaparm_emax_vmf_x,
		.param .s32 __cudaparm_emax_vmf_lx,
		.param .u64 __cudaparm_emax_vmf_B,
		.param .s32 __cudaparm_emax_vmf_ldb,
		.param .u64 __cudaparm_emax_vmf_C,
		.param .s32 __cudaparm_emax_vmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emax_vmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emax_vmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emax_vmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_61_1282;
	ld.param.u64 	%rd1, [__cudaparm_emax_vmf_x];
	ld.param.s32 	%r15, [__cudaparm_emax_vmf_lx];
	mul.lo.s32 	%r16, %r15, %r6;
	cvt.s64.s32 	%rd2, %r16;
	mul.wide.s32 	%rd3, %r16, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_emax_vmf_B];
	ld.param.s32 	%r17, [__cudaparm_emax_vmf_ldb];
	mul.lo.s32 	%r18, %r17, %r4;
	add.s32 	%r19, %r6, %r18;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	max.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_emax_vmf_C];
	ld.param.s32 	%r20, [__cudaparm_emax_vmf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_61_1282:
	exit;
$LDWend_emax_vmf:
	} // emax_vmf

	.entry emax_mvf (
		.param .s32 __cudaparm_emax_mvf_rs,
		.param .s32 __cudaparm_emax_mvf_cs,
		.param .u64 __cudaparm_emax_mvf_A,
		.param .s32 __cudaparm_emax_mvf_lda,
		.param .u64 __cudaparm_emax_mvf_y,
		.param .s32 __cudaparm_emax_mvf_ly,
		.param .u64 __cudaparm_emax_mvf_C,
		.param .s32 __cudaparm_emax_mvf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emax_mvf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emax_mvf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emax_mvf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_62_1282;
	ld.param.u64 	%rd1, [__cudaparm_emax_mvf_A];
	ld.param.s32 	%r15, [__cudaparm_emax_mvf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_emax_mvf_y];
	ld.param.s32 	%r18, [__cudaparm_emax_mvf_ly];
	mul.lo.s32 	%r19, %r18, %r6;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	max.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_emax_mvf_C];
	ld.param.s32 	%r20, [__cudaparm_emax_mvf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_62_1282:
	exit;
$LDWend_emax_mvf:
	} // emax_mvf

	.entry emax_mmf (
		.param .s32 __cudaparm_emax_mmf_rs,
		.param .s32 __cudaparm_emax_mmf_cs,
		.param .u64 __cudaparm_emax_mmf_A,
		.param .s32 __cudaparm_emax_mmf_lda,
		.param .u64 __cudaparm_emax_mmf_B,
		.param .s32 __cudaparm_emax_mmf_ldb,
		.param .u64 __cudaparm_emax_mmf_C,
		.param .s32 __cudaparm_emax_mmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<25>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emax_mmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emax_mmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emax_mmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_63_1282;
	ld.param.u64 	%rd1, [__cudaparm_emax_mmf_A];
	ld.param.s32 	%r15, [__cudaparm_emax_mmf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_emax_mmf_B];
	ld.param.s32 	%r18, [__cudaparm_emax_mmf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	max.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_emax_mmf_C];
	ld.param.s32 	%r21, [__cudaparm_emax_mmf_ldc];
	mul.lo.s32 	%r22, %r21, %r4;
	add.s32 	%r23, %r6, %r22;
	cvt.s64.s32 	%rd10, %r23;
	mul.wide.s32 	%rd11, %r23, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_63_1282:
	exit;
$LDWend_emax_mmf:
	} // emax_mmf

	.entry emin_vsf (
		.param .u64 __cudaparm_emin_vsf_n,
		.param .u64 __cudaparm_emin_vsf_x,
		.param .s32 __cudaparm_emin_vsf_lx,
		.param .f32 __cudaparm_emin_vsf_y,
		.param .u64 __cudaparm_emin_vsf_result,
		.param .s32 __cudaparm_emin_vsf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
	.loc	15	152	0
$LDWbegin_emin_vsf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_emin_vsf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_64_1026;
	ld.param.u64 	%rd3, [__cudaparm_emin_vsf_x];
	ld.param.s32 	%r4, [__cudaparm_emin_vsf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.f32 	%f2, [__cudaparm_emin_vsf_y];
	min.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_emin_vsf_result];
	ld.param.s32 	%r6, [__cudaparm_emin_vsf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f3;
$Lt_64_1026:
	exit;
$LDWend_emin_vsf:
	} // emin_vsf

	.entry emin_msf (
		.param .s32 __cudaparm_emin_msf_rs,
		.param .s32 __cudaparm_emin_msf_cs,
		.param .u64 __cudaparm_emin_msf_A,
		.param .s32 __cudaparm_emin_msf_lda,
		.param .f32 __cudaparm_emin_msf_B,
		.param .u64 __cudaparm_emin_msf_C,
		.param .s32 __cudaparm_emin_msf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emin_msf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emin_msf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emin_msf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_65_1282;
	ld.param.u64 	%rd1, [__cudaparm_emin_msf_A];
	ld.param.s32 	%r15, [__cudaparm_emin_msf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.f32 	%f2, [__cudaparm_emin_msf_B];
	min.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd5, [__cudaparm_emin_msf_C];
	ld.param.s32 	%r18, [__cudaparm_emin_msf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f3;
$Lt_65_1282:
	exit;
$LDWend_emin_msf:
	} // emin_msf

	.entry emin_svf (
		.param .u64 __cudaparm_emin_svf_n,
		.param .f32 __cudaparm_emin_svf_x,
		.param .u64 __cudaparm_emin_svf_y,
		.param .s32 __cudaparm_emin_svf_ly,
		.param .u64 __cudaparm_emin_svf_result,
		.param .s32 __cudaparm_emin_svf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emin_svf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_emin_svf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_66_1026;
	ld.param.u64 	%rd3, [__cudaparm_emin_svf_y];
	ld.param.s32 	%r4, [__cudaparm_emin_svf_ly];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.f32 	%f2, [__cudaparm_emin_svf_x];
	min.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_emin_svf_result];
	ld.param.s32 	%r6, [__cudaparm_emin_svf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f3;
$Lt_66_1026:
	exit;
$LDWend_emin_svf:
	} // emin_svf

	.entry emin_smf (
		.param .s32 __cudaparm_emin_smf_rs,
		.param .s32 __cudaparm_emin_smf_cs,
		.param .f32 __cudaparm_emin_smf_A,
		.param .u64 __cudaparm_emin_smf_B,
		.param .s32 __cudaparm_emin_smf_ldb,
		.param .u64 __cudaparm_emin_smf_C,
		.param .s32 __cudaparm_emin_smf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emin_smf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emin_smf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emin_smf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_67_1282;
	ld.param.u64 	%rd1, [__cudaparm_emin_smf_B];
	ld.param.s32 	%r15, [__cudaparm_emin_smf_ldb];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.f32 	%f2, [__cudaparm_emin_smf_A];
	min.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd5, [__cudaparm_emin_smf_C];
	ld.param.s32 	%r18, [__cudaparm_emin_smf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f3;
$Lt_67_1282:
	exit;
$LDWend_emin_smf:
	} // emin_smf

	.entry emin_vvf (
		.param .u64 __cudaparm_emin_vvf_n,
		.param .u64 __cudaparm_emin_vvf_x,
		.param .s32 __cudaparm_emin_vvf_lx,
		.param .u64 __cudaparm_emin_vvf_y,
		.param .s32 __cudaparm_emin_vvf_ly,
		.param .u64 __cudaparm_emin_vvf_result,
		.param .s32 __cudaparm_emin_vvf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<11>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emin_vvf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_emin_vvf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_68_1026;
	ld.param.u64 	%rd3, [__cudaparm_emin_vvf_x];
	ld.param.s32 	%r4, [__cudaparm_emin_vvf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_emin_vvf_y];
	ld.param.s32 	%r6, [__cudaparm_emin_vvf_ly];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.global.f32 	%f2, [%rd10+0];
	min.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd11, [__cudaparm_emin_vvf_result];
	ld.param.s32 	%r8, [__cudaparm_emin_vvf_lr];
	mul.lo.s32 	%r9, %r8, %r3;
	cvt.s64.s32 	%rd12, %r9;
	mul.wide.s32 	%rd13, %r9, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f3;
$Lt_68_1026:
	exit;
$LDWend_emin_vvf:
	} // emin_vvf

	.entry emin_vmf (
		.param .s32 __cudaparm_emin_vmf_rs,
		.param .s32 __cudaparm_emin_vmf_cs,
		.param .u64 __cudaparm_emin_vmf_x,
		.param .s32 __cudaparm_emin_vmf_lx,
		.param .u64 __cudaparm_emin_vmf_B,
		.param .s32 __cudaparm_emin_vmf_ldb,
		.param .u64 __cudaparm_emin_vmf_C,
		.param .s32 __cudaparm_emin_vmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emin_vmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emin_vmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emin_vmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_69_1282;
	ld.param.u64 	%rd1, [__cudaparm_emin_vmf_x];
	ld.param.s32 	%r15, [__cudaparm_emin_vmf_lx];
	mul.lo.s32 	%r16, %r15, %r6;
	cvt.s64.s32 	%rd2, %r16;
	mul.wide.s32 	%rd3, %r16, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_emin_vmf_B];
	ld.param.s32 	%r17, [__cudaparm_emin_vmf_ldb];
	mul.lo.s32 	%r18, %r17, %r4;
	add.s32 	%r19, %r6, %r18;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	min.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_emin_vmf_C];
	ld.param.s32 	%r20, [__cudaparm_emin_vmf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_69_1282:
	exit;
$LDWend_emin_vmf:
	} // emin_vmf

	.entry emin_mvf (
		.param .s32 __cudaparm_emin_mvf_rs,
		.param .s32 __cudaparm_emin_mvf_cs,
		.param .u64 __cudaparm_emin_mvf_A,
		.param .s32 __cudaparm_emin_mvf_lda,
		.param .u64 __cudaparm_emin_mvf_y,
		.param .s32 __cudaparm_emin_mvf_ly,
		.param .u64 __cudaparm_emin_mvf_C,
		.param .s32 __cudaparm_emin_mvf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emin_mvf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emin_mvf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emin_mvf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_70_1282;
	ld.param.u64 	%rd1, [__cudaparm_emin_mvf_A];
	ld.param.s32 	%r15, [__cudaparm_emin_mvf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_emin_mvf_y];
	ld.param.s32 	%r18, [__cudaparm_emin_mvf_ly];
	mul.lo.s32 	%r19, %r18, %r6;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	min.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_emin_mvf_C];
	ld.param.s32 	%r20, [__cudaparm_emin_mvf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_70_1282:
	exit;
$LDWend_emin_mvf:
	} // emin_mvf

	.entry emin_mmf (
		.param .s32 __cudaparm_emin_mmf_rs,
		.param .s32 __cudaparm_emin_mmf_cs,
		.param .u64 __cudaparm_emin_mmf_A,
		.param .s32 __cudaparm_emin_mmf_lda,
		.param .u64 __cudaparm_emin_mmf_B,
		.param .s32 __cudaparm_emin_mmf_ldb,
		.param .u64 __cudaparm_emin_mmf_C,
		.param .s32 __cudaparm_emin_mmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<25>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_emin_mmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emin_mmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emin_mmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_71_1282;
	ld.param.u64 	%rd1, [__cudaparm_emin_mmf_A];
	ld.param.s32 	%r15, [__cudaparm_emin_mmf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_emin_mmf_B];
	ld.param.s32 	%r18, [__cudaparm_emin_mmf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	min.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd9, [__cudaparm_emin_mmf_C];
	ld.param.s32 	%r21, [__cudaparm_emin_mmf_ldc];
	mul.lo.s32 	%r22, %r21, %r4;
	add.s32 	%r23, %r6, %r22;
	cvt.s64.s32 	%rd10, %r23;
	mul.wide.s32 	%rd11, %r23, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f3;
$Lt_71_1282:
	exit;
$LDWend_emin_mmf:
	} // emin_mmf

	.entry emod_vsf (
		.param .u64 __cudaparm_emod_vsf_n,
		.param .u64 __cudaparm_emod_vsf_x,
		.param .s32 __cudaparm_emod_vsf_lx,
		.param .f32 __cudaparm_emod_vsf_y,
		.param .u64 __cudaparm_emod_vsf_result,
		.param .s32 __cudaparm_emod_vsf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<23>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<21>;
	.reg .pred %p<12>;
	.loc	15	153	0
$LDWbegin_emod_vsf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_emod_vsf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_72_6914;
	ld.param.u64 	%rd3, [__cudaparm_emod_vsf_x];
	ld.param.s32 	%r4, [__cudaparm_emod_vsf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	10940	0
	abs.f32 	%f2, %f1;
	ld.param.f32 	%f3, [__cudaparm_emod_vsf_y];
	abs.f32 	%f4, %f3;
	mov.f32 	%f5, 0f00000000;     	// 0
	set.eq.u32.f32 	%r6, %f4, %f5;
	neg.s32 	%r7, %r6;
	mov.f32 	%f6, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.eq.u32.f32 	%r8, %f2, %f6;
	neg.s32 	%r9, %r8;
	or.b32 	%r10, %r7, %r9;
	mov.u32 	%r11, 0;
	setp.eq.s32 	%p2, %r10, %r11;
	@%p2 bra 	$Lt_72_7682;
	mov.f32 	%f7, 0f7fffffff;     	// nan
	bra.uni 	$Lt_72_7426;
$Lt_72_7682:
	setp.le.f32 	%p3, %f4, %f2;
	@!%p3 bra 	$Lt_72_8194;
	.loc	17	10947	0
	mov.b32 	%r12, %f2;
	mov.b32 	%r13, %f4;
	and.b32 	%r14, %r12, 2139095040;
	and.b32 	%r15, %r13, 8388607;
	or.b32 	%r16, %r14, %r15;
	mov.b32 	%f8, %r16;
	setp.gt.f32 	%p4, %f8, %f2;
	mov.f32 	%f9, 0f3f000000;     	// 0.5
	mul.f32 	%f10, %f8, %f9;
	selp.f32 	%f11, %f10, %f8, %p4;
	mov.f32 	%f12, %f11;
	setp.le.f32 	%p5, %f4, %f11;
	@!%p5 bra 	$Lt_72_8450;
$Lt_72_8962:
	.loc	17	10962	0
	sub.f32 	%f13, %f2, %f12;
	setp.ge.f32 	%p6, %f2, %f12;
	selp.f32 	%f2, %f13, %f2, %p6;
	.loc	17	10965	0
	mov.f32 	%f14, 0f3f000000;    	// 0.5
	mul.f32 	%f12, %f12, %f14;
	setp.le.f32 	%p7, %f4, %f12;
	@%p7 bra 	$Lt_72_8962;
	mov.b32 	%r12, %f2;
$Lt_72_8450:
	.loc	17	10967	0
	mov.b32 	%r17, %f1;
	and.b32 	%r18, %r17, -2147483648;
	or.b32 	%r19, %r12, %r18;
	mov.b32 	%f7, %r19;
	bra.uni 	$Lt_72_7938;
$Lt_72_8194:
	.loc	17	10940	0
	ld.param.f32 	%f3, [__cudaparm_emod_vsf_y];
	.loc	17	10971	0
	add.f32 	%f15, %f1, %f3;
	mov.f32 	%f16, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p8, %f4, %f16;
	not.pred 	%p9, %p8;
	selp.f32 	%f17, %f15, %f1, %p9;
	add.f32 	%f18, %f17, %f1;
	mov.f32 	%f19, 0f00000000;    	// 0
	setp.gt.f32 	%p10, %f2, %f19;
	selp.f32 	%f7, %f17, %f18, %p10;
$Lt_72_7938:
$Lt_72_7426:
	.loc	15	153	0
	ld.param.u64 	%rd7, [__cudaparm_emod_vsf_result];
	ld.param.s32 	%r20, [__cudaparm_emod_vsf_lr];
	mul.lo.s32 	%r21, %r20, %r3;
	cvt.s64.s32 	%rd8, %r21;
	mul.wide.s32 	%rd9, %r21, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f7;
$Lt_72_6914:
	exit;
$LDWend_emod_vsf:
	} // emod_vsf

	.entry emod_msf (
		.param .s32 __cudaparm_emod_msf_rs,
		.param .s32 __cudaparm_emod_msf_cs,
		.param .u64 __cudaparm_emod_msf_A,
		.param .s32 __cudaparm_emod_msf_lda,
		.param .f32 __cudaparm_emod_msf_B,
		.param .u64 __cudaparm_emod_msf_C,
		.param .s32 __cudaparm_emod_msf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<36>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<21>;
	.reg .pred %p<12>;
$LDWbegin_emod_msf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emod_msf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emod_msf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_73_7170;
	ld.param.u64 	%rd1, [__cudaparm_emod_msf_A];
	ld.param.s32 	%r15, [__cudaparm_emod_msf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	10940	0
	abs.f32 	%f2, %f1;
	ld.param.f32 	%f3, [__cudaparm_emod_msf_B];
	abs.f32 	%f4, %f3;
	mov.f32 	%f5, 0f00000000;     	// 0
	set.eq.u32.f32 	%r18, %f4, %f5;
	neg.s32 	%r19, %r18;
	mov.f32 	%f6, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.eq.u32.f32 	%r20, %f2, %f6;
	neg.s32 	%r21, %r20;
	or.b32 	%r22, %r19, %r21;
	mov.u32 	%r23, 0;
	setp.eq.s32 	%p2, %r22, %r23;
	@%p2 bra 	$Lt_73_7938;
	mov.f32 	%f7, 0f7fffffff;     	// nan
	bra.uni 	$Lt_73_7682;
$Lt_73_7938:
	setp.le.f32 	%p3, %f4, %f2;
	@!%p3 bra 	$Lt_73_8450;
	.loc	17	10947	0
	mov.b32 	%r24, %f2;
	mov.b32 	%r25, %f4;
	and.b32 	%r26, %r24, 2139095040;
	and.b32 	%r27, %r25, 8388607;
	or.b32 	%r28, %r26, %r27;
	mov.b32 	%f8, %r28;
	setp.gt.f32 	%p4, %f8, %f2;
	mov.f32 	%f9, 0f3f000000;     	// 0.5
	mul.f32 	%f10, %f8, %f9;
	selp.f32 	%f11, %f10, %f8, %p4;
	mov.f32 	%f12, %f11;
	setp.le.f32 	%p5, %f4, %f11;
	@!%p5 bra 	$Lt_73_8706;
$Lt_73_9218:
	.loc	17	10962	0
	sub.f32 	%f13, %f2, %f12;
	setp.ge.f32 	%p6, %f2, %f12;
	selp.f32 	%f2, %f13, %f2, %p6;
	.loc	17	10965	0
	mov.f32 	%f14, 0f3f000000;    	// 0.5
	mul.f32 	%f12, %f12, %f14;
	setp.le.f32 	%p7, %f4, %f12;
	@%p7 bra 	$Lt_73_9218;
	mov.b32 	%r24, %f2;
$Lt_73_8706:
	.loc	17	10967	0
	mov.b32 	%r29, %f1;
	and.b32 	%r30, %r29, -2147483648;
	or.b32 	%r31, %r24, %r30;
	mov.b32 	%f7, %r31;
	bra.uni 	$Lt_73_8194;
$Lt_73_8450:
	.loc	17	10940	0
	ld.param.f32 	%f3, [__cudaparm_emod_msf_B];
	.loc	17	10971	0
	add.f32 	%f15, %f1, %f3;
	mov.f32 	%f16, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p8, %f4, %f16;
	not.pred 	%p9, %p8;
	selp.f32 	%f17, %f15, %f1, %p9;
	add.f32 	%f18, %f17, %f1;
	mov.f32 	%f19, 0f00000000;    	// 0
	setp.gt.f32 	%p10, %f2, %f19;
	selp.f32 	%f7, %f17, %f18, %p10;
$Lt_73_8194:
$Lt_73_7682:
	.loc	15	153	0
	ld.param.u64 	%rd5, [__cudaparm_emod_msf_C];
	ld.param.s32 	%r32, [__cudaparm_emod_msf_ldc];
	mul.lo.s32 	%r33, %r32, %r4;
	add.s32 	%r34, %r6, %r33;
	cvt.s64.s32 	%rd6, %r34;
	mul.wide.s32 	%rd7, %r34, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f7;
$Lt_73_7170:
	exit;
$LDWend_emod_msf:
	} // emod_msf

	.entry emod_svf (
		.param .u64 __cudaparm_emod_svf_n,
		.param .f32 __cudaparm_emod_svf_x,
		.param .u64 __cudaparm_emod_svf_y,
		.param .s32 __cudaparm_emod_svf_ly,
		.param .u64 __cudaparm_emod_svf_result,
		.param .s32 __cudaparm_emod_svf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<22>;
	.reg .pred %p<12>;
$LDWbegin_emod_svf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_emod_svf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_74_6914;
	ld.param.u64 	%rd3, [__cudaparm_emod_svf_y];
	ld.param.s32 	%r4, [__cudaparm_emod_svf_ly];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	10940	0
	ld.param.f32 	%f2, [__cudaparm_emod_svf_x];
	abs.f32 	%f3, %f2;
	mov.f32 	%f4, %f3;
	abs.f32 	%f5, %f1;
	mov.f32 	%f6, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.eq.u32.f32 	%r6, %f3, %f6;
	neg.s32 	%r7, %r6;
	mov.f32 	%f7, 0f00000000;     	// 0
	set.eq.u32.f32 	%r8, %f5, %f7;
	neg.s32 	%r9, %r8;
	or.b32 	%r10, %r7, %r9;
	mov.u32 	%r11, 0;
	setp.eq.s32 	%p2, %r10, %r11;
	@%p2 bra 	$Lt_74_7682;
	mov.f32 	%f8, 0f7fffffff;     	// nan
	bra.uni 	$Lt_74_7426;
$Lt_74_7682:
	setp.ge.f32 	%p3, %f3, %f5;
	@!%p3 bra 	$Lt_74_8194;
	.loc	17	10947	0
	mov.b32 	%r12, %f3;
	mov.b32 	%r13, %f5;
	and.b32 	%r14, %r12, 2139095040;
	and.b32 	%r15, %r13, 8388607;
	or.b32 	%r16, %r14, %r15;
	mov.b32 	%f9, %r16;
	setp.lt.f32 	%p4, %f3, %f9;
	mov.f32 	%f10, 0f3f000000;    	// 0.5
	mul.f32 	%f11, %f9, %f10;
	selp.f32 	%f12, %f11, %f9, %p4;
	mov.f32 	%f13, %f12;
	setp.le.f32 	%p5, %f5, %f12;
	@!%p5 bra 	$Lt_74_8450;
$Lt_74_8962:
	.loc	17	10962	0
	sub.f32 	%f14, %f4, %f13;
	setp.ge.f32 	%p6, %f4, %f13;
	selp.f32 	%f4, %f14, %f4, %p6;
	.loc	17	10965	0
	mov.f32 	%f15, 0f3f000000;    	// 0.5
	mul.f32 	%f13, %f13, %f15;
	setp.le.f32 	%p7, %f5, %f13;
	@%p7 bra 	$Lt_74_8962;
$Lt_74_8450:
	.loc	17	10967	0
	mov.b32 	%r17, %f4;
	.loc	17	10940	0
	ld.param.f32 	%f2, [__cudaparm_emod_svf_x];
	.loc	17	10967	0
	mov.b32 	%r18, %f2;
	and.b32 	%r19, %r18, -2147483648;
	or.b32 	%r20, %r17, %r19;
	mov.b32 	%f8, %r20;
	bra.uni 	$Lt_74_7938;
$Lt_74_8194:
	.loc	17	10940	0
	ld.param.f32 	%f2, [__cudaparm_emod_svf_x];
	.loc	17	10971	0
	add.f32 	%f16, %f1, %f2;
	mov.f32 	%f17, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p8, %f5, %f17;
	not.pred 	%p9, %p8;
	selp.f32 	%f18, %f16, %f2, %p9;
	add.f32 	%f19, %f18, %f2;
	mov.f32 	%f20, 0f00000000;    	// 0
	setp.gt.f32 	%p10, %f3, %f20;
	selp.f32 	%f8, %f18, %f19, %p10;
$Lt_74_7938:
$Lt_74_7426:
	.loc	15	153	0
	ld.param.u64 	%rd7, [__cudaparm_emod_svf_result];
	ld.param.s32 	%r21, [__cudaparm_emod_svf_lr];
	mul.lo.s32 	%r22, %r21, %r3;
	cvt.s64.s32 	%rd8, %r22;
	mul.wide.s32 	%rd9, %r22, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f8;
$Lt_74_6914:
	exit;
$LDWend_emod_svf:
	} // emod_svf

	.entry emod_smf (
		.param .s32 __cudaparm_emod_smf_rs,
		.param .s32 __cudaparm_emod_smf_cs,
		.param .f32 __cudaparm_emod_smf_A,
		.param .u64 __cudaparm_emod_smf_B,
		.param .s32 __cudaparm_emod_smf_ldb,
		.param .u64 __cudaparm_emod_smf_C,
		.param .s32 __cudaparm_emod_smf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<37>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<22>;
	.reg .pred %p<12>;
$LDWbegin_emod_smf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emod_smf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emod_smf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_75_7170;
	ld.param.u64 	%rd1, [__cudaparm_emod_smf_B];
	ld.param.s32 	%r15, [__cudaparm_emod_smf_ldb];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	10940	0
	ld.param.f32 	%f2, [__cudaparm_emod_smf_A];
	abs.f32 	%f3, %f2;
	mov.f32 	%f4, %f3;
	abs.f32 	%f5, %f1;
	mov.f32 	%f6, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.eq.u32.f32 	%r18, %f3, %f6;
	neg.s32 	%r19, %r18;
	mov.f32 	%f7, 0f00000000;     	// 0
	set.eq.u32.f32 	%r20, %f5, %f7;
	neg.s32 	%r21, %r20;
	or.b32 	%r22, %r19, %r21;
	mov.u32 	%r23, 0;
	setp.eq.s32 	%p2, %r22, %r23;
	@%p2 bra 	$Lt_75_7938;
	mov.f32 	%f8, 0f7fffffff;     	// nan
	bra.uni 	$Lt_75_7682;
$Lt_75_7938:
	setp.ge.f32 	%p3, %f3, %f5;
	@!%p3 bra 	$Lt_75_8450;
	.loc	17	10947	0
	mov.b32 	%r24, %f3;
	mov.b32 	%r25, %f5;
	and.b32 	%r26, %r24, 2139095040;
	and.b32 	%r27, %r25, 8388607;
	or.b32 	%r28, %r26, %r27;
	mov.b32 	%f9, %r28;
	setp.lt.f32 	%p4, %f3, %f9;
	mov.f32 	%f10, 0f3f000000;    	// 0.5
	mul.f32 	%f11, %f9, %f10;
	selp.f32 	%f12, %f11, %f9, %p4;
	mov.f32 	%f13, %f12;
	setp.le.f32 	%p5, %f5, %f12;
	@!%p5 bra 	$Lt_75_8706;
$Lt_75_9218:
	.loc	17	10962	0
	sub.f32 	%f14, %f4, %f13;
	setp.ge.f32 	%p6, %f4, %f13;
	selp.f32 	%f4, %f14, %f4, %p6;
	.loc	17	10965	0
	mov.f32 	%f15, 0f3f000000;    	// 0.5
	mul.f32 	%f13, %f13, %f15;
	setp.le.f32 	%p7, %f5, %f13;
	@%p7 bra 	$Lt_75_9218;
$Lt_75_8706:
	.loc	17	10967	0
	mov.b32 	%r29, %f4;
	.loc	17	10940	0
	ld.param.f32 	%f2, [__cudaparm_emod_smf_A];
	.loc	17	10967	0
	mov.b32 	%r30, %f2;
	and.b32 	%r31, %r30, -2147483648;
	or.b32 	%r32, %r29, %r31;
	mov.b32 	%f8, %r32;
	bra.uni 	$Lt_75_8194;
$Lt_75_8450:
	.loc	17	10940	0
	ld.param.f32 	%f2, [__cudaparm_emod_smf_A];
	.loc	17	10971	0
	add.f32 	%f16, %f1, %f2;
	mov.f32 	%f17, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p8, %f5, %f17;
	not.pred 	%p9, %p8;
	selp.f32 	%f18, %f16, %f2, %p9;
	add.f32 	%f19, %f18, %f2;
	mov.f32 	%f20, 0f00000000;    	// 0
	setp.gt.f32 	%p10, %f3, %f20;
	selp.f32 	%f8, %f18, %f19, %p10;
$Lt_75_8194:
$Lt_75_7682:
	.loc	15	153	0
	ld.param.u64 	%rd5, [__cudaparm_emod_smf_C];
	ld.param.s32 	%r33, [__cudaparm_emod_smf_ldc];
	mul.lo.s32 	%r34, %r33, %r4;
	add.s32 	%r35, %r6, %r34;
	cvt.s64.s32 	%rd6, %r35;
	mul.wide.s32 	%rd7, %r35, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f8;
$Lt_75_7170:
	exit;
$LDWend_emod_smf:
	} // emod_smf

	.entry emod_vvf (
		.param .u64 __cudaparm_emod_vvf_n,
		.param .u64 __cudaparm_emod_vvf_x,
		.param .s32 __cudaparm_emod_vvf_lx,
		.param .u64 __cudaparm_emod_vvf_y,
		.param .s32 __cudaparm_emod_vvf_ly,
		.param .u64 __cudaparm_emod_vvf_result,
		.param .s32 __cudaparm_emod_vvf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<25>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<21>;
	.reg .pred %p<12>;
$LDWbegin_emod_vvf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_emod_vvf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_76_6914;
	ld.param.u64 	%rd3, [__cudaparm_emod_vvf_x];
	ld.param.s32 	%r4, [__cudaparm_emod_vvf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_emod_vvf_y];
	ld.param.s32 	%r6, [__cudaparm_emod_vvf_ly];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.global.f32 	%f2, [%rd10+0];
	.loc	17	10940	0
	abs.f32 	%f3, %f1;
	abs.f32 	%f4, %f2;
	mov.f32 	%f5, 0f00000000;     	// 0
	set.eq.u32.f32 	%r8, %f4, %f5;
	neg.s32 	%r9, %r8;
	mov.f32 	%f6, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.eq.u32.f32 	%r10, %f3, %f6;
	neg.s32 	%r11, %r10;
	or.b32 	%r12, %r9, %r11;
	mov.u32 	%r13, 0;
	setp.eq.s32 	%p2, %r12, %r13;
	@%p2 bra 	$Lt_76_7682;
	mov.f32 	%f7, 0f7fffffff;     	// nan
	bra.uni 	$Lt_76_7426;
$Lt_76_7682:
	setp.le.f32 	%p3, %f4, %f3;
	@!%p3 bra 	$Lt_76_8194;
	.loc	17	10947	0
	mov.b32 	%r14, %f3;
	mov.b32 	%r15, %f4;
	and.b32 	%r16, %r14, 2139095040;
	and.b32 	%r17, %r15, 8388607;
	or.b32 	%r18, %r16, %r17;
	mov.b32 	%f8, %r18;
	setp.gt.f32 	%p4, %f8, %f3;
	mov.f32 	%f9, 0f3f000000;     	// 0.5
	mul.f32 	%f10, %f8, %f9;
	selp.f32 	%f11, %f10, %f8, %p4;
	mov.f32 	%f12, %f11;
	setp.le.f32 	%p5, %f4, %f11;
	@!%p5 bra 	$Lt_76_8450;
$Lt_76_8962:
	.loc	17	10962	0
	sub.f32 	%f13, %f3, %f12;
	setp.ge.f32 	%p6, %f3, %f12;
	selp.f32 	%f3, %f13, %f3, %p6;
	.loc	17	10965	0
	mov.f32 	%f14, 0f3f000000;    	// 0.5
	mul.f32 	%f12, %f12, %f14;
	setp.le.f32 	%p7, %f4, %f12;
	@%p7 bra 	$Lt_76_8962;
	mov.b32 	%r14, %f3;
$Lt_76_8450:
	.loc	17	10967	0
	mov.b32 	%r19, %f1;
	and.b32 	%r20, %r19, -2147483648;
	or.b32 	%r21, %r14, %r20;
	mov.b32 	%f7, %r21;
	bra.uni 	$Lt_76_7938;
$Lt_76_8194:
	.loc	17	10971	0
	add.f32 	%f15, %f1, %f2;
	mov.f32 	%f16, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p8, %f4, %f16;
	not.pred 	%p9, %p8;
	selp.f32 	%f17, %f15, %f1, %p9;
	add.f32 	%f18, %f17, %f1;
	mov.f32 	%f19, 0f00000000;    	// 0
	setp.gt.f32 	%p10, %f3, %f19;
	selp.f32 	%f7, %f17, %f18, %p10;
$Lt_76_7938:
$Lt_76_7426:
	.loc	15	153	0
	ld.param.u64 	%rd11, [__cudaparm_emod_vvf_result];
	ld.param.s32 	%r22, [__cudaparm_emod_vvf_lr];
	mul.lo.s32 	%r23, %r22, %r3;
	cvt.s64.s32 	%rd12, %r23;
	mul.wide.s32 	%rd13, %r23, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f7;
$Lt_76_6914:
	exit;
$LDWend_emod_vvf:
	} // emod_vvf

	.entry emod_vmf (
		.param .s32 __cudaparm_emod_vmf_rs,
		.param .s32 __cudaparm_emod_vmf_cs,
		.param .u64 __cudaparm_emod_vmf_x,
		.param .s32 __cudaparm_emod_vmf_lx,
		.param .u64 __cudaparm_emod_vmf_B,
		.param .s32 __cudaparm_emod_vmf_ldb,
		.param .u64 __cudaparm_emod_vmf_C,
		.param .s32 __cudaparm_emod_vmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<38>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<21>;
	.reg .pred %p<12>;
$LDWbegin_emod_vmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emod_vmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emod_vmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_77_7170;
	ld.param.u64 	%rd1, [__cudaparm_emod_vmf_x];
	ld.param.s32 	%r15, [__cudaparm_emod_vmf_lx];
	mul.lo.s32 	%r16, %r15, %r6;
	cvt.s64.s32 	%rd2, %r16;
	mul.wide.s32 	%rd3, %r16, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_emod_vmf_B];
	ld.param.s32 	%r17, [__cudaparm_emod_vmf_ldb];
	mul.lo.s32 	%r18, %r17, %r4;
	add.s32 	%r19, %r6, %r18;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	.loc	17	10940	0
	abs.f32 	%f3, %f1;
	abs.f32 	%f4, %f2;
	mov.f32 	%f5, 0f00000000;     	// 0
	set.eq.u32.f32 	%r20, %f4, %f5;
	neg.s32 	%r21, %r20;
	mov.f32 	%f6, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.eq.u32.f32 	%r22, %f3, %f6;
	neg.s32 	%r23, %r22;
	or.b32 	%r24, %r21, %r23;
	mov.u32 	%r25, 0;
	setp.eq.s32 	%p2, %r24, %r25;
	@%p2 bra 	$Lt_77_7938;
	mov.f32 	%f7, 0f7fffffff;     	// nan
	bra.uni 	$Lt_77_7682;
$Lt_77_7938:
	setp.le.f32 	%p3, %f4, %f3;
	@!%p3 bra 	$Lt_77_8450;
	.loc	17	10947	0
	mov.b32 	%r26, %f3;
	mov.b32 	%r27, %f4;
	and.b32 	%r28, %r26, 2139095040;
	and.b32 	%r29, %r27, 8388607;
	or.b32 	%r30, %r28, %r29;
	mov.b32 	%f8, %r30;
	setp.gt.f32 	%p4, %f8, %f3;
	mov.f32 	%f9, 0f3f000000;     	// 0.5
	mul.f32 	%f10, %f8, %f9;
	selp.f32 	%f11, %f10, %f8, %p4;
	mov.f32 	%f12, %f11;
	setp.le.f32 	%p5, %f4, %f11;
	@!%p5 bra 	$Lt_77_8706;
$Lt_77_9218:
	.loc	17	10962	0
	sub.f32 	%f13, %f3, %f12;
	setp.ge.f32 	%p6, %f3, %f12;
	selp.f32 	%f3, %f13, %f3, %p6;
	.loc	17	10965	0
	mov.f32 	%f14, 0f3f000000;    	// 0.5
	mul.f32 	%f12, %f12, %f14;
	setp.le.f32 	%p7, %f4, %f12;
	@%p7 bra 	$Lt_77_9218;
	mov.b32 	%r26, %f3;
$Lt_77_8706:
	.loc	17	10967	0
	mov.b32 	%r31, %f1;
	and.b32 	%r32, %r31, -2147483648;
	or.b32 	%r33, %r26, %r32;
	mov.b32 	%f7, %r33;
	bra.uni 	$Lt_77_8194;
$Lt_77_8450:
	.loc	17	10971	0
	add.f32 	%f15, %f1, %f2;
	mov.f32 	%f16, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p8, %f4, %f16;
	not.pred 	%p9, %p8;
	selp.f32 	%f17, %f15, %f1, %p9;
	add.f32 	%f18, %f17, %f1;
	mov.f32 	%f19, 0f00000000;    	// 0
	setp.gt.f32 	%p10, %f3, %f19;
	selp.f32 	%f7, %f17, %f18, %p10;
$Lt_77_8194:
$Lt_77_7682:
	.loc	15	153	0
	ld.param.u64 	%rd9, [__cudaparm_emod_vmf_C];
	ld.param.s32 	%r34, [__cudaparm_emod_vmf_ldc];
	mul.lo.s32 	%r35, %r34, %r4;
	add.s32 	%r36, %r6, %r35;
	cvt.s64.s32 	%rd10, %r36;
	mul.wide.s32 	%rd11, %r36, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f7;
$Lt_77_7170:
	exit;
$LDWend_emod_vmf:
	} // emod_vmf

	.entry emod_mvf (
		.param .s32 __cudaparm_emod_mvf_rs,
		.param .s32 __cudaparm_emod_mvf_cs,
		.param .u64 __cudaparm_emod_mvf_A,
		.param .s32 __cudaparm_emod_mvf_lda,
		.param .u64 __cudaparm_emod_mvf_y,
		.param .s32 __cudaparm_emod_mvf_ly,
		.param .u64 __cudaparm_emod_mvf_C,
		.param .s32 __cudaparm_emod_mvf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<38>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<21>;
	.reg .pred %p<12>;
$LDWbegin_emod_mvf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emod_mvf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emod_mvf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_78_7170;
	ld.param.u64 	%rd1, [__cudaparm_emod_mvf_A];
	ld.param.s32 	%r15, [__cudaparm_emod_mvf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_emod_mvf_y];
	ld.param.s32 	%r18, [__cudaparm_emod_mvf_ly];
	mul.lo.s32 	%r19, %r18, %r6;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	.loc	17	10940	0
	abs.f32 	%f3, %f1;
	abs.f32 	%f4, %f2;
	mov.f32 	%f5, 0f00000000;     	// 0
	set.eq.u32.f32 	%r20, %f4, %f5;
	neg.s32 	%r21, %r20;
	mov.f32 	%f6, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.eq.u32.f32 	%r22, %f3, %f6;
	neg.s32 	%r23, %r22;
	or.b32 	%r24, %r21, %r23;
	mov.u32 	%r25, 0;
	setp.eq.s32 	%p2, %r24, %r25;
	@%p2 bra 	$Lt_78_7938;
	mov.f32 	%f7, 0f7fffffff;     	// nan
	bra.uni 	$Lt_78_7682;
$Lt_78_7938:
	setp.le.f32 	%p3, %f4, %f3;
	@!%p3 bra 	$Lt_78_8450;
	.loc	17	10947	0
	mov.b32 	%r26, %f3;
	mov.b32 	%r27, %f4;
	and.b32 	%r28, %r26, 2139095040;
	and.b32 	%r29, %r27, 8388607;
	or.b32 	%r30, %r28, %r29;
	mov.b32 	%f8, %r30;
	setp.gt.f32 	%p4, %f8, %f3;
	mov.f32 	%f9, 0f3f000000;     	// 0.5
	mul.f32 	%f10, %f8, %f9;
	selp.f32 	%f11, %f10, %f8, %p4;
	mov.f32 	%f12, %f11;
	setp.le.f32 	%p5, %f4, %f11;
	@!%p5 bra 	$Lt_78_8706;
$Lt_78_9218:
	.loc	17	10962	0
	sub.f32 	%f13, %f3, %f12;
	setp.ge.f32 	%p6, %f3, %f12;
	selp.f32 	%f3, %f13, %f3, %p6;
	.loc	17	10965	0
	mov.f32 	%f14, 0f3f000000;    	// 0.5
	mul.f32 	%f12, %f12, %f14;
	setp.le.f32 	%p7, %f4, %f12;
	@%p7 bra 	$Lt_78_9218;
	mov.b32 	%r26, %f3;
$Lt_78_8706:
	.loc	17	10967	0
	mov.b32 	%r31, %f1;
	and.b32 	%r32, %r31, -2147483648;
	or.b32 	%r33, %r26, %r32;
	mov.b32 	%f7, %r33;
	bra.uni 	$Lt_78_8194;
$Lt_78_8450:
	.loc	17	10971	0
	add.f32 	%f15, %f1, %f2;
	mov.f32 	%f16, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p8, %f4, %f16;
	not.pred 	%p9, %p8;
	selp.f32 	%f17, %f15, %f1, %p9;
	add.f32 	%f18, %f17, %f1;
	mov.f32 	%f19, 0f00000000;    	// 0
	setp.gt.f32 	%p10, %f3, %f19;
	selp.f32 	%f7, %f17, %f18, %p10;
$Lt_78_8194:
$Lt_78_7682:
	.loc	15	153	0
	ld.param.u64 	%rd9, [__cudaparm_emod_mvf_C];
	ld.param.s32 	%r34, [__cudaparm_emod_mvf_ldc];
	mul.lo.s32 	%r35, %r34, %r4;
	add.s32 	%r36, %r6, %r35;
	cvt.s64.s32 	%rd10, %r36;
	mul.wide.s32 	%rd11, %r36, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f7;
$Lt_78_7170:
	exit;
$LDWend_emod_mvf:
	} // emod_mvf

	.entry emod_mmf (
		.param .s32 __cudaparm_emod_mmf_rs,
		.param .s32 __cudaparm_emod_mmf_cs,
		.param .u64 __cudaparm_emod_mmf_A,
		.param .s32 __cudaparm_emod_mmf_lda,
		.param .u64 __cudaparm_emod_mmf_B,
		.param .s32 __cudaparm_emod_mmf_ldb,
		.param .u64 __cudaparm_emod_mmf_C,
		.param .s32 __cudaparm_emod_mmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<39>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<21>;
	.reg .pred %p<12>;
$LDWbegin_emod_mmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_emod_mmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_emod_mmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_79_7170;
	ld.param.u64 	%rd1, [__cudaparm_emod_mmf_A];
	ld.param.s32 	%r15, [__cudaparm_emod_mmf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_emod_mmf_B];
	ld.param.s32 	%r18, [__cudaparm_emod_mmf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	.loc	17	10940	0
	abs.f32 	%f3, %f1;
	abs.f32 	%f4, %f2;
	mov.f32 	%f5, 0f00000000;     	// 0
	set.eq.u32.f32 	%r21, %f4, %f5;
	neg.s32 	%r22, %r21;
	mov.f32 	%f6, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.eq.u32.f32 	%r23, %f3, %f6;
	neg.s32 	%r24, %r23;
	or.b32 	%r25, %r22, %r24;
	mov.u32 	%r26, 0;
	setp.eq.s32 	%p2, %r25, %r26;
	@%p2 bra 	$Lt_79_7938;
	mov.f32 	%f7, 0f7fffffff;     	// nan
	bra.uni 	$Lt_79_7682;
$Lt_79_7938:
	setp.le.f32 	%p3, %f4, %f3;
	@!%p3 bra 	$Lt_79_8450;
	.loc	17	10947	0
	mov.b32 	%r27, %f3;
	mov.b32 	%r28, %f4;
	and.b32 	%r29, %r27, 2139095040;
	and.b32 	%r30, %r28, 8388607;
	or.b32 	%r31, %r29, %r30;
	mov.b32 	%f8, %r31;
	setp.gt.f32 	%p4, %f8, %f3;
	mov.f32 	%f9, 0f3f000000;     	// 0.5
	mul.f32 	%f10, %f8, %f9;
	selp.f32 	%f11, %f10, %f8, %p4;
	mov.f32 	%f12, %f11;
	setp.le.f32 	%p5, %f4, %f11;
	@!%p5 bra 	$Lt_79_8706;
$Lt_79_9218:
	.loc	17	10962	0
	sub.f32 	%f13, %f3, %f12;
	setp.ge.f32 	%p6, %f3, %f12;
	selp.f32 	%f3, %f13, %f3, %p6;
	.loc	17	10965	0
	mov.f32 	%f14, 0f3f000000;    	// 0.5
	mul.f32 	%f12, %f12, %f14;
	setp.le.f32 	%p7, %f4, %f12;
	@%p7 bra 	$Lt_79_9218;
	mov.b32 	%r27, %f3;
$Lt_79_8706:
	.loc	17	10967	0
	mov.b32 	%r32, %f1;
	and.b32 	%r33, %r32, -2147483648;
	or.b32 	%r34, %r27, %r33;
	mov.b32 	%f7, %r34;
	bra.uni 	$Lt_79_8194;
$Lt_79_8450:
	.loc	17	10971	0
	add.f32 	%f15, %f1, %f2;
	mov.f32 	%f16, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p8, %f4, %f16;
	not.pred 	%p9, %p8;
	selp.f32 	%f17, %f15, %f1, %p9;
	add.f32 	%f18, %f17, %f1;
	mov.f32 	%f19, 0f00000000;    	// 0
	setp.gt.f32 	%p10, %f3, %f19;
	selp.f32 	%f7, %f17, %f18, %p10;
$Lt_79_8194:
$Lt_79_7682:
	.loc	15	153	0
	ld.param.u64 	%rd9, [__cudaparm_emod_mmf_C];
	ld.param.s32 	%r35, [__cudaparm_emod_mmf_ldc];
	mul.lo.s32 	%r36, %r35, %r4;
	add.s32 	%r37, %r6, %r36;
	cvt.s64.s32 	%rd10, %r37;
	mul.wide.s32 	%rd11, %r37, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f7;
$Lt_79_7170:
	exit;
$LDWend_emod_mmf:
	} // emod_mmf

	.entry elt_vvf (
		.param .u64 __cudaparm_elt_vvf_n,
		.param .u64 __cudaparm_elt_vvf_x,
		.param .s32 __cudaparm_elt_vvf_lx,
		.param .u64 __cudaparm_elt_vvf_y,
		.param .s32 __cudaparm_elt_vvf_ly,
		.param .u64 __cudaparm_elt_vvf_result,
		.param .s32 __cudaparm_elt_vvf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<11>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
	.loc	15	155	0
$LDWbegin_elt_vvf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_elt_vvf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_80_1794;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd3, [__cudaparm_elt_vvf_x];
	ld.param.s32 	%r4, [__cudaparm_elt_vvf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f3, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_elt_vvf_y];
	ld.param.s32 	%r6, [__cudaparm_elt_vvf_ly];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.global.f32 	%f4, [%rd10+0];
	setp.lt.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd11, [__cudaparm_elt_vvf_result];
	ld.param.s32 	%r8, [__cudaparm_elt_vvf_lr];
	mul.lo.s32 	%r9, %r8, %r3;
	cvt.s64.s32 	%rd12, %r9;
	mul.wide.s32 	%rd13, %r9, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f5;
$Lt_80_1794:
	exit;
$LDWend_elt_vvf:
	} // elt_vvf

	.entry elt_vmf (
		.param .s32 __cudaparm_elt_vmf_rs,
		.param .s32 __cudaparm_elt_vmf_cs,
		.param .u64 __cudaparm_elt_vmf_x,
		.param .s32 __cudaparm_elt_vmf_lx,
		.param .u64 __cudaparm_elt_vmf_B,
		.param .s32 __cudaparm_elt_vmf_ldb,
		.param .u64 __cudaparm_elt_vmf_C,
		.param .s32 __cudaparm_elt_vmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_elt_vmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_elt_vmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_elt_vmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_81_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_elt_vmf_x];
	ld.param.s32 	%r15, [__cudaparm_elt_vmf_lx];
	mul.lo.s32 	%r16, %r15, %r6;
	cvt.s64.s32 	%rd2, %r16;
	mul.wide.s32 	%rd3, %r16, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_elt_vmf_B];
	ld.param.s32 	%r17, [__cudaparm_elt_vmf_ldb];
	mul.lo.s32 	%r18, %r17, %r4;
	add.s32 	%r19, %r6, %r18;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.lt.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_elt_vmf_C];
	ld.param.s32 	%r20, [__cudaparm_elt_vmf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_81_2050:
	exit;
$LDWend_elt_vmf:
	} // elt_vmf

	.entry elt_mvf (
		.param .s32 __cudaparm_elt_mvf_rs,
		.param .s32 __cudaparm_elt_mvf_cs,
		.param .u64 __cudaparm_elt_mvf_A,
		.param .s32 __cudaparm_elt_mvf_lda,
		.param .u64 __cudaparm_elt_mvf_y,
		.param .s32 __cudaparm_elt_mvf_ly,
		.param .u64 __cudaparm_elt_mvf_C,
		.param .s32 __cudaparm_elt_mvf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_elt_mvf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_elt_mvf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_elt_mvf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_82_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_elt_mvf_A];
	ld.param.s32 	%r15, [__cudaparm_elt_mvf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_elt_mvf_y];
	ld.param.s32 	%r18, [__cudaparm_elt_mvf_ly];
	mul.lo.s32 	%r19, %r18, %r6;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.lt.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_elt_mvf_C];
	ld.param.s32 	%r20, [__cudaparm_elt_mvf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_82_2050:
	exit;
$LDWend_elt_mvf:
	} // elt_mvf

	.entry elt_mmf (
		.param .s32 __cudaparm_elt_mmf_rs,
		.param .s32 __cudaparm_elt_mmf_cs,
		.param .u64 __cudaparm_elt_mmf_A,
		.param .s32 __cudaparm_elt_mmf_lda,
		.param .u64 __cudaparm_elt_mmf_B,
		.param .s32 __cudaparm_elt_mmf_ldb,
		.param .u64 __cudaparm_elt_mmf_C,
		.param .s32 __cudaparm_elt_mmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<25>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_elt_mmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_elt_mmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_elt_mmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_83_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_elt_mmf_A];
	ld.param.s32 	%r15, [__cudaparm_elt_mmf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_elt_mmf_B];
	ld.param.s32 	%r18, [__cudaparm_elt_mmf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.lt.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_elt_mmf_C];
	ld.param.s32 	%r21, [__cudaparm_elt_mmf_ldc];
	mul.lo.s32 	%r22, %r21, %r4;
	add.s32 	%r23, %r6, %r22;
	cvt.s64.s32 	%rd10, %r23;
	mul.wide.s32 	%rd11, %r23, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_83_2050:
	exit;
$LDWend_elt_mmf:
	} // elt_mmf

	.entry elte_vvf (
		.param .u64 __cudaparm_elte_vvf_n,
		.param .u64 __cudaparm_elte_vvf_x,
		.param .s32 __cudaparm_elte_vvf_lx,
		.param .u64 __cudaparm_elte_vvf_y,
		.param .s32 __cudaparm_elte_vvf_ly,
		.param .u64 __cudaparm_elte_vvf_result,
		.param .s32 __cudaparm_elte_vvf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<11>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
	.loc	15	156	0
$LDWbegin_elte_vvf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_elte_vvf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_84_1794;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd3, [__cudaparm_elte_vvf_x];
	ld.param.s32 	%r4, [__cudaparm_elte_vvf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f3, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_elte_vvf_y];
	ld.param.s32 	%r6, [__cudaparm_elte_vvf_ly];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.global.f32 	%f4, [%rd10+0];
	setp.le.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd11, [__cudaparm_elte_vvf_result];
	ld.param.s32 	%r8, [__cudaparm_elte_vvf_lr];
	mul.lo.s32 	%r9, %r8, %r3;
	cvt.s64.s32 	%rd12, %r9;
	mul.wide.s32 	%rd13, %r9, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f5;
$Lt_84_1794:
	exit;
$LDWend_elte_vvf:
	} // elte_vvf

	.entry elte_vmf (
		.param .s32 __cudaparm_elte_vmf_rs,
		.param .s32 __cudaparm_elte_vmf_cs,
		.param .u64 __cudaparm_elte_vmf_x,
		.param .s32 __cudaparm_elte_vmf_lx,
		.param .u64 __cudaparm_elte_vmf_B,
		.param .s32 __cudaparm_elte_vmf_ldb,
		.param .u64 __cudaparm_elte_vmf_C,
		.param .s32 __cudaparm_elte_vmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_elte_vmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_elte_vmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_elte_vmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_85_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_elte_vmf_x];
	ld.param.s32 	%r15, [__cudaparm_elte_vmf_lx];
	mul.lo.s32 	%r16, %r15, %r6;
	cvt.s64.s32 	%rd2, %r16;
	mul.wide.s32 	%rd3, %r16, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_elte_vmf_B];
	ld.param.s32 	%r17, [__cudaparm_elte_vmf_ldb];
	mul.lo.s32 	%r18, %r17, %r4;
	add.s32 	%r19, %r6, %r18;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.le.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_elte_vmf_C];
	ld.param.s32 	%r20, [__cudaparm_elte_vmf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_85_2050:
	exit;
$LDWend_elte_vmf:
	} // elte_vmf

	.entry elte_mvf (
		.param .s32 __cudaparm_elte_mvf_rs,
		.param .s32 __cudaparm_elte_mvf_cs,
		.param .u64 __cudaparm_elte_mvf_A,
		.param .s32 __cudaparm_elte_mvf_lda,
		.param .u64 __cudaparm_elte_mvf_y,
		.param .s32 __cudaparm_elte_mvf_ly,
		.param .u64 __cudaparm_elte_mvf_C,
		.param .s32 __cudaparm_elte_mvf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_elte_mvf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_elte_mvf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_elte_mvf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_86_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_elte_mvf_A];
	ld.param.s32 	%r15, [__cudaparm_elte_mvf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_elte_mvf_y];
	ld.param.s32 	%r18, [__cudaparm_elte_mvf_ly];
	mul.lo.s32 	%r19, %r18, %r6;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.le.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_elte_mvf_C];
	ld.param.s32 	%r20, [__cudaparm_elte_mvf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_86_2050:
	exit;
$LDWend_elte_mvf:
	} // elte_mvf

	.entry elte_mmf (
		.param .s32 __cudaparm_elte_mmf_rs,
		.param .s32 __cudaparm_elte_mmf_cs,
		.param .u64 __cudaparm_elte_mmf_A,
		.param .s32 __cudaparm_elte_mmf_lda,
		.param .u64 __cudaparm_elte_mmf_B,
		.param .s32 __cudaparm_elte_mmf_ldb,
		.param .u64 __cudaparm_elte_mmf_C,
		.param .s32 __cudaparm_elte_mmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<25>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_elte_mmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_elte_mmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_elte_mmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_87_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_elte_mmf_A];
	ld.param.s32 	%r15, [__cudaparm_elte_mmf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_elte_mmf_B];
	ld.param.s32 	%r18, [__cudaparm_elte_mmf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.le.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_elte_mmf_C];
	ld.param.s32 	%r21, [__cudaparm_elte_mmf_ldc];
	mul.lo.s32 	%r22, %r21, %r4;
	add.s32 	%r23, %r6, %r22;
	cvt.s64.s32 	%rd10, %r23;
	mul.wide.s32 	%rd11, %r23, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_87_2050:
	exit;
$LDWend_elte_mmf:
	} // elte_mmf

	.entry eeq_vvf (
		.param .u64 __cudaparm_eeq_vvf_n,
		.param .u64 __cudaparm_eeq_vvf_x,
		.param .s32 __cudaparm_eeq_vvf_lx,
		.param .u64 __cudaparm_eeq_vvf_y,
		.param .s32 __cudaparm_eeq_vvf_ly,
		.param .u64 __cudaparm_eeq_vvf_result,
		.param .s32 __cudaparm_eeq_vvf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<11>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
	.loc	15	157	0
$LDWbegin_eeq_vvf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eeq_vvf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_88_1794;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd3, [__cudaparm_eeq_vvf_x];
	ld.param.s32 	%r4, [__cudaparm_eeq_vvf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f3, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_eeq_vvf_y];
	ld.param.s32 	%r6, [__cudaparm_eeq_vvf_ly];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.global.f32 	%f4, [%rd10+0];
	setp.eq.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd11, [__cudaparm_eeq_vvf_result];
	ld.param.s32 	%r8, [__cudaparm_eeq_vvf_lr];
	mul.lo.s32 	%r9, %r8, %r3;
	cvt.s64.s32 	%rd12, %r9;
	mul.wide.s32 	%rd13, %r9, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f5;
$Lt_88_1794:
	exit;
$LDWend_eeq_vvf:
	} // eeq_vvf

	.entry eeq_vmf (
		.param .s32 __cudaparm_eeq_vmf_rs,
		.param .s32 __cudaparm_eeq_vmf_cs,
		.param .u64 __cudaparm_eeq_vmf_x,
		.param .s32 __cudaparm_eeq_vmf_lx,
		.param .u64 __cudaparm_eeq_vmf_B,
		.param .s32 __cudaparm_eeq_vmf_ldb,
		.param .u64 __cudaparm_eeq_vmf_C,
		.param .s32 __cudaparm_eeq_vmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_eeq_vmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eeq_vmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eeq_vmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_89_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_eeq_vmf_x];
	ld.param.s32 	%r15, [__cudaparm_eeq_vmf_lx];
	mul.lo.s32 	%r16, %r15, %r6;
	cvt.s64.s32 	%rd2, %r16;
	mul.wide.s32 	%rd3, %r16, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_eeq_vmf_B];
	ld.param.s32 	%r17, [__cudaparm_eeq_vmf_ldb];
	mul.lo.s32 	%r18, %r17, %r4;
	add.s32 	%r19, %r6, %r18;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.eq.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_eeq_vmf_C];
	ld.param.s32 	%r20, [__cudaparm_eeq_vmf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_89_2050:
	exit;
$LDWend_eeq_vmf:
	} // eeq_vmf

	.entry eeq_mvf (
		.param .s32 __cudaparm_eeq_mvf_rs,
		.param .s32 __cudaparm_eeq_mvf_cs,
		.param .u64 __cudaparm_eeq_mvf_A,
		.param .s32 __cudaparm_eeq_mvf_lda,
		.param .u64 __cudaparm_eeq_mvf_y,
		.param .s32 __cudaparm_eeq_mvf_ly,
		.param .u64 __cudaparm_eeq_mvf_C,
		.param .s32 __cudaparm_eeq_mvf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_eeq_mvf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eeq_mvf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eeq_mvf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_90_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_eeq_mvf_A];
	ld.param.s32 	%r15, [__cudaparm_eeq_mvf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_eeq_mvf_y];
	ld.param.s32 	%r18, [__cudaparm_eeq_mvf_ly];
	mul.lo.s32 	%r19, %r18, %r6;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.eq.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_eeq_mvf_C];
	ld.param.s32 	%r20, [__cudaparm_eeq_mvf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_90_2050:
	exit;
$LDWend_eeq_mvf:
	} // eeq_mvf

	.entry eeq_mmf (
		.param .s32 __cudaparm_eeq_mmf_rs,
		.param .s32 __cudaparm_eeq_mmf_cs,
		.param .u64 __cudaparm_eeq_mmf_A,
		.param .s32 __cudaparm_eeq_mmf_lda,
		.param .u64 __cudaparm_eeq_mmf_B,
		.param .s32 __cudaparm_eeq_mmf_ldb,
		.param .u64 __cudaparm_eeq_mmf_C,
		.param .s32 __cudaparm_eeq_mmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<25>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_eeq_mmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eeq_mmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eeq_mmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_91_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_eeq_mmf_A];
	ld.param.s32 	%r15, [__cudaparm_eeq_mmf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_eeq_mmf_B];
	ld.param.s32 	%r18, [__cudaparm_eeq_mmf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.eq.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_eeq_mmf_C];
	ld.param.s32 	%r21, [__cudaparm_eeq_mmf_ldc];
	mul.lo.s32 	%r22, %r21, %r4;
	add.s32 	%r23, %r6, %r22;
	cvt.s64.s32 	%rd10, %r23;
	mul.wide.s32 	%rd11, %r23, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_91_2050:
	exit;
$LDWend_eeq_mmf:
	} // eeq_mmf

	.entry egte_vvf (
		.param .u64 __cudaparm_egte_vvf_n,
		.param .u64 __cudaparm_egte_vvf_x,
		.param .s32 __cudaparm_egte_vvf_lx,
		.param .u64 __cudaparm_egte_vvf_y,
		.param .s32 __cudaparm_egte_vvf_ly,
		.param .u64 __cudaparm_egte_vvf_result,
		.param .s32 __cudaparm_egte_vvf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<11>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
	.loc	15	158	0
$LDWbegin_egte_vvf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_egte_vvf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_92_1794;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd3, [__cudaparm_egte_vvf_x];
	ld.param.s32 	%r4, [__cudaparm_egte_vvf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f3, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_egte_vvf_y];
	ld.param.s32 	%r6, [__cudaparm_egte_vvf_ly];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.global.f32 	%f4, [%rd10+0];
	setp.ge.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd11, [__cudaparm_egte_vvf_result];
	ld.param.s32 	%r8, [__cudaparm_egte_vvf_lr];
	mul.lo.s32 	%r9, %r8, %r3;
	cvt.s64.s32 	%rd12, %r9;
	mul.wide.s32 	%rd13, %r9, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f5;
$Lt_92_1794:
	exit;
$LDWend_egte_vvf:
	} // egte_vvf

	.entry egte_vmf (
		.param .s32 __cudaparm_egte_vmf_rs,
		.param .s32 __cudaparm_egte_vmf_cs,
		.param .u64 __cudaparm_egte_vmf_x,
		.param .s32 __cudaparm_egte_vmf_lx,
		.param .u64 __cudaparm_egte_vmf_B,
		.param .s32 __cudaparm_egte_vmf_ldb,
		.param .u64 __cudaparm_egte_vmf_C,
		.param .s32 __cudaparm_egte_vmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_egte_vmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_egte_vmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_egte_vmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_93_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_egte_vmf_x];
	ld.param.s32 	%r15, [__cudaparm_egte_vmf_lx];
	mul.lo.s32 	%r16, %r15, %r6;
	cvt.s64.s32 	%rd2, %r16;
	mul.wide.s32 	%rd3, %r16, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_egte_vmf_B];
	ld.param.s32 	%r17, [__cudaparm_egte_vmf_ldb];
	mul.lo.s32 	%r18, %r17, %r4;
	add.s32 	%r19, %r6, %r18;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.ge.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_egte_vmf_C];
	ld.param.s32 	%r20, [__cudaparm_egte_vmf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_93_2050:
	exit;
$LDWend_egte_vmf:
	} // egte_vmf

	.entry egte_mvf (
		.param .s32 __cudaparm_egte_mvf_rs,
		.param .s32 __cudaparm_egte_mvf_cs,
		.param .u64 __cudaparm_egte_mvf_A,
		.param .s32 __cudaparm_egte_mvf_lda,
		.param .u64 __cudaparm_egte_mvf_y,
		.param .s32 __cudaparm_egte_mvf_ly,
		.param .u64 __cudaparm_egte_mvf_C,
		.param .s32 __cudaparm_egte_mvf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_egte_mvf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_egte_mvf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_egte_mvf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_94_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_egte_mvf_A];
	ld.param.s32 	%r15, [__cudaparm_egte_mvf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_egte_mvf_y];
	ld.param.s32 	%r18, [__cudaparm_egte_mvf_ly];
	mul.lo.s32 	%r19, %r18, %r6;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.ge.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_egte_mvf_C];
	ld.param.s32 	%r20, [__cudaparm_egte_mvf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_94_2050:
	exit;
$LDWend_egte_mvf:
	} // egte_mvf

	.entry egte_mmf (
		.param .s32 __cudaparm_egte_mmf_rs,
		.param .s32 __cudaparm_egte_mmf_cs,
		.param .u64 __cudaparm_egte_mmf_A,
		.param .s32 __cudaparm_egte_mmf_lda,
		.param .u64 __cudaparm_egte_mmf_B,
		.param .s32 __cudaparm_egte_mmf_ldb,
		.param .u64 __cudaparm_egte_mmf_C,
		.param .s32 __cudaparm_egte_mmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<25>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_egte_mmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_egte_mmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_egte_mmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_95_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_egte_mmf_A];
	ld.param.s32 	%r15, [__cudaparm_egte_mmf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_egte_mmf_B];
	ld.param.s32 	%r18, [__cudaparm_egte_mmf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.ge.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_egte_mmf_C];
	ld.param.s32 	%r21, [__cudaparm_egte_mmf_ldc];
	mul.lo.s32 	%r22, %r21, %r4;
	add.s32 	%r23, %r6, %r22;
	cvt.s64.s32 	%rd10, %r23;
	mul.wide.s32 	%rd11, %r23, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_95_2050:
	exit;
$LDWend_egte_mmf:
	} // egte_mmf

	.entry egt_vvf (
		.param .u64 __cudaparm_egt_vvf_n,
		.param .u64 __cudaparm_egt_vvf_x,
		.param .s32 __cudaparm_egt_vvf_lx,
		.param .u64 __cudaparm_egt_vvf_y,
		.param .s32 __cudaparm_egt_vvf_ly,
		.param .u64 __cudaparm_egt_vvf_result,
		.param .s32 __cudaparm_egt_vvf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<11>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
	.loc	15	159	0
$LDWbegin_egt_vvf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_egt_vvf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_96_1794;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd3, [__cudaparm_egt_vvf_x];
	ld.param.s32 	%r4, [__cudaparm_egt_vvf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f3, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_egt_vvf_y];
	ld.param.s32 	%r6, [__cudaparm_egt_vvf_ly];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.global.f32 	%f4, [%rd10+0];
	setp.gt.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd11, [__cudaparm_egt_vvf_result];
	ld.param.s32 	%r8, [__cudaparm_egt_vvf_lr];
	mul.lo.s32 	%r9, %r8, %r3;
	cvt.s64.s32 	%rd12, %r9;
	mul.wide.s32 	%rd13, %r9, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f5;
$Lt_96_1794:
	exit;
$LDWend_egt_vvf:
	} // egt_vvf

	.entry egt_vmf (
		.param .s32 __cudaparm_egt_vmf_rs,
		.param .s32 __cudaparm_egt_vmf_cs,
		.param .u64 __cudaparm_egt_vmf_x,
		.param .s32 __cudaparm_egt_vmf_lx,
		.param .u64 __cudaparm_egt_vmf_B,
		.param .s32 __cudaparm_egt_vmf_ldb,
		.param .u64 __cudaparm_egt_vmf_C,
		.param .s32 __cudaparm_egt_vmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_egt_vmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_egt_vmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_egt_vmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_97_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_egt_vmf_x];
	ld.param.s32 	%r15, [__cudaparm_egt_vmf_lx];
	mul.lo.s32 	%r16, %r15, %r6;
	cvt.s64.s32 	%rd2, %r16;
	mul.wide.s32 	%rd3, %r16, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_egt_vmf_B];
	ld.param.s32 	%r17, [__cudaparm_egt_vmf_ldb];
	mul.lo.s32 	%r18, %r17, %r4;
	add.s32 	%r19, %r6, %r18;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.gt.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_egt_vmf_C];
	ld.param.s32 	%r20, [__cudaparm_egt_vmf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_97_2050:
	exit;
$LDWend_egt_vmf:
	} // egt_vmf

	.entry egt_mvf (
		.param .s32 __cudaparm_egt_mvf_rs,
		.param .s32 __cudaparm_egt_mvf_cs,
		.param .u64 __cudaparm_egt_mvf_A,
		.param .s32 __cudaparm_egt_mvf_lda,
		.param .u64 __cudaparm_egt_mvf_y,
		.param .s32 __cudaparm_egt_mvf_ly,
		.param .u64 __cudaparm_egt_mvf_C,
		.param .s32 __cudaparm_egt_mvf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_egt_mvf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_egt_mvf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_egt_mvf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_98_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_egt_mvf_A];
	ld.param.s32 	%r15, [__cudaparm_egt_mvf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_egt_mvf_y];
	ld.param.s32 	%r18, [__cudaparm_egt_mvf_ly];
	mul.lo.s32 	%r19, %r18, %r6;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.gt.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_egt_mvf_C];
	ld.param.s32 	%r20, [__cudaparm_egt_mvf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_98_2050:
	exit;
$LDWend_egt_mvf:
	} // egt_mvf

	.entry egt_mmf (
		.param .s32 __cudaparm_egt_mmf_rs,
		.param .s32 __cudaparm_egt_mmf_cs,
		.param .u64 __cudaparm_egt_mmf_A,
		.param .s32 __cudaparm_egt_mmf_lda,
		.param .u64 __cudaparm_egt_mmf_B,
		.param .s32 __cudaparm_egt_mmf_ldb,
		.param .u64 __cudaparm_egt_mmf_C,
		.param .s32 __cudaparm_egt_mmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<25>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_egt_mmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_egt_mmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_egt_mmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_99_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_egt_mmf_A];
	ld.param.s32 	%r15, [__cudaparm_egt_mmf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_egt_mmf_B];
	ld.param.s32 	%r18, [__cudaparm_egt_mmf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.gt.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_egt_mmf_C];
	ld.param.s32 	%r21, [__cudaparm_egt_mmf_ldc];
	mul.lo.s32 	%r22, %r21, %r4;
	add.s32 	%r23, %r6, %r22;
	cvt.s64.s32 	%rd10, %r23;
	mul.wide.s32 	%rd11, %r23, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_99_2050:
	exit;
$LDWend_egt_mmf:
	} // egt_mmf

	.entry ene_vvf (
		.param .u64 __cudaparm_ene_vvf_n,
		.param .u64 __cudaparm_ene_vvf_x,
		.param .s32 __cudaparm_ene_vvf_lx,
		.param .u64 __cudaparm_ene_vvf_y,
		.param .s32 __cudaparm_ene_vvf_ly,
		.param .u64 __cudaparm_ene_vvf_result,
		.param .s32 __cudaparm_ene_vvf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<11>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
	.loc	15	160	0
$LDWbegin_ene_vvf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_ene_vvf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_100_1794;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd3, [__cudaparm_ene_vvf_x];
	ld.param.s32 	%r4, [__cudaparm_ene_vvf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f3, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_ene_vvf_y];
	ld.param.s32 	%r6, [__cudaparm_ene_vvf_ly];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.global.f32 	%f4, [%rd10+0];
	setp.neu.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd11, [__cudaparm_ene_vvf_result];
	ld.param.s32 	%r8, [__cudaparm_ene_vvf_lr];
	mul.lo.s32 	%r9, %r8, %r3;
	cvt.s64.s32 	%rd12, %r9;
	mul.wide.s32 	%rd13, %r9, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f5;
$Lt_100_1794:
	exit;
$LDWend_ene_vvf:
	} // ene_vvf

	.entry ene_vmf (
		.param .s32 __cudaparm_ene_vmf_rs,
		.param .s32 __cudaparm_ene_vmf_cs,
		.param .u64 __cudaparm_ene_vmf_x,
		.param .s32 __cudaparm_ene_vmf_lx,
		.param .u64 __cudaparm_ene_vmf_B,
		.param .s32 __cudaparm_ene_vmf_ldb,
		.param .u64 __cudaparm_ene_vmf_C,
		.param .s32 __cudaparm_ene_vmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_ene_vmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_ene_vmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_ene_vmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_101_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_ene_vmf_x];
	ld.param.s32 	%r15, [__cudaparm_ene_vmf_lx];
	mul.lo.s32 	%r16, %r15, %r6;
	cvt.s64.s32 	%rd2, %r16;
	mul.wide.s32 	%rd3, %r16, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_ene_vmf_B];
	ld.param.s32 	%r17, [__cudaparm_ene_vmf_ldb];
	mul.lo.s32 	%r18, %r17, %r4;
	add.s32 	%r19, %r6, %r18;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.neu.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_ene_vmf_C];
	ld.param.s32 	%r20, [__cudaparm_ene_vmf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_101_2050:
	exit;
$LDWend_ene_vmf:
	} // ene_vmf

	.entry ene_mvf (
		.param .s32 __cudaparm_ene_mvf_rs,
		.param .s32 __cudaparm_ene_mvf_cs,
		.param .u64 __cudaparm_ene_mvf_A,
		.param .s32 __cudaparm_ene_mvf_lda,
		.param .u64 __cudaparm_ene_mvf_y,
		.param .s32 __cudaparm_ene_mvf_ly,
		.param .u64 __cudaparm_ene_mvf_C,
		.param .s32 __cudaparm_ene_mvf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_ene_mvf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_ene_mvf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_ene_mvf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_102_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_ene_mvf_A];
	ld.param.s32 	%r15, [__cudaparm_ene_mvf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_ene_mvf_y];
	ld.param.s32 	%r18, [__cudaparm_ene_mvf_ly];
	mul.lo.s32 	%r19, %r18, %r6;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.neu.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_ene_mvf_C];
	ld.param.s32 	%r20, [__cudaparm_ene_mvf_ldc];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd10, %r22;
	mul.wide.s32 	%rd11, %r22, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_102_2050:
	exit;
$LDWend_ene_mvf:
	} // ene_mvf

	.entry ene_mmf (
		.param .s32 __cudaparm_ene_mmf_rs,
		.param .s32 __cudaparm_ene_mmf_cs,
		.param .u64 __cudaparm_ene_mmf_A,
		.param .s32 __cudaparm_ene_mmf_lda,
		.param .u64 __cudaparm_ene_mmf_B,
		.param .s32 __cudaparm_ene_mmf_ldb,
		.param .u64 __cudaparm_ene_mmf_C,
		.param .s32 __cudaparm_ene_mmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<25>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_ene_mmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_ene_mmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_ene_mmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_103_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_ene_mmf_A];
	ld.param.s32 	%r15, [__cudaparm_ene_mmf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_ene_mmf_B];
	ld.param.s32 	%r18, [__cudaparm_ene_mmf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f4, [%rd8+0];
	setp.neu.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd9, [__cudaparm_ene_mmf_C];
	ld.param.s32 	%r21, [__cudaparm_ene_mmf_ldc];
	mul.lo.s32 	%r22, %r21, %r4;
	add.s32 	%r23, %r6, %r22;
	cvt.s64.s32 	%rd10, %r23;
	mul.wide.s32 	%rd11, %r23, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f5;
$Lt_103_2050:
	exit;
$LDWend_ene_mmf:
	} // ene_mmf

	.entry elt_vsf (
		.param .u64 __cudaparm_elt_vsf_n,
		.param .u64 __cudaparm_elt_vsf_x,
		.param .s32 __cudaparm_elt_vsf_lx,
		.param .f32 __cudaparm_elt_vsf_y,
		.param .u64 __cudaparm_elt_vsf_result,
		.param .s32 __cudaparm_elt_vsf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
	.loc	15	162	0
$LDWbegin_elt_vsf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_elt_vsf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_104_1794;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd3, [__cudaparm_elt_vsf_x];
	ld.param.s32 	%r4, [__cudaparm_elt_vsf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f3, [%rd6+0];
	ld.param.f32 	%f4, [__cudaparm_elt_vsf_y];
	setp.lt.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd7, [__cudaparm_elt_vsf_result];
	ld.param.s32 	%r6, [__cudaparm_elt_vsf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f5;
$Lt_104_1794:
	exit;
$LDWend_elt_vsf:
	} // elt_vsf

	.entry elt_msf (
		.param .s32 __cudaparm_elt_msf_rs,
		.param .s32 __cudaparm_elt_msf_cs,
		.param .u64 __cudaparm_elt_msf_A,
		.param .s32 __cudaparm_elt_msf_lda,
		.param .f32 __cudaparm_elt_msf_B,
		.param .u64 __cudaparm_elt_msf_C,
		.param .s32 __cudaparm_elt_msf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_elt_msf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_elt_msf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_elt_msf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_105_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_elt_msf_A];
	ld.param.s32 	%r15, [__cudaparm_elt_msf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.f32 	%f4, [__cudaparm_elt_msf_B];
	setp.lt.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd5, [__cudaparm_elt_msf_C];
	ld.param.s32 	%r18, [__cudaparm_elt_msf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f5;
$Lt_105_2050:
	exit;
$LDWend_elt_msf:
	} // elt_msf

	.entry elte_vsf (
		.param .u64 __cudaparm_elte_vsf_n,
		.param .u64 __cudaparm_elte_vsf_x,
		.param .s32 __cudaparm_elte_vsf_lx,
		.param .f32 __cudaparm_elte_vsf_y,
		.param .u64 __cudaparm_elte_vsf_result,
		.param .s32 __cudaparm_elte_vsf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
	.loc	15	163	0
$LDWbegin_elte_vsf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_elte_vsf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_106_1794;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd3, [__cudaparm_elte_vsf_x];
	ld.param.s32 	%r4, [__cudaparm_elte_vsf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f3, [%rd6+0];
	ld.param.f32 	%f4, [__cudaparm_elte_vsf_y];
	setp.le.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd7, [__cudaparm_elte_vsf_result];
	ld.param.s32 	%r6, [__cudaparm_elte_vsf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f5;
$Lt_106_1794:
	exit;
$LDWend_elte_vsf:
	} // elte_vsf

	.entry elte_msf (
		.param .s32 __cudaparm_elte_msf_rs,
		.param .s32 __cudaparm_elte_msf_cs,
		.param .u64 __cudaparm_elte_msf_A,
		.param .s32 __cudaparm_elte_msf_lda,
		.param .f32 __cudaparm_elte_msf_B,
		.param .u64 __cudaparm_elte_msf_C,
		.param .s32 __cudaparm_elte_msf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_elte_msf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_elte_msf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_elte_msf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_107_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_elte_msf_A];
	ld.param.s32 	%r15, [__cudaparm_elte_msf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.f32 	%f4, [__cudaparm_elte_msf_B];
	setp.le.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd5, [__cudaparm_elte_msf_C];
	ld.param.s32 	%r18, [__cudaparm_elte_msf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f5;
$Lt_107_2050:
	exit;
$LDWend_elte_msf:
	} // elte_msf

	.entry eeq_vsf (
		.param .u64 __cudaparm_eeq_vsf_n,
		.param .u64 __cudaparm_eeq_vsf_x,
		.param .s32 __cudaparm_eeq_vsf_lx,
		.param .f32 __cudaparm_eeq_vsf_y,
		.param .u64 __cudaparm_eeq_vsf_result,
		.param .s32 __cudaparm_eeq_vsf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
	.loc	15	164	0
$LDWbegin_eeq_vsf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eeq_vsf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_108_1794;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd3, [__cudaparm_eeq_vsf_x];
	ld.param.s32 	%r4, [__cudaparm_eeq_vsf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f3, [%rd6+0];
	ld.param.f32 	%f4, [__cudaparm_eeq_vsf_y];
	setp.eq.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd7, [__cudaparm_eeq_vsf_result];
	ld.param.s32 	%r6, [__cudaparm_eeq_vsf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f5;
$Lt_108_1794:
	exit;
$LDWend_eeq_vsf:
	} // eeq_vsf

	.entry eeq_msf (
		.param .s32 __cudaparm_eeq_msf_rs,
		.param .s32 __cudaparm_eeq_msf_cs,
		.param .u64 __cudaparm_eeq_msf_A,
		.param .s32 __cudaparm_eeq_msf_lda,
		.param .f32 __cudaparm_eeq_msf_B,
		.param .u64 __cudaparm_eeq_msf_C,
		.param .s32 __cudaparm_eeq_msf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_eeq_msf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eeq_msf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eeq_msf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_109_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_eeq_msf_A];
	ld.param.s32 	%r15, [__cudaparm_eeq_msf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.f32 	%f4, [__cudaparm_eeq_msf_B];
	setp.eq.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd5, [__cudaparm_eeq_msf_C];
	ld.param.s32 	%r18, [__cudaparm_eeq_msf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f5;
$Lt_109_2050:
	exit;
$LDWend_eeq_msf:
	} // eeq_msf

	.entry egte_vsf (
		.param .u64 __cudaparm_egte_vsf_n,
		.param .u64 __cudaparm_egte_vsf_x,
		.param .s32 __cudaparm_egte_vsf_lx,
		.param .f32 __cudaparm_egte_vsf_y,
		.param .u64 __cudaparm_egte_vsf_result,
		.param .s32 __cudaparm_egte_vsf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
	.loc	15	165	0
$LDWbegin_egte_vsf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_egte_vsf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_110_1794;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd3, [__cudaparm_egte_vsf_x];
	ld.param.s32 	%r4, [__cudaparm_egte_vsf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f3, [%rd6+0];
	ld.param.f32 	%f4, [__cudaparm_egte_vsf_y];
	setp.ge.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd7, [__cudaparm_egte_vsf_result];
	ld.param.s32 	%r6, [__cudaparm_egte_vsf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f5;
$Lt_110_1794:
	exit;
$LDWend_egte_vsf:
	} // egte_vsf

	.entry egte_msf (
		.param .s32 __cudaparm_egte_msf_rs,
		.param .s32 __cudaparm_egte_msf_cs,
		.param .u64 __cudaparm_egte_msf_A,
		.param .s32 __cudaparm_egte_msf_lda,
		.param .f32 __cudaparm_egte_msf_B,
		.param .u64 __cudaparm_egte_msf_C,
		.param .s32 __cudaparm_egte_msf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_egte_msf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_egte_msf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_egte_msf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_111_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_egte_msf_A];
	ld.param.s32 	%r15, [__cudaparm_egte_msf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.f32 	%f4, [__cudaparm_egte_msf_B];
	setp.ge.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd5, [__cudaparm_egte_msf_C];
	ld.param.s32 	%r18, [__cudaparm_egte_msf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f5;
$Lt_111_2050:
	exit;
$LDWend_egte_msf:
	} // egte_msf

	.entry egt_vsf (
		.param .u64 __cudaparm_egt_vsf_n,
		.param .u64 __cudaparm_egt_vsf_x,
		.param .s32 __cudaparm_egt_vsf_lx,
		.param .f32 __cudaparm_egt_vsf_y,
		.param .u64 __cudaparm_egt_vsf_result,
		.param .s32 __cudaparm_egt_vsf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
	.loc	15	166	0
$LDWbegin_egt_vsf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_egt_vsf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_112_1794;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd3, [__cudaparm_egt_vsf_x];
	ld.param.s32 	%r4, [__cudaparm_egt_vsf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f3, [%rd6+0];
	ld.param.f32 	%f4, [__cudaparm_egt_vsf_y];
	setp.gt.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd7, [__cudaparm_egt_vsf_result];
	ld.param.s32 	%r6, [__cudaparm_egt_vsf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f5;
$Lt_112_1794:
	exit;
$LDWend_egt_vsf:
	} // egt_vsf

	.entry egt_msf (
		.param .s32 __cudaparm_egt_msf_rs,
		.param .s32 __cudaparm_egt_msf_cs,
		.param .u64 __cudaparm_egt_msf_A,
		.param .s32 __cudaparm_egt_msf_lda,
		.param .f32 __cudaparm_egt_msf_B,
		.param .u64 __cudaparm_egt_msf_C,
		.param .s32 __cudaparm_egt_msf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_egt_msf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_egt_msf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_egt_msf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_113_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_egt_msf_A];
	ld.param.s32 	%r15, [__cudaparm_egt_msf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.f32 	%f4, [__cudaparm_egt_msf_B];
	setp.gt.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd5, [__cudaparm_egt_msf_C];
	ld.param.s32 	%r18, [__cudaparm_egt_msf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f5;
$Lt_113_2050:
	exit;
$LDWend_egt_msf:
	} // egt_msf

	.entry ene_vsf (
		.param .u64 __cudaparm_ene_vsf_n,
		.param .u64 __cudaparm_ene_vsf_x,
		.param .s32 __cudaparm_ene_vsf_lx,
		.param .f32 __cudaparm_ene_vsf_y,
		.param .u64 __cudaparm_ene_vsf_result,
		.param .s32 __cudaparm_ene_vsf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
	.loc	15	167	0
$LDWbegin_ene_vsf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_ene_vsf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_114_1794;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd3, [__cudaparm_ene_vsf_x];
	ld.param.s32 	%r4, [__cudaparm_ene_vsf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f3, [%rd6+0];
	ld.param.f32 	%f4, [__cudaparm_ene_vsf_y];
	setp.neu.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd7, [__cudaparm_ene_vsf_result];
	ld.param.s32 	%r6, [__cudaparm_ene_vsf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f5;
$Lt_114_1794:
	exit;
$LDWend_ene_vsf:
	} // ene_vsf

	.entry ene_msf (
		.param .s32 __cudaparm_ene_msf_rs,
		.param .s32 __cudaparm_ene_msf_cs,
		.param .u64 __cudaparm_ene_msf_A,
		.param .s32 __cudaparm_ene_msf_lda,
		.param .f32 __cudaparm_ene_msf_B,
		.param .u64 __cudaparm_ene_msf_C,
		.param .s32 __cudaparm_ene_msf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<7>;
	.reg .pred %p<4>;
$LDWbegin_ene_msf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_ene_msf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_ene_msf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_115_2050;
	mov.f32 	%f1, 0f3f800000;     	// 1
	mov.f32 	%f2, 0f00000000;     	// 0
	ld.param.u64 	%rd1, [__cudaparm_ene_msf_A];
	ld.param.s32 	%r15, [__cudaparm_ene_msf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f3, [%rd4+0];
	ld.param.f32 	%f4, [__cudaparm_ene_msf_B];
	setp.neu.f32 	%p2, %f3, %f4;
	selp.f32 	%f5, %f1, %f2, %p2;
	ld.param.u64 	%rd5, [__cudaparm_ene_msf_C];
	ld.param.s32 	%r18, [__cudaparm_ene_msf_ldc];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f5;
$Lt_115_2050:
	exit;
$LDWend_ene_msf:
	} // ene_msf

	.entry enegate_vf (
		.param .u64 __cudaparm_enegate_vf_n,
		.param .u64 __cudaparm_enegate_vf_x,
		.param .s32 __cudaparm_enegate_vf_lx,
		.param .u64 __cudaparm_enegate_vf_result,
		.param .s32 __cudaparm_enegate_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
	.loc	15	169	0
$LDWbegin_enegate_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_enegate_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_116_1026;
	ld.param.u64 	%rd3, [__cudaparm_enegate_vf_x];
	ld.param.s32 	%r4, [__cudaparm_enegate_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	neg.f32 	%f2, %f1;
	ld.param.u64 	%rd7, [__cudaparm_enegate_vf_result];
	ld.param.s32 	%r6, [__cudaparm_enegate_vf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f2;
$Lt_116_1026:
	exit;
$LDWend_enegate_vf:
	} // enegate_vf

	.entry enegate_mf (
		.param .s32 __cudaparm_enegate_mf_rs,
		.param .s32 __cudaparm_enegate_mf_cs,
		.param .u64 __cudaparm_enegate_mf_A,
		.param .s32 __cudaparm_enegate_mf_lda,
		.param .u64 __cudaparm_enegate_mf_B,
		.param .s32 __cudaparm_enegate_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
$LDWbegin_enegate_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_enegate_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_enegate_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_117_1282;
	ld.param.u64 	%rd1, [__cudaparm_enegate_mf_A];
	ld.param.s32 	%r15, [__cudaparm_enegate_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	neg.f32 	%f2, %f1;
	ld.param.u64 	%rd5, [__cudaparm_enegate_mf_B];
	ld.param.s32 	%r18, [__cudaparm_enegate_mf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f2;
$Lt_117_1282:
	exit;
$LDWend_enegate_mf:
	} // enegate_mf
	.const .align 4 .b8 __cudart_i2opi_f[24] = {65,144,67,60,153,149,98,219,192,221,52,245,209,87,39,252,41,21,68,78,110,131,249,162};

	.entry ecos_vf (
		.param .u64 __cudaparm_ecos_vf_n,
		.param .u64 __cudaparm_ecos_vf_x,
		.param .s32 __cudaparm_ecos_vf_lx,
		.param .u64 __cudaparm_ecos_vf_result,
		.param .s32 __cudaparm_ecos_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<89>;
	.reg .u64 %rd<18>;
	.reg .f32 %f<97>;
	.reg .pred %p<16>;
	.local .align 4 .b8 __cuda___cuda_result_165860[28];
	.loc	15	171	0
$LDWbegin_ecos_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_ecos_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_118_11266;
	ld.param.u64 	%rd3, [__cudaparm_ecos_vf_x];
	ld.param.s32 	%r4, [__cudaparm_ecos_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	9561	0
	mov.f32 	%f2, %f1;
	.loc	17	9511	0
	abs.f32 	%f3, %f1;
	mov.f32 	%f4, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p2, %f3, %f4;
	@!%p2 bra 	$Lt_118_11778;
	.loc	17	9512	0
	mov.f32 	%f5, 0f00000000;     	// 0
	mul.rn.f32 	%f2, %f1, %f5;
$Lt_118_11778:
	.loc	17	9280	0
	mov.f32 	%f6, 0f3f22f983;     	// 0.63662
	mul.f32 	%f7, %f2, %f6;
	cvt.rni.s32.f32 	%r6, %f7;
	mov.s32 	%r7, %r6;
	.loc	17	8936	0
	cvt.rn.f32.s32 	%f8, %r6;
	neg.f32 	%f9, %f8;
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, 0f3fc90000;    	// 1.57031
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f2;
	mad.f32 %f14, %f10, %f12, %f13;
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f9;
	mov.f32 	%f17, 0f39fd8000;    	// 0.000483513
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f15;
	mad.f32 %f20, %f16, %f18, %f19;
	mov.f32 	%f21, %f20;
	mov.f32 	%f22, %f9;
	mov.f32 	%f23, 0f34a88000;    	// 3.13856e-07
	mov.f32 	%f24, %f23;
	mov.f32 	%f25, %f21;
	mad.f32 %f26, %f22, %f24, %f25;
	mov.f32 	%f27, %f26;
	mov.f32 	%f28, %f9;
	mov.f32 	%f29, 0f2e85a309;    	// 6.0771e-11
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f27;
	mad.f32 %f32, %f28, %f30, %f31;
	mov.f32 	%f33, %f32;
	.loc	17	9291	0
	mov.f32 	%f34, %f33;
	abs.f32 	%f35, %f2;
	mov.f32 	%f36, 0f473ba700;    	// 48039
	setp.gt.f32 	%p3, %f35, %f36;
	@!%p3 bra 	$Lt_118_12290;
	.loc	17	9215	0
	mov.b32 	%r8, %f2;
	and.b32 	%r9, %r8, -2147483648;
	mov.s32 	%r10, %r9;
	.loc	17	24	0
	shl.b32 	%r11, %r8, 8;
	or.b32 	%r12, %r11, -2147483648;
	mov.u64 	%rd7, __cudart_i2opi_f;
	mov.u64 	%rd8, __cuda___cuda_result_165860;
	mov.s32 	%r13, 0;
	mov.u32 	%r14, 0;
$Lt_118_13314:
 //<loop> Loop body line 24, nesting depth: 1, iterations: 6
	.loc	17	9187	0
	ld.const.u32 	%r15, [%rd7+0];
	mov.u32 	%r16, %r15;
	mov.u32 	%r17, %r12;
	mov.u32 	%r18, %r14;
	{
	.reg .u64 tmp;
	mul.wide.u32 tmp, %r16, %r17;
	mov.b64         {%r19,%r20}, tmp;
	add.cc.u32      %r19, %r19, %r18;
	addc.u32        %r20, %r20, 0;
	}
	mov.s32 	%r21, %r19;
	mov.s32 	%r22, %r20;
	.loc	17	9229	0
	mov.s32 	%r14, %r22;
	.loc	17	9230	0
	st.local.u32 	[%rd8+0], %r21;
	add.s32 	%r13, %r13, 1;
	add.u64 	%rd8, %rd8, 4;
	add.u64 	%rd7, %rd7, 4;
	mov.u32 	%r23, 6;
	setp.ne.s32 	%p4, %r13, %r23;
	@%p4 bra 	$Lt_118_13314;
	.loc	17	9232	0
	st.local.u32 	[__cuda___cuda_result_165860+24], %r22;
	.loc	17	9237	0
	shl.b32 	%r24, %r8, 1;
	shr.u32 	%r25, %r24, 24;
	sub.u32 	%r26, %r25, 128;
	mov.u64 	%rd9, __cuda___cuda_result_165860;
	shr.u32 	%r27, %r26, 5;
	mov.s32 	%r28, 4;
	sub.s32 	%r29, %r28, %r27;
	cvt.s64.s32 	%rd10, %r29;
	mul.wide.s32 	%rd11, %r29, 4;
	add.u64 	%rd12, %rd9, %rd11;
	ld.local.u32 	%r14, [%rd12+8];
	.loc	17	9238	0
	ld.local.u32 	%r30, [%rd12+4];
	and.b32 	%r31, %r26, 31;
	mov.u32 	%r32, 0;
	setp.eq.u32 	%p5, %r31, %r32;
	@%p5 bra 	$Lt_118_13826;
	.loc	17	9241	0
	mov.s32 	%r33, 32;
	sub.s32 	%r34, %r33, %r31;
	shr.u32 	%r35, %r30, %r34;
	shl.b32 	%r36, %r14, %r31;
	add.u32 	%r14, %r35, %r36;
	.loc	17	9242	0
	ld.local.u32 	%r37, [%rd12+0];
	shr.u32 	%r38, %r37, %r34;
	shl.b32 	%r39, %r30, %r31;
	add.u32 	%r30, %r38, %r39;
$Lt_118_13826:
	.loc	17	9244	0
	shr.u32 	%r40, %r14, 30;
	.loc	17	9246	0
	shr.u32 	%r41, %r30, 30;
	shl.b32 	%r42, %r14, 2;
	add.u32 	%r14, %r41, %r42;
	.loc	17	9247	0
	shl.b32 	%r30, %r30, 2;
	.loc	17	9249	0
	shr.u32 	%r43, %r14, 31;
	add.u32 	%r44, %r40, %r43;
	.loc	17	9244	0
	neg.s32 	%r45, %r44;
	mov.u32 	%r46, 0;
	setp.ne.u32 	%p6, %r9, %r46;
	selp.s32 	%r13, %r45, %r44, %p6;
	.loc	17	9251	0
	mov.s32 	%r7, %r13;
	mov.u32 	%r47, 0;
	setp.eq.u32 	%p7, %r43, %r47;
	@%p7 bra 	$Lt_118_14338;
	.loc	17	9255	0
	neg.s32 	%r30, %r30;
	.loc	17	9257	0
	mov.u32 	%r48, 0;
	set.eq.u32.u32 	%r49, %r30, %r48;
	neg.s32 	%r50, %r49;
	not.b32 	%r51, %r14;
	add.u32 	%r14, %r50, %r51;
	.loc	17	9258	0
	xor.b32 	%r10, %r9, -2147483648;
$Lt_118_14338:
	.loc	17	9261	0
	mov.u32 	%r52, 0;
	setp.eq.s32 	%p8, %r14, %r52;
	@%p8 bra 	$Lt_118_15106;
	.loc	19	6283	0
	cvt.rz.f32.u32 	%f37, %r14;
	mov.b32 	%r53, %f37;
	shr.s32 	%r54, %r53, 23;
	mov.s32 	%r55, 158;
	sub.s32 	%r56, %r55, %r54;
	bra.uni 	$Lt_118_14850;
$Lt_118_15106:
	mov.s32 	%r56, 32;
$Lt_118_14850:
	.loc	17	9261	0
	mov.s32 	%r57, %r56;
	mov.s32 	%r58, %r57;
	.loc	19	6283	0
	mov.s32 	%r59, 32;
	sub.s32 	%r60, %r59, %r57;
	shr.u32 	%r61, %r30, %r60;
	shl.b32 	%r62, %r14, %r57;
	add.u32 	%r63, %r61, %r62;
	mov.u32 	%r64, 0;
	setp.ne.u32 	%p9, %r57, %r64;
	selp.u32 	%r65, %r63, %r14, %p9;
	.loc	17	9265	0
	mul.lo.u32 	%r30, %r65, -921707870;
	.loc	17	9266	0
	mov.u32 	%r66, -921707870;
	mul.hi.u32 	%r14, %r65, %r66;
	mov.u32 	%r67, 0;
	setp.le.s32 	%p10, %r14, %r67;
	@%p10 bra 	$Lt_118_15362;
	.loc	17	9268	0
	shr.u32 	%r68, %r30, 31;
	shl.b32 	%r69, %r14, 1;
	add.u32 	%r14, %r68, %r69;
	.loc	17	9269	0
	add.u32 	%r58, %r57, 1;
$Lt_118_15362:
	.loc	17	9294	0
	add.u32 	%r70, %r14, 1;
	shr.u32 	%r71, %r70, 7;
	add.u32 	%r72, %r71, 1;
	shr.u32 	%r73, %r72, 1;
	mov.s32 	%r74, 126;
	sub.s32 	%r75, %r74, %r58;
	shl.b32 	%r76, %r75, 23;
	add.u32 	%r77, %r73, %r76;
	or.b32 	%r78, %r10, %r77;
	mov.b32 	%f34, %r78;
$Lt_118_12290:
	.loc	17	8936	0
	mul.f32 	%f38, %f34, %f34;
	mov.f32 	%f39, 0f37ccf5ce;    	// 2.44332e-05
	mov.f32 	%f40, %f39;
	mov.f32 	%f41, %f38;
	mov.f32 	%f42, 0fbab6061a;    	// -0.00138873
	mov.f32 	%f43, %f42;
	mad.f32 %f44, %f40, %f41, %f43;
	mov.f32 	%f45, %f44;
	mov.f32 	%f46, %f45;
	mov.f32 	%f47, %f38;
	mov.f32 	%f48, 0f3d2aaaa5;    	// 0.0416666
	mov.f32 	%f49, %f48;
	mad.f32 %f50, %f46, %f47, %f49;
	mov.f32 	%f51, %f50;
	mov.f32 	%f52, %f51;
	mov.f32 	%f53, %f38;
	mov.f32 	%f54, 0fbf000000;    	// -0.5
	mov.f32 	%f55, %f54;
	mad.f32 %f56, %f52, %f53, %f55;
	mov.f32 	%f57, %f56;
	mov.f32 	%f58, %f57;
	mov.f32 	%f59, %f38;
	mov.f32 	%f60, 0f3f800000;    	// 1
	mov.f32 	%f61, %f60;
	mad.f32 %f62, %f58, %f59, %f61;
	mov.f32 	%f63, %f62;
	.loc	17	9515	0
	mov.f32 	%f64, %f63;
	.loc	17	8936	0
	mov.f32 	%f65, 0fb94ca1f9;    	// -0.000195153
	mov.f32 	%f66, %f65;
	mov.f32 	%f67, %f38;
	mov.f32 	%f68, 0f3c08839e;    	// 0.00833216
	mov.f32 	%f69, %f68;
	mad.f32 %f70, %f66, %f67, %f69;
	mov.f32 	%f71, %f70;
	mov.f32 	%f72, %f71;
	mov.f32 	%f73, %f38;
	mov.f32 	%f74, 0fbe2aaaa3;    	// -0.166667
	mov.f32 	%f75, %f74;
	mad.f32 %f76, %f72, %f73, %f75;
	mov.f32 	%f77, %f76;
	mul.f32 	%f78, %f38, %f77;
	mov.f32 	%f79, %f78;
	mov.f32 	%f80, %f34;
	mov.f32 	%f81, %f34;
	mad.f32 %f82, %f79, %f80, %f81;
	mov.f32 	%f83, %f82;
	.loc	17	9516	0
	mov.f32 	%f84, %f83;
	.loc	17	9517	0
	mov.f32 	%f85, %f84;
	and.b32 	%r79, %r7, 1;
	mov.u32 	%r80, 0;
	setp.eq.s32 	%p11, %r79, %r80;
	@%p11 bra 	$Lt_118_15874;
	.loc	17	9519	0
	mov.f32 	%f86, %f64;
	mov.f32 	%f84, %f86;
	.loc	17	9520	0
	mov.f32 	%f64, %f85;
$Lt_118_15874:
	and.b32 	%r81, %r7, 2;
	mov.u32 	%r82, 0;
	setp.eq.s32 	%p12, %r81, %r82;
	@%p12 bra 	$Lt_118_16386;
	.loc	17	9523	0
	mov.f32 	%f87, %f84;
	neg.f32 	%f88, %f87;
	mov.f32 	%f84, %f88;
$Lt_118_16386:
	add.s32 	%r83, %r7, 1;
	and.b32 	%r84, %r83, 2;
	mov.u32 	%r85, 0;
	setp.eq.s32 	%p13, %r84, %r85;
	@%p13 bra 	$Lt_118_16898;
	.loc	17	9527	0
	mov.f32 	%f89, %f64;
	neg.f32 	%f90, %f89;
	mov.f32 	%f64, %f90;
$Lt_118_16898:
	mov.f32 	%f91, 0f00000000;    	// 0
	setp.eq.f32 	%p14, %f34, %f91;
	@!%p14 bra 	$Lt_118_17410;
	.loc	17	9531	0
	mov.f32 	%f92, 0f00000000;    	// 0
	mul.rn.f32 	%f93, %f34, %f92;
	mov.f32 	%f84, %f93;
$Lt_118_17410:
	.loc	17	9534	0
	mov.f32 	%f94, %f84;
	.loc	17	9535	0
	mov.f32 	%f95, %f64;
	.loc	15	171	0
	ld.param.u64 	%rd13, [__cudaparm_ecos_vf_result];
	ld.param.s32 	%r86, [__cudaparm_ecos_vf_lr];
	mul.lo.s32 	%r87, %r86, %r3;
	cvt.s64.s32 	%rd14, %r87;
	mul.wide.s32 	%rd15, %r87, 4;
	add.u64 	%rd16, %rd13, %rd15;
	st.global.f32 	[%rd16+0], %f95;
$Lt_118_11266:
	exit;
$LDWend_ecos_vf:
	} // ecos_vf

	.entry ecos_mf (
		.param .s32 __cudaparm_ecos_mf_rs,
		.param .s32 __cudaparm_ecos_mf_cs,
		.param .u64 __cudaparm_ecos_mf_A,
		.param .s32 __cudaparm_ecos_mf_lda,
		.param .u64 __cudaparm_ecos_mf_B,
		.param .s32 __cudaparm_ecos_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<102>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<97>;
	.reg .pred %p<16>;
	.local .align 4 .b8 __cuda___cuda_result_165924[28];
$LDWbegin_ecos_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_ecos_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_ecos_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_119_11522;
	ld.param.u64 	%rd1, [__cudaparm_ecos_mf_A];
	ld.param.s32 	%r15, [__cudaparm_ecos_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	9561	0
	mov.f32 	%f2, %f1;
	.loc	17	9511	0
	abs.f32 	%f3, %f1;
	mov.f32 	%f4, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p2, %f3, %f4;
	@!%p2 bra 	$Lt_119_12034;
	.loc	17	9512	0
	mov.f32 	%f5, 0f00000000;     	// 0
	mul.rn.f32 	%f2, %f1, %f5;
$Lt_119_12034:
	.loc	17	9280	0
	mov.f32 	%f6, 0f3f22f983;     	// 0.63662
	mul.f32 	%f7, %f2, %f6;
	cvt.rni.s32.f32 	%r18, %f7;
	mov.s32 	%r19, %r18;
	.loc	17	8936	0
	cvt.rn.f32.s32 	%f8, %r18;
	neg.f32 	%f9, %f8;
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, 0f3fc90000;    	// 1.57031
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f2;
	mad.f32 %f14, %f10, %f12, %f13;
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f9;
	mov.f32 	%f17, 0f39fd8000;    	// 0.000483513
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f15;
	mad.f32 %f20, %f16, %f18, %f19;
	mov.f32 	%f21, %f20;
	mov.f32 	%f22, %f9;
	mov.f32 	%f23, 0f34a88000;    	// 3.13856e-07
	mov.f32 	%f24, %f23;
	mov.f32 	%f25, %f21;
	mad.f32 %f26, %f22, %f24, %f25;
	mov.f32 	%f27, %f26;
	mov.f32 	%f28, %f9;
	mov.f32 	%f29, 0f2e85a309;    	// 6.0771e-11
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f27;
	mad.f32 %f32, %f28, %f30, %f31;
	mov.f32 	%f33, %f32;
	.loc	17	9291	0
	mov.f32 	%f34, %f33;
	abs.f32 	%f35, %f2;
	mov.f32 	%f36, 0f473ba700;    	// 48039
	setp.gt.f32 	%p3, %f35, %f36;
	@!%p3 bra 	$Lt_119_12546;
	.loc	17	9215	0
	mov.b32 	%r20, %f2;
	and.b32 	%r21, %r20, -2147483648;
	mov.s32 	%r22, %r21;
	.loc	17	24	0
	shl.b32 	%r23, %r20, 8;
	or.b32 	%r24, %r23, -2147483648;
	mov.u64 	%rd5, __cudart_i2opi_f;
	mov.u64 	%rd6, __cuda___cuda_result_165924;
	mov.s32 	%r25, 0;
	mov.u32 	%r26, 0;
$Lt_119_13570:
 //<loop> Loop body line 24, nesting depth: 1, iterations: 6
	.loc	17	9187	0
	ld.const.u32 	%r27, [%rd5+0];
	mov.u32 	%r28, %r27;
	mov.u32 	%r29, %r24;
	mov.u32 	%r30, %r26;
	{
	.reg .u64 tmp;
	mul.wide.u32 tmp, %r28, %r29;
	mov.b64         {%r31,%r32}, tmp;
	add.cc.u32      %r31, %r31, %r30;
	addc.u32        %r32, %r32, 0;
	}
	mov.s32 	%r33, %r31;
	mov.s32 	%r34, %r32;
	.loc	17	9229	0
	mov.s32 	%r26, %r34;
	.loc	17	9230	0
	st.local.u32 	[%rd6+0], %r33;
	add.s32 	%r25, %r25, 1;
	add.u64 	%rd6, %rd6, 4;
	add.u64 	%rd5, %rd5, 4;
	mov.u32 	%r35, 6;
	setp.ne.s32 	%p4, %r25, %r35;
	@%p4 bra 	$Lt_119_13570;
	.loc	17	9232	0
	st.local.u32 	[__cuda___cuda_result_165924+24], %r34;
	.loc	17	9237	0
	shl.b32 	%r36, %r20, 1;
	shr.u32 	%r37, %r36, 24;
	sub.u32 	%r38, %r37, 128;
	mov.u64 	%rd7, __cuda___cuda_result_165924;
	shr.u32 	%r39, %r38, 5;
	mov.s32 	%r40, 4;
	sub.s32 	%r41, %r40, %r39;
	cvt.s64.s32 	%rd8, %r41;
	mul.wide.s32 	%rd9, %r41, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.local.u32 	%r26, [%rd10+8];
	.loc	17	9238	0
	ld.local.u32 	%r42, [%rd10+4];
	and.b32 	%r43, %r38, 31;
	mov.u32 	%r44, 0;
	setp.eq.u32 	%p5, %r43, %r44;
	@%p5 bra 	$Lt_119_14082;
	.loc	17	9241	0
	mov.s32 	%r45, 32;
	sub.s32 	%r46, %r45, %r43;
	shr.u32 	%r47, %r42, %r46;
	shl.b32 	%r48, %r26, %r43;
	add.u32 	%r26, %r47, %r48;
	.loc	17	9242	0
	ld.local.u32 	%r49, [%rd10+0];
	shr.u32 	%r50, %r49, %r46;
	shl.b32 	%r51, %r42, %r43;
	add.u32 	%r42, %r50, %r51;
$Lt_119_14082:
	.loc	17	9244	0
	shr.u32 	%r52, %r26, 30;
	.loc	17	9246	0
	shr.u32 	%r53, %r42, 30;
	shl.b32 	%r54, %r26, 2;
	add.u32 	%r26, %r53, %r54;
	.loc	17	9247	0
	shl.b32 	%r42, %r42, 2;
	.loc	17	9249	0
	shr.u32 	%r55, %r26, 31;
	add.u32 	%r56, %r52, %r55;
	.loc	17	9244	0
	neg.s32 	%r57, %r56;
	mov.u32 	%r58, 0;
	setp.ne.u32 	%p6, %r21, %r58;
	selp.s32 	%r25, %r57, %r56, %p6;
	.loc	17	9251	0
	mov.s32 	%r19, %r25;
	mov.u32 	%r59, 0;
	setp.eq.u32 	%p7, %r55, %r59;
	@%p7 bra 	$Lt_119_14594;
	.loc	17	9255	0
	neg.s32 	%r42, %r42;
	.loc	17	9257	0
	mov.u32 	%r60, 0;
	set.eq.u32.u32 	%r61, %r42, %r60;
	neg.s32 	%r62, %r61;
	not.b32 	%r63, %r26;
	add.u32 	%r26, %r62, %r63;
	.loc	17	9258	0
	xor.b32 	%r22, %r21, -2147483648;
$Lt_119_14594:
	.loc	17	9261	0
	mov.u32 	%r64, 0;
	setp.eq.s32 	%p8, %r26, %r64;
	@%p8 bra 	$Lt_119_15362;
	.loc	19	6283	0
	cvt.rz.f32.u32 	%f37, %r26;
	mov.b32 	%r65, %f37;
	shr.s32 	%r66, %r65, 23;
	mov.s32 	%r67, 158;
	sub.s32 	%r68, %r67, %r66;
	bra.uni 	$Lt_119_15106;
$Lt_119_15362:
	mov.s32 	%r68, 32;
$Lt_119_15106:
	.loc	17	9261	0
	mov.s32 	%r69, %r68;
	mov.s32 	%r70, %r69;
	.loc	19	6283	0
	mov.s32 	%r71, 32;
	sub.s32 	%r72, %r71, %r69;
	shr.u32 	%r73, %r42, %r72;
	shl.b32 	%r74, %r26, %r69;
	add.u32 	%r75, %r73, %r74;
	mov.u32 	%r76, 0;
	setp.ne.u32 	%p9, %r69, %r76;
	selp.u32 	%r77, %r75, %r26, %p9;
	.loc	17	9265	0
	mul.lo.u32 	%r42, %r77, -921707870;
	.loc	17	9266	0
	mov.u32 	%r78, -921707870;
	mul.hi.u32 	%r26, %r77, %r78;
	mov.u32 	%r79, 0;
	setp.le.s32 	%p10, %r26, %r79;
	@%p10 bra 	$Lt_119_15618;
	.loc	17	9268	0
	shr.u32 	%r80, %r42, 31;
	shl.b32 	%r81, %r26, 1;
	add.u32 	%r26, %r80, %r81;
	.loc	17	9269	0
	add.u32 	%r70, %r69, 1;
$Lt_119_15618:
	.loc	17	9294	0
	add.u32 	%r82, %r26, 1;
	shr.u32 	%r83, %r82, 7;
	add.u32 	%r84, %r83, 1;
	shr.u32 	%r85, %r84, 1;
	mov.s32 	%r86, 126;
	sub.s32 	%r87, %r86, %r70;
	shl.b32 	%r88, %r87, 23;
	add.u32 	%r89, %r85, %r88;
	or.b32 	%r90, %r22, %r89;
	mov.b32 	%f34, %r90;
$Lt_119_12546:
	.loc	17	8936	0
	mul.f32 	%f38, %f34, %f34;
	mov.f32 	%f39, 0f37ccf5ce;    	// 2.44332e-05
	mov.f32 	%f40, %f39;
	mov.f32 	%f41, %f38;
	mov.f32 	%f42, 0fbab6061a;    	// -0.00138873
	mov.f32 	%f43, %f42;
	mad.f32 %f44, %f40, %f41, %f43;
	mov.f32 	%f45, %f44;
	mov.f32 	%f46, %f45;
	mov.f32 	%f47, %f38;
	mov.f32 	%f48, 0f3d2aaaa5;    	// 0.0416666
	mov.f32 	%f49, %f48;
	mad.f32 %f50, %f46, %f47, %f49;
	mov.f32 	%f51, %f50;
	mov.f32 	%f52, %f51;
	mov.f32 	%f53, %f38;
	mov.f32 	%f54, 0fbf000000;    	// -0.5
	mov.f32 	%f55, %f54;
	mad.f32 %f56, %f52, %f53, %f55;
	mov.f32 	%f57, %f56;
	mov.f32 	%f58, %f57;
	mov.f32 	%f59, %f38;
	mov.f32 	%f60, 0f3f800000;    	// 1
	mov.f32 	%f61, %f60;
	mad.f32 %f62, %f58, %f59, %f61;
	mov.f32 	%f63, %f62;
	.loc	17	9515	0
	mov.f32 	%f64, %f63;
	.loc	17	8936	0
	mov.f32 	%f65, 0fb94ca1f9;    	// -0.000195153
	mov.f32 	%f66, %f65;
	mov.f32 	%f67, %f38;
	mov.f32 	%f68, 0f3c08839e;    	// 0.00833216
	mov.f32 	%f69, %f68;
	mad.f32 %f70, %f66, %f67, %f69;
	mov.f32 	%f71, %f70;
	mov.f32 	%f72, %f71;
	mov.f32 	%f73, %f38;
	mov.f32 	%f74, 0fbe2aaaa3;    	// -0.166667
	mov.f32 	%f75, %f74;
	mad.f32 %f76, %f72, %f73, %f75;
	mov.f32 	%f77, %f76;
	mul.f32 	%f78, %f38, %f77;
	mov.f32 	%f79, %f78;
	mov.f32 	%f80, %f34;
	mov.f32 	%f81, %f34;
	mad.f32 %f82, %f79, %f80, %f81;
	mov.f32 	%f83, %f82;
	.loc	17	9516	0
	mov.f32 	%f84, %f83;
	.loc	17	9517	0
	mov.f32 	%f85, %f84;
	and.b32 	%r91, %r19, 1;
	mov.u32 	%r92, 0;
	setp.eq.s32 	%p11, %r91, %r92;
	@%p11 bra 	$Lt_119_16130;
	.loc	17	9519	0
	mov.f32 	%f86, %f64;
	mov.f32 	%f84, %f86;
	.loc	17	9520	0
	mov.f32 	%f64, %f85;
$Lt_119_16130:
	and.b32 	%r93, %r19, 2;
	mov.u32 	%r94, 0;
	setp.eq.s32 	%p12, %r93, %r94;
	@%p12 bra 	$Lt_119_16642;
	.loc	17	9523	0
	mov.f32 	%f87, %f84;
	neg.f32 	%f88, %f87;
	mov.f32 	%f84, %f88;
$Lt_119_16642:
	add.s32 	%r95, %r19, 1;
	and.b32 	%r96, %r95, 2;
	mov.u32 	%r97, 0;
	setp.eq.s32 	%p13, %r96, %r97;
	@%p13 bra 	$Lt_119_17154;
	.loc	17	9527	0
	mov.f32 	%f89, %f64;
	neg.f32 	%f90, %f89;
	mov.f32 	%f64, %f90;
$Lt_119_17154:
	mov.f32 	%f91, 0f00000000;    	// 0
	setp.eq.f32 	%p14, %f34, %f91;
	@!%p14 bra 	$Lt_119_17666;
	.loc	17	9531	0
	mov.f32 	%f92, 0f00000000;    	// 0
	mul.rn.f32 	%f93, %f34, %f92;
	mov.f32 	%f84, %f93;
$Lt_119_17666:
	.loc	17	9534	0
	mov.f32 	%f94, %f84;
	.loc	17	9535	0
	mov.f32 	%f95, %f64;
	.loc	15	171	0
	ld.param.u64 	%rd11, [__cudaparm_ecos_mf_B];
	ld.param.s32 	%r98, [__cudaparm_ecos_mf_ldb];
	mul.lo.s32 	%r99, %r98, %r4;
	add.s32 	%r100, %r6, %r99;
	cvt.s64.s32 	%rd12, %r100;
	mul.wide.s32 	%rd13, %r100, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f95;
$Lt_119_11522:
	exit;
$LDWend_ecos_mf:
	} // ecos_mf

	.entry ecosh_vf (
		.param .u64 __cudaparm_ecosh_vf_n,
		.param .u64 __cudaparm_ecosh_vf_x,
		.param .s32 __cudaparm_ecosh_vf_lx,
		.param .u64 __cudaparm_ecosh_vf_result,
		.param .s32 __cudaparm_ecosh_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<39>;
	.reg .pred %p<4>;
	.loc	15	172	0
$LDWbegin_ecosh_vf:
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r1, %rh1, %rh2;
	cvt.u32.u16 	%r2, %tid.x;
	add.u32 	%r3, %r2, %r1;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_ecosh_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_120_1794;
	.loc	17	9758	0
	ld.param.u64 	%rd3, [__cudaparm_ecosh_vf_x];
	ld.param.s32 	%r4, [__cudaparm_ecosh_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	abs.f32 	%f2, %f1;
	.loc	17	8936	0
	mov.f32 	%f3, 0f3fb8aa3b;     	// 1.4427
	mul.f32 	%f4, %f2, %f3;
	cvt.rzi.f32.f32 	%f5, %f4;
	mov.f32 	%f6, %f5;
	mov.f32 	%f7, 0fbf317200;     	// -0.693146
	mov.f32 	%f8, %f7;
	mov.f32 	%f9, %f2;
	mad.f32 %f10, %f6, %f8, %f9;
	mov.f32 	%f11, %f10;
	mov.f32 	%f12, %f5;
	mov.f32 	%f13, 0fb5bfbe8e;    	// -1.42861e-06
	mov.f32 	%f14, %f13;
	mov.f32 	%f15, %f11;
	mad.f32 %f16, %f12, %f14, %f15;
	mov.f32 	%f17, %f16;
	.loc	17	8965	0
	mov.f32 	%f18, 0f3fb8aa3b;    	// 1.4427
	mul.f32 	%f19, %f17, %f18;
	mov.f32 	%f20, %f19;
	ex2.approx.ftz.f32 %f21,%f20;
	mov.f32 	%f22, %f21;
	.loc	17	8936	0
	mov.f32 	%f23, 0fc0000000;    	// -2
	add.f32 	%f24, %f5, %f23;
	ex2.approx.f32 	%f25, %f24;
	mul.f32 	%f26, %f25, %f22;
	mov.f32 	%f27, 0f40000000;    	// 2
	mov.f32 	%f28, %f27;
	mov.f32 	%f29, %f26;
	mov.f32 	%f30, 0f3e000000;    	// 0.125
	div.approx.f32 	%f31, %f30, %f26;
	mov.f32 	%f32, %f31;
	mad.f32 %f33, %f28, %f29, %f32;
	mov.f32 	%f34, %f33;
	.loc	15	172	0
	mov.f32 	%f35, 0f7f800000;    	// ((1.0F)/(0.0F))
	mov.f32 	%f36, 0f42b40000;    	// 90
	setp.ge.f32 	%p2, %f2, %f36;
	selp.f32 	%f37, %f35, %f34, %p2;
	ld.param.u64 	%rd7, [__cudaparm_ecosh_vf_result];
	ld.param.s32 	%r6, [__cudaparm_ecosh_vf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f37;
$Lt_120_1794:
	exit;
$LDWend_ecosh_vf:
	} // ecosh_vf

	.entry ecosh_mf (
		.param .s32 __cudaparm_ecosh_mf_rs,
		.param .s32 __cudaparm_ecosh_mf_cs,
		.param .u64 __cudaparm_ecosh_mf_A,
		.param .s32 __cudaparm_ecosh_mf_lda,
		.param .u64 __cudaparm_ecosh_mf_B,
		.param .s32 __cudaparm_ecosh_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<39>;
	.reg .pred %p<4>;
$LDWbegin_ecosh_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_ecosh_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_ecosh_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_121_2050;
	.loc	17	9758	0
	ld.param.u64 	%rd1, [__cudaparm_ecosh_mf_A];
	ld.param.s32 	%r15, [__cudaparm_ecosh_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	abs.f32 	%f2, %f1;
	.loc	17	8936	0
	mov.f32 	%f3, 0f3fb8aa3b;     	// 1.4427
	mul.f32 	%f4, %f2, %f3;
	cvt.rzi.f32.f32 	%f5, %f4;
	mov.f32 	%f6, %f5;
	mov.f32 	%f7, 0fbf317200;     	// -0.693146
	mov.f32 	%f8, %f7;
	mov.f32 	%f9, %f2;
	mad.f32 %f10, %f6, %f8, %f9;
	mov.f32 	%f11, %f10;
	mov.f32 	%f12, %f5;
	mov.f32 	%f13, 0fb5bfbe8e;    	// -1.42861e-06
	mov.f32 	%f14, %f13;
	mov.f32 	%f15, %f11;
	mad.f32 %f16, %f12, %f14, %f15;
	mov.f32 	%f17, %f16;
	.loc	17	8965	0
	mov.f32 	%f18, 0f3fb8aa3b;    	// 1.4427
	mul.f32 	%f19, %f17, %f18;
	mov.f32 	%f20, %f19;
	ex2.approx.ftz.f32 %f21,%f20;
	mov.f32 	%f22, %f21;
	.loc	17	8936	0
	mov.f32 	%f23, 0fc0000000;    	// -2
	add.f32 	%f24, %f5, %f23;
	ex2.approx.f32 	%f25, %f24;
	mul.f32 	%f26, %f25, %f22;
	mov.f32 	%f27, 0f40000000;    	// 2
	mov.f32 	%f28, %f27;
	mov.f32 	%f29, %f26;
	mov.f32 	%f30, 0f3e000000;    	// 0.125
	div.approx.f32 	%f31, %f30, %f26;
	mov.f32 	%f32, %f31;
	mad.f32 %f33, %f28, %f29, %f32;
	mov.f32 	%f34, %f33;
	.loc	15	172	0
	mov.f32 	%f35, 0f7f800000;    	// ((1.0F)/(0.0F))
	mov.f32 	%f36, 0f42b40000;    	// 90
	setp.ge.f32 	%p2, %f2, %f36;
	selp.f32 	%f37, %f35, %f34, %p2;
	ld.param.u64 	%rd5, [__cudaparm_ecosh_mf_B];
	ld.param.s32 	%r18, [__cudaparm_ecosh_mf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f37;
$Lt_121_2050:
	exit;
$LDWend_ecosh_mf:
	} // ecosh_mf

	.entry esin_vf (
		.param .u64 __cudaparm_esin_vf_n,
		.param .u64 __cudaparm_esin_vf_x,
		.param .s32 __cudaparm_esin_vf_lx,
		.param .u64 __cudaparm_esin_vf_result,
		.param .s32 __cudaparm_esin_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<89>;
	.reg .u64 %rd<18>;
	.reg .f32 %f<97>;
	.reg .pred %p<16>;
	.local .align 4 .b8 __cuda___cuda_result_166068[28];
	.loc	15	173	0
$LDWbegin_esin_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_esin_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_122_11266;
	ld.param.u64 	%rd3, [__cudaparm_esin_vf_x];
	ld.param.s32 	%r4, [__cudaparm_esin_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	9542	0
	mov.f32 	%f2, %f1;
	.loc	17	9511	0
	abs.f32 	%f3, %f1;
	mov.f32 	%f4, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p2, %f3, %f4;
	@!%p2 bra 	$Lt_122_11778;
	.loc	17	9512	0
	mov.f32 	%f5, 0f00000000;     	// 0
	mul.rn.f32 	%f2, %f1, %f5;
$Lt_122_11778:
	.loc	17	9280	0
	mov.f32 	%f6, 0f3f22f983;     	// 0.63662
	mul.f32 	%f7, %f2, %f6;
	cvt.rni.s32.f32 	%r6, %f7;
	mov.s32 	%r7, %r6;
	.loc	17	8936	0
	cvt.rn.f32.s32 	%f8, %r6;
	neg.f32 	%f9, %f8;
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, 0f3fc90000;    	// 1.57031
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f2;
	mad.f32 %f14, %f10, %f12, %f13;
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f9;
	mov.f32 	%f17, 0f39fd8000;    	// 0.000483513
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f15;
	mad.f32 %f20, %f16, %f18, %f19;
	mov.f32 	%f21, %f20;
	mov.f32 	%f22, %f9;
	mov.f32 	%f23, 0f34a88000;    	// 3.13856e-07
	mov.f32 	%f24, %f23;
	mov.f32 	%f25, %f21;
	mad.f32 %f26, %f22, %f24, %f25;
	mov.f32 	%f27, %f26;
	mov.f32 	%f28, %f9;
	mov.f32 	%f29, 0f2e85a309;    	// 6.0771e-11
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f27;
	mad.f32 %f32, %f28, %f30, %f31;
	mov.f32 	%f33, %f32;
	.loc	17	9291	0
	mov.f32 	%f34, %f33;
	abs.f32 	%f35, %f2;
	mov.f32 	%f36, 0f473ba700;    	// 48039
	setp.gt.f32 	%p3, %f35, %f36;
	@!%p3 bra 	$Lt_122_12290;
	.loc	17	9215	0
	mov.b32 	%r8, %f2;
	and.b32 	%r9, %r8, -2147483648;
	mov.s32 	%r10, %r9;
	.loc	17	24	0
	shl.b32 	%r11, %r8, 8;
	or.b32 	%r12, %r11, -2147483648;
	mov.u64 	%rd7, __cudart_i2opi_f;
	mov.u64 	%rd8, __cuda___cuda_result_166068;
	mov.s32 	%r13, 0;
	mov.u32 	%r14, 0;
$Lt_122_13314:
 //<loop> Loop body line 24, nesting depth: 1, iterations: 6
	.loc	17	9187	0
	ld.const.u32 	%r15, [%rd7+0];
	mov.u32 	%r16, %r15;
	mov.u32 	%r17, %r12;
	mov.u32 	%r18, %r14;
	{
	.reg .u64 tmp;
	mul.wide.u32 tmp, %r16, %r17;
	mov.b64         {%r19,%r20}, tmp;
	add.cc.u32      %r19, %r19, %r18;
	addc.u32        %r20, %r20, 0;
	}
	mov.s32 	%r21, %r19;
	mov.s32 	%r22, %r20;
	.loc	17	9229	0
	mov.s32 	%r14, %r22;
	.loc	17	9230	0
	st.local.u32 	[%rd8+0], %r21;
	add.s32 	%r13, %r13, 1;
	add.u64 	%rd8, %rd8, 4;
	add.u64 	%rd7, %rd7, 4;
	mov.u32 	%r23, 6;
	setp.ne.s32 	%p4, %r13, %r23;
	@%p4 bra 	$Lt_122_13314;
	.loc	17	9232	0
	st.local.u32 	[__cuda___cuda_result_166068+24], %r22;
	.loc	17	9237	0
	shl.b32 	%r24, %r8, 1;
	shr.u32 	%r25, %r24, 24;
	sub.u32 	%r26, %r25, 128;
	mov.u64 	%rd9, __cuda___cuda_result_166068;
	shr.u32 	%r27, %r26, 5;
	mov.s32 	%r28, 4;
	sub.s32 	%r29, %r28, %r27;
	cvt.s64.s32 	%rd10, %r29;
	mul.wide.s32 	%rd11, %r29, 4;
	add.u64 	%rd12, %rd9, %rd11;
	ld.local.u32 	%r14, [%rd12+8];
	.loc	17	9238	0
	ld.local.u32 	%r30, [%rd12+4];
	and.b32 	%r31, %r26, 31;
	mov.u32 	%r32, 0;
	setp.eq.u32 	%p5, %r31, %r32;
	@%p5 bra 	$Lt_122_13826;
	.loc	17	9241	0
	mov.s32 	%r33, 32;
	sub.s32 	%r34, %r33, %r31;
	shr.u32 	%r35, %r30, %r34;
	shl.b32 	%r36, %r14, %r31;
	add.u32 	%r14, %r35, %r36;
	.loc	17	9242	0
	ld.local.u32 	%r37, [%rd12+0];
	shr.u32 	%r38, %r37, %r34;
	shl.b32 	%r39, %r30, %r31;
	add.u32 	%r30, %r38, %r39;
$Lt_122_13826:
	.loc	17	9244	0
	shr.u32 	%r40, %r14, 30;
	.loc	17	9246	0
	shr.u32 	%r41, %r30, 30;
	shl.b32 	%r42, %r14, 2;
	add.u32 	%r14, %r41, %r42;
	.loc	17	9247	0
	shl.b32 	%r30, %r30, 2;
	.loc	17	9249	0
	shr.u32 	%r43, %r14, 31;
	add.u32 	%r44, %r40, %r43;
	.loc	17	9244	0
	neg.s32 	%r45, %r44;
	mov.u32 	%r46, 0;
	setp.ne.u32 	%p6, %r9, %r46;
	selp.s32 	%r13, %r45, %r44, %p6;
	.loc	17	9251	0
	mov.s32 	%r7, %r13;
	mov.u32 	%r47, 0;
	setp.eq.u32 	%p7, %r43, %r47;
	@%p7 bra 	$Lt_122_14338;
	.loc	17	9255	0
	neg.s32 	%r30, %r30;
	.loc	17	9257	0
	mov.u32 	%r48, 0;
	set.eq.u32.u32 	%r49, %r30, %r48;
	neg.s32 	%r50, %r49;
	not.b32 	%r51, %r14;
	add.u32 	%r14, %r50, %r51;
	.loc	17	9258	0
	xor.b32 	%r10, %r9, -2147483648;
$Lt_122_14338:
	.loc	17	9261	0
	mov.u32 	%r52, 0;
	setp.eq.s32 	%p8, %r14, %r52;
	@%p8 bra 	$Lt_122_15106;
	.loc	19	6283	0
	cvt.rz.f32.u32 	%f37, %r14;
	mov.b32 	%r53, %f37;
	shr.s32 	%r54, %r53, 23;
	mov.s32 	%r55, 158;
	sub.s32 	%r56, %r55, %r54;
	bra.uni 	$Lt_122_14850;
$Lt_122_15106:
	mov.s32 	%r56, 32;
$Lt_122_14850:
	.loc	17	9261	0
	mov.s32 	%r57, %r56;
	mov.s32 	%r58, %r57;
	.loc	19	6283	0
	mov.s32 	%r59, 32;
	sub.s32 	%r60, %r59, %r57;
	shr.u32 	%r61, %r30, %r60;
	shl.b32 	%r62, %r14, %r57;
	add.u32 	%r63, %r61, %r62;
	mov.u32 	%r64, 0;
	setp.ne.u32 	%p9, %r57, %r64;
	selp.u32 	%r65, %r63, %r14, %p9;
	.loc	17	9265	0
	mul.lo.u32 	%r30, %r65, -921707870;
	.loc	17	9266	0
	mov.u32 	%r66, -921707870;
	mul.hi.u32 	%r14, %r65, %r66;
	mov.u32 	%r67, 0;
	setp.le.s32 	%p10, %r14, %r67;
	@%p10 bra 	$Lt_122_15362;
	.loc	17	9268	0
	shr.u32 	%r68, %r30, 31;
	shl.b32 	%r69, %r14, 1;
	add.u32 	%r14, %r68, %r69;
	.loc	17	9269	0
	add.u32 	%r58, %r57, 1;
$Lt_122_15362:
	.loc	17	9294	0
	add.u32 	%r70, %r14, 1;
	shr.u32 	%r71, %r70, 7;
	add.u32 	%r72, %r71, 1;
	shr.u32 	%r73, %r72, 1;
	mov.s32 	%r74, 126;
	sub.s32 	%r75, %r74, %r58;
	shl.b32 	%r76, %r75, 23;
	add.u32 	%r77, %r73, %r76;
	or.b32 	%r78, %r10, %r77;
	mov.b32 	%f34, %r78;
$Lt_122_12290:
	.loc	17	8936	0
	mul.f32 	%f38, %f34, %f34;
	mov.f32 	%f39, 0f37ccf5ce;    	// 2.44332e-05
	mov.f32 	%f40, %f39;
	mov.f32 	%f41, %f38;
	mov.f32 	%f42, 0fbab6061a;    	// -0.00138873
	mov.f32 	%f43, %f42;
	mad.f32 %f44, %f40, %f41, %f43;
	mov.f32 	%f45, %f44;
	mov.f32 	%f46, %f45;
	mov.f32 	%f47, %f38;
	mov.f32 	%f48, 0f3d2aaaa5;    	// 0.0416666
	mov.f32 	%f49, %f48;
	mad.f32 %f50, %f46, %f47, %f49;
	mov.f32 	%f51, %f50;
	mov.f32 	%f52, %f51;
	mov.f32 	%f53, %f38;
	mov.f32 	%f54, 0fbf000000;    	// -0.5
	mov.f32 	%f55, %f54;
	mad.f32 %f56, %f52, %f53, %f55;
	mov.f32 	%f57, %f56;
	mov.f32 	%f58, %f57;
	mov.f32 	%f59, %f38;
	mov.f32 	%f60, 0f3f800000;    	// 1
	mov.f32 	%f61, %f60;
	mad.f32 %f62, %f58, %f59, %f61;
	mov.f32 	%f63, %f62;
	.loc	17	9515	0
	mov.f32 	%f64, %f63;
	.loc	17	8936	0
	mov.f32 	%f65, 0fb94ca1f9;    	// -0.000195153
	mov.f32 	%f66, %f65;
	mov.f32 	%f67, %f38;
	mov.f32 	%f68, 0f3c08839e;    	// 0.00833216
	mov.f32 	%f69, %f68;
	mad.f32 %f70, %f66, %f67, %f69;
	mov.f32 	%f71, %f70;
	mov.f32 	%f72, %f71;
	mov.f32 	%f73, %f38;
	mov.f32 	%f74, 0fbe2aaaa3;    	// -0.166667
	mov.f32 	%f75, %f74;
	mad.f32 %f76, %f72, %f73, %f75;
	mov.f32 	%f77, %f76;
	mul.f32 	%f78, %f38, %f77;
	mov.f32 	%f79, %f78;
	mov.f32 	%f80, %f34;
	mov.f32 	%f81, %f34;
	mad.f32 %f82, %f79, %f80, %f81;
	mov.f32 	%f83, %f82;
	.loc	17	9516	0
	mov.f32 	%f84, %f83;
	.loc	17	9517	0
	mov.f32 	%f85, %f84;
	and.b32 	%r79, %r7, 1;
	mov.u32 	%r80, 0;
	setp.eq.s32 	%p11, %r79, %r80;
	@%p11 bra 	$Lt_122_15874;
	.loc	17	9519	0
	mov.f32 	%f86, %f64;
	mov.f32 	%f84, %f86;
	.loc	17	9520	0
	mov.f32 	%f64, %f85;
$Lt_122_15874:
	and.b32 	%r81, %r7, 2;
	mov.u32 	%r82, 0;
	setp.eq.s32 	%p12, %r81, %r82;
	@%p12 bra 	$Lt_122_16386;
	.loc	17	9523	0
	mov.f32 	%f87, %f84;
	neg.f32 	%f88, %f87;
	mov.f32 	%f84, %f88;
$Lt_122_16386:
	add.s32 	%r83, %r7, 1;
	and.b32 	%r84, %r83, 2;
	mov.u32 	%r85, 0;
	setp.eq.s32 	%p13, %r84, %r85;
	@%p13 bra 	$Lt_122_16898;
	.loc	17	9527	0
	mov.f32 	%f89, %f64;
	neg.f32 	%f90, %f89;
	mov.f32 	%f64, %f90;
$Lt_122_16898:
	mov.f32 	%f91, 0f00000000;    	// 0
	setp.eq.f32 	%p14, %f34, %f91;
	@!%p14 bra 	$Lt_122_17410;
	.loc	17	9531	0
	mov.f32 	%f92, 0f00000000;    	// 0
	mul.rn.f32 	%f93, %f34, %f92;
	mov.f32 	%f84, %f93;
$Lt_122_17410:
	.loc	17	9534	0
	mov.f32 	%f94, %f84;
	.loc	17	9535	0
	mov.f32 	%f95, %f64;
	.loc	15	173	0
	ld.param.u64 	%rd13, [__cudaparm_esin_vf_result];
	ld.param.s32 	%r86, [__cudaparm_esin_vf_lr];
	mul.lo.s32 	%r87, %r86, %r3;
	cvt.s64.s32 	%rd14, %r87;
	mul.wide.s32 	%rd15, %r87, 4;
	add.u64 	%rd16, %rd13, %rd15;
	st.global.f32 	[%rd16+0], %f94;
$Lt_122_11266:
	exit;
$LDWend_esin_vf:
	} // esin_vf

	.entry esin_mf (
		.param .s32 __cudaparm_esin_mf_rs,
		.param .s32 __cudaparm_esin_mf_cs,
		.param .u64 __cudaparm_esin_mf_A,
		.param .s32 __cudaparm_esin_mf_lda,
		.param .u64 __cudaparm_esin_mf_B,
		.param .s32 __cudaparm_esin_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<102>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<97>;
	.reg .pred %p<16>;
	.local .align 4 .b8 __cuda___cuda_result_166132[28];
$LDWbegin_esin_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_esin_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_esin_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_123_11522;
	ld.param.u64 	%rd1, [__cudaparm_esin_mf_A];
	ld.param.s32 	%r15, [__cudaparm_esin_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	9542	0
	mov.f32 	%f2, %f1;
	.loc	17	9511	0
	abs.f32 	%f3, %f1;
	mov.f32 	%f4, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p2, %f3, %f4;
	@!%p2 bra 	$Lt_123_12034;
	.loc	17	9512	0
	mov.f32 	%f5, 0f00000000;     	// 0
	mul.rn.f32 	%f2, %f1, %f5;
$Lt_123_12034:
	.loc	17	9280	0
	mov.f32 	%f6, 0f3f22f983;     	// 0.63662
	mul.f32 	%f7, %f2, %f6;
	cvt.rni.s32.f32 	%r18, %f7;
	mov.s32 	%r19, %r18;
	.loc	17	8936	0
	cvt.rn.f32.s32 	%f8, %r18;
	neg.f32 	%f9, %f8;
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, 0f3fc90000;    	// 1.57031
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f2;
	mad.f32 %f14, %f10, %f12, %f13;
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f9;
	mov.f32 	%f17, 0f39fd8000;    	// 0.000483513
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f15;
	mad.f32 %f20, %f16, %f18, %f19;
	mov.f32 	%f21, %f20;
	mov.f32 	%f22, %f9;
	mov.f32 	%f23, 0f34a88000;    	// 3.13856e-07
	mov.f32 	%f24, %f23;
	mov.f32 	%f25, %f21;
	mad.f32 %f26, %f22, %f24, %f25;
	mov.f32 	%f27, %f26;
	mov.f32 	%f28, %f9;
	mov.f32 	%f29, 0f2e85a309;    	// 6.0771e-11
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f27;
	mad.f32 %f32, %f28, %f30, %f31;
	mov.f32 	%f33, %f32;
	.loc	17	9291	0
	mov.f32 	%f34, %f33;
	abs.f32 	%f35, %f2;
	mov.f32 	%f36, 0f473ba700;    	// 48039
	setp.gt.f32 	%p3, %f35, %f36;
	@!%p3 bra 	$Lt_123_12546;
	.loc	17	9215	0
	mov.b32 	%r20, %f2;
	and.b32 	%r21, %r20, -2147483648;
	mov.s32 	%r22, %r21;
	.loc	17	24	0
	shl.b32 	%r23, %r20, 8;
	or.b32 	%r24, %r23, -2147483648;
	mov.u64 	%rd5, __cudart_i2opi_f;
	mov.u64 	%rd6, __cuda___cuda_result_166132;
	mov.s32 	%r25, 0;
	mov.u32 	%r26, 0;
$Lt_123_13570:
 //<loop> Loop body line 24, nesting depth: 1, iterations: 6
	.loc	17	9187	0
	ld.const.u32 	%r27, [%rd5+0];
	mov.u32 	%r28, %r27;
	mov.u32 	%r29, %r24;
	mov.u32 	%r30, %r26;
	{
	.reg .u64 tmp;
	mul.wide.u32 tmp, %r28, %r29;
	mov.b64         {%r31,%r32}, tmp;
	add.cc.u32      %r31, %r31, %r30;
	addc.u32        %r32, %r32, 0;
	}
	mov.s32 	%r33, %r31;
	mov.s32 	%r34, %r32;
	.loc	17	9229	0
	mov.s32 	%r26, %r34;
	.loc	17	9230	0
	st.local.u32 	[%rd6+0], %r33;
	add.s32 	%r25, %r25, 1;
	add.u64 	%rd6, %rd6, 4;
	add.u64 	%rd5, %rd5, 4;
	mov.u32 	%r35, 6;
	setp.ne.s32 	%p4, %r25, %r35;
	@%p4 bra 	$Lt_123_13570;
	.loc	17	9232	0
	st.local.u32 	[__cuda___cuda_result_166132+24], %r34;
	.loc	17	9237	0
	shl.b32 	%r36, %r20, 1;
	shr.u32 	%r37, %r36, 24;
	sub.u32 	%r38, %r37, 128;
	mov.u64 	%rd7, __cuda___cuda_result_166132;
	shr.u32 	%r39, %r38, 5;
	mov.s32 	%r40, 4;
	sub.s32 	%r41, %r40, %r39;
	cvt.s64.s32 	%rd8, %r41;
	mul.wide.s32 	%rd9, %r41, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.local.u32 	%r26, [%rd10+8];
	.loc	17	9238	0
	ld.local.u32 	%r42, [%rd10+4];
	and.b32 	%r43, %r38, 31;
	mov.u32 	%r44, 0;
	setp.eq.u32 	%p5, %r43, %r44;
	@%p5 bra 	$Lt_123_14082;
	.loc	17	9241	0
	mov.s32 	%r45, 32;
	sub.s32 	%r46, %r45, %r43;
	shr.u32 	%r47, %r42, %r46;
	shl.b32 	%r48, %r26, %r43;
	add.u32 	%r26, %r47, %r48;
	.loc	17	9242	0
	ld.local.u32 	%r49, [%rd10+0];
	shr.u32 	%r50, %r49, %r46;
	shl.b32 	%r51, %r42, %r43;
	add.u32 	%r42, %r50, %r51;
$Lt_123_14082:
	.loc	17	9244	0
	shr.u32 	%r52, %r26, 30;
	.loc	17	9246	0
	shr.u32 	%r53, %r42, 30;
	shl.b32 	%r54, %r26, 2;
	add.u32 	%r26, %r53, %r54;
	.loc	17	9247	0
	shl.b32 	%r42, %r42, 2;
	.loc	17	9249	0
	shr.u32 	%r55, %r26, 31;
	add.u32 	%r56, %r52, %r55;
	.loc	17	9244	0
	neg.s32 	%r57, %r56;
	mov.u32 	%r58, 0;
	setp.ne.u32 	%p6, %r21, %r58;
	selp.s32 	%r25, %r57, %r56, %p6;
	.loc	17	9251	0
	mov.s32 	%r19, %r25;
	mov.u32 	%r59, 0;
	setp.eq.u32 	%p7, %r55, %r59;
	@%p7 bra 	$Lt_123_14594;
	.loc	17	9255	0
	neg.s32 	%r42, %r42;
	.loc	17	9257	0
	mov.u32 	%r60, 0;
	set.eq.u32.u32 	%r61, %r42, %r60;
	neg.s32 	%r62, %r61;
	not.b32 	%r63, %r26;
	add.u32 	%r26, %r62, %r63;
	.loc	17	9258	0
	xor.b32 	%r22, %r21, -2147483648;
$Lt_123_14594:
	.loc	17	9261	0
	mov.u32 	%r64, 0;
	setp.eq.s32 	%p8, %r26, %r64;
	@%p8 bra 	$Lt_123_15362;
	.loc	19	6283	0
	cvt.rz.f32.u32 	%f37, %r26;
	mov.b32 	%r65, %f37;
	shr.s32 	%r66, %r65, 23;
	mov.s32 	%r67, 158;
	sub.s32 	%r68, %r67, %r66;
	bra.uni 	$Lt_123_15106;
$Lt_123_15362:
	mov.s32 	%r68, 32;
$Lt_123_15106:
	.loc	17	9261	0
	mov.s32 	%r69, %r68;
	mov.s32 	%r70, %r69;
	.loc	19	6283	0
	mov.s32 	%r71, 32;
	sub.s32 	%r72, %r71, %r69;
	shr.u32 	%r73, %r42, %r72;
	shl.b32 	%r74, %r26, %r69;
	add.u32 	%r75, %r73, %r74;
	mov.u32 	%r76, 0;
	setp.ne.u32 	%p9, %r69, %r76;
	selp.u32 	%r77, %r75, %r26, %p9;
	.loc	17	9265	0
	mul.lo.u32 	%r42, %r77, -921707870;
	.loc	17	9266	0
	mov.u32 	%r78, -921707870;
	mul.hi.u32 	%r26, %r77, %r78;
	mov.u32 	%r79, 0;
	setp.le.s32 	%p10, %r26, %r79;
	@%p10 bra 	$Lt_123_15618;
	.loc	17	9268	0
	shr.u32 	%r80, %r42, 31;
	shl.b32 	%r81, %r26, 1;
	add.u32 	%r26, %r80, %r81;
	.loc	17	9269	0
	add.u32 	%r70, %r69, 1;
$Lt_123_15618:
	.loc	17	9294	0
	add.u32 	%r82, %r26, 1;
	shr.u32 	%r83, %r82, 7;
	add.u32 	%r84, %r83, 1;
	shr.u32 	%r85, %r84, 1;
	mov.s32 	%r86, 126;
	sub.s32 	%r87, %r86, %r70;
	shl.b32 	%r88, %r87, 23;
	add.u32 	%r89, %r85, %r88;
	or.b32 	%r90, %r22, %r89;
	mov.b32 	%f34, %r90;
$Lt_123_12546:
	.loc	17	8936	0
	mul.f32 	%f38, %f34, %f34;
	mov.f32 	%f39, 0f37ccf5ce;    	// 2.44332e-05
	mov.f32 	%f40, %f39;
	mov.f32 	%f41, %f38;
	mov.f32 	%f42, 0fbab6061a;    	// -0.00138873
	mov.f32 	%f43, %f42;
	mad.f32 %f44, %f40, %f41, %f43;
	mov.f32 	%f45, %f44;
	mov.f32 	%f46, %f45;
	mov.f32 	%f47, %f38;
	mov.f32 	%f48, 0f3d2aaaa5;    	// 0.0416666
	mov.f32 	%f49, %f48;
	mad.f32 %f50, %f46, %f47, %f49;
	mov.f32 	%f51, %f50;
	mov.f32 	%f52, %f51;
	mov.f32 	%f53, %f38;
	mov.f32 	%f54, 0fbf000000;    	// -0.5
	mov.f32 	%f55, %f54;
	mad.f32 %f56, %f52, %f53, %f55;
	mov.f32 	%f57, %f56;
	mov.f32 	%f58, %f57;
	mov.f32 	%f59, %f38;
	mov.f32 	%f60, 0f3f800000;    	// 1
	mov.f32 	%f61, %f60;
	mad.f32 %f62, %f58, %f59, %f61;
	mov.f32 	%f63, %f62;
	.loc	17	9515	0
	mov.f32 	%f64, %f63;
	.loc	17	8936	0
	mov.f32 	%f65, 0fb94ca1f9;    	// -0.000195153
	mov.f32 	%f66, %f65;
	mov.f32 	%f67, %f38;
	mov.f32 	%f68, 0f3c08839e;    	// 0.00833216
	mov.f32 	%f69, %f68;
	mad.f32 %f70, %f66, %f67, %f69;
	mov.f32 	%f71, %f70;
	mov.f32 	%f72, %f71;
	mov.f32 	%f73, %f38;
	mov.f32 	%f74, 0fbe2aaaa3;    	// -0.166667
	mov.f32 	%f75, %f74;
	mad.f32 %f76, %f72, %f73, %f75;
	mov.f32 	%f77, %f76;
	mul.f32 	%f78, %f38, %f77;
	mov.f32 	%f79, %f78;
	mov.f32 	%f80, %f34;
	mov.f32 	%f81, %f34;
	mad.f32 %f82, %f79, %f80, %f81;
	mov.f32 	%f83, %f82;
	.loc	17	9516	0
	mov.f32 	%f84, %f83;
	.loc	17	9517	0
	mov.f32 	%f85, %f84;
	and.b32 	%r91, %r19, 1;
	mov.u32 	%r92, 0;
	setp.eq.s32 	%p11, %r91, %r92;
	@%p11 bra 	$Lt_123_16130;
	.loc	17	9519	0
	mov.f32 	%f86, %f64;
	mov.f32 	%f84, %f86;
	.loc	17	9520	0
	mov.f32 	%f64, %f85;
$Lt_123_16130:
	and.b32 	%r93, %r19, 2;
	mov.u32 	%r94, 0;
	setp.eq.s32 	%p12, %r93, %r94;
	@%p12 bra 	$Lt_123_16642;
	.loc	17	9523	0
	mov.f32 	%f87, %f84;
	neg.f32 	%f88, %f87;
	mov.f32 	%f84, %f88;
$Lt_123_16642:
	add.s32 	%r95, %r19, 1;
	and.b32 	%r96, %r95, 2;
	mov.u32 	%r97, 0;
	setp.eq.s32 	%p13, %r96, %r97;
	@%p13 bra 	$Lt_123_17154;
	.loc	17	9527	0
	mov.f32 	%f89, %f64;
	neg.f32 	%f90, %f89;
	mov.f32 	%f64, %f90;
$Lt_123_17154:
	mov.f32 	%f91, 0f00000000;    	// 0
	setp.eq.f32 	%p14, %f34, %f91;
	@!%p14 bra 	$Lt_123_17666;
	.loc	17	9531	0
	mov.f32 	%f92, 0f00000000;    	// 0
	mul.rn.f32 	%f93, %f34, %f92;
	mov.f32 	%f84, %f93;
$Lt_123_17666:
	.loc	17	9534	0
	mov.f32 	%f94, %f84;
	.loc	17	9535	0
	mov.f32 	%f95, %f64;
	.loc	15	173	0
	ld.param.u64 	%rd11, [__cudaparm_esin_mf_B];
	ld.param.s32 	%r98, [__cudaparm_esin_mf_ldb];
	mul.lo.s32 	%r99, %r98, %r4;
	add.s32 	%r100, %r6, %r99;
	cvt.s64.s32 	%rd12, %r100;
	mul.wide.s32 	%rd13, %r100, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f94;
$Lt_123_11522:
	exit;
$LDWend_esin_mf:
	} // esin_mf

	.entry esinh_vf (
		.param .u64 __cudaparm_esinh_vf_n,
		.param .u64 __cudaparm_esinh_vf_x,
		.param .s32 __cudaparm_esinh_vf_lx,
		.param .u64 __cudaparm_esinh_vf_result,
		.param .s32 __cudaparm_esinh_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<13>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<64>;
	.reg .pred %p<5>;
	.loc	15	174	0
$LDWbegin_esinh_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_esinh_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_124_2562;
	ld.param.u64 	%rd3, [__cudaparm_esinh_vf_x];
	ld.param.s32 	%r4, [__cudaparm_esinh_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f3f800000;     	// 1
	setp.ge.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_124_3330;
	.loc	17	8936	0
	mov.f32 	%f4, 0f3fb8aa3b;     	// 1.4427
	mul.f32 	%f5, %f2, %f4;
	cvt.rzi.f32.f32 	%f6, %f5;
	mov.f32 	%f7, %f6;
	mov.f32 	%f8, 0fbf317200;     	// -0.693146
	mov.f32 	%f9, %f8;
	mov.f32 	%f10, %f2;
	mad.f32 %f11, %f7, %f9, %f10;
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f6;
	mov.f32 	%f14, 0fb5bfbe8e;    	// -1.42861e-06
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f12;
	mad.f32 %f17, %f13, %f15, %f16;
	mov.f32 	%f18, %f17;
	.loc	17	8965	0
	mov.f32 	%f19, 0f3fb8aa3b;    	// 1.4427
	mul.f32 	%f20, %f18, %f19;
	mov.f32 	%f21, %f20;
	ex2.approx.ftz.f32 %f22,%f21;
	mov.f32 	%f23, %f22;
	.loc	17	8936	0
	mov.f32 	%f24, 0fc0000000;    	// -2
	add.f32 	%f25, %f6, %f24;
	ex2.approx.f32 	%f26, %f25;
	mul.f32 	%f27, %f26, %f23;
	mov.f32 	%f28, 0f40000000;    	// 2
	mov.f32 	%f29, %f28;
	mov.f32 	%f30, %f27;
	mov.f32 	%f31, 0f3e000000;    	// 0.125
	div.approx.f32 	%f32, %f31, %f27;
	neg.f32 	%f33, %f32;
	mov.f32 	%f34, %f33;
	mad.f32 %f35, %f29, %f30, %f34;
	mov.f32 	%f36, %f35;
	.loc	17	9779	0
	mov.f32 	%f37, 0f7f800000;    	// ((1.0F)/(0.0F))
	mov.f32 	%f38, 0f42b40000;    	// 90
	setp.ge.f32 	%p3, %f2, %f38;
	selp.f32 	%f39, %f37, %f36, %p3;
	mov.b32 	%r6, %f39;
	mov.b32 	%r7, %f1;
	and.b32 	%r8, %r7, -2147483648;
	or.b32 	%r9, %r6, %r8;
	mov.b32 	%f40, %r9;
	bra.uni 	$Lt_124_3074;
$Lt_124_3330:
	.loc	17	8936	0
	mul.f32 	%f41, %f1, %f1;
	mov.f32 	%f42, 0f363d0ada;    	// 2.81695e-06
	mov.f32 	%f43, %f42;
	mov.f32 	%f44, %f41;
	mov.f32 	%f45, 0f394fff49;    	// 0.000198362
	mov.f32 	%f46, %f45;
	mad.f32 %f47, %f43, %f44, %f46;
	mov.f32 	%f36, %f47;
	mov.f32 	%f48, %f36;
	mov.f32 	%f49, %f41;
	mov.f32 	%f50, 0f3c08889a;    	// 0.00833335
	mov.f32 	%f51, %f50;
	mad.f32 %f52, %f48, %f49, %f51;
	mov.f32 	%f36, %f52;
	mov.f32 	%f53, %f36;
	mov.f32 	%f54, %f41;
	mov.f32 	%f55, 0f3e2aaaab;    	// 0.166667
	mov.f32 	%f56, %f55;
	mad.f32 %f57, %f53, %f54, %f56;
	mov.f32 	%f36, %f57;
	mul.f32 	%f58, %f41, %f36;
	mov.f32 	%f59, %f58;
	mov.f32 	%f60, %f1;
	mov.f32 	%f61, %f1;
	mad.f32 %f62, %f59, %f60, %f61;
	mov.f32 	%f36, %f62;
	.loc	17	9788	0
	mov.f32 	%f40, %f36;
$Lt_124_3074:
	.loc	15	174	0
	ld.param.u64 	%rd7, [__cudaparm_esinh_vf_result];
	ld.param.s32 	%r10, [__cudaparm_esinh_vf_lr];
	mul.lo.s32 	%r11, %r10, %r3;
	cvt.s64.s32 	%rd8, %r11;
	mul.wide.s32 	%rd9, %r11, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f40;
$Lt_124_2562:
	exit;
$LDWend_esinh_vf:
	} // esinh_vf

	.entry esinh_mf (
		.param .s32 __cudaparm_esinh_mf_rs,
		.param .s32 __cudaparm_esinh_mf_cs,
		.param .u64 __cudaparm_esinh_mf_A,
		.param .s32 __cudaparm_esinh_mf_lda,
		.param .u64 __cudaparm_esinh_mf_B,
		.param .s32 __cudaparm_esinh_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<26>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<64>;
	.reg .pred %p<5>;
$LDWbegin_esinh_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_esinh_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_esinh_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_125_2818;
	ld.param.u64 	%rd1, [__cudaparm_esinh_mf_A];
	ld.param.s32 	%r15, [__cudaparm_esinh_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f3f800000;     	// 1
	setp.ge.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_125_3586;
	.loc	17	8936	0
	mov.f32 	%f4, 0f3fb8aa3b;     	// 1.4427
	mul.f32 	%f5, %f2, %f4;
	cvt.rzi.f32.f32 	%f6, %f5;
	mov.f32 	%f7, %f6;
	mov.f32 	%f8, 0fbf317200;     	// -0.693146
	mov.f32 	%f9, %f8;
	mov.f32 	%f10, %f2;
	mad.f32 %f11, %f7, %f9, %f10;
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f6;
	mov.f32 	%f14, 0fb5bfbe8e;    	// -1.42861e-06
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f12;
	mad.f32 %f17, %f13, %f15, %f16;
	mov.f32 	%f18, %f17;
	.loc	17	8965	0
	mov.f32 	%f19, 0f3fb8aa3b;    	// 1.4427
	mul.f32 	%f20, %f18, %f19;
	mov.f32 	%f21, %f20;
	ex2.approx.ftz.f32 %f22,%f21;
	mov.f32 	%f23, %f22;
	.loc	17	8936	0
	mov.f32 	%f24, 0fc0000000;    	// -2
	add.f32 	%f25, %f6, %f24;
	ex2.approx.f32 	%f26, %f25;
	mul.f32 	%f27, %f26, %f23;
	mov.f32 	%f28, 0f40000000;    	// 2
	mov.f32 	%f29, %f28;
	mov.f32 	%f30, %f27;
	mov.f32 	%f31, 0f3e000000;    	// 0.125
	div.approx.f32 	%f32, %f31, %f27;
	neg.f32 	%f33, %f32;
	mov.f32 	%f34, %f33;
	mad.f32 %f35, %f29, %f30, %f34;
	mov.f32 	%f36, %f35;
	.loc	17	9779	0
	mov.f32 	%f37, 0f7f800000;    	// ((1.0F)/(0.0F))
	mov.f32 	%f38, 0f42b40000;    	// 90
	setp.ge.f32 	%p3, %f2, %f38;
	selp.f32 	%f39, %f37, %f36, %p3;
	mov.b32 	%r18, %f39;
	mov.b32 	%r19, %f1;
	and.b32 	%r20, %r19, -2147483648;
	or.b32 	%r21, %r18, %r20;
	mov.b32 	%f40, %r21;
	bra.uni 	$Lt_125_3330;
$Lt_125_3586:
	.loc	17	8936	0
	mul.f32 	%f41, %f1, %f1;
	mov.f32 	%f42, 0f363d0ada;    	// 2.81695e-06
	mov.f32 	%f43, %f42;
	mov.f32 	%f44, %f41;
	mov.f32 	%f45, 0f394fff49;    	// 0.000198362
	mov.f32 	%f46, %f45;
	mad.f32 %f47, %f43, %f44, %f46;
	mov.f32 	%f36, %f47;
	mov.f32 	%f48, %f36;
	mov.f32 	%f49, %f41;
	mov.f32 	%f50, 0f3c08889a;    	// 0.00833335
	mov.f32 	%f51, %f50;
	mad.f32 %f52, %f48, %f49, %f51;
	mov.f32 	%f36, %f52;
	mov.f32 	%f53, %f36;
	mov.f32 	%f54, %f41;
	mov.f32 	%f55, 0f3e2aaaab;    	// 0.166667
	mov.f32 	%f56, %f55;
	mad.f32 %f57, %f53, %f54, %f56;
	mov.f32 	%f36, %f57;
	mul.f32 	%f58, %f41, %f36;
	mov.f32 	%f59, %f58;
	mov.f32 	%f60, %f1;
	mov.f32 	%f61, %f1;
	mad.f32 %f62, %f59, %f60, %f61;
	mov.f32 	%f36, %f62;
	.loc	17	9788	0
	mov.f32 	%f40, %f36;
$Lt_125_3330:
	.loc	15	174	0
	ld.param.u64 	%rd5, [__cudaparm_esinh_mf_B];
	ld.param.s32 	%r22, [__cudaparm_esinh_mf_ldb];
	mul.lo.s32 	%r23, %r22, %r4;
	add.s32 	%r24, %r6, %r23;
	cvt.s64.s32 	%rd6, %r24;
	mul.wide.s32 	%rd7, %r24, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f40;
$Lt_125_2818:
	exit;
$LDWend_esinh_mf:
	} // esinh_mf

	.entry etan_vf (
		.param .u64 __cudaparm_etan_vf_n,
		.param .u64 __cudaparm_etan_vf_x,
		.param .s32 __cudaparm_etan_vf_lx,
		.param .u64 __cudaparm_etan_vf_result,
		.param .s32 __cudaparm_etan_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<84>;
	.reg .u64 %rd<18>;
	.reg .f32 %f<58>;
	.reg .pred %p<12>;
	.local .align 4 .b8 __cuda___cuda_result_166276[28];
	.loc	15	175	0
$LDWbegin_etan_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_etan_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_126_8962;
	ld.param.u64 	%rd3, [__cudaparm_etan_vf_x];
	ld.param.s32 	%r4, [__cudaparm_etan_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	9714	0
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_126_9474;
	.loc	17	9715	0
	mov.f32 	%f4, 0f00000000;     	// 0
	mul.rn.f32 	%f1, %f1, %f4;
	abs.f32 	%f2, %f1;
$Lt_126_9474:
	.loc	17	9280	0
	mov.f32 	%f5, 0f3f22f983;     	// 0.63662
	mul.f32 	%f6, %f1, %f5;
	cvt.rni.s32.f32 	%r6, %f6;
	mov.s32 	%r7, %r6;
	.loc	17	8936	0
	cvt.rn.f32.s32 	%f7, %r6;
	neg.f32 	%f8, %f7;
	mov.f32 	%f9, %f8;
	mov.f32 	%f10, 0f3fc90000;    	// 1.57031
	mov.f32 	%f11, %f10;
	mov.f32 	%f12, %f1;
	mad.f32 %f13, %f9, %f11, %f12;
	mov.f32 	%f14, %f13;
	mov.f32 	%f15, %f8;
	mov.f32 	%f16, 0f39fd8000;    	// 0.000483513
	mov.f32 	%f17, %f16;
	mov.f32 	%f18, %f14;
	mad.f32 %f19, %f15, %f17, %f18;
	mov.f32 	%f20, %f19;
	mov.f32 	%f21, %f8;
	mov.f32 	%f22, 0f34a88000;    	// 3.13856e-07
	mov.f32 	%f23, %f22;
	mov.f32 	%f24, %f20;
	mad.f32 %f25, %f21, %f23, %f24;
	mov.f32 	%f26, %f25;
	mov.f32 	%f27, %f8;
	mov.f32 	%f28, 0f2e85a309;    	// 6.0771e-11
	mov.f32 	%f29, %f28;
	mov.f32 	%f30, %f26;
	mad.f32 %f31, %f27, %f29, %f30;
	mov.f32 	%f32, %f31;
	.loc	17	9291	0
	mov.f32 	%f33, %f32;
	mov.f32 	%f34, 0f473ba700;    	// 48039
	setp.gt.f32 	%p3, %f2, %f34;
	@!%p3 bra 	$Lt_126_9986;
	.loc	17	9215	0
	mov.b32 	%r8, %f1;
	and.b32 	%r9, %r8, -2147483648;
	mov.s32 	%r10, %r9;
	.loc	17	24	0
	shl.b32 	%r11, %r8, 8;
	or.b32 	%r12, %r11, -2147483648;
	mov.u64 	%rd7, __cudart_i2opi_f;
	mov.u64 	%rd8, __cuda___cuda_result_166276;
	mov.s32 	%r13, 0;
	mov.u32 	%r14, 0;
$Lt_126_11010:
 //<loop> Loop body line 24, nesting depth: 1, iterations: 6
	.loc	17	9187	0
	ld.const.u32 	%r15, [%rd7+0];
	mov.u32 	%r16, %r15;
	mov.u32 	%r17, %r12;
	mov.u32 	%r18, %r14;
	{
	.reg .u64 tmp;
	mul.wide.u32 tmp, %r16, %r17;
	mov.b64         {%r19,%r20}, tmp;
	add.cc.u32      %r19, %r19, %r18;
	addc.u32        %r20, %r20, 0;
	}
	mov.s32 	%r21, %r19;
	mov.s32 	%r22, %r20;
	.loc	17	9229	0
	mov.s32 	%r14, %r22;
	.loc	17	9230	0
	st.local.u32 	[%rd8+0], %r21;
	add.s32 	%r13, %r13, 1;
	add.u64 	%rd8, %rd8, 4;
	add.u64 	%rd7, %rd7, 4;
	mov.u32 	%r23, 6;
	setp.ne.s32 	%p4, %r13, %r23;
	@%p4 bra 	$Lt_126_11010;
	.loc	17	9232	0
	st.local.u32 	[__cuda___cuda_result_166276+24], %r22;
	.loc	17	9237	0
	shl.b32 	%r24, %r8, 1;
	shr.u32 	%r25, %r24, 24;
	sub.u32 	%r26, %r25, 128;
	mov.u64 	%rd9, __cuda___cuda_result_166276;
	shr.u32 	%r27, %r26, 5;
	mov.s32 	%r28, 4;
	sub.s32 	%r29, %r28, %r27;
	cvt.s64.s32 	%rd10, %r29;
	mul.wide.s32 	%rd11, %r29, 4;
	add.u64 	%rd12, %rd9, %rd11;
	ld.local.u32 	%r14, [%rd12+8];
	.loc	17	9238	0
	ld.local.u32 	%r30, [%rd12+4];
	and.b32 	%r31, %r26, 31;
	mov.u32 	%r32, 0;
	setp.eq.u32 	%p5, %r31, %r32;
	@%p5 bra 	$Lt_126_11522;
	.loc	17	9241	0
	mov.s32 	%r33, 32;
	sub.s32 	%r34, %r33, %r31;
	shr.u32 	%r35, %r30, %r34;
	shl.b32 	%r36, %r14, %r31;
	add.u32 	%r14, %r35, %r36;
	.loc	17	9242	0
	ld.local.u32 	%r37, [%rd12+0];
	shr.u32 	%r38, %r37, %r34;
	shl.b32 	%r39, %r30, %r31;
	add.u32 	%r30, %r38, %r39;
$Lt_126_11522:
	.loc	17	9244	0
	shr.u32 	%r40, %r14, 30;
	.loc	17	9246	0
	shr.u32 	%r41, %r30, 30;
	shl.b32 	%r42, %r14, 2;
	add.u32 	%r14, %r41, %r42;
	.loc	17	9247	0
	shl.b32 	%r30, %r30, 2;
	.loc	17	9249	0
	shr.u32 	%r43, %r14, 31;
	add.u32 	%r44, %r40, %r43;
	.loc	17	9244	0
	neg.s32 	%r45, %r44;
	mov.u32 	%r46, 0;
	setp.ne.u32 	%p6, %r9, %r46;
	selp.s32 	%r13, %r45, %r44, %p6;
	.loc	17	9251	0
	mov.s32 	%r7, %r13;
	mov.u32 	%r47, 0;
	setp.eq.u32 	%p7, %r43, %r47;
	@%p7 bra 	$Lt_126_12034;
	.loc	17	9255	0
	neg.s32 	%r30, %r30;
	.loc	17	9257	0
	mov.u32 	%r48, 0;
	set.eq.u32.u32 	%r49, %r30, %r48;
	neg.s32 	%r50, %r49;
	not.b32 	%r51, %r14;
	add.u32 	%r14, %r50, %r51;
	.loc	17	9258	0
	xor.b32 	%r10, %r9, -2147483648;
$Lt_126_12034:
	.loc	17	9261	0
	mov.u32 	%r52, 0;
	setp.eq.s32 	%p8, %r14, %r52;
	@%p8 bra 	$Lt_126_12802;
	.loc	19	6283	0
	cvt.rz.f32.u32 	%f35, %r14;
	mov.b32 	%r53, %f35;
	shr.s32 	%r54, %r53, 23;
	mov.s32 	%r55, 158;
	sub.s32 	%r56, %r55, %r54;
	bra.uni 	$Lt_126_12546;
$Lt_126_12802:
	mov.s32 	%r56, 32;
$Lt_126_12546:
	.loc	17	9261	0
	mov.s32 	%r57, %r56;
	mov.s32 	%r58, %r57;
	.loc	19	6283	0
	mov.s32 	%r59, 32;
	sub.s32 	%r60, %r59, %r57;
	shr.u32 	%r61, %r30, %r60;
	shl.b32 	%r62, %r14, %r57;
	add.u32 	%r63, %r61, %r62;
	mov.u32 	%r64, 0;
	setp.ne.u32 	%p9, %r57, %r64;
	selp.u32 	%r65, %r63, %r14, %p9;
	.loc	17	9265	0
	mul.lo.u32 	%r30, %r65, -921707870;
	.loc	17	9266	0
	mov.u32 	%r66, -921707870;
	mul.hi.u32 	%r14, %r65, %r66;
	mov.u32 	%r67, 0;
	setp.le.s32 	%p10, %r14, %r67;
	@%p10 bra 	$Lt_126_13058;
	.loc	17	9268	0
	shr.u32 	%r68, %r30, 31;
	shl.b32 	%r69, %r14, 1;
	add.u32 	%r14, %r68, %r69;
	.loc	17	9269	0
	add.u32 	%r58, %r57, 1;
$Lt_126_13058:
	.loc	17	9294	0
	add.u32 	%r70, %r14, 1;
	shr.u32 	%r71, %r70, 7;
	add.u32 	%r72, %r71, 1;
	shr.u32 	%r73, %r72, 1;
	mov.s32 	%r74, 126;
	sub.s32 	%r75, %r74, %r58;
	shl.b32 	%r76, %r75, 23;
	add.u32 	%r77, %r73, %r76;
	or.b32 	%r78, %r10, %r77;
	mov.b32 	%f33, %r78;
$Lt_126_9986:
	.loc	17	8936	0
	mul.f32 	%f36, %f33, %f33;
	mov.f32 	%f37, 0f3b86d46d;    	// 0.00411468
	mov.f32 	%f38, %f37;
	mov.f32 	%f39, %f36;
	mov.f32 	%f40, 0fbf52b7f4;    	// -0.823119
	mov.f32 	%f41, %f40;
	mad.f32 %f42, %f38, %f39, %f41;
	mov.f32 	%f43, %f42;
	mov.f32 	%f44, 0fc01e09d0;    	// -2.46935
	add.f32 	%f45, %f36, %f44;
	rcp.approx.f32 	%f46, %f45;
	mul.f32 	%f47, %f43, %f46;
	mul.f32 	%f48, %f36, %f47;
	mov.f32 	%f49, %f48;
	mov.f32 	%f50, %f33;
	mov.f32 	%f51, %f33;
	mad.f32 %f52, %f49, %f50, %f51;
	mov.f32 	%f53, %f52;
	.loc	15	175	0
	rcp.approx.f32 	%f54, %f53;
	neg.f32 	%f55, %f54;
	and.b32 	%r79, %r7, 1;
	neg.s32 	%r80, %r79;
	slct.f32.s32 	%f56, %f53, %f55, %r80;
	ld.param.u64 	%rd13, [__cudaparm_etan_vf_result];
	ld.param.s32 	%r81, [__cudaparm_etan_vf_lr];
	mul.lo.s32 	%r82, %r81, %r3;
	cvt.s64.s32 	%rd14, %r82;
	mul.wide.s32 	%rd15, %r82, 4;
	add.u64 	%rd16, %rd13, %rd15;
	st.global.f32 	[%rd16+0], %f56;
$Lt_126_8962:
	exit;
$LDWend_etan_vf:
	} // etan_vf

	.entry etan_mf (
		.param .s32 __cudaparm_etan_mf_rs,
		.param .s32 __cudaparm_etan_mf_cs,
		.param .u64 __cudaparm_etan_mf_A,
		.param .s32 __cudaparm_etan_mf_lda,
		.param .u64 __cudaparm_etan_mf_B,
		.param .s32 __cudaparm_etan_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<97>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<58>;
	.reg .pred %p<12>;
	.local .align 4 .b8 __cuda___cuda_result_166340[28];
$LDWbegin_etan_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_etan_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_etan_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_127_9218;
	ld.param.u64 	%rd1, [__cudaparm_etan_mf_A];
	ld.param.s32 	%r15, [__cudaparm_etan_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	9714	0
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f7f800000;     	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_127_9730;
	.loc	17	9715	0
	mov.f32 	%f4, 0f00000000;     	// 0
	mul.rn.f32 	%f1, %f1, %f4;
	abs.f32 	%f2, %f1;
$Lt_127_9730:
	.loc	17	9280	0
	mov.f32 	%f5, 0f3f22f983;     	// 0.63662
	mul.f32 	%f6, %f1, %f5;
	cvt.rni.s32.f32 	%r18, %f6;
	mov.s32 	%r19, %r18;
	.loc	17	8936	0
	cvt.rn.f32.s32 	%f7, %r18;
	neg.f32 	%f8, %f7;
	mov.f32 	%f9, %f8;
	mov.f32 	%f10, 0f3fc90000;    	// 1.57031
	mov.f32 	%f11, %f10;
	mov.f32 	%f12, %f1;
	mad.f32 %f13, %f9, %f11, %f12;
	mov.f32 	%f14, %f13;
	mov.f32 	%f15, %f8;
	mov.f32 	%f16, 0f39fd8000;    	// 0.000483513
	mov.f32 	%f17, %f16;
	mov.f32 	%f18, %f14;
	mad.f32 %f19, %f15, %f17, %f18;
	mov.f32 	%f20, %f19;
	mov.f32 	%f21, %f8;
	mov.f32 	%f22, 0f34a88000;    	// 3.13856e-07
	mov.f32 	%f23, %f22;
	mov.f32 	%f24, %f20;
	mad.f32 %f25, %f21, %f23, %f24;
	mov.f32 	%f26, %f25;
	mov.f32 	%f27, %f8;
	mov.f32 	%f28, 0f2e85a309;    	// 6.0771e-11
	mov.f32 	%f29, %f28;
	mov.f32 	%f30, %f26;
	mad.f32 %f31, %f27, %f29, %f30;
	mov.f32 	%f32, %f31;
	.loc	17	9291	0
	mov.f32 	%f33, %f32;
	mov.f32 	%f34, 0f473ba700;    	// 48039
	setp.gt.f32 	%p3, %f2, %f34;
	@!%p3 bra 	$Lt_127_10242;
	.loc	17	9215	0
	mov.b32 	%r20, %f1;
	and.b32 	%r21, %r20, -2147483648;
	mov.s32 	%r22, %r21;
	.loc	17	24	0
	shl.b32 	%r23, %r20, 8;
	or.b32 	%r24, %r23, -2147483648;
	mov.u64 	%rd5, __cudart_i2opi_f;
	mov.u64 	%rd6, __cuda___cuda_result_166340;
	mov.s32 	%r25, 0;
	mov.u32 	%r26, 0;
$Lt_127_11266:
 //<loop> Loop body line 24, nesting depth: 1, iterations: 6
	.loc	17	9187	0
	ld.const.u32 	%r27, [%rd5+0];
	mov.u32 	%r28, %r27;
	mov.u32 	%r29, %r24;
	mov.u32 	%r30, %r26;
	{
	.reg .u64 tmp;
	mul.wide.u32 tmp, %r28, %r29;
	mov.b64         {%r31,%r32}, tmp;
	add.cc.u32      %r31, %r31, %r30;
	addc.u32        %r32, %r32, 0;
	}
	mov.s32 	%r33, %r31;
	mov.s32 	%r34, %r32;
	.loc	17	9229	0
	mov.s32 	%r26, %r34;
	.loc	17	9230	0
	st.local.u32 	[%rd6+0], %r33;
	add.s32 	%r25, %r25, 1;
	add.u64 	%rd6, %rd6, 4;
	add.u64 	%rd5, %rd5, 4;
	mov.u32 	%r35, 6;
	setp.ne.s32 	%p4, %r25, %r35;
	@%p4 bra 	$Lt_127_11266;
	.loc	17	9232	0
	st.local.u32 	[__cuda___cuda_result_166340+24], %r34;
	.loc	17	9237	0
	shl.b32 	%r36, %r20, 1;
	shr.u32 	%r37, %r36, 24;
	sub.u32 	%r38, %r37, 128;
	mov.u64 	%rd7, __cuda___cuda_result_166340;
	shr.u32 	%r39, %r38, 5;
	mov.s32 	%r40, 4;
	sub.s32 	%r41, %r40, %r39;
	cvt.s64.s32 	%rd8, %r41;
	mul.wide.s32 	%rd9, %r41, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.local.u32 	%r26, [%rd10+8];
	.loc	17	9238	0
	ld.local.u32 	%r42, [%rd10+4];
	and.b32 	%r43, %r38, 31;
	mov.u32 	%r44, 0;
	setp.eq.u32 	%p5, %r43, %r44;
	@%p5 bra 	$Lt_127_11778;
	.loc	17	9241	0
	mov.s32 	%r45, 32;
	sub.s32 	%r46, %r45, %r43;
	shr.u32 	%r47, %r42, %r46;
	shl.b32 	%r48, %r26, %r43;
	add.u32 	%r26, %r47, %r48;
	.loc	17	9242	0
	ld.local.u32 	%r49, [%rd10+0];
	shr.u32 	%r50, %r49, %r46;
	shl.b32 	%r51, %r42, %r43;
	add.u32 	%r42, %r50, %r51;
$Lt_127_11778:
	.loc	17	9244	0
	shr.u32 	%r52, %r26, 30;
	.loc	17	9246	0
	shr.u32 	%r53, %r42, 30;
	shl.b32 	%r54, %r26, 2;
	add.u32 	%r26, %r53, %r54;
	.loc	17	9247	0
	shl.b32 	%r42, %r42, 2;
	.loc	17	9249	0
	shr.u32 	%r55, %r26, 31;
	add.u32 	%r56, %r52, %r55;
	.loc	17	9244	0
	neg.s32 	%r57, %r56;
	mov.u32 	%r58, 0;
	setp.ne.u32 	%p6, %r21, %r58;
	selp.s32 	%r25, %r57, %r56, %p6;
	.loc	17	9251	0
	mov.s32 	%r19, %r25;
	mov.u32 	%r59, 0;
	setp.eq.u32 	%p7, %r55, %r59;
	@%p7 bra 	$Lt_127_12290;
	.loc	17	9255	0
	neg.s32 	%r42, %r42;
	.loc	17	9257	0
	mov.u32 	%r60, 0;
	set.eq.u32.u32 	%r61, %r42, %r60;
	neg.s32 	%r62, %r61;
	not.b32 	%r63, %r26;
	add.u32 	%r26, %r62, %r63;
	.loc	17	9258	0
	xor.b32 	%r22, %r21, -2147483648;
$Lt_127_12290:
	.loc	17	9261	0
	mov.u32 	%r64, 0;
	setp.eq.s32 	%p8, %r26, %r64;
	@%p8 bra 	$Lt_127_13058;
	.loc	19	6283	0
	cvt.rz.f32.u32 	%f35, %r26;
	mov.b32 	%r65, %f35;
	shr.s32 	%r66, %r65, 23;
	mov.s32 	%r67, 158;
	sub.s32 	%r68, %r67, %r66;
	bra.uni 	$Lt_127_12802;
$Lt_127_13058:
	mov.s32 	%r68, 32;
$Lt_127_12802:
	.loc	17	9261	0
	mov.s32 	%r69, %r68;
	mov.s32 	%r70, %r69;
	.loc	19	6283	0
	mov.s32 	%r71, 32;
	sub.s32 	%r72, %r71, %r69;
	shr.u32 	%r73, %r42, %r72;
	shl.b32 	%r74, %r26, %r69;
	add.u32 	%r75, %r73, %r74;
	mov.u32 	%r76, 0;
	setp.ne.u32 	%p9, %r69, %r76;
	selp.u32 	%r77, %r75, %r26, %p9;
	.loc	17	9265	0
	mul.lo.u32 	%r42, %r77, -921707870;
	.loc	17	9266	0
	mov.u32 	%r78, -921707870;
	mul.hi.u32 	%r26, %r77, %r78;
	mov.u32 	%r79, 0;
	setp.le.s32 	%p10, %r26, %r79;
	@%p10 bra 	$Lt_127_13314;
	.loc	17	9268	0
	shr.u32 	%r80, %r42, 31;
	shl.b32 	%r81, %r26, 1;
	add.u32 	%r26, %r80, %r81;
	.loc	17	9269	0
	add.u32 	%r70, %r69, 1;
$Lt_127_13314:
	.loc	17	9294	0
	add.u32 	%r82, %r26, 1;
	shr.u32 	%r83, %r82, 7;
	add.u32 	%r84, %r83, 1;
	shr.u32 	%r85, %r84, 1;
	mov.s32 	%r86, 126;
	sub.s32 	%r87, %r86, %r70;
	shl.b32 	%r88, %r87, 23;
	add.u32 	%r89, %r85, %r88;
	or.b32 	%r90, %r22, %r89;
	mov.b32 	%f33, %r90;
$Lt_127_10242:
	.loc	17	8936	0
	mul.f32 	%f36, %f33, %f33;
	mov.f32 	%f37, 0f3b86d46d;    	// 0.00411468
	mov.f32 	%f38, %f37;
	mov.f32 	%f39, %f36;
	mov.f32 	%f40, 0fbf52b7f4;    	// -0.823119
	mov.f32 	%f41, %f40;
	mad.f32 %f42, %f38, %f39, %f41;
	mov.f32 	%f43, %f42;
	mov.f32 	%f44, 0fc01e09d0;    	// -2.46935
	add.f32 	%f45, %f36, %f44;
	rcp.approx.f32 	%f46, %f45;
	mul.f32 	%f47, %f43, %f46;
	mul.f32 	%f48, %f36, %f47;
	mov.f32 	%f49, %f48;
	mov.f32 	%f50, %f33;
	mov.f32 	%f51, %f33;
	mad.f32 %f52, %f49, %f50, %f51;
	mov.f32 	%f53, %f52;
	.loc	15	175	0
	rcp.approx.f32 	%f54, %f53;
	neg.f32 	%f55, %f54;
	and.b32 	%r91, %r19, 1;
	neg.s32 	%r92, %r91;
	slct.f32.s32 	%f56, %f53, %f55, %r92;
	ld.param.u64 	%rd11, [__cudaparm_etan_mf_B];
	ld.param.s32 	%r93, [__cudaparm_etan_mf_ldb];
	mul.lo.s32 	%r94, %r93, %r4;
	add.s32 	%r95, %r6, %r94;
	cvt.s64.s32 	%rd12, %r95;
	mul.wide.s32 	%rd13, %r95, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f56;
$Lt_127_9218:
	exit;
$LDWend_etan_mf:
	} // etan_mf

	.entry etanh_vf (
		.param .u64 __cudaparm_etanh_vf_n,
		.param .u64 __cudaparm_etanh_vf_x,
		.param .s32 __cudaparm_etanh_vf_lx,
		.param .u64 __cudaparm_etanh_vf_result,
		.param .s32 __cudaparm_etanh_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<13>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<71>;
	.reg .pred %p<6>;
	.loc	15	176	0
$LDWbegin_etanh_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_etanh_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_128_3330;
	ld.param.u64 	%rd3, [__cudaparm_etanh_vf_x];
	ld.param.s32 	%r4, [__cudaparm_etanh_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f3f0ccccd;     	// 0.55
	setp.ge.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_128_4098;
	.loc	17	8936	0
	add.f32 	%f4, %f2, %f2;
	mov.f32 	%f5, 0f3fb8aa3b;     	// 1.4427
	mul.f32 	%f6, %f4, %f5;
	cvt.rzi.f32.f32 	%f7, %f6;
	mov.f32 	%f8, %f7;
	mov.f32 	%f9, 0fbf317200;     	// -0.693146
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, %f4;
	mad.f32 %f12, %f8, %f10, %f11;
	mov.f32 	%f13, %f12;
	mov.f32 	%f14, %f7;
	mov.f32 	%f15, 0fb5bfbe8e;    	// -1.42861e-06
	mov.f32 	%f16, %f15;
	mov.f32 	%f17, %f13;
	mad.f32 %f18, %f14, %f16, %f17;
	mov.f32 	%f19, %f18;
	.loc	17	8965	0
	mov.f32 	%f20, 0f3fb8aa3b;    	// 1.4427
	mul.f32 	%f21, %f19, %f20;
	mov.f32 	%f22, %f21;
	ex2.approx.ftz.f32 %f23,%f22;
	mov.f32 	%f24, %f23;
	.loc	17	8936	0
	mov.f32 	%f25, %f24;
	ex2.approx.f32 	%f26, %f7;
	mov.f32 	%f27, %f26;
	mov.f32 	%f28, 0f3f800000;    	// 1
	mov.f32 	%f29, %f28;
	mad.f32 %f30, %f25, %f27, %f29;
	mov.f32 	%f31, %f30;
	.loc	17	8944	0
	mov.f32 	%f32, %f31;
	rcp.approx.ftz.f32 %f33,%f32;
	mov.f32 	%f34, %f33;
	.loc	17	8936	0
	mov.f32 	%f35, %f34;
	mov.f32 	%f36, 0fc0000000;    	// -2
	mov.f32 	%f37, %f36;
	mov.f32 	%f38, 0f3f800000;    	// 1
	mov.f32 	%f39, %f38;
	mad.f32 %f40, %f35, %f37, %f39;
	mov.f32 	%f41, %f40;
	.loc	17	9804	0
	mov.f32 	%f42, 0f3f800000;    	// 1
	mov.f32 	%f43, 0f42b00000;    	// 88
	setp.ge.f32 	%p3, %f2, %f43;
	selp.f32 	%f44, %f42, %f41, %p3;
	mov.b32 	%r6, %f44;
	mov.b32 	%r7, %f1;
	and.b32 	%r8, %r7, -2147483648;
	or.b32 	%r9, %r6, %r8;
	mov.b32 	%f45, %r9;
	bra.uni 	$Lt_128_3842;
$Lt_128_4098:
	.loc	17	8936	0
	mul.f32 	%f46, %f1, %f1;
	mov.f32 	%f47, 0f3c86a81b;    	// 0.0164376
	mov.f32 	%f48, %f47;
	mov.f32 	%f49, %f46;
	mov.f32 	%f50, 0fbd57be66;    	// -0.0526718
	mov.f32 	%f51, %f50;
	mad.f32 %f52, %f48, %f49, %f51;
	mov.f32 	%f41, %f52;
	mov.f32 	%f53, %f41;
	mov.f32 	%f54, %f46;
	mov.f32 	%f55, 0f3e08677b;    	// 0.133207
	mov.f32 	%f56, %f55;
	mad.f32 %f57, %f53, %f54, %f56;
	mov.f32 	%f41, %f57;
	mov.f32 	%f58, %f41;
	mov.f32 	%f59, %f46;
	mov.f32 	%f60, 0fbeaaaa29;    	// -0.333329
	mov.f32 	%f61, %f60;
	mad.f32 %f62, %f58, %f59, %f61;
	mov.f32 	%f41, %f62;
	mul.f32 	%f63, %f46, %f41;
	mov.f32 	%f64, %f63;
	mov.f32 	%f65, %f1;
	mov.f32 	%f66, %f1;
	mad.f32 %f67, %f64, %f65, %f66;
	mov.f32 	%f41, %f67;
	.loc	17	9807	0
	add.f32 	%f68, %f1, %f1;
	mov.f32 	%f69, 0f00000000;    	// 0
	setp.eq.f32 	%p4, %f1, %f69;
	selp.f32 	%f45, %f68, %f41, %p4;
$Lt_128_3842:
	.loc	15	176	0
	ld.param.u64 	%rd7, [__cudaparm_etanh_vf_result];
	ld.param.s32 	%r10, [__cudaparm_etanh_vf_lr];
	mul.lo.s32 	%r11, %r10, %r3;
	cvt.s64.s32 	%rd8, %r11;
	mul.wide.s32 	%rd9, %r11, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f45;
$Lt_128_3330:
	exit;
$LDWend_etanh_vf:
	} // etanh_vf

	.entry etanh_mf (
		.param .s32 __cudaparm_etanh_mf_rs,
		.param .s32 __cudaparm_etanh_mf_cs,
		.param .u64 __cudaparm_etanh_mf_A,
		.param .s32 __cudaparm_etanh_mf_lda,
		.param .u64 __cudaparm_etanh_mf_B,
		.param .s32 __cudaparm_etanh_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<26>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<71>;
	.reg .pred %p<6>;
$LDWbegin_etanh_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_etanh_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_etanh_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_129_3586;
	ld.param.u64 	%rd1, [__cudaparm_etanh_mf_A];
	ld.param.s32 	%r15, [__cudaparm_etanh_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f3f0ccccd;     	// 0.55
	setp.ge.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_129_4354;
	.loc	17	8936	0
	add.f32 	%f4, %f2, %f2;
	mov.f32 	%f5, 0f3fb8aa3b;     	// 1.4427
	mul.f32 	%f6, %f4, %f5;
	cvt.rzi.f32.f32 	%f7, %f6;
	mov.f32 	%f8, %f7;
	mov.f32 	%f9, 0fbf317200;     	// -0.693146
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, %f4;
	mad.f32 %f12, %f8, %f10, %f11;
	mov.f32 	%f13, %f12;
	mov.f32 	%f14, %f7;
	mov.f32 	%f15, 0fb5bfbe8e;    	// -1.42861e-06
	mov.f32 	%f16, %f15;
	mov.f32 	%f17, %f13;
	mad.f32 %f18, %f14, %f16, %f17;
	mov.f32 	%f19, %f18;
	.loc	17	8965	0
	mov.f32 	%f20, 0f3fb8aa3b;    	// 1.4427
	mul.f32 	%f21, %f19, %f20;
	mov.f32 	%f22, %f21;
	ex2.approx.ftz.f32 %f23,%f22;
	mov.f32 	%f24, %f23;
	.loc	17	8936	0
	mov.f32 	%f25, %f24;
	ex2.approx.f32 	%f26, %f7;
	mov.f32 	%f27, %f26;
	mov.f32 	%f28, 0f3f800000;    	// 1
	mov.f32 	%f29, %f28;
	mad.f32 %f30, %f25, %f27, %f29;
	mov.f32 	%f31, %f30;
	.loc	17	8944	0
	mov.f32 	%f32, %f31;
	rcp.approx.ftz.f32 %f33,%f32;
	mov.f32 	%f34, %f33;
	.loc	17	8936	0
	mov.f32 	%f35, %f34;
	mov.f32 	%f36, 0fc0000000;    	// -2
	mov.f32 	%f37, %f36;
	mov.f32 	%f38, 0f3f800000;    	// 1
	mov.f32 	%f39, %f38;
	mad.f32 %f40, %f35, %f37, %f39;
	mov.f32 	%f41, %f40;
	.loc	17	9804	0
	mov.f32 	%f42, 0f3f800000;    	// 1
	mov.f32 	%f43, 0f42b00000;    	// 88
	setp.ge.f32 	%p3, %f2, %f43;
	selp.f32 	%f44, %f42, %f41, %p3;
	mov.b32 	%r18, %f44;
	mov.b32 	%r19, %f1;
	and.b32 	%r20, %r19, -2147483648;
	or.b32 	%r21, %r18, %r20;
	mov.b32 	%f45, %r21;
	bra.uni 	$Lt_129_4098;
$Lt_129_4354:
	.loc	17	8936	0
	mul.f32 	%f46, %f1, %f1;
	mov.f32 	%f47, 0f3c86a81b;    	// 0.0164376
	mov.f32 	%f48, %f47;
	mov.f32 	%f49, %f46;
	mov.f32 	%f50, 0fbd57be66;    	// -0.0526718
	mov.f32 	%f51, %f50;
	mad.f32 %f52, %f48, %f49, %f51;
	mov.f32 	%f41, %f52;
	mov.f32 	%f53, %f41;
	mov.f32 	%f54, %f46;
	mov.f32 	%f55, 0f3e08677b;    	// 0.133207
	mov.f32 	%f56, %f55;
	mad.f32 %f57, %f53, %f54, %f56;
	mov.f32 	%f41, %f57;
	mov.f32 	%f58, %f41;
	mov.f32 	%f59, %f46;
	mov.f32 	%f60, 0fbeaaaa29;    	// -0.333329
	mov.f32 	%f61, %f60;
	mad.f32 %f62, %f58, %f59, %f61;
	mov.f32 	%f41, %f62;
	mul.f32 	%f63, %f46, %f41;
	mov.f32 	%f64, %f63;
	mov.f32 	%f65, %f1;
	mov.f32 	%f66, %f1;
	mad.f32 %f67, %f64, %f65, %f66;
	mov.f32 	%f41, %f67;
	.loc	17	9807	0
	add.f32 	%f68, %f1, %f1;
	mov.f32 	%f69, 0f00000000;    	// 0
	setp.eq.f32 	%p4, %f1, %f69;
	selp.f32 	%f45, %f68, %f41, %p4;
$Lt_129_4098:
	.loc	15	176	0
	ld.param.u64 	%rd5, [__cudaparm_etanh_mf_B];
	ld.param.s32 	%r22, [__cudaparm_etanh_mf_ldb];
	mul.lo.s32 	%r23, %r22, %r4;
	add.s32 	%r24, %r6, %r23;
	cvt.s64.s32 	%rd6, %r24;
	mul.wide.s32 	%rd7, %r24, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f45;
$Lt_129_3586:
	exit;
$LDWend_etanh_mf:
	} // etanh_mf

	.entry eacos_vf (
		.param .u64 __cudaparm_eacos_vf_n,
		.param .u64 __cudaparm_eacos_vf_x,
		.param .s32 __cudaparm_eacos_vf_lx,
		.param .u64 __cudaparm_eacos_vf_result,
		.param .s32 __cudaparm_eacos_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<47>;
	.reg .pred %p<5>;
	.loc	15	177	0
$LDWbegin_eacos_vf:
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r1, %rh1, %rh2;
	cvt.u32.u16 	%r2, %tid.x;
	add.u32 	%r3, %r2, %r1;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eacos_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_130_3330;
	ld.param.u64 	%rd3, [__cudaparm_eacos_vf_x];
	ld.param.s32 	%r4, [__cudaparm_eacos_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	8936	0
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f3f11eb85;     	// 0.57
	setp.gt.f32 	%p2, %f2, %f3;
	mov.f32 	%f4, 0f3f800000;     	// 1
	sub.f32 	%f5, %f4, %f2;
	mov.f32 	%f6, 0f3f000000;     	// 0.5
	mul.f32 	%f7, %f5, %f6;
	sqrt.approx.f32 	%f8, %f7;
	selp.f32 	%f9, %f8, %f2, %p2;
	mul.f32 	%f10, %f9, %f9;
	mov.f32 	%f11, 0f3d53f941;    	// 0.0517514
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f10;
	mov.f32 	%f14, 0f3c94d2e9;    	// 0.018167
	mov.f32 	%f15, %f14;
	mad.f32 %f16, %f12, %f13, %f15;
	mov.f32 	%f17, %f16;
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f10;
	mov.f32 	%f20, 0f3d3f841f;    	// 0.0467569
	mov.f32 	%f21, %f20;
	mad.f32 %f22, %f18, %f19, %f21;
	mov.f32 	%f17, %f22;
	mov.f32 	%f23, %f17;
	mov.f32 	%f24, %f10;
	mov.f32 	%f25, 0f3d994929;    	// 0.0748466
	mov.f32 	%f26, %f25;
	mad.f32 %f27, %f23, %f24, %f26;
	mov.f32 	%f17, %f27;
	mov.f32 	%f28, %f17;
	mov.f32 	%f29, %f10;
	mov.f32 	%f30, 0f3e2aab94;    	// 0.16667
	mov.f32 	%f31, %f30;
	mad.f32 %f32, %f28, %f29, %f31;
	mov.f32 	%f17, %f32;
	mul.f32 	%f33, %f10, %f17;
	mov.f32 	%f34, %f33;
	mov.f32 	%f35, %f9;
	mov.f32 	%f36, %f9;
	mad.f32 %f37, %f34, %f35, %f36;
	mov.f32 	%f17, %f37;
	.loc	15	177	0
	add.f32 	%f38, %f17, %f17;
	mov.f32 	%f39, 0f3fc90fdb;    	// 1.5708
	sub.f32 	%f40, %f39, %f17;
	selp.f32 	%f41, %f38, %f40, %p2;
	mov.f32 	%f42, 0f40490fdb;    	// 3.14159
	sub.f32 	%f43, %f42, %f41;
	mov.f32 	%f44, 0f00000000;    	// 0
	setp.lt.f32 	%p3, %f1, %f44;
	selp.f32 	%f45, %f43, %f41, %p3;
	ld.param.u64 	%rd7, [__cudaparm_eacos_vf_result];
	ld.param.s32 	%r6, [__cudaparm_eacos_vf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f45;
$Lt_130_3330:
	exit;
$LDWend_eacos_vf:
	} // eacos_vf

	.entry eacos_mf (
		.param .s32 __cudaparm_eacos_mf_rs,
		.param .s32 __cudaparm_eacos_mf_cs,
		.param .u64 __cudaparm_eacos_mf_A,
		.param .s32 __cudaparm_eacos_mf_lda,
		.param .u64 __cudaparm_eacos_mf_B,
		.param .s32 __cudaparm_eacos_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<47>;
	.reg .pred %p<5>;
$LDWbegin_eacos_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eacos_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eacos_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_131_3586;
	ld.param.u64 	%rd1, [__cudaparm_eacos_mf_A];
	ld.param.s32 	%r15, [__cudaparm_eacos_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	8936	0
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f3f11eb85;     	// 0.57
	setp.gt.f32 	%p2, %f2, %f3;
	mov.f32 	%f4, 0f3f800000;     	// 1
	sub.f32 	%f5, %f4, %f2;
	mov.f32 	%f6, 0f3f000000;     	// 0.5
	mul.f32 	%f7, %f5, %f6;
	sqrt.approx.f32 	%f8, %f7;
	selp.f32 	%f9, %f8, %f2, %p2;
	mul.f32 	%f10, %f9, %f9;
	mov.f32 	%f11, 0f3d53f941;    	// 0.0517514
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f10;
	mov.f32 	%f14, 0f3c94d2e9;    	// 0.018167
	mov.f32 	%f15, %f14;
	mad.f32 %f16, %f12, %f13, %f15;
	mov.f32 	%f17, %f16;
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f10;
	mov.f32 	%f20, 0f3d3f841f;    	// 0.0467569
	mov.f32 	%f21, %f20;
	mad.f32 %f22, %f18, %f19, %f21;
	mov.f32 	%f17, %f22;
	mov.f32 	%f23, %f17;
	mov.f32 	%f24, %f10;
	mov.f32 	%f25, 0f3d994929;    	// 0.0748466
	mov.f32 	%f26, %f25;
	mad.f32 %f27, %f23, %f24, %f26;
	mov.f32 	%f17, %f27;
	mov.f32 	%f28, %f17;
	mov.f32 	%f29, %f10;
	mov.f32 	%f30, 0f3e2aab94;    	// 0.16667
	mov.f32 	%f31, %f30;
	mad.f32 %f32, %f28, %f29, %f31;
	mov.f32 	%f17, %f32;
	mul.f32 	%f33, %f10, %f17;
	mov.f32 	%f34, %f33;
	mov.f32 	%f35, %f9;
	mov.f32 	%f36, %f9;
	mad.f32 %f37, %f34, %f35, %f36;
	mov.f32 	%f17, %f37;
	.loc	15	177	0
	add.f32 	%f38, %f17, %f17;
	mov.f32 	%f39, 0f3fc90fdb;    	// 1.5708
	sub.f32 	%f40, %f39, %f17;
	selp.f32 	%f41, %f38, %f40, %p2;
	mov.f32 	%f42, 0f40490fdb;    	// 3.14159
	sub.f32 	%f43, %f42, %f41;
	mov.f32 	%f44, 0f00000000;    	// 0
	setp.lt.f32 	%p3, %f1, %f44;
	selp.f32 	%f45, %f43, %f41, %p3;
	ld.param.u64 	%rd5, [__cudaparm_eacos_mf_B];
	ld.param.s32 	%r18, [__cudaparm_eacos_mf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f45;
$Lt_131_3586:
	exit;
$LDWend_eacos_mf:
	} // eacos_mf

	.entry eacosh_vf (
		.param .u64 __cudaparm_eacosh_vf_n,
		.param .u64 __cudaparm_eacosh_vf_x,
		.param .s32 __cudaparm_eacosh_vf_lx,
		.param .u64 __cudaparm_eacosh_vf_result,
		.param .s32 __cudaparm_eacosh_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<35>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<140>;
	.reg .pred %p<9>;
	.loc	15	178	0
$LDWbegin_eacosh_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eacosh_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_132_6402;
	ld.param.u64 	%rd3, [__cudaparm_eacosh_vf_x];
	ld.param.s32 	%r4, [__cudaparm_eacosh_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	mov.f32 	%f2, 0fbf800000;     	// -1
	add.f32 	%f3, %f1, %f2;
	abs.f32 	%f4, %f3;
	mov.f32 	%f5, 0f4b000000;     	// 8.38861e+06
	setp.gt.f32 	%p2, %f4, %f5;
	@!%p2 bra 	$Lt_132_7170;
	.loc	17	9962	0
	mov.f32 	%f6, 0f00000000;     	// 0
	set.gt.u32.f32 	%r6, %f1, %f6;
	neg.s32 	%r7, %r6;
	mov.f32 	%f7, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r8, %f1, %f7;
	neg.s32 	%r9, %r8;
	and.b32 	%r10, %r7, %r9;
	mov.u32 	%r11, 0;
	setp.eq.s32 	%p3, %r10, %r11;
	@%p3 bra 	$Lt_132_7682;
	.loc	17	9039	0
	mov.b32 	%r12, %f1;
	and.b32 	%r13, %r12, 8388607;
	or.b32 	%r14, %r13, 1065353216;
	mov.b32 	%f8, %r14;
	mov.f32 	%f9, %f8;
	.loc	17	9040	0
	shr.u32 	%r15, %r12, 23;
	cvt.rn.f32.u32 	%f10, %r15;
	mov.f32 	%f11, 0fc2fe0000;    	// -127
	add.f32 	%f12, %f10, %f11;
	mov.f32 	%f13, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p4, %f8, %f13;
	@!%p4 bra 	$Lt_132_7938;
	.loc	17	9042	0
	mov.f32 	%f14, 0f3f000000;    	// 0.5
	mul.f32 	%f9, %f8, %f14;
	.loc	17	9043	0
	mov.f32 	%f15, 0f3f800000;    	// 1
	add.f32 	%f12, %f12, %f15;
$Lt_132_7938:
	.loc	17	8944	0
	mov.f32 	%f16, 0f3f800000;    	// 1
	add.f32 	%f17, %f9, %f16;
	mov.f32 	%f18, %f17;
	rcp.approx.ftz.f32 %f19,%f18;
	mov.f32 	%f20, %f19;
	.loc	17	8936	0
	mov.f32 	%f21, 0fbf800000;    	// -1
	add.f32 	%f22, %f9, %f21;
	mul.f32 	%f23, %f22, %f22;
	neg.f32 	%f24, %f23;
	mul.rn.f32 	%f25, %f20, %f24;
	add.rn.f32 	%f26, %f22, %f25;
	mul.f32 	%f27, %f26, %f26;
	mov.f32 	%f28, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f29, %f28;
	mov.f32 	%f30, %f27;
	mov.f32 	%f31, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f32, %f31;
	mad.f32 %f33, %f29, %f30, %f32;
	mov.f32 	%f34, %f33;
	mov.f32 	%f35, %f34;
	mov.f32 	%f36, %f27;
	mov.f32 	%f37, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f38, %f37;
	mad.f32 %f39, %f35, %f36, %f38;
	mov.f32 	%f40, %f39;
	mul.f32 	%f41, %f27, %f40;
	mov.f32 	%f42, %f41;
	mov.f32 	%f43, %f26;
	mov.f32 	%f44, %f25;
	mad.f32 %f45, %f42, %f43, %f44;
	mov.f32 	%f46, %f45;
	mov.f32 	%f47, %f12;
	mov.f32 	%f48, 0f3f317218;    	// 0.693147
	mov.f32 	%f49, %f48;
	add.f32 	%f50, %f22, %f46;
	mov.f32 	%f51, %f50;
	mad.f32 %f52, %f47, %f49, %f51;
	mov.f32 	%f53, %f52;
	.loc	17	9050	0
	mov.f32 	%f54, %f53;
	bra.uni 	$Lt_132_7426;
$Lt_132_7682:
	.loc	17	9053	0
	lg2.approx.f32 	%f54, %f1;
$Lt_132_7426:
	.loc	17	9962	0
	mov.f32 	%f55, 0f3f317218;    	// 0.693147
	add.f32 	%f56, %f54, %f55;
	bra.uni 	$Lt_132_6914;
$Lt_132_7170:
	.loc	17	9965	0
	mul.rz.f32 	%f57, %f1, %f3;
	add.rn.f32 	%f58, %f57, %f3;
	sqrt.approx.f32 	%f59, %f58;
	add.f32 	%f60, %f3, %f59;
	mov.f32 	%f61, 0fbec9ba5e;    	// -0.394
	set.ge.u32.f32 	%r16, %f60, %f61;
	neg.s32 	%r17, %r16;
	mov.f32 	%f62, 0f3f266666;    	// 0.65
	set.le.u32.f32 	%r18, %f60, %f62;
	neg.s32 	%r19, %r18;
	and.b32 	%r20, %r17, %r19;
	mov.u32 	%r21, 0;
	setp.eq.s32 	%p5, %r20, %r21;
	@%p5 bra 	$Lt_132_8706;
	.loc	17	9947	0
	neg.f32 	%f63, %f60;
	mov.f32 	%f64, 0f40000000;    	// 2
	add.f32 	%f65, %f60, %f64;
	div.approx.f32 	%f66, %f60, %f65;
	mul.rn.f32 	%f67, %f63, %f66;
	.loc	17	8936	0
	add.rn.f32 	%f68, %f60, %f67;
	mul.f32 	%f69, %f68, %f68;
	mov.f32 	%f70, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f71, %f70;
	mov.f32 	%f72, %f69;
	mov.f32 	%f73, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f74, %f73;
	mad.f32 %f75, %f71, %f72, %f74;
	mov.f32 	%f76, %f75;
	mov.f32 	%f77, %f76;
	mov.f32 	%f78, %f69;
	mov.f32 	%f79, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f80, %f79;
	mad.f32 %f81, %f77, %f78, %f80;
	mov.f32 	%f82, %f81;
	mul.f32 	%f83, %f69, %f82;
	mov.f32 	%f84, %f83;
	mov.f32 	%f85, %f68;
	mov.f32 	%f86, %f67;
	mad.f32 %f87, %f84, %f85, %f86;
	mov.f32 	%f88, %f87;
	.loc	17	9948	0
	add.f32 	%f67, %f60, %f88;
	bra.uni 	$Lt_132_8450;
$Lt_132_8706:
	.loc	17	9950	0
	mov.f32 	%f89, 0f3f800000;    	// 1
	add.f32 	%f90, %f60, %f89;
	mov.f32 	%f91, 0f00000000;    	// 0
	set.gt.u32.f32 	%r22, %f90, %f91;
	neg.s32 	%r23, %r22;
	mov.f32 	%f92, 0f7f800000;    	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r24, %f90, %f92;
	neg.s32 	%r25, %r24;
	and.b32 	%r26, %r23, %r25;
	mov.u32 	%r27, 0;
	setp.eq.s32 	%p6, %r26, %r27;
	@%p6 bra 	$Lt_132_9218;
	.loc	17	9039	0
	mov.b32 	%r28, %f90;
	and.b32 	%r29, %r28, 8388607;
	or.b32 	%r30, %r29, 1065353216;
	mov.b32 	%f93, %r30;
	.loc	17	9040	0
	shr.u32 	%r31, %r28, 23;
	cvt.rn.f32.u32 	%f94, %r31;
	mov.f32 	%f95, 0fc2fe0000;    	// -127
	add.f32 	%f96, %f94, %f95;
	mov.f32 	%f97, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p7, %f93, %f97;
	@!%p7 bra 	$Lt_132_9474;
	.loc	17	9042	0
	mov.f32 	%f98, 0f3f000000;    	// 0.5
	mul.f32 	%f93, %f93, %f98;
	.loc	17	9043	0
	mov.f32 	%f99, 0f3f800000;    	// 1
	add.f32 	%f96, %f96, %f99;
$Lt_132_9474:
	.loc	17	8944	0
	mov.f32 	%f100, 0f3f800000;   	// 1
	add.f32 	%f101, %f93, %f100;
	mov.f32 	%f102, %f101;
	rcp.approx.ftz.f32 %f103,%f102;
	mov.f32 	%f104, %f103;
	.loc	17	8936	0
	mov.f32 	%f105, 0fbf800000;   	// -1
	add.f32 	%f106, %f93, %f105;
	mul.f32 	%f107, %f106, %f106;
	neg.f32 	%f108, %f107;
	mul.rn.f32 	%f109, %f104, %f108;
	add.rn.f32 	%f110, %f106, %f109;
	mul.f32 	%f111, %f110, %f110;
	mov.f32 	%f112, 0f3b2063c3;   	// 0.00244735
	mov.f32 	%f113, %f112;
	mov.f32 	%f114, %f111;
	mov.f32 	%f115, 0f3c4c4be0;   	// 0.0124693
	mov.f32 	%f116, %f115;
	mad.f32 %f117, %f113, %f114, %f116;
	mov.f32 	%f118, %f117;
	mov.f32 	%f119, %f118;
	mov.f32 	%f120, %f111;
	mov.f32 	%f121, 0f3daaab50;   	// 0.0833346
	mov.f32 	%f122, %f121;
	mad.f32 %f123, %f119, %f120, %f122;
	mov.f32 	%f124, %f123;
	mul.f32 	%f125, %f111, %f124;
	mov.f32 	%f126, %f125;
	mov.f32 	%f127, %f110;
	mov.f32 	%f128, %f109;
	mad.f32 %f129, %f126, %f127, %f128;
	mov.f32 	%f130, %f129;
	mov.f32 	%f131, %f96;
	mov.f32 	%f132, 0f3f317218;   	// 0.693147
	mov.f32 	%f133, %f132;
	add.f32 	%f134, %f106, %f130;
	mov.f32 	%f135, %f134;
	mad.f32 %f136, %f131, %f133, %f135;
	mov.f32 	%f137, %f136;
	.loc	17	9050	0
	mov.f32 	%f138, %f137;
	bra.uni 	$Lt_132_8962;
$Lt_132_9218:
	.loc	17	9053	0
	lg2.approx.f32 	%f138, %f90;
$Lt_132_8962:
	.loc	17	9950	0
	mov.f32 	%f67, %f138;
$Lt_132_8450:
	.loc	17	9965	0
	mov.f32 	%f56, %f67;
$Lt_132_6914:
	.loc	15	178	0
	ld.param.u64 	%rd7, [__cudaparm_eacosh_vf_result];
	ld.param.s32 	%r32, [__cudaparm_eacosh_vf_lr];
	mul.lo.s32 	%r33, %r32, %r3;
	cvt.s64.s32 	%rd8, %r33;
	mul.wide.s32 	%rd9, %r33, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f56;
$Lt_132_6402:
	exit;
$LDWend_eacosh_vf:
	} // eacosh_vf

	.entry eacosh_mf (
		.param .s32 __cudaparm_eacosh_mf_rs,
		.param .s32 __cudaparm_eacosh_mf_cs,
		.param .u64 __cudaparm_eacosh_mf_A,
		.param .s32 __cudaparm_eacosh_mf_lda,
		.param .u64 __cudaparm_eacosh_mf_B,
		.param .s32 __cudaparm_eacosh_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<48>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<140>;
	.reg .pred %p<9>;
$LDWbegin_eacosh_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eacosh_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eacosh_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_133_6658;
	ld.param.u64 	%rd1, [__cudaparm_eacosh_mf_A];
	ld.param.s32 	%r15, [__cudaparm_eacosh_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	mov.f32 	%f2, 0fbf800000;     	// -1
	add.f32 	%f3, %f1, %f2;
	abs.f32 	%f4, %f3;
	mov.f32 	%f5, 0f4b000000;     	// 8.38861e+06
	setp.gt.f32 	%p2, %f4, %f5;
	@!%p2 bra 	$Lt_133_7426;
	.loc	17	9962	0
	mov.f32 	%f6, 0f00000000;     	// 0
	set.gt.u32.f32 	%r18, %f1, %f6;
	neg.s32 	%r19, %r18;
	mov.f32 	%f7, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r20, %f1, %f7;
	neg.s32 	%r21, %r20;
	and.b32 	%r22, %r19, %r21;
	mov.u32 	%r23, 0;
	setp.eq.s32 	%p3, %r22, %r23;
	@%p3 bra 	$Lt_133_7938;
	.loc	17	9039	0
	mov.b32 	%r24, %f1;
	and.b32 	%r25, %r24, 8388607;
	or.b32 	%r26, %r25, 1065353216;
	mov.b32 	%f8, %r26;
	mov.f32 	%f9, %f8;
	.loc	17	9040	0
	shr.u32 	%r27, %r24, 23;
	cvt.rn.f32.u32 	%f10, %r27;
	mov.f32 	%f11, 0fc2fe0000;    	// -127
	add.f32 	%f12, %f10, %f11;
	mov.f32 	%f13, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p4, %f8, %f13;
	@!%p4 bra 	$Lt_133_8194;
	.loc	17	9042	0
	mov.f32 	%f14, 0f3f000000;    	// 0.5
	mul.f32 	%f9, %f8, %f14;
	.loc	17	9043	0
	mov.f32 	%f15, 0f3f800000;    	// 1
	add.f32 	%f12, %f12, %f15;
$Lt_133_8194:
	.loc	17	8944	0
	mov.f32 	%f16, 0f3f800000;    	// 1
	add.f32 	%f17, %f9, %f16;
	mov.f32 	%f18, %f17;
	rcp.approx.ftz.f32 %f19,%f18;
	mov.f32 	%f20, %f19;
	.loc	17	8936	0
	mov.f32 	%f21, 0fbf800000;    	// -1
	add.f32 	%f22, %f9, %f21;
	mul.f32 	%f23, %f22, %f22;
	neg.f32 	%f24, %f23;
	mul.rn.f32 	%f25, %f20, %f24;
	add.rn.f32 	%f26, %f22, %f25;
	mul.f32 	%f27, %f26, %f26;
	mov.f32 	%f28, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f29, %f28;
	mov.f32 	%f30, %f27;
	mov.f32 	%f31, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f32, %f31;
	mad.f32 %f33, %f29, %f30, %f32;
	mov.f32 	%f34, %f33;
	mov.f32 	%f35, %f34;
	mov.f32 	%f36, %f27;
	mov.f32 	%f37, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f38, %f37;
	mad.f32 %f39, %f35, %f36, %f38;
	mov.f32 	%f40, %f39;
	mul.f32 	%f41, %f27, %f40;
	mov.f32 	%f42, %f41;
	mov.f32 	%f43, %f26;
	mov.f32 	%f44, %f25;
	mad.f32 %f45, %f42, %f43, %f44;
	mov.f32 	%f46, %f45;
	mov.f32 	%f47, %f12;
	mov.f32 	%f48, 0f3f317218;    	// 0.693147
	mov.f32 	%f49, %f48;
	add.f32 	%f50, %f22, %f46;
	mov.f32 	%f51, %f50;
	mad.f32 %f52, %f47, %f49, %f51;
	mov.f32 	%f53, %f52;
	.loc	17	9050	0
	mov.f32 	%f54, %f53;
	bra.uni 	$Lt_133_7682;
$Lt_133_7938:
	.loc	17	9053	0
	lg2.approx.f32 	%f54, %f1;
$Lt_133_7682:
	.loc	17	9962	0
	mov.f32 	%f55, 0f3f317218;    	// 0.693147
	add.f32 	%f56, %f54, %f55;
	bra.uni 	$Lt_133_7170;
$Lt_133_7426:
	.loc	17	9965	0
	mul.rz.f32 	%f57, %f1, %f3;
	add.rn.f32 	%f58, %f57, %f3;
	sqrt.approx.f32 	%f59, %f58;
	add.f32 	%f60, %f3, %f59;
	mov.f32 	%f61, 0fbec9ba5e;    	// -0.394
	set.ge.u32.f32 	%r28, %f60, %f61;
	neg.s32 	%r29, %r28;
	mov.f32 	%f62, 0f3f266666;    	// 0.65
	set.le.u32.f32 	%r30, %f60, %f62;
	neg.s32 	%r31, %r30;
	and.b32 	%r32, %r29, %r31;
	mov.u32 	%r33, 0;
	setp.eq.s32 	%p5, %r32, %r33;
	@%p5 bra 	$Lt_133_8962;
	.loc	17	9947	0
	neg.f32 	%f63, %f60;
	mov.f32 	%f64, 0f40000000;    	// 2
	add.f32 	%f65, %f60, %f64;
	div.approx.f32 	%f66, %f60, %f65;
	mul.rn.f32 	%f67, %f63, %f66;
	.loc	17	8936	0
	add.rn.f32 	%f68, %f60, %f67;
	mul.f32 	%f69, %f68, %f68;
	mov.f32 	%f70, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f71, %f70;
	mov.f32 	%f72, %f69;
	mov.f32 	%f73, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f74, %f73;
	mad.f32 %f75, %f71, %f72, %f74;
	mov.f32 	%f76, %f75;
	mov.f32 	%f77, %f76;
	mov.f32 	%f78, %f69;
	mov.f32 	%f79, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f80, %f79;
	mad.f32 %f81, %f77, %f78, %f80;
	mov.f32 	%f82, %f81;
	mul.f32 	%f83, %f69, %f82;
	mov.f32 	%f84, %f83;
	mov.f32 	%f85, %f68;
	mov.f32 	%f86, %f67;
	mad.f32 %f87, %f84, %f85, %f86;
	mov.f32 	%f88, %f87;
	.loc	17	9948	0
	add.f32 	%f67, %f60, %f88;
	bra.uni 	$Lt_133_8706;
$Lt_133_8962:
	.loc	17	9950	0
	mov.f32 	%f89, 0f3f800000;    	// 1
	add.f32 	%f90, %f60, %f89;
	mov.f32 	%f91, 0f00000000;    	// 0
	set.gt.u32.f32 	%r34, %f90, %f91;
	neg.s32 	%r35, %r34;
	mov.f32 	%f92, 0f7f800000;    	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r36, %f90, %f92;
	neg.s32 	%r37, %r36;
	and.b32 	%r38, %r35, %r37;
	mov.u32 	%r39, 0;
	setp.eq.s32 	%p6, %r38, %r39;
	@%p6 bra 	$Lt_133_9474;
	.loc	17	9039	0
	mov.b32 	%r40, %f90;
	and.b32 	%r41, %r40, 8388607;
	or.b32 	%r42, %r41, 1065353216;
	mov.b32 	%f93, %r42;
	.loc	17	9040	0
	shr.u32 	%r43, %r40, 23;
	cvt.rn.f32.u32 	%f94, %r43;
	mov.f32 	%f95, 0fc2fe0000;    	// -127
	add.f32 	%f96, %f94, %f95;
	mov.f32 	%f97, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p7, %f93, %f97;
	@!%p7 bra 	$Lt_133_9730;
	.loc	17	9042	0
	mov.f32 	%f98, 0f3f000000;    	// 0.5
	mul.f32 	%f93, %f93, %f98;
	.loc	17	9043	0
	mov.f32 	%f99, 0f3f800000;    	// 1
	add.f32 	%f96, %f96, %f99;
$Lt_133_9730:
	.loc	17	8944	0
	mov.f32 	%f100, 0f3f800000;   	// 1
	add.f32 	%f101, %f93, %f100;
	mov.f32 	%f102, %f101;
	rcp.approx.ftz.f32 %f103,%f102;
	mov.f32 	%f104, %f103;
	.loc	17	8936	0
	mov.f32 	%f105, 0fbf800000;   	// -1
	add.f32 	%f106, %f93, %f105;
	mul.f32 	%f107, %f106, %f106;
	neg.f32 	%f108, %f107;
	mul.rn.f32 	%f109, %f104, %f108;
	add.rn.f32 	%f110, %f106, %f109;
	mul.f32 	%f111, %f110, %f110;
	mov.f32 	%f112, 0f3b2063c3;   	// 0.00244735
	mov.f32 	%f113, %f112;
	mov.f32 	%f114, %f111;
	mov.f32 	%f115, 0f3c4c4be0;   	// 0.0124693
	mov.f32 	%f116, %f115;
	mad.f32 %f117, %f113, %f114, %f116;
	mov.f32 	%f118, %f117;
	mov.f32 	%f119, %f118;
	mov.f32 	%f120, %f111;
	mov.f32 	%f121, 0f3daaab50;   	// 0.0833346
	mov.f32 	%f122, %f121;
	mad.f32 %f123, %f119, %f120, %f122;
	mov.f32 	%f124, %f123;
	mul.f32 	%f125, %f111, %f124;
	mov.f32 	%f126, %f125;
	mov.f32 	%f127, %f110;
	mov.f32 	%f128, %f109;
	mad.f32 %f129, %f126, %f127, %f128;
	mov.f32 	%f130, %f129;
	mov.f32 	%f131, %f96;
	mov.f32 	%f132, 0f3f317218;   	// 0.693147
	mov.f32 	%f133, %f132;
	add.f32 	%f134, %f106, %f130;
	mov.f32 	%f135, %f134;
	mad.f32 %f136, %f131, %f133, %f135;
	mov.f32 	%f137, %f136;
	.loc	17	9050	0
	mov.f32 	%f138, %f137;
	bra.uni 	$Lt_133_9218;
$Lt_133_9474:
	.loc	17	9053	0
	lg2.approx.f32 	%f138, %f90;
$Lt_133_9218:
	.loc	17	9950	0
	mov.f32 	%f67, %f138;
$Lt_133_8706:
	.loc	17	9965	0
	mov.f32 	%f56, %f67;
$Lt_133_7170:
	.loc	15	178	0
	ld.param.u64 	%rd5, [__cudaparm_eacosh_mf_B];
	ld.param.s32 	%r44, [__cudaparm_eacosh_mf_ldb];
	mul.lo.s32 	%r45, %r44, %r4;
	add.s32 	%r46, %r6, %r45;
	cvt.s64.s32 	%rd6, %r46;
	mul.wide.s32 	%rd7, %r46, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f56;
$Lt_133_6658:
	exit;
$LDWend_eacosh_mf:
	} // eacosh_mf

	.entry easin_vf (
		.param .u64 __cudaparm_easin_vf_n,
		.param .u64 __cudaparm_easin_vf_x,
		.param .s32 __cudaparm_easin_vf_lx,
		.param .u64 __cudaparm_easin_vf_result,
		.param .s32 __cudaparm_easin_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<13>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<49>;
	.reg .pred %p<5>;
	.loc	15	179	0
$LDWbegin_easin_vf:
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r1, %rh1, %rh2;
	cvt.u32.u16 	%r2, %tid.x;
	add.u32 	%r3, %r2, %r1;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_easin_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_134_3330;
	ld.param.u64 	%rd3, [__cudaparm_easin_vf_x];
	ld.param.s32 	%r4, [__cudaparm_easin_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	8936	0
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f3f11eb85;     	// 0.57
	setp.gt.f32 	%p2, %f2, %f3;
	mov.f32 	%f4, 0f3f800000;     	// 1
	sub.f32 	%f5, %f4, %f2;
	mov.f32 	%f6, 0f3f000000;     	// 0.5
	mul.f32 	%f7, %f5, %f6;
	sqrt.approx.f32 	%f8, %f7;
	selp.f32 	%f9, %f8, %f2, %p2;
	mul.f32 	%f10, %f9, %f9;
	mov.f32 	%f11, 0f3d53f941;    	// 0.0517514
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f10;
	mov.f32 	%f14, 0f3c94d2e9;    	// 0.018167
	mov.f32 	%f15, %f14;
	mad.f32 %f16, %f12, %f13, %f15;
	mov.f32 	%f17, %f16;
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f10;
	mov.f32 	%f20, 0f3d3f841f;    	// 0.0467569
	mov.f32 	%f21, %f20;
	mad.f32 %f22, %f18, %f19, %f21;
	mov.f32 	%f17, %f22;
	mov.f32 	%f23, %f17;
	mov.f32 	%f24, %f10;
	mov.f32 	%f25, 0f3d994929;    	// 0.0748466
	mov.f32 	%f26, %f25;
	mad.f32 %f27, %f23, %f24, %f26;
	mov.f32 	%f17, %f27;
	mov.f32 	%f28, %f17;
	mov.f32 	%f29, %f10;
	mov.f32 	%f30, 0f3e2aab94;    	// 0.16667
	mov.f32 	%f31, %f30;
	mad.f32 %f32, %f28, %f29, %f31;
	mov.f32 	%f17, %f32;
	mul.f32 	%f33, %f10, %f17;
	mov.f32 	%f34, %f33;
	mov.f32 	%f35, %f9;
	mov.f32 	%f36, %f9;
	mad.f32 %f37, %f34, %f35, %f36;
	mov.f32 	%f17, %f37;
	mov.f32 	%f38, 0fc0000000;    	// -2
	mov.f32 	%f39, %f38;
	mov.f32 	%f40, %f17;
	mov.f32 	%f41, 0f3fc90fdb;    	// 1.5708
	mov.f32 	%f42, %f41;
	mad.f32 %f43, %f39, %f40, %f42;
	mov.f32 	%f44, %f43;
	.loc	17	9893	0
	selp.f32 	%f45, %f44, %f17, %p2;
	mov.f32 	%f46, %f45;
	mov.f32 	%f47, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p3, %f45, %f47;
	@!%p3 bra 	$Lt_134_3842;
	.loc	17	9900	0
	mov.b32 	%r6, %f45;
	mov.b32 	%r7, %f1;
	and.b32 	%r8, %r7, -2147483648;
	or.b32 	%r9, %r6, %r8;
	mov.b32 	%f46, %r9;
$Lt_134_3842:
	.loc	15	179	0
	ld.param.u64 	%rd7, [__cudaparm_easin_vf_result];
	ld.param.s32 	%r10, [__cudaparm_easin_vf_lr];
	mul.lo.s32 	%r11, %r10, %r3;
	cvt.s64.s32 	%rd8, %r11;
	mul.wide.s32 	%rd9, %r11, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f46;
$Lt_134_3330:
	exit;
$LDWend_easin_vf:
	} // easin_vf

	.entry easin_mf (
		.param .s32 __cudaparm_easin_mf_rs,
		.param .s32 __cudaparm_easin_mf_cs,
		.param .u64 __cudaparm_easin_mf_A,
		.param .s32 __cudaparm_easin_mf_lda,
		.param .u64 __cudaparm_easin_mf_B,
		.param .s32 __cudaparm_easin_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<26>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<49>;
	.reg .pred %p<5>;
$LDWbegin_easin_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_easin_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_easin_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_135_3586;
	ld.param.u64 	%rd1, [__cudaparm_easin_mf_A];
	ld.param.s32 	%r15, [__cudaparm_easin_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	8936	0
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f3f11eb85;     	// 0.57
	setp.gt.f32 	%p2, %f2, %f3;
	mov.f32 	%f4, 0f3f800000;     	// 1
	sub.f32 	%f5, %f4, %f2;
	mov.f32 	%f6, 0f3f000000;     	// 0.5
	mul.f32 	%f7, %f5, %f6;
	sqrt.approx.f32 	%f8, %f7;
	selp.f32 	%f9, %f8, %f2, %p2;
	mul.f32 	%f10, %f9, %f9;
	mov.f32 	%f11, 0f3d53f941;    	// 0.0517514
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f10;
	mov.f32 	%f14, 0f3c94d2e9;    	// 0.018167
	mov.f32 	%f15, %f14;
	mad.f32 %f16, %f12, %f13, %f15;
	mov.f32 	%f17, %f16;
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f10;
	mov.f32 	%f20, 0f3d3f841f;    	// 0.0467569
	mov.f32 	%f21, %f20;
	mad.f32 %f22, %f18, %f19, %f21;
	mov.f32 	%f17, %f22;
	mov.f32 	%f23, %f17;
	mov.f32 	%f24, %f10;
	mov.f32 	%f25, 0f3d994929;    	// 0.0748466
	mov.f32 	%f26, %f25;
	mad.f32 %f27, %f23, %f24, %f26;
	mov.f32 	%f17, %f27;
	mov.f32 	%f28, %f17;
	mov.f32 	%f29, %f10;
	mov.f32 	%f30, 0f3e2aab94;    	// 0.16667
	mov.f32 	%f31, %f30;
	mad.f32 %f32, %f28, %f29, %f31;
	mov.f32 	%f17, %f32;
	mul.f32 	%f33, %f10, %f17;
	mov.f32 	%f34, %f33;
	mov.f32 	%f35, %f9;
	mov.f32 	%f36, %f9;
	mad.f32 %f37, %f34, %f35, %f36;
	mov.f32 	%f17, %f37;
	mov.f32 	%f38, 0fc0000000;    	// -2
	mov.f32 	%f39, %f38;
	mov.f32 	%f40, %f17;
	mov.f32 	%f41, 0f3fc90fdb;    	// 1.5708
	mov.f32 	%f42, %f41;
	mad.f32 %f43, %f39, %f40, %f42;
	mov.f32 	%f44, %f43;
	.loc	17	9893	0
	selp.f32 	%f45, %f44, %f17, %p2;
	mov.f32 	%f46, %f45;
	mov.f32 	%f47, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p3, %f45, %f47;
	@!%p3 bra 	$Lt_135_4098;
	.loc	17	9900	0
	mov.b32 	%r18, %f45;
	mov.b32 	%r19, %f1;
	and.b32 	%r20, %r19, -2147483648;
	or.b32 	%r21, %r18, %r20;
	mov.b32 	%f46, %r21;
$Lt_135_4098:
	.loc	15	179	0
	ld.param.u64 	%rd5, [__cudaparm_easin_mf_B];
	ld.param.s32 	%r22, [__cudaparm_easin_mf_ldb];
	mul.lo.s32 	%r23, %r22, %r4;
	add.s32 	%r24, %r6, %r23;
	cvt.s64.s32 	%rd6, %r24;
	mul.wide.s32 	%rd7, %r24, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f46;
$Lt_135_3586:
	exit;
$LDWend_easin_mf:
	} // easin_mf

	.entry easinh_vf (
		.param .u64 __cudaparm_easinh_vf_n,
		.param .u64 __cudaparm_easinh_vf_x,
		.param .s32 __cudaparm_easinh_vf_lx,
		.param .u64 __cudaparm_easinh_vf_result,
		.param .s32 __cudaparm_easinh_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<29>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<108>;
	.reg .pred %p<8>;
	.loc	15	180	0
$LDWbegin_easinh_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_easinh_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_136_5378;
	ld.param.u64 	%rd3, [__cudaparm_easinh_vf_x];
	ld.param.s32 	%r4, [__cudaparm_easinh_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f7e800000;     	// 8.50706e+37
	setp.gt.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_136_6146;
	.loc	17	9976	0
	mov.f32 	%f4, 0f3f317218;     	// 0.693147
	lg2.approx.f32 	%f5, %f2;
	mov.f32 	%f6, 0f3f317218;     	// 0.693147
	mul.f32 	%f7, %f5, %f6;
	add.rn.f32 	%f8, %f4, %f7;
	bra.uni 	$Lt_136_5890;
$Lt_136_6146:
	.loc	17	8936	0
	rcp.approx.f32 	%f9, %f2;
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, %f9;
	mov.f32 	%f12, 0f3f800000;    	// 1
	mov.f32 	%f13, %f12;
	mad.f32 %f14, %f10, %f11, %f13;
	mov.f32 	%f15, %f14;
	.loc	17	8944	0
	sqrt.approx.f32 	%f16, %f15;
	add.f32 	%f17, %f9, %f16;
	mov.f32 	%f18, %f17;
	rcp.approx.ftz.f32 %f19,%f18;
	mov.f32 	%f20, %f19;
	.loc	17	8936	0
	mov.f32 	%f21, %f2;
	mov.f32 	%f22, %f20;
	mov.f32 	%f23, %f2;
	mad.f32 %f24, %f21, %f22, %f23;
	mov.f32 	%f25, %f24;
	.loc	17	9981	0
	mov.f32 	%f26, 0fbec9ba5e;    	// -0.394
	set.ge.u32.f32 	%r6, %f25, %f26;
	neg.s32 	%r7, %r6;
	mov.f32 	%f27, 0f3f266666;    	// 0.65
	set.le.u32.f32 	%r8, %f25, %f27;
	neg.s32 	%r9, %r8;
	and.b32 	%r10, %r7, %r9;
	mov.u32 	%r11, 0;
	setp.eq.s32 	%p3, %r10, %r11;
	@%p3 bra 	$Lt_136_6658;
	.loc	17	8936	0
	neg.f32 	%f28, %f25;
	mov.f32 	%f29, 0f40000000;    	// 2
	add.f32 	%f30, %f25, %f29;
	div.approx.f32 	%f31, %f25, %f30;
	mul.rn.f32 	%f32, %f28, %f31;
	add.rn.f32 	%f33, %f25, %f32;
	mul.f32 	%f34, %f33, %f33;
	mov.f32 	%f35, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f36, %f35;
	mov.f32 	%f37, %f34;
	mov.f32 	%f38, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f39, %f38;
	mad.f32 %f40, %f36, %f37, %f39;
	mov.f32 	%f41, %f40;
	mov.f32 	%f42, %f41;
	mov.f32 	%f43, %f34;
	mov.f32 	%f44, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f45, %f44;
	mad.f32 %f46, %f42, %f43, %f45;
	mov.f32 	%f47, %f46;
	mul.f32 	%f48, %f34, %f47;
	mov.f32 	%f49, %f48;
	mov.f32 	%f50, %f33;
	mov.f32 	%f51, %f32;
	mad.f32 %f52, %f49, %f50, %f51;
	mov.f32 	%f53, %f52;
	.loc	17	9948	0
	add.f32 	%f54, %f25, %f53;
	bra.uni 	$Lt_136_6402;
$Lt_136_6658:
	.loc	17	9950	0
	mov.f32 	%f55, 0f3f800000;    	// 1
	add.f32 	%f56, %f25, %f55;
	mov.f32 	%f57, 0f00000000;    	// 0
	set.gt.u32.f32 	%r12, %f56, %f57;
	neg.s32 	%r13, %r12;
	mov.f32 	%f58, 0f7f800000;    	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r14, %f56, %f58;
	neg.s32 	%r15, %r14;
	and.b32 	%r16, %r13, %r15;
	mov.u32 	%r17, 0;
	setp.eq.s32 	%p4, %r16, %r17;
	@%p4 bra 	$Lt_136_7170;
	.loc	17	9039	0
	mov.b32 	%r18, %f56;
	and.b32 	%r19, %r18, 8388607;
	or.b32 	%r20, %r19, 1065353216;
	mov.b32 	%f59, %r20;
	mov.f32 	%f60, %f59;
	.loc	17	9040	0
	shr.u32 	%r21, %r18, 23;
	cvt.rn.f32.u32 	%f61, %r21;
	mov.f32 	%f62, 0fc2fe0000;    	// -127
	add.f32 	%f63, %f61, %f62;
	mov.f32 	%f64, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p5, %f59, %f64;
	@!%p5 bra 	$Lt_136_7426;
	.loc	17	9042	0
	mov.f32 	%f65, 0f3f000000;    	// 0.5
	mul.f32 	%f60, %f59, %f65;
	.loc	17	9043	0
	mov.f32 	%f66, 0f3f800000;    	// 1
	add.f32 	%f63, %f63, %f66;
$Lt_136_7426:
	.loc	17	8944	0
	mov.f32 	%f67, 0f3f800000;    	// 1
	add.f32 	%f68, %f60, %f67;
	mov.f32 	%f69, %f68;
	rcp.approx.ftz.f32 %f70,%f69;
	mov.f32 	%f71, %f70;
	.loc	17	8936	0
	mov.f32 	%f72, 0fbf800000;    	// -1
	add.f32 	%f73, %f60, %f72;
	mul.f32 	%f74, %f73, %f73;
	neg.f32 	%f75, %f74;
	mul.rn.f32 	%f76, %f71, %f75;
	add.rn.f32 	%f77, %f73, %f76;
	mul.f32 	%f78, %f77, %f77;
	mov.f32 	%f79, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f80, %f79;
	mov.f32 	%f81, %f78;
	mov.f32 	%f82, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f83, %f82;
	mad.f32 %f84, %f80, %f81, %f83;
	mov.f32 	%f85, %f84;
	mov.f32 	%f86, %f85;
	mov.f32 	%f87, %f78;
	mov.f32 	%f88, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f89, %f88;
	mad.f32 %f90, %f86, %f87, %f89;
	mov.f32 	%f91, %f90;
	mul.f32 	%f92, %f78, %f91;
	mov.f32 	%f93, %f92;
	mov.f32 	%f94, %f77;
	mov.f32 	%f95, %f76;
	mad.f32 %f96, %f93, %f94, %f95;
	mov.f32 	%f97, %f96;
	mov.f32 	%f98, %f63;
	mov.f32 	%f99, 0f3f317218;    	// 0.693147
	mov.f32 	%f100, %f99;
	add.f32 	%f101, %f73, %f97;
	mov.f32 	%f102, %f101;
	mad.f32 %f103, %f98, %f100, %f102;
	mov.f32 	%f104, %f103;
	.loc	17	9050	0
	mov.f32 	%f105, %f104;
	bra.uni 	$Lt_136_6914;
$Lt_136_7170:
	.loc	17	9053	0
	lg2.approx.f32 	%f105, %f56;
$Lt_136_6914:
	.loc	17	9950	0
	mov.f32 	%f54, %f105;
$Lt_136_6402:
	.loc	17	9981	0
	mov.f32 	%f8, %f54;
$Lt_136_5890:
	mov.f32 	%f106, 0f7f800000;   	// ((1.0F)/(0.0F))
	setp.le.f32 	%p6, %f2, %f106;
	@!%p6 bra 	$Lt_136_7938;
	.loc	17	9984	0
	mov.b32 	%r22, %f8;
	mov.b32 	%r23, %f1;
	and.b32 	%r24, %r23, -2147483648;
	or.b32 	%r25, %r22, %r24;
	mov.b32 	%f8, %r25;
$Lt_136_7938:
	.loc	15	180	0
	ld.param.u64 	%rd7, [__cudaparm_easinh_vf_result];
	ld.param.s32 	%r26, [__cudaparm_easinh_vf_lr];
	mul.lo.s32 	%r27, %r26, %r3;
	cvt.s64.s32 	%rd8, %r27;
	mul.wide.s32 	%rd9, %r27, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f8;
$Lt_136_5378:
	exit;
$LDWend_easinh_vf:
	} // easinh_vf

	.entry easinh_mf (
		.param .s32 __cudaparm_easinh_mf_rs,
		.param .s32 __cudaparm_easinh_mf_cs,
		.param .u64 __cudaparm_easinh_mf_A,
		.param .s32 __cudaparm_easinh_mf_lda,
		.param .u64 __cudaparm_easinh_mf_B,
		.param .s32 __cudaparm_easinh_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<42>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<108>;
	.reg .pred %p<8>;
$LDWbegin_easinh_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_easinh_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_easinh_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_137_5634;
	ld.param.u64 	%rd1, [__cudaparm_easinh_mf_A];
	ld.param.s32 	%r15, [__cudaparm_easinh_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f7e800000;     	// 8.50706e+37
	setp.gt.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_137_6402;
	.loc	17	9976	0
	mov.f32 	%f4, 0f3f317218;     	// 0.693147
	lg2.approx.f32 	%f5, %f2;
	mov.f32 	%f6, 0f3f317218;     	// 0.693147
	mul.f32 	%f7, %f5, %f6;
	add.rn.f32 	%f8, %f4, %f7;
	bra.uni 	$Lt_137_6146;
$Lt_137_6402:
	.loc	17	8936	0
	rcp.approx.f32 	%f9, %f2;
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, %f9;
	mov.f32 	%f12, 0f3f800000;    	// 1
	mov.f32 	%f13, %f12;
	mad.f32 %f14, %f10, %f11, %f13;
	mov.f32 	%f15, %f14;
	.loc	17	8944	0
	sqrt.approx.f32 	%f16, %f15;
	add.f32 	%f17, %f9, %f16;
	mov.f32 	%f18, %f17;
	rcp.approx.ftz.f32 %f19,%f18;
	mov.f32 	%f20, %f19;
	.loc	17	8936	0
	mov.f32 	%f21, %f2;
	mov.f32 	%f22, %f20;
	mov.f32 	%f23, %f2;
	mad.f32 %f24, %f21, %f22, %f23;
	mov.f32 	%f25, %f24;
	.loc	17	9981	0
	mov.f32 	%f26, 0fbec9ba5e;    	// -0.394
	set.ge.u32.f32 	%r18, %f25, %f26;
	neg.s32 	%r19, %r18;
	mov.f32 	%f27, 0f3f266666;    	// 0.65
	set.le.u32.f32 	%r20, %f25, %f27;
	neg.s32 	%r21, %r20;
	and.b32 	%r22, %r19, %r21;
	mov.u32 	%r23, 0;
	setp.eq.s32 	%p3, %r22, %r23;
	@%p3 bra 	$Lt_137_6914;
	.loc	17	8936	0
	neg.f32 	%f28, %f25;
	mov.f32 	%f29, 0f40000000;    	// 2
	add.f32 	%f30, %f25, %f29;
	div.approx.f32 	%f31, %f25, %f30;
	mul.rn.f32 	%f32, %f28, %f31;
	add.rn.f32 	%f33, %f25, %f32;
	mul.f32 	%f34, %f33, %f33;
	mov.f32 	%f35, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f36, %f35;
	mov.f32 	%f37, %f34;
	mov.f32 	%f38, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f39, %f38;
	mad.f32 %f40, %f36, %f37, %f39;
	mov.f32 	%f41, %f40;
	mov.f32 	%f42, %f41;
	mov.f32 	%f43, %f34;
	mov.f32 	%f44, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f45, %f44;
	mad.f32 %f46, %f42, %f43, %f45;
	mov.f32 	%f47, %f46;
	mul.f32 	%f48, %f34, %f47;
	mov.f32 	%f49, %f48;
	mov.f32 	%f50, %f33;
	mov.f32 	%f51, %f32;
	mad.f32 %f52, %f49, %f50, %f51;
	mov.f32 	%f53, %f52;
	.loc	17	9948	0
	add.f32 	%f54, %f25, %f53;
	bra.uni 	$Lt_137_6658;
$Lt_137_6914:
	.loc	17	9950	0
	mov.f32 	%f55, 0f3f800000;    	// 1
	add.f32 	%f56, %f25, %f55;
	mov.f32 	%f57, 0f00000000;    	// 0
	set.gt.u32.f32 	%r24, %f56, %f57;
	neg.s32 	%r25, %r24;
	mov.f32 	%f58, 0f7f800000;    	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r26, %f56, %f58;
	neg.s32 	%r27, %r26;
	and.b32 	%r28, %r25, %r27;
	mov.u32 	%r29, 0;
	setp.eq.s32 	%p4, %r28, %r29;
	@%p4 bra 	$Lt_137_7426;
	.loc	17	9039	0
	mov.b32 	%r30, %f56;
	and.b32 	%r31, %r30, 8388607;
	or.b32 	%r32, %r31, 1065353216;
	mov.b32 	%f59, %r32;
	mov.f32 	%f60, %f59;
	.loc	17	9040	0
	shr.u32 	%r33, %r30, 23;
	cvt.rn.f32.u32 	%f61, %r33;
	mov.f32 	%f62, 0fc2fe0000;    	// -127
	add.f32 	%f63, %f61, %f62;
	mov.f32 	%f64, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p5, %f59, %f64;
	@!%p5 bra 	$Lt_137_7682;
	.loc	17	9042	0
	mov.f32 	%f65, 0f3f000000;    	// 0.5
	mul.f32 	%f60, %f59, %f65;
	.loc	17	9043	0
	mov.f32 	%f66, 0f3f800000;    	// 1
	add.f32 	%f63, %f63, %f66;
$Lt_137_7682:
	.loc	17	8944	0
	mov.f32 	%f67, 0f3f800000;    	// 1
	add.f32 	%f68, %f60, %f67;
	mov.f32 	%f69, %f68;
	rcp.approx.ftz.f32 %f70,%f69;
	mov.f32 	%f71, %f70;
	.loc	17	8936	0
	mov.f32 	%f72, 0fbf800000;    	// -1
	add.f32 	%f73, %f60, %f72;
	mul.f32 	%f74, %f73, %f73;
	neg.f32 	%f75, %f74;
	mul.rn.f32 	%f76, %f71, %f75;
	add.rn.f32 	%f77, %f73, %f76;
	mul.f32 	%f78, %f77, %f77;
	mov.f32 	%f79, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f80, %f79;
	mov.f32 	%f81, %f78;
	mov.f32 	%f82, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f83, %f82;
	mad.f32 %f84, %f80, %f81, %f83;
	mov.f32 	%f85, %f84;
	mov.f32 	%f86, %f85;
	mov.f32 	%f87, %f78;
	mov.f32 	%f88, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f89, %f88;
	mad.f32 %f90, %f86, %f87, %f89;
	mov.f32 	%f91, %f90;
	mul.f32 	%f92, %f78, %f91;
	mov.f32 	%f93, %f92;
	mov.f32 	%f94, %f77;
	mov.f32 	%f95, %f76;
	mad.f32 %f96, %f93, %f94, %f95;
	mov.f32 	%f97, %f96;
	mov.f32 	%f98, %f63;
	mov.f32 	%f99, 0f3f317218;    	// 0.693147
	mov.f32 	%f100, %f99;
	add.f32 	%f101, %f73, %f97;
	mov.f32 	%f102, %f101;
	mad.f32 %f103, %f98, %f100, %f102;
	mov.f32 	%f104, %f103;
	.loc	17	9050	0
	mov.f32 	%f105, %f104;
	bra.uni 	$Lt_137_7170;
$Lt_137_7426:
	.loc	17	9053	0
	lg2.approx.f32 	%f105, %f56;
$Lt_137_7170:
	.loc	17	9950	0
	mov.f32 	%f54, %f105;
$Lt_137_6658:
	.loc	17	9981	0
	mov.f32 	%f8, %f54;
$Lt_137_6146:
	mov.f32 	%f106, 0f7f800000;   	// ((1.0F)/(0.0F))
	setp.le.f32 	%p6, %f2, %f106;
	@!%p6 bra 	$Lt_137_8194;
	.loc	17	9984	0
	mov.b32 	%r34, %f8;
	mov.b32 	%r35, %f1;
	and.b32 	%r36, %r35, -2147483648;
	or.b32 	%r37, %r34, %r36;
	mov.b32 	%f8, %r37;
$Lt_137_8194:
	.loc	15	180	0
	ld.param.u64 	%rd5, [__cudaparm_easinh_mf_B];
	ld.param.s32 	%r38, [__cudaparm_easinh_mf_ldb];
	mul.lo.s32 	%r39, %r38, %r4;
	add.s32 	%r40, %r6, %r39;
	cvt.s64.s32 	%rd6, %r40;
	mul.wide.s32 	%rd7, %r40, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f8;
$Lt_137_5634:
	exit;
$LDWend_easinh_mf:
	} // easinh_mf

	.entry eatan_vf (
		.param .u64 __cudaparm_eatan_vf_n,
		.param .u64 __cudaparm_eatan_vf_x,
		.param .s32 __cudaparm_eatan_vf_lx,
		.param .u64 __cudaparm_eatan_vf_result,
		.param .s32 __cudaparm_eatan_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<13>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<43>;
	.reg .pred %p<5>;
	.loc	15	181	0
$LDWbegin_eatan_vf:
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r1, %rh1, %rh2;
	cvt.u32.u16 	%r2, %tid.x;
	add.u32 	%r3, %r2, %r1;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eatan_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_138_3330;
	ld.param.u64 	%rd3, [__cudaparm_eatan_vf_x];
	ld.param.s32 	%r4, [__cudaparm_eatan_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	8936	0
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f3f800000;     	// 1
	setp.gt.f32 	%p2, %f2, %f3;
	rcp.approx.f32 	%f4, %f2;
	selp.f32 	%f5, %f4, %f2, %p2;
	mul.rn.f32 	%f6, %f5, %f5;
	mov.f32 	%f7, %f6;
	mov.f32 	%f8, 0fbf52c7ea;     	// -0.823363
	mov.f32 	%f9, %f8;
	mov.f32 	%f10, 0fc0b59883;    	// -5.67487
	mov.f32 	%f11, %f10;
	mad.f32 %f12, %f7, %f9, %f11;
	mov.f32 	%f13, %f12;
	mov.f32 	%f14, %f13;
	mov.f32 	%f15, %f6;
	mov.f32 	%f16, 0fc0d21907;    	// -6.56556
	mov.f32 	%f17, %f16;
	mad.f32 %f18, %f14, %f15, %f17;
	mov.f32 	%f13, %f18;
	.loc	17	8997	0
	mul.f32 	%f19, %f6, %f13;
	mul.f32 	%f20, %f5, %f19;
	.loc	17	8936	0
	mov.f32 	%f21, 0f41355dc0;    	// 11.3354
	add.f32 	%f22, %f6, %f21;
	mov.f32 	%f23, %f22;
	mov.f32 	%f24, %f6;
	mov.f32 	%f25, 0f41e6bd60;    	// 28.8425
	mov.f32 	%f26, %f25;
	mad.f32 %f27, %f23, %f24, %f26;
	mov.f32 	%f13, %f27;
	mov.f32 	%f28, %f13;
	mov.f32 	%f29, %f6;
	mov.f32 	%f30, 0f419d92c8;    	// 19.6967
	mov.f32 	%f31, %f30;
	mad.f32 %f32, %f28, %f29, %f31;
	mov.f32 	%f13, %f32;
	mov.f32 	%f33, %f20;
	rcp.approx.f32 	%f34, %f13;
	mov.f32 	%f35, %f34;
	mov.f32 	%f36, %f5;
	mad.f32 %f37, %f33, %f35, %f36;
	mov.f32 	%f13, %f37;
	.loc	17	9859	0
	mov.f32 	%f38, 0f3fc90fdb;    	// 1.5708
	sub.f32 	%f39, %f38, %f13;
	selp.f32 	%f40, %f39, %f13, %p2;
	mov.f32 	%f41, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p3, %f2, %f41;
	@!%p3 bra 	$Lt_138_3842;
	.loc	17	9865	0
	mov.b32 	%r6, %f40;
	mov.b32 	%r7, %f1;
	and.b32 	%r8, %r7, -2147483648;
	or.b32 	%r9, %r6, %r8;
	mov.b32 	%f40, %r9;
$Lt_138_3842:
	.loc	15	181	0
	ld.param.u64 	%rd7, [__cudaparm_eatan_vf_result];
	ld.param.s32 	%r10, [__cudaparm_eatan_vf_lr];
	mul.lo.s32 	%r11, %r10, %r3;
	cvt.s64.s32 	%rd8, %r11;
	mul.wide.s32 	%rd9, %r11, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f40;
$Lt_138_3330:
	exit;
$LDWend_eatan_vf:
	} // eatan_vf

	.entry eatan_mf (
		.param .s32 __cudaparm_eatan_mf_rs,
		.param .s32 __cudaparm_eatan_mf_cs,
		.param .u64 __cudaparm_eatan_mf_A,
		.param .s32 __cudaparm_eatan_mf_lda,
		.param .u64 __cudaparm_eatan_mf_B,
		.param .s32 __cudaparm_eatan_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<26>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<43>;
	.reg .pred %p<5>;
$LDWbegin_eatan_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eatan_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eatan_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_139_3586;
	ld.param.u64 	%rd1, [__cudaparm_eatan_mf_A];
	ld.param.s32 	%r15, [__cudaparm_eatan_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	8936	0
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f3f800000;     	// 1
	setp.gt.f32 	%p2, %f2, %f3;
	rcp.approx.f32 	%f4, %f2;
	selp.f32 	%f5, %f4, %f2, %p2;
	mul.rn.f32 	%f6, %f5, %f5;
	mov.f32 	%f7, %f6;
	mov.f32 	%f8, 0fbf52c7ea;     	// -0.823363
	mov.f32 	%f9, %f8;
	mov.f32 	%f10, 0fc0b59883;    	// -5.67487
	mov.f32 	%f11, %f10;
	mad.f32 %f12, %f7, %f9, %f11;
	mov.f32 	%f13, %f12;
	mov.f32 	%f14, %f13;
	mov.f32 	%f15, %f6;
	mov.f32 	%f16, 0fc0d21907;    	// -6.56556
	mov.f32 	%f17, %f16;
	mad.f32 %f18, %f14, %f15, %f17;
	mov.f32 	%f13, %f18;
	.loc	17	8997	0
	mul.f32 	%f19, %f6, %f13;
	mul.f32 	%f20, %f5, %f19;
	.loc	17	8936	0
	mov.f32 	%f21, 0f41355dc0;    	// 11.3354
	add.f32 	%f22, %f6, %f21;
	mov.f32 	%f23, %f22;
	mov.f32 	%f24, %f6;
	mov.f32 	%f25, 0f41e6bd60;    	// 28.8425
	mov.f32 	%f26, %f25;
	mad.f32 %f27, %f23, %f24, %f26;
	mov.f32 	%f13, %f27;
	mov.f32 	%f28, %f13;
	mov.f32 	%f29, %f6;
	mov.f32 	%f30, 0f419d92c8;    	// 19.6967
	mov.f32 	%f31, %f30;
	mad.f32 %f32, %f28, %f29, %f31;
	mov.f32 	%f13, %f32;
	mov.f32 	%f33, %f20;
	rcp.approx.f32 	%f34, %f13;
	mov.f32 	%f35, %f34;
	mov.f32 	%f36, %f5;
	mad.f32 %f37, %f33, %f35, %f36;
	mov.f32 	%f13, %f37;
	.loc	17	9859	0
	mov.f32 	%f38, 0f3fc90fdb;    	// 1.5708
	sub.f32 	%f39, %f38, %f13;
	selp.f32 	%f40, %f39, %f13, %p2;
	mov.f32 	%f41, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p3, %f2, %f41;
	@!%p3 bra 	$Lt_139_4098;
	.loc	17	9865	0
	mov.b32 	%r18, %f40;
	mov.b32 	%r19, %f1;
	and.b32 	%r20, %r19, -2147483648;
	or.b32 	%r21, %r18, %r20;
	mov.b32 	%f40, %r21;
$Lt_139_4098:
	.loc	15	181	0
	ld.param.u64 	%rd5, [__cudaparm_eatan_mf_B];
	ld.param.s32 	%r22, [__cudaparm_eatan_mf_ldb];
	mul.lo.s32 	%r23, %r22, %r4;
	add.s32 	%r24, %r6, %r23;
	cvt.s64.s32 	%rd6, %r24;
	mul.wide.s32 	%rd7, %r24, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f40;
$Lt_139_3586:
	exit;
$LDWend_eatan_mf:
	} // eatan_mf

	.entry eatanh_vf (
		.param .u64 __cudaparm_eatanh_vf_n,
		.param .u64 __cudaparm_eatanh_vf_x,
		.param .s32 __cudaparm_eatanh_vf_lx,
		.param .u64 __cudaparm_eatanh_vf_result,
		.param .s32 __cudaparm_eatanh_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<29>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<93>;
	.reg .pred %p<7>;
	.loc	15	182	0
$LDWbegin_eatanh_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eatanh_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_140_4610;
	ld.param.u64 	%rd3, [__cudaparm_eatanh_vf_x];
	ld.param.s32 	%r4, [__cudaparm_eatanh_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	9995	0
	abs.f32 	%f2, %f1;
	add.f32 	%f3, %f2, %f2;
	mov.f32 	%f4, 0f3f800000;     	// 1
	sub.f32 	%f5, %f4, %f2;
	div.approx.f32 	%f6, %f3, %f5;
	mov.f32 	%f7, 0fbec9ba5e;     	// -0.394
	set.ge.u32.f32 	%r6, %f6, %f7;
	neg.s32 	%r7, %r6;
	mov.f32 	%f8, 0f3f266666;     	// 0.65
	set.le.u32.f32 	%r8, %f6, %f8;
	neg.s32 	%r9, %r8;
	and.b32 	%r10, %r7, %r9;
	mov.u32 	%r11, 0;
	setp.eq.s32 	%p2, %r10, %r11;
	@%p2 bra 	$Lt_140_5378;
	.loc	17	8975	0
	neg.f32 	%f9, %f6;
	mov.f32 	%f10, 0f40000000;    	// 2
	add.f32 	%f11, %f6, %f10;
	div.approx.f32 	%f12, %f6, %f11;
	mul.rn.f32 	%f13, %f9, %f12;
	add.rn.f32 	%f14, %f6, %f13;
	mul.f32 	%f15, %f14, %f14;
	.loc	17	8936	0
	mov.f32 	%f16, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f17, %f16;
	mov.f32 	%f18, %f15;
	mov.f32 	%f19, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f20, %f19;
	mad.f32 %f21, %f17, %f18, %f20;
	mov.f32 	%f22, %f21;
	mov.f32 	%f23, %f22;
	mov.f32 	%f24, %f15;
	mov.f32 	%f25, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f26, %f25;
	mad.f32 %f27, %f23, %f24, %f26;
	mov.f32 	%f28, %f27;
	mul.f32 	%f29, %f15, %f28;
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f14;
	mov.f32 	%f32, %f13;
	mad.f32 %f33, %f30, %f31, %f32;
	mov.f32 	%f34, %f33;
	.loc	17	9948	0
	add.f32 	%f35, %f6, %f34;
	bra.uni 	$Lt_140_5122;
$Lt_140_5378:
	.loc	17	9950	0
	mov.f32 	%f36, 0f3f800000;    	// 1
	add.f32 	%f37, %f6, %f36;
	mov.f32 	%f38, 0f00000000;    	// 0
	set.gt.u32.f32 	%r12, %f37, %f38;
	neg.s32 	%r13, %r12;
	mov.f32 	%f39, 0f7f800000;    	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r14, %f37, %f39;
	neg.s32 	%r15, %r14;
	and.b32 	%r16, %r13, %r15;
	mov.u32 	%r17, 0;
	setp.eq.s32 	%p3, %r16, %r17;
	@%p3 bra 	$Lt_140_5890;
	.loc	17	9039	0
	mov.b32 	%r18, %f37;
	and.b32 	%r19, %r18, 8388607;
	or.b32 	%r20, %r19, 1065353216;
	mov.b32 	%f40, %r20;
	mov.f32 	%f41, %f40;
	.loc	17	9040	0
	shr.u32 	%r21, %r18, 23;
	cvt.rn.f32.u32 	%f42, %r21;
	mov.f32 	%f43, 0fc2fe0000;    	// -127
	add.f32 	%f44, %f42, %f43;
	mov.f32 	%f45, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p4, %f40, %f45;
	@!%p4 bra 	$Lt_140_6146;
	.loc	17	9042	0
	mov.f32 	%f46, 0f3f000000;    	// 0.5
	mul.f32 	%f41, %f40, %f46;
	.loc	17	9043	0
	mov.f32 	%f47, 0f3f800000;    	// 1
	add.f32 	%f44, %f44, %f47;
$Lt_140_6146:
	.loc	17	8944	0
	mov.f32 	%f48, 0f3f800000;    	// 1
	add.f32 	%f49, %f41, %f48;
	mov.f32 	%f50, %f49;
	rcp.approx.ftz.f32 %f51,%f50;
	mov.f32 	%f52, %f51;
	.loc	17	8936	0
	mov.f32 	%f53, 0fbf800000;    	// -1
	add.f32 	%f54, %f41, %f53;
	mul.f32 	%f55, %f54, %f54;
	neg.f32 	%f56, %f55;
	mul.rn.f32 	%f57, %f52, %f56;
	add.rn.f32 	%f58, %f54, %f57;
	mul.f32 	%f59, %f58, %f58;
	mov.f32 	%f60, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f61, %f60;
	mov.f32 	%f62, %f59;
	mov.f32 	%f63, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f64, %f63;
	mad.f32 %f65, %f61, %f62, %f64;
	mov.f32 	%f66, %f65;
	mov.f32 	%f67, %f66;
	mov.f32 	%f68, %f59;
	mov.f32 	%f69, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f70, %f69;
	mad.f32 %f71, %f67, %f68, %f70;
	mov.f32 	%f72, %f71;
	mul.f32 	%f73, %f59, %f72;
	mov.f32 	%f74, %f73;
	mov.f32 	%f75, %f58;
	mov.f32 	%f76, %f57;
	mad.f32 %f77, %f74, %f75, %f76;
	mov.f32 	%f78, %f77;
	mov.f32 	%f79, %f44;
	mov.f32 	%f80, 0f3f317218;    	// 0.693147
	mov.f32 	%f81, %f80;
	add.f32 	%f82, %f54, %f78;
	mov.f32 	%f83, %f82;
	mad.f32 %f84, %f79, %f81, %f83;
	mov.f32 	%f85, %f84;
	.loc	17	9050	0
	mov.f32 	%f86, %f85;
	bra.uni 	$Lt_140_5634;
$Lt_140_5890:
	.loc	17	9053	0
	lg2.approx.f32 	%f86, %f37;
$Lt_140_5634:
	.loc	17	9950	0
	mov.f32 	%f35, %f86;
$Lt_140_5122:
	.loc	17	9995	0
	mov.f32 	%f87, 0f3f000000;    	// 0.5
	mul.f32 	%f88, %f35, %f87;
	mov.f32 	%f89, %f88;
	abs.f32 	%f90, %f88;
	mov.f32 	%f91, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p5, %f90, %f91;
	@!%p5 bra 	$Lt_140_6658;
	.loc	17	9997	0
	mov.b32 	%r22, %f88;
	mov.b32 	%r23, %f1;
	and.b32 	%r24, %r23, -2147483648;
	or.b32 	%r25, %r22, %r24;
	mov.b32 	%f89, %r25;
$Lt_140_6658:
	.loc	15	182	0
	ld.param.u64 	%rd7, [__cudaparm_eatanh_vf_result];
	ld.param.s32 	%r26, [__cudaparm_eatanh_vf_lr];
	mul.lo.s32 	%r27, %r26, %r3;
	cvt.s64.s32 	%rd8, %r27;
	mul.wide.s32 	%rd9, %r27, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f89;
$Lt_140_4610:
	exit;
$LDWend_eatanh_vf:
	} // eatanh_vf

	.entry eatanh_mf (
		.param .s32 __cudaparm_eatanh_mf_rs,
		.param .s32 __cudaparm_eatanh_mf_cs,
		.param .u64 __cudaparm_eatanh_mf_A,
		.param .s32 __cudaparm_eatanh_mf_lda,
		.param .u64 __cudaparm_eatanh_mf_B,
		.param .s32 __cudaparm_eatanh_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<42>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<93>;
	.reg .pred %p<7>;
$LDWbegin_eatanh_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eatanh_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eatanh_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_141_4866;
	ld.param.u64 	%rd1, [__cudaparm_eatanh_mf_A];
	ld.param.s32 	%r15, [__cudaparm_eatanh_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	9995	0
	abs.f32 	%f2, %f1;
	add.f32 	%f3, %f2, %f2;
	mov.f32 	%f4, 0f3f800000;     	// 1
	sub.f32 	%f5, %f4, %f2;
	div.approx.f32 	%f6, %f3, %f5;
	mov.f32 	%f7, 0fbec9ba5e;     	// -0.394
	set.ge.u32.f32 	%r18, %f6, %f7;
	neg.s32 	%r19, %r18;
	mov.f32 	%f8, 0f3f266666;     	// 0.65
	set.le.u32.f32 	%r20, %f6, %f8;
	neg.s32 	%r21, %r20;
	and.b32 	%r22, %r19, %r21;
	mov.u32 	%r23, 0;
	setp.eq.s32 	%p2, %r22, %r23;
	@%p2 bra 	$Lt_141_5634;
	.loc	17	8975	0
	neg.f32 	%f9, %f6;
	mov.f32 	%f10, 0f40000000;    	// 2
	add.f32 	%f11, %f6, %f10;
	div.approx.f32 	%f12, %f6, %f11;
	mul.rn.f32 	%f13, %f9, %f12;
	add.rn.f32 	%f14, %f6, %f13;
	mul.f32 	%f15, %f14, %f14;
	.loc	17	8936	0
	mov.f32 	%f16, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f17, %f16;
	mov.f32 	%f18, %f15;
	mov.f32 	%f19, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f20, %f19;
	mad.f32 %f21, %f17, %f18, %f20;
	mov.f32 	%f22, %f21;
	mov.f32 	%f23, %f22;
	mov.f32 	%f24, %f15;
	mov.f32 	%f25, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f26, %f25;
	mad.f32 %f27, %f23, %f24, %f26;
	mov.f32 	%f28, %f27;
	mul.f32 	%f29, %f15, %f28;
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f14;
	mov.f32 	%f32, %f13;
	mad.f32 %f33, %f30, %f31, %f32;
	mov.f32 	%f34, %f33;
	.loc	17	9948	0
	add.f32 	%f35, %f6, %f34;
	bra.uni 	$Lt_141_5378;
$Lt_141_5634:
	.loc	17	9950	0
	mov.f32 	%f36, 0f3f800000;    	// 1
	add.f32 	%f37, %f6, %f36;
	mov.f32 	%f38, 0f00000000;    	// 0
	set.gt.u32.f32 	%r24, %f37, %f38;
	neg.s32 	%r25, %r24;
	mov.f32 	%f39, 0f7f800000;    	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r26, %f37, %f39;
	neg.s32 	%r27, %r26;
	and.b32 	%r28, %r25, %r27;
	mov.u32 	%r29, 0;
	setp.eq.s32 	%p3, %r28, %r29;
	@%p3 bra 	$Lt_141_6146;
	.loc	17	9039	0
	mov.b32 	%r30, %f37;
	and.b32 	%r31, %r30, 8388607;
	or.b32 	%r32, %r31, 1065353216;
	mov.b32 	%f40, %r32;
	mov.f32 	%f41, %f40;
	.loc	17	9040	0
	shr.u32 	%r33, %r30, 23;
	cvt.rn.f32.u32 	%f42, %r33;
	mov.f32 	%f43, 0fc2fe0000;    	// -127
	add.f32 	%f44, %f42, %f43;
	mov.f32 	%f45, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p4, %f40, %f45;
	@!%p4 bra 	$Lt_141_6402;
	.loc	17	9042	0
	mov.f32 	%f46, 0f3f000000;    	// 0.5
	mul.f32 	%f41, %f40, %f46;
	.loc	17	9043	0
	mov.f32 	%f47, 0f3f800000;    	// 1
	add.f32 	%f44, %f44, %f47;
$Lt_141_6402:
	.loc	17	8944	0
	mov.f32 	%f48, 0f3f800000;    	// 1
	add.f32 	%f49, %f41, %f48;
	mov.f32 	%f50, %f49;
	rcp.approx.ftz.f32 %f51,%f50;
	mov.f32 	%f52, %f51;
	.loc	17	8936	0
	mov.f32 	%f53, 0fbf800000;    	// -1
	add.f32 	%f54, %f41, %f53;
	mul.f32 	%f55, %f54, %f54;
	neg.f32 	%f56, %f55;
	mul.rn.f32 	%f57, %f52, %f56;
	add.rn.f32 	%f58, %f54, %f57;
	mul.f32 	%f59, %f58, %f58;
	mov.f32 	%f60, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f61, %f60;
	mov.f32 	%f62, %f59;
	mov.f32 	%f63, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f64, %f63;
	mad.f32 %f65, %f61, %f62, %f64;
	mov.f32 	%f66, %f65;
	mov.f32 	%f67, %f66;
	mov.f32 	%f68, %f59;
	mov.f32 	%f69, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f70, %f69;
	mad.f32 %f71, %f67, %f68, %f70;
	mov.f32 	%f72, %f71;
	mul.f32 	%f73, %f59, %f72;
	mov.f32 	%f74, %f73;
	mov.f32 	%f75, %f58;
	mov.f32 	%f76, %f57;
	mad.f32 %f77, %f74, %f75, %f76;
	mov.f32 	%f78, %f77;
	mov.f32 	%f79, %f44;
	mov.f32 	%f80, 0f3f317218;    	// 0.693147
	mov.f32 	%f81, %f80;
	add.f32 	%f82, %f54, %f78;
	mov.f32 	%f83, %f82;
	mad.f32 %f84, %f79, %f81, %f83;
	mov.f32 	%f85, %f84;
	.loc	17	9050	0
	mov.f32 	%f86, %f85;
	bra.uni 	$Lt_141_5890;
$Lt_141_6146:
	.loc	17	9053	0
	lg2.approx.f32 	%f86, %f37;
$Lt_141_5890:
	.loc	17	9950	0
	mov.f32 	%f35, %f86;
$Lt_141_5378:
	.loc	17	9995	0
	mov.f32 	%f87, 0f3f000000;    	// 0.5
	mul.f32 	%f88, %f35, %f87;
	mov.f32 	%f89, %f88;
	abs.f32 	%f90, %f88;
	mov.f32 	%f91, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p5, %f90, %f91;
	@!%p5 bra 	$Lt_141_6914;
	.loc	17	9997	0
	mov.b32 	%r34, %f88;
	mov.b32 	%r35, %f1;
	and.b32 	%r36, %r35, -2147483648;
	or.b32 	%r37, %r34, %r36;
	mov.b32 	%f89, %r37;
$Lt_141_6914:
	.loc	15	182	0
	ld.param.u64 	%rd5, [__cudaparm_eatanh_mf_B];
	ld.param.s32 	%r38, [__cudaparm_eatanh_mf_ldb];
	mul.lo.s32 	%r39, %r38, %r4;
	add.s32 	%r40, %r6, %r39;
	cvt.s64.s32 	%rd6, %r40;
	mul.wide.s32 	%rd7, %r40, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f89;
$Lt_141_4866:
	exit;
$LDWend_eatanh_mf:
	} // eatanh_mf

	.entry eatan2_vvf (
		.param .u64 __cudaparm_eatan2_vvf_n,
		.param .u64 __cudaparm_eatan2_vvf_x,
		.param .s32 __cudaparm_eatan2_vvf_lx,
		.param .u64 __cudaparm_eatan2_vvf_y,
		.param .s32 __cudaparm_eatan2_vvf_ly,
		.param .u64 __cudaparm_eatan2_vvf_result,
		.param .s32 __cudaparm_eatan2_vvf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<37>;
	.reg .u64 %rd<16>;
	.reg .f32 %f<55>;
	.reg .pred %p<8>;
	.loc	15	183	0
$LDWbegin_eatan2_vvf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eatan2_vvf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_142_6914;
	ld.param.u64 	%rd3, [__cudaparm_eatan2_vvf_x];
	ld.param.s32 	%r4, [__cudaparm_eatan2_vvf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_eatan2_vvf_y];
	ld.param.s32 	%r6, [__cudaparm_eatan2_vvf_ly];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	ld.global.f32 	%f2, [%rd10+0];
	abs.f32 	%f3, %f1;
	abs.f32 	%f4, %f2;
	mov.b32 	%r8, %f2;
	mov.b32 	%r9, %f1;
	mov.s32 	%r10, 0;
	setp.lt.s32 	%p2, %r8, %r10;
	and.b32 	%r11, %r9, -2147483648;
	mov.f32 	%f5, 0f00000000;     	// 0
	set.eq.u32.f32 	%r12, %f3, %f5;
	neg.s32 	%r13, %r12;
	mov.f32 	%f6, 0f00000000;     	// 0
	set.eq.u32.f32 	%r14, %f4, %f6;
	neg.s32 	%r15, %r14;
	and.b32 	%r16, %r13, %r15;
	mov.u32 	%r17, 0;
	setp.eq.s32 	%p3, %r16, %r17;
	@%p3 bra 	$Lt_142_7682;
	.loc	17	9829	0
	mov.s32 	%r18, 1078530011;
	mov.s32 	%r19, 0;
	selp.s32 	%r20, %r18, %r19, %p2;
	or.b32 	%r21, %r20, %r11;
	mov.b32 	%f7, %r21;
	bra.uni 	$Lt_142_7426;
$Lt_142_7682:
	mov.f32 	%f8, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.eq.u32.f32 	%r22, %f3, %f8;
	neg.s32 	%r23, %r22;
	mov.f32 	%f9, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.eq.u32.f32 	%r24, %f4, %f9;
	neg.s32 	%r25, %r24;
	and.b32 	%r26, %r23, %r25;
	mov.u32 	%r27, 0;
	setp.eq.s32 	%p4, %r26, %r27;
	@%p4 bra 	$Lt_142_8194;
	.loc	17	9832	0
	mov.s32 	%r28, 1075235812;
	mov.s32 	%r29, 1061752795;
	selp.s32 	%r30, %r28, %r29, %p2;
	or.b32 	%r31, %r30, %r11;
	mov.b32 	%f7, %r31;
	bra.uni 	$Lt_142_7938;
$Lt_142_8194:
	.loc	17	8936	0
	min.f32 	%f10, %f3, %f4;
	max.f32 	%f11, %f3, %f4;
	div.full.f32 	%f12, %f10, %f11;
	mul.rn.f32 	%f13, %f12, %f12;
	mov.f32 	%f14, %f13;
	mov.f32 	%f15, 0fbf52c7ea;    	// -0.823363
	mov.f32 	%f16, %f15;
	mov.f32 	%f17, 0fc0b59883;    	// -5.67487
	mov.f32 	%f18, %f17;
	mad.f32 %f19, %f14, %f16, %f18;
	mov.f32 	%f20, %f19;
	mov.f32 	%f21, %f20;
	mov.f32 	%f22, %f13;
	mov.f32 	%f23, 0fc0d21907;    	// -6.56556
	mov.f32 	%f24, %f23;
	mad.f32 %f25, %f21, %f22, %f24;
	mov.f32 	%f20, %f25;
	.loc	17	8997	0
	mul.f32 	%f26, %f13, %f20;
	mul.f32 	%f27, %f12, %f26;
	.loc	17	8936	0
	mov.f32 	%f28, 0f41355dc0;    	// 11.3354
	add.f32 	%f29, %f13, %f28;
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f13;
	mov.f32 	%f32, 0f41e6bd60;    	// 28.8425
	mov.f32 	%f33, %f32;
	mad.f32 %f34, %f30, %f31, %f33;
	mov.f32 	%f20, %f34;
	mov.f32 	%f35, %f20;
	mov.f32 	%f36, %f13;
	mov.f32 	%f37, 0f419d92c8;    	// 19.6967
	mov.f32 	%f38, %f37;
	mad.f32 %f39, %f35, %f36, %f38;
	mov.f32 	%f20, %f39;
	mov.f32 	%f40, %f27;
	rcp.approx.f32 	%f41, %f20;
	mov.f32 	%f42, %f41;
	mov.f32 	%f43, %f12;
	mad.f32 %f44, %f40, %f42, %f43;
	mov.f32 	%f20, %f44;
	.loc	17	9841	0
	mov.f32 	%f45, 0f3fc90fdb;    	// 1.5708
	sub.f32 	%f46, %f45, %f20;
	add.f32 	%f47, %f3, %f4;
	setp.gt.f32 	%p5, %f3, %f4;
	selp.f32 	%f48, %f46, %f20, %p5;
	mov.f32 	%f49, 0f40490fdb;    	// 3.14159
	sub.f32 	%f50, %f49, %f48;
	selp.f32 	%f51, %f50, %f48, %p2;
	mov.b32 	%r32, %f51;
	or.b32 	%r33, %r11, %r32;
	mov.b32 	%f52, %r33;
	mov.f32 	%f53, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p6, %f47, %f53;
	selp.f32 	%f7, %f52, %f47, %p6;
$Lt_142_7938:
$Lt_142_7426:
	.loc	15	183	0
	ld.param.u64 	%rd11, [__cudaparm_eatan2_vvf_result];
	ld.param.s32 	%r34, [__cudaparm_eatan2_vvf_lr];
	mul.lo.s32 	%r35, %r34, %r3;
	cvt.s64.s32 	%rd12, %r35;
	mul.wide.s32 	%rd13, %r35, 4;
	add.u64 	%rd14, %rd11, %rd13;
	st.global.f32 	[%rd14+0], %f7;
$Lt_142_6914:
	exit;
$LDWend_eatan2_vvf:
	} // eatan2_vvf

	.entry eatan2_vmf (
		.param .s32 __cudaparm_eatan2_vmf_rs,
		.param .s32 __cudaparm_eatan2_vmf_cs,
		.param .u64 __cudaparm_eatan2_vmf_x,
		.param .s32 __cudaparm_eatan2_vmf_lx,
		.param .u64 __cudaparm_eatan2_vmf_B,
		.param .s32 __cudaparm_eatan2_vmf_ldb,
		.param .u64 __cudaparm_eatan2_vmf_C,
		.param .s32 __cudaparm_eatan2_vmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<50>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<55>;
	.reg .pred %p<8>;
$LDWbegin_eatan2_vmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eatan2_vmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eatan2_vmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_143_7170;
	ld.param.u64 	%rd1, [__cudaparm_eatan2_vmf_x];
	ld.param.s32 	%r15, [__cudaparm_eatan2_vmf_lx];
	mul.lo.s32 	%r16, %r15, %r6;
	cvt.s64.s32 	%rd2, %r16;
	mul.wide.s32 	%rd3, %r16, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_eatan2_vmf_B];
	ld.param.s32 	%r17, [__cudaparm_eatan2_vmf_ldb];
	mul.lo.s32 	%r18, %r17, %r4;
	add.s32 	%r19, %r6, %r18;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	abs.f32 	%f3, %f1;
	abs.f32 	%f4, %f2;
	mov.b32 	%r20, %f2;
	mov.b32 	%r21, %f1;
	mov.s32 	%r22, 0;
	setp.lt.s32 	%p2, %r20, %r22;
	and.b32 	%r23, %r21, -2147483648;
	mov.f32 	%f5, 0f00000000;     	// 0
	set.eq.u32.f32 	%r24, %f3, %f5;
	neg.s32 	%r25, %r24;
	mov.f32 	%f6, 0f00000000;     	// 0
	set.eq.u32.f32 	%r26, %f4, %f6;
	neg.s32 	%r27, %r26;
	and.b32 	%r28, %r25, %r27;
	mov.u32 	%r29, 0;
	setp.eq.s32 	%p3, %r28, %r29;
	@%p3 bra 	$Lt_143_7938;
	.loc	17	9829	0
	mov.s32 	%r30, 1078530011;
	mov.s32 	%r31, 0;
	selp.s32 	%r32, %r30, %r31, %p2;
	or.b32 	%r33, %r32, %r23;
	mov.b32 	%f7, %r33;
	bra.uni 	$Lt_143_7682;
$Lt_143_7938:
	mov.f32 	%f8, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.eq.u32.f32 	%r34, %f3, %f8;
	neg.s32 	%r35, %r34;
	mov.f32 	%f9, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.eq.u32.f32 	%r36, %f4, %f9;
	neg.s32 	%r37, %r36;
	and.b32 	%r38, %r35, %r37;
	mov.u32 	%r39, 0;
	setp.eq.s32 	%p4, %r38, %r39;
	@%p4 bra 	$Lt_143_8450;
	.loc	17	9832	0
	mov.s32 	%r40, 1075235812;
	mov.s32 	%r41, 1061752795;
	selp.s32 	%r42, %r40, %r41, %p2;
	or.b32 	%r43, %r42, %r23;
	mov.b32 	%f7, %r43;
	bra.uni 	$Lt_143_8194;
$Lt_143_8450:
	.loc	17	8936	0
	min.f32 	%f10, %f3, %f4;
	max.f32 	%f11, %f3, %f4;
	div.full.f32 	%f12, %f10, %f11;
	mul.rn.f32 	%f13, %f12, %f12;
	mov.f32 	%f14, %f13;
	mov.f32 	%f15, 0fbf52c7ea;    	// -0.823363
	mov.f32 	%f16, %f15;
	mov.f32 	%f17, 0fc0b59883;    	// -5.67487
	mov.f32 	%f18, %f17;
	mad.f32 %f19, %f14, %f16, %f18;
	mov.f32 	%f20, %f19;
	mov.f32 	%f21, %f20;
	mov.f32 	%f22, %f13;
	mov.f32 	%f23, 0fc0d21907;    	// -6.56556
	mov.f32 	%f24, %f23;
	mad.f32 %f25, %f21, %f22, %f24;
	mov.f32 	%f20, %f25;
	.loc	17	8997	0
	mul.f32 	%f26, %f13, %f20;
	mul.f32 	%f27, %f12, %f26;
	.loc	17	8936	0
	mov.f32 	%f28, 0f41355dc0;    	// 11.3354
	add.f32 	%f29, %f13, %f28;
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f13;
	mov.f32 	%f32, 0f41e6bd60;    	// 28.8425
	mov.f32 	%f33, %f32;
	mad.f32 %f34, %f30, %f31, %f33;
	mov.f32 	%f20, %f34;
	mov.f32 	%f35, %f20;
	mov.f32 	%f36, %f13;
	mov.f32 	%f37, 0f419d92c8;    	// 19.6967
	mov.f32 	%f38, %f37;
	mad.f32 %f39, %f35, %f36, %f38;
	mov.f32 	%f20, %f39;
	mov.f32 	%f40, %f27;
	rcp.approx.f32 	%f41, %f20;
	mov.f32 	%f42, %f41;
	mov.f32 	%f43, %f12;
	mad.f32 %f44, %f40, %f42, %f43;
	mov.f32 	%f20, %f44;
	.loc	17	9841	0
	mov.f32 	%f45, 0f3fc90fdb;    	// 1.5708
	sub.f32 	%f46, %f45, %f20;
	add.f32 	%f47, %f3, %f4;
	setp.gt.f32 	%p5, %f3, %f4;
	selp.f32 	%f48, %f46, %f20, %p5;
	mov.f32 	%f49, 0f40490fdb;    	// 3.14159
	sub.f32 	%f50, %f49, %f48;
	selp.f32 	%f51, %f50, %f48, %p2;
	mov.b32 	%r44, %f51;
	or.b32 	%r45, %r23, %r44;
	mov.b32 	%f52, %r45;
	mov.f32 	%f53, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p6, %f47, %f53;
	selp.f32 	%f7, %f52, %f47, %p6;
$Lt_143_8194:
$Lt_143_7682:
	.loc	15	183	0
	ld.param.u64 	%rd9, [__cudaparm_eatan2_vmf_C];
	ld.param.s32 	%r46, [__cudaparm_eatan2_vmf_ldc];
	mul.lo.s32 	%r47, %r46, %r4;
	add.s32 	%r48, %r6, %r47;
	cvt.s64.s32 	%rd10, %r48;
	mul.wide.s32 	%rd11, %r48, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f7;
$Lt_143_7170:
	exit;
$LDWend_eatan2_vmf:
	} // eatan2_vmf

	.entry eatan2_mvf (
		.param .s32 __cudaparm_eatan2_mvf_rs,
		.param .s32 __cudaparm_eatan2_mvf_cs,
		.param .u64 __cudaparm_eatan2_mvf_A,
		.param .s32 __cudaparm_eatan2_mvf_lda,
		.param .u64 __cudaparm_eatan2_mvf_y,
		.param .s32 __cudaparm_eatan2_mvf_ly,
		.param .u64 __cudaparm_eatan2_mvf_C,
		.param .s32 __cudaparm_eatan2_mvf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<50>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<55>;
	.reg .pred %p<8>;
$LDWbegin_eatan2_mvf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eatan2_mvf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eatan2_mvf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_144_7170;
	ld.param.u64 	%rd1, [__cudaparm_eatan2_mvf_A];
	ld.param.s32 	%r15, [__cudaparm_eatan2_mvf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_eatan2_mvf_y];
	ld.param.s32 	%r18, [__cudaparm_eatan2_mvf_ly];
	mul.lo.s32 	%r19, %r18, %r6;
	cvt.s64.s32 	%rd6, %r19;
	mul.wide.s32 	%rd7, %r19, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	abs.f32 	%f3, %f1;
	abs.f32 	%f4, %f2;
	mov.b32 	%r20, %f2;
	mov.b32 	%r21, %f1;
	mov.s32 	%r22, 0;
	setp.lt.s32 	%p2, %r20, %r22;
	and.b32 	%r23, %r21, -2147483648;
	mov.f32 	%f5, 0f00000000;     	// 0
	set.eq.u32.f32 	%r24, %f3, %f5;
	neg.s32 	%r25, %r24;
	mov.f32 	%f6, 0f00000000;     	// 0
	set.eq.u32.f32 	%r26, %f4, %f6;
	neg.s32 	%r27, %r26;
	and.b32 	%r28, %r25, %r27;
	mov.u32 	%r29, 0;
	setp.eq.s32 	%p3, %r28, %r29;
	@%p3 bra 	$Lt_144_7938;
	.loc	17	9829	0
	mov.s32 	%r30, 1078530011;
	mov.s32 	%r31, 0;
	selp.s32 	%r32, %r30, %r31, %p2;
	or.b32 	%r33, %r32, %r23;
	mov.b32 	%f7, %r33;
	bra.uni 	$Lt_144_7682;
$Lt_144_7938:
	mov.f32 	%f8, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.eq.u32.f32 	%r34, %f3, %f8;
	neg.s32 	%r35, %r34;
	mov.f32 	%f9, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.eq.u32.f32 	%r36, %f4, %f9;
	neg.s32 	%r37, %r36;
	and.b32 	%r38, %r35, %r37;
	mov.u32 	%r39, 0;
	setp.eq.s32 	%p4, %r38, %r39;
	@%p4 bra 	$Lt_144_8450;
	.loc	17	9832	0
	mov.s32 	%r40, 1075235812;
	mov.s32 	%r41, 1061752795;
	selp.s32 	%r42, %r40, %r41, %p2;
	or.b32 	%r43, %r42, %r23;
	mov.b32 	%f7, %r43;
	bra.uni 	$Lt_144_8194;
$Lt_144_8450:
	.loc	17	8936	0
	min.f32 	%f10, %f3, %f4;
	max.f32 	%f11, %f3, %f4;
	div.full.f32 	%f12, %f10, %f11;
	mul.rn.f32 	%f13, %f12, %f12;
	mov.f32 	%f14, %f13;
	mov.f32 	%f15, 0fbf52c7ea;    	// -0.823363
	mov.f32 	%f16, %f15;
	mov.f32 	%f17, 0fc0b59883;    	// -5.67487
	mov.f32 	%f18, %f17;
	mad.f32 %f19, %f14, %f16, %f18;
	mov.f32 	%f20, %f19;
	mov.f32 	%f21, %f20;
	mov.f32 	%f22, %f13;
	mov.f32 	%f23, 0fc0d21907;    	// -6.56556
	mov.f32 	%f24, %f23;
	mad.f32 %f25, %f21, %f22, %f24;
	mov.f32 	%f20, %f25;
	.loc	17	8997	0
	mul.f32 	%f26, %f13, %f20;
	mul.f32 	%f27, %f12, %f26;
	.loc	17	8936	0
	mov.f32 	%f28, 0f41355dc0;    	// 11.3354
	add.f32 	%f29, %f13, %f28;
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f13;
	mov.f32 	%f32, 0f41e6bd60;    	// 28.8425
	mov.f32 	%f33, %f32;
	mad.f32 %f34, %f30, %f31, %f33;
	mov.f32 	%f20, %f34;
	mov.f32 	%f35, %f20;
	mov.f32 	%f36, %f13;
	mov.f32 	%f37, 0f419d92c8;    	// 19.6967
	mov.f32 	%f38, %f37;
	mad.f32 %f39, %f35, %f36, %f38;
	mov.f32 	%f20, %f39;
	mov.f32 	%f40, %f27;
	rcp.approx.f32 	%f41, %f20;
	mov.f32 	%f42, %f41;
	mov.f32 	%f43, %f12;
	mad.f32 %f44, %f40, %f42, %f43;
	mov.f32 	%f20, %f44;
	.loc	17	9841	0
	mov.f32 	%f45, 0f3fc90fdb;    	// 1.5708
	sub.f32 	%f46, %f45, %f20;
	add.f32 	%f47, %f3, %f4;
	setp.gt.f32 	%p5, %f3, %f4;
	selp.f32 	%f48, %f46, %f20, %p5;
	mov.f32 	%f49, 0f40490fdb;    	// 3.14159
	sub.f32 	%f50, %f49, %f48;
	selp.f32 	%f51, %f50, %f48, %p2;
	mov.b32 	%r44, %f51;
	or.b32 	%r45, %r23, %r44;
	mov.b32 	%f52, %r45;
	mov.f32 	%f53, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p6, %f47, %f53;
	selp.f32 	%f7, %f52, %f47, %p6;
$Lt_144_8194:
$Lt_144_7682:
	.loc	15	183	0
	ld.param.u64 	%rd9, [__cudaparm_eatan2_mvf_C];
	ld.param.s32 	%r46, [__cudaparm_eatan2_mvf_ldc];
	mul.lo.s32 	%r47, %r46, %r4;
	add.s32 	%r48, %r6, %r47;
	cvt.s64.s32 	%rd10, %r48;
	mul.wide.s32 	%rd11, %r48, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f7;
$Lt_144_7170:
	exit;
$LDWend_eatan2_mvf:
	} // eatan2_mvf

	.entry eatan2_mmf (
		.param .s32 __cudaparm_eatan2_mmf_rs,
		.param .s32 __cudaparm_eatan2_mmf_cs,
		.param .u64 __cudaparm_eatan2_mmf_A,
		.param .s32 __cudaparm_eatan2_mmf_lda,
		.param .u64 __cudaparm_eatan2_mmf_B,
		.param .s32 __cudaparm_eatan2_mmf_ldb,
		.param .u64 __cudaparm_eatan2_mmf_C,
		.param .s32 __cudaparm_eatan2_mmf_ldc)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<51>;
	.reg .u64 %rd<14>;
	.reg .f32 %f<55>;
	.reg .pred %p<8>;
$LDWbegin_eatan2_mmf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eatan2_mmf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eatan2_mmf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_145_7170;
	ld.param.u64 	%rd1, [__cudaparm_eatan2_mmf_A];
	ld.param.s32 	%r15, [__cudaparm_eatan2_mmf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_eatan2_mmf_B];
	ld.param.s32 	%r18, [__cudaparm_eatan2_mmf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.f32 	%f2, [%rd8+0];
	abs.f32 	%f3, %f1;
	abs.f32 	%f4, %f2;
	mov.b32 	%r21, %f2;
	mov.b32 	%r22, %f1;
	mov.s32 	%r23, 0;
	setp.lt.s32 	%p2, %r21, %r23;
	and.b32 	%r24, %r22, -2147483648;
	mov.f32 	%f5, 0f00000000;     	// 0
	set.eq.u32.f32 	%r25, %f3, %f5;
	neg.s32 	%r26, %r25;
	mov.f32 	%f6, 0f00000000;     	// 0
	set.eq.u32.f32 	%r27, %f4, %f6;
	neg.s32 	%r28, %r27;
	and.b32 	%r29, %r26, %r28;
	mov.u32 	%r30, 0;
	setp.eq.s32 	%p3, %r29, %r30;
	@%p3 bra 	$Lt_145_7938;
	.loc	17	9829	0
	mov.s32 	%r31, 1078530011;
	mov.s32 	%r32, 0;
	selp.s32 	%r33, %r31, %r32, %p2;
	or.b32 	%r34, %r33, %r24;
	mov.b32 	%f7, %r34;
	bra.uni 	$Lt_145_7682;
$Lt_145_7938:
	mov.f32 	%f8, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.eq.u32.f32 	%r35, %f3, %f8;
	neg.s32 	%r36, %r35;
	mov.f32 	%f9, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.eq.u32.f32 	%r37, %f4, %f9;
	neg.s32 	%r38, %r37;
	and.b32 	%r39, %r36, %r38;
	mov.u32 	%r40, 0;
	setp.eq.s32 	%p4, %r39, %r40;
	@%p4 bra 	$Lt_145_8450;
	.loc	17	9832	0
	mov.s32 	%r41, 1075235812;
	mov.s32 	%r42, 1061752795;
	selp.s32 	%r43, %r41, %r42, %p2;
	or.b32 	%r44, %r43, %r24;
	mov.b32 	%f7, %r44;
	bra.uni 	$Lt_145_8194;
$Lt_145_8450:
	.loc	17	8936	0
	min.f32 	%f10, %f3, %f4;
	max.f32 	%f11, %f3, %f4;
	div.full.f32 	%f12, %f10, %f11;
	mul.rn.f32 	%f13, %f12, %f12;
	mov.f32 	%f14, %f13;
	mov.f32 	%f15, 0fbf52c7ea;    	// -0.823363
	mov.f32 	%f16, %f15;
	mov.f32 	%f17, 0fc0b59883;    	// -5.67487
	mov.f32 	%f18, %f17;
	mad.f32 %f19, %f14, %f16, %f18;
	mov.f32 	%f20, %f19;
	mov.f32 	%f21, %f20;
	mov.f32 	%f22, %f13;
	mov.f32 	%f23, 0fc0d21907;    	// -6.56556
	mov.f32 	%f24, %f23;
	mad.f32 %f25, %f21, %f22, %f24;
	mov.f32 	%f20, %f25;
	.loc	17	8997	0
	mul.f32 	%f26, %f13, %f20;
	mul.f32 	%f27, %f12, %f26;
	.loc	17	8936	0
	mov.f32 	%f28, 0f41355dc0;    	// 11.3354
	add.f32 	%f29, %f13, %f28;
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f13;
	mov.f32 	%f32, 0f41e6bd60;    	// 28.8425
	mov.f32 	%f33, %f32;
	mad.f32 %f34, %f30, %f31, %f33;
	mov.f32 	%f20, %f34;
	mov.f32 	%f35, %f20;
	mov.f32 	%f36, %f13;
	mov.f32 	%f37, 0f419d92c8;    	// 19.6967
	mov.f32 	%f38, %f37;
	mad.f32 %f39, %f35, %f36, %f38;
	mov.f32 	%f20, %f39;
	mov.f32 	%f40, %f27;
	rcp.approx.f32 	%f41, %f20;
	mov.f32 	%f42, %f41;
	mov.f32 	%f43, %f12;
	mad.f32 %f44, %f40, %f42, %f43;
	mov.f32 	%f20, %f44;
	.loc	17	9841	0
	mov.f32 	%f45, 0f3fc90fdb;    	// 1.5708
	sub.f32 	%f46, %f45, %f20;
	add.f32 	%f47, %f3, %f4;
	setp.gt.f32 	%p5, %f3, %f4;
	selp.f32 	%f48, %f46, %f20, %p5;
	mov.f32 	%f49, 0f40490fdb;    	// 3.14159
	sub.f32 	%f50, %f49, %f48;
	selp.f32 	%f51, %f50, %f48, %p2;
	mov.b32 	%r45, %f51;
	or.b32 	%r46, %r24, %r45;
	mov.b32 	%f52, %r46;
	mov.f32 	%f53, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.le.f32 	%p6, %f47, %f53;
	selp.f32 	%f7, %f52, %f47, %p6;
$Lt_145_8194:
$Lt_145_7682:
	.loc	15	183	0
	ld.param.u64 	%rd9, [__cudaparm_eatan2_mmf_C];
	ld.param.s32 	%r47, [__cudaparm_eatan2_mmf_ldc];
	mul.lo.s32 	%r48, %r47, %r4;
	add.s32 	%r49, %r6, %r48;
	cvt.s64.s32 	%rd10, %r49;
	mul.wide.s32 	%rd11, %r49, 4;
	add.u64 	%rd12, %rd9, %rd11;
	st.global.f32 	[%rd12+0], %f7;
$Lt_145_7170:
	exit;
$LDWend_eatan2_mmf:
	} // eatan2_mmf

	.entry ecospi_vf (
		.param .u64 __cudaparm_ecospi_vf_n,
		.param .u64 __cudaparm_ecospi_vf_x,
		.param .s32 __cudaparm_ecospi_vf_lx,
		.param .u64 __cudaparm_ecospi_vf_result,
		.param .s32 __cudaparm_ecospi_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<15>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<70>;
	.reg .pred %p<6>;
	.loc	15	184	0
$LDWbegin_ecospi_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_ecospi_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_146_3330;
	ld.param.u64 	%rd3, [__cudaparm_ecospi_vf_x];
	ld.param.s32 	%r4, [__cudaparm_ecospi_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f4b800000;     	// 1.67772e+07
	setp.gt.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_146_3842;
	.loc	17	9650	0
	mov.f32 	%f4, 0f00000000;     	// 0
	mul.rn.f32 	%f1, %f1, %f4;
$Lt_146_3842:
	.loc	17	8936	0
	add.f32 	%f5, %f1, %f1;
	cvt.rni.f32.f32 	%f6, %f5;
	neg.f32 	%f7, %f6;
	mov.f32 	%f8, %f7;
	mov.f32 	%f9, 0f3f000000;     	// 0.5
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, %f1;
	mad.f32 %f12, %f8, %f10, %f11;
	mov.f32 	%f13, %f12;
	.loc	17	9661	0
	mov.f32 	%f14, 0f40490fdb;    	// 3.14159
	mul.f32 	%f15, %f13, %f14;
	mul.f32 	%f16, %f15, %f15;
	cvt.rzi.s32.f32 	%r6, %f6;
	add.s32 	%r7, %r6, 1;
	and.b32 	%r8, %r7, 1;
	mov.u32 	%r9, 0;
	setp.eq.s32 	%p3, %r8, %r9;
	@%p3 bra 	$Lt_146_4610;
	.loc	17	8936	0
	mov.f32 	%f17, 0f37ccf5ce;    	// 2.44332e-05
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f16;
	mov.f32 	%f20, 0fbab6061a;    	// -0.00138873
	mov.f32 	%f21, %f20;
	mad.f32 %f22, %f18, %f19, %f21;
	mov.f32 	%f23, %f22;
	mov.f32 	%f24, %f23;
	mov.f32 	%f25, %f16;
	mov.f32 	%f26, 0f3d2aaaa5;    	// 0.0416666
	mov.f32 	%f27, %f26;
	mad.f32 %f28, %f24, %f25, %f27;
	mov.f32 	%f29, %f28;
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f16;
	mov.f32 	%f32, 0fbf000000;    	// -0.5
	mov.f32 	%f33, %f32;
	mad.f32 %f34, %f30, %f31, %f33;
	mov.f32 	%f35, %f34;
	mov.f32 	%f36, %f35;
	mov.f32 	%f37, %f16;
	mov.f32 	%f38, 0f3f800000;    	// 1
	mov.f32 	%f39, %f38;
	mad.f32 %f40, %f36, %f37, %f39;
	mov.f32 	%f41, %f40;
	.loc	17	9491	0
	mov.f32 	%f42, %f41;
	bra.uni 	$Lt_146_4354;
$Lt_146_4610:
	.loc	17	8936	0
	mov.f32 	%f43, 0fb94ca1f9;    	// -0.000195153
	mov.f32 	%f44, %f43;
	mov.f32 	%f45, %f16;
	mov.f32 	%f46, 0f3c08839e;    	// 0.00833216
	mov.f32 	%f47, %f46;
	mad.f32 %f48, %f44, %f45, %f47;
	mov.f32 	%f49, %f48;
	mov.f32 	%f50, %f49;
	mov.f32 	%f51, %f16;
	mov.f32 	%f52, 0fbe2aaaa3;    	// -0.166667
	mov.f32 	%f53, %f52;
	mad.f32 %f54, %f50, %f51, %f53;
	mov.f32 	%f55, %f54;
	mul.f32 	%f56, %f16, %f55;
	mov.f32 	%f57, %f56;
	mov.f32 	%f58, %f15;
	mov.f32 	%f59, %f15;
	mad.f32 %f60, %f57, %f58, %f59;
	mov.f32 	%f61, %f60;
	.loc	17	9493	0
	mov.f32 	%f42, %f61;
$Lt_146_4354:
	and.b32 	%r10, %r7, 2;
	mov.u32 	%r11, 0;
	setp.eq.s32 	%p4, %r10, %r11;
	@%p4 bra 	$Lt_146_4866;
	.loc	17	8936	0
	mov.f32 	%f62, %f42;
	mov.f32 	%f63, 0fbf800000;    	// -1
	mov.f32 	%f64, %f63;
	mov.f32 	%f65, 0f00000000;    	// 0
	mov.f32 	%f66, %f65;
	mad.f32 %f67, %f62, %f64, %f66;
	mov.f32 	%f68, %f67;
	.loc	17	9496	0
	mov.f32 	%f42, %f68;
$Lt_146_4866:
	.loc	15	184	0
	ld.param.u64 	%rd7, [__cudaparm_ecospi_vf_result];
	ld.param.s32 	%r12, [__cudaparm_ecospi_vf_lr];
	mul.lo.s32 	%r13, %r12, %r3;
	cvt.s64.s32 	%rd8, %r13;
	mul.wide.s32 	%rd9, %r13, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f42;
$Lt_146_3330:
	exit;
$LDWend_ecospi_vf:
	} // ecospi_vf

	.entry ecospi_mf (
		.param .s32 __cudaparm_ecospi_mf_rs,
		.param .s32 __cudaparm_ecospi_mf_cs,
		.param .u64 __cudaparm_ecospi_mf_A,
		.param .s32 __cudaparm_ecospi_mf_lda,
		.param .u64 __cudaparm_ecospi_mf_B,
		.param .s32 __cudaparm_ecospi_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<28>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<70>;
	.reg .pred %p<6>;
$LDWbegin_ecospi_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_ecospi_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_ecospi_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_147_3586;
	ld.param.u64 	%rd1, [__cudaparm_ecospi_mf_A];
	ld.param.s32 	%r15, [__cudaparm_ecospi_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f4b800000;     	// 1.67772e+07
	setp.gt.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_147_4098;
	.loc	17	9650	0
	mov.f32 	%f4, 0f00000000;     	// 0
	mul.rn.f32 	%f1, %f1, %f4;
$Lt_147_4098:
	.loc	17	8936	0
	add.f32 	%f5, %f1, %f1;
	cvt.rni.f32.f32 	%f6, %f5;
	neg.f32 	%f7, %f6;
	mov.f32 	%f8, %f7;
	mov.f32 	%f9, 0f3f000000;     	// 0.5
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, %f1;
	mad.f32 %f12, %f8, %f10, %f11;
	mov.f32 	%f13, %f12;
	.loc	17	9661	0
	mov.f32 	%f14, 0f40490fdb;    	// 3.14159
	mul.f32 	%f15, %f13, %f14;
	mul.f32 	%f16, %f15, %f15;
	cvt.rzi.s32.f32 	%r18, %f6;
	add.s32 	%r19, %r18, 1;
	and.b32 	%r20, %r19, 1;
	mov.u32 	%r21, 0;
	setp.eq.s32 	%p3, %r20, %r21;
	@%p3 bra 	$Lt_147_4866;
	.loc	17	8936	0
	mov.f32 	%f17, 0f37ccf5ce;    	// 2.44332e-05
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f16;
	mov.f32 	%f20, 0fbab6061a;    	// -0.00138873
	mov.f32 	%f21, %f20;
	mad.f32 %f22, %f18, %f19, %f21;
	mov.f32 	%f23, %f22;
	mov.f32 	%f24, %f23;
	mov.f32 	%f25, %f16;
	mov.f32 	%f26, 0f3d2aaaa5;    	// 0.0416666
	mov.f32 	%f27, %f26;
	mad.f32 %f28, %f24, %f25, %f27;
	mov.f32 	%f29, %f28;
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f16;
	mov.f32 	%f32, 0fbf000000;    	// -0.5
	mov.f32 	%f33, %f32;
	mad.f32 %f34, %f30, %f31, %f33;
	mov.f32 	%f35, %f34;
	mov.f32 	%f36, %f35;
	mov.f32 	%f37, %f16;
	mov.f32 	%f38, 0f3f800000;    	// 1
	mov.f32 	%f39, %f38;
	mad.f32 %f40, %f36, %f37, %f39;
	mov.f32 	%f41, %f40;
	.loc	17	9491	0
	mov.f32 	%f42, %f41;
	bra.uni 	$Lt_147_4610;
$Lt_147_4866:
	.loc	17	8936	0
	mov.f32 	%f43, 0fb94ca1f9;    	// -0.000195153
	mov.f32 	%f44, %f43;
	mov.f32 	%f45, %f16;
	mov.f32 	%f46, 0f3c08839e;    	// 0.00833216
	mov.f32 	%f47, %f46;
	mad.f32 %f48, %f44, %f45, %f47;
	mov.f32 	%f49, %f48;
	mov.f32 	%f50, %f49;
	mov.f32 	%f51, %f16;
	mov.f32 	%f52, 0fbe2aaaa3;    	// -0.166667
	mov.f32 	%f53, %f52;
	mad.f32 %f54, %f50, %f51, %f53;
	mov.f32 	%f55, %f54;
	mul.f32 	%f56, %f16, %f55;
	mov.f32 	%f57, %f56;
	mov.f32 	%f58, %f15;
	mov.f32 	%f59, %f15;
	mad.f32 %f60, %f57, %f58, %f59;
	mov.f32 	%f61, %f60;
	.loc	17	9493	0
	mov.f32 	%f42, %f61;
$Lt_147_4610:
	and.b32 	%r22, %r19, 2;
	mov.u32 	%r23, 0;
	setp.eq.s32 	%p4, %r22, %r23;
	@%p4 bra 	$Lt_147_5122;
	.loc	17	8936	0
	mov.f32 	%f62, %f42;
	mov.f32 	%f63, 0fbf800000;    	// -1
	mov.f32 	%f64, %f63;
	mov.f32 	%f65, 0f00000000;    	// 0
	mov.f32 	%f66, %f65;
	mad.f32 %f67, %f62, %f64, %f66;
	mov.f32 	%f68, %f67;
	.loc	17	9496	0
	mov.f32 	%f42, %f68;
$Lt_147_5122:
	.loc	15	184	0
	ld.param.u64 	%rd5, [__cudaparm_ecospi_mf_B];
	ld.param.s32 	%r24, [__cudaparm_ecospi_mf_ldb];
	mul.lo.s32 	%r25, %r24, %r4;
	add.s32 	%r26, %r6, %r25;
	cvt.s64.s32 	%rd6, %r26;
	mul.wide.s32 	%rd7, %r26, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f42;
$Lt_147_3586:
	exit;
$LDWend_ecospi_mf:
	} // ecospi_mf

	.entry esinpi_vf (
		.param .u64 __cudaparm_esinpi_vf_n,
		.param .u64 __cudaparm_esinpi_vf_x,
		.param .s32 __cudaparm_esinpi_vf_lx,
		.param .u64 __cudaparm_esinpi_vf_result,
		.param .s32 __cudaparm_esinpi_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<14>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<70>;
	.reg .pred %p<6>;
	.loc	15	185	0
$LDWbegin_esinpi_vf:
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r1, %rh1, %rh2;
	cvt.u32.u16 	%r2, %tid.x;
	add.u32 	%r3, %r2, %r1;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_esinpi_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_148_3330;
	ld.param.u64 	%rd3, [__cudaparm_esinpi_vf_x];
	ld.param.s32 	%r4, [__cudaparm_esinpi_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	8936	0
	add.f32 	%f2, %f1, %f1;
	cvt.rni.f32.f32 	%f3, %f2;
	neg.f32 	%f4, %f3;
	mov.f32 	%f5, %f4;
	mov.f32 	%f6, 0f3f000000;     	// 0.5
	mov.f32 	%f7, %f6;
	mov.f32 	%f8, %f1;
	mad.f32 %f9, %f5, %f7, %f8;
	mov.f32 	%f10, %f9;
	.loc	17	9637	0
	mov.f32 	%f11, 0f40490fdb;    	// 3.14159
	mul.f32 	%f12, %f10, %f11;
	mul.f32 	%f13, %f12, %f12;
	cvt.rzi.s32.f32 	%r6, %f3;
	and.b32 	%r7, %r6, 1;
	mov.u32 	%r8, 0;
	setp.eq.s32 	%p2, %r7, %r8;
	@%p2 bra 	$Lt_148_4098;
	.loc	17	8936	0
	mov.f32 	%f14, 0f37ccf5ce;    	// 2.44332e-05
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f13;
	mov.f32 	%f17, 0fbab6061a;    	// -0.00138873
	mov.f32 	%f18, %f17;
	mad.f32 %f19, %f15, %f16, %f18;
	mov.f32 	%f20, %f19;
	mov.f32 	%f21, %f20;
	mov.f32 	%f22, %f13;
	mov.f32 	%f23, 0f3d2aaaa5;    	// 0.0416666
	mov.f32 	%f24, %f23;
	mad.f32 %f25, %f21, %f22, %f24;
	mov.f32 	%f26, %f25;
	mov.f32 	%f27, %f26;
	mov.f32 	%f28, %f13;
	mov.f32 	%f29, 0fbf000000;    	// -0.5
	mov.f32 	%f30, %f29;
	mad.f32 %f31, %f27, %f28, %f30;
	mov.f32 	%f32, %f31;
	mov.f32 	%f33, %f32;
	mov.f32 	%f34, %f13;
	mov.f32 	%f35, 0f3f800000;    	// 1
	mov.f32 	%f36, %f35;
	mad.f32 %f37, %f33, %f34, %f36;
	mov.f32 	%f38, %f37;
	.loc	17	9491	0
	mov.f32 	%f39, %f38;
	bra.uni 	$Lt_148_3842;
$Lt_148_4098:
	.loc	17	8936	0
	mov.f32 	%f40, 0fb94ca1f9;    	// -0.000195153
	mov.f32 	%f41, %f40;
	mov.f32 	%f42, %f13;
	mov.f32 	%f43, 0f3c08839e;    	// 0.00833216
	mov.f32 	%f44, %f43;
	mad.f32 %f45, %f41, %f42, %f44;
	mov.f32 	%f46, %f45;
	mov.f32 	%f47, %f46;
	mov.f32 	%f48, %f13;
	mov.f32 	%f49, 0fbe2aaaa3;    	// -0.166667
	mov.f32 	%f50, %f49;
	mad.f32 %f51, %f47, %f48, %f50;
	mov.f32 	%f52, %f51;
	mul.f32 	%f53, %f13, %f52;
	mov.f32 	%f54, %f53;
	mov.f32 	%f55, %f12;
	mov.f32 	%f56, %f12;
	mad.f32 %f57, %f54, %f55, %f56;
	mov.f32 	%f58, %f57;
	.loc	17	9493	0
	mov.f32 	%f39, %f58;
$Lt_148_3842:
	and.b32 	%r9, %r6, 2;
	mov.u32 	%r10, 0;
	setp.eq.s32 	%p3, %r9, %r10;
	@%p3 bra 	$Lt_148_4354;
	.loc	17	8936	0
	mov.f32 	%f59, %f39;
	mov.f32 	%f60, 0fbf800000;    	// -1
	mov.f32 	%f61, %f60;
	mov.f32 	%f62, 0f00000000;    	// 0
	mov.f32 	%f63, %f62;
	mad.f32 %f64, %f59, %f61, %f63;
	mov.f32 	%f65, %f64;
	.loc	17	9496	0
	mov.f32 	%f39, %f65;
$Lt_148_4354:
	.loc	17	9637	0
	mov.f32 	%f66, %f39;
	cvt.rzi.f32.f32 	%f67, %f1;
	setp.eq.f32 	%p4, %f1, %f67;
	@!%p4 bra 	$Lt_148_4866;
	.loc	17	9639	0
	mov.f32 	%f68, 0f00000000;    	// 0
	mul.rn.f32 	%f66, %f1, %f68;
$Lt_148_4866:
	.loc	15	185	0
	ld.param.u64 	%rd7, [__cudaparm_esinpi_vf_result];
	ld.param.s32 	%r11, [__cudaparm_esinpi_vf_lr];
	mul.lo.s32 	%r12, %r11, %r3;
	cvt.s64.s32 	%rd8, %r12;
	mul.wide.s32 	%rd9, %r12, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f66;
$Lt_148_3330:
	exit;
$LDWend_esinpi_vf:
	} // esinpi_vf

	.entry esinpi_mf (
		.param .s32 __cudaparm_esinpi_mf_rs,
		.param .s32 __cudaparm_esinpi_mf_cs,
		.param .u64 __cudaparm_esinpi_mf_A,
		.param .s32 __cudaparm_esinpi_mf_lda,
		.param .u64 __cudaparm_esinpi_mf_B,
		.param .s32 __cudaparm_esinpi_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<27>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<70>;
	.reg .pred %p<6>;
$LDWbegin_esinpi_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_esinpi_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_esinpi_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_149_3586;
	ld.param.u64 	%rd1, [__cudaparm_esinpi_mf_A];
	ld.param.s32 	%r15, [__cudaparm_esinpi_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	8936	0
	add.f32 	%f2, %f1, %f1;
	cvt.rni.f32.f32 	%f3, %f2;
	neg.f32 	%f4, %f3;
	mov.f32 	%f5, %f4;
	mov.f32 	%f6, 0f3f000000;     	// 0.5
	mov.f32 	%f7, %f6;
	mov.f32 	%f8, %f1;
	mad.f32 %f9, %f5, %f7, %f8;
	mov.f32 	%f10, %f9;
	.loc	17	9637	0
	mov.f32 	%f11, 0f40490fdb;    	// 3.14159
	mul.f32 	%f12, %f10, %f11;
	mul.f32 	%f13, %f12, %f12;
	cvt.rzi.s32.f32 	%r18, %f3;
	and.b32 	%r19, %r18, 1;
	mov.u32 	%r20, 0;
	setp.eq.s32 	%p2, %r19, %r20;
	@%p2 bra 	$Lt_149_4354;
	.loc	17	8936	0
	mov.f32 	%f14, 0f37ccf5ce;    	// 2.44332e-05
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f13;
	mov.f32 	%f17, 0fbab6061a;    	// -0.00138873
	mov.f32 	%f18, %f17;
	mad.f32 %f19, %f15, %f16, %f18;
	mov.f32 	%f20, %f19;
	mov.f32 	%f21, %f20;
	mov.f32 	%f22, %f13;
	mov.f32 	%f23, 0f3d2aaaa5;    	// 0.0416666
	mov.f32 	%f24, %f23;
	mad.f32 %f25, %f21, %f22, %f24;
	mov.f32 	%f26, %f25;
	mov.f32 	%f27, %f26;
	mov.f32 	%f28, %f13;
	mov.f32 	%f29, 0fbf000000;    	// -0.5
	mov.f32 	%f30, %f29;
	mad.f32 %f31, %f27, %f28, %f30;
	mov.f32 	%f32, %f31;
	mov.f32 	%f33, %f32;
	mov.f32 	%f34, %f13;
	mov.f32 	%f35, 0f3f800000;    	// 1
	mov.f32 	%f36, %f35;
	mad.f32 %f37, %f33, %f34, %f36;
	mov.f32 	%f38, %f37;
	.loc	17	9491	0
	mov.f32 	%f39, %f38;
	bra.uni 	$Lt_149_4098;
$Lt_149_4354:
	.loc	17	8936	0
	mov.f32 	%f40, 0fb94ca1f9;    	// -0.000195153
	mov.f32 	%f41, %f40;
	mov.f32 	%f42, %f13;
	mov.f32 	%f43, 0f3c08839e;    	// 0.00833216
	mov.f32 	%f44, %f43;
	mad.f32 %f45, %f41, %f42, %f44;
	mov.f32 	%f46, %f45;
	mov.f32 	%f47, %f46;
	mov.f32 	%f48, %f13;
	mov.f32 	%f49, 0fbe2aaaa3;    	// -0.166667
	mov.f32 	%f50, %f49;
	mad.f32 %f51, %f47, %f48, %f50;
	mov.f32 	%f52, %f51;
	mul.f32 	%f53, %f13, %f52;
	mov.f32 	%f54, %f53;
	mov.f32 	%f55, %f12;
	mov.f32 	%f56, %f12;
	mad.f32 %f57, %f54, %f55, %f56;
	mov.f32 	%f58, %f57;
	.loc	17	9493	0
	mov.f32 	%f39, %f58;
$Lt_149_4098:
	and.b32 	%r21, %r18, 2;
	mov.u32 	%r22, 0;
	setp.eq.s32 	%p3, %r21, %r22;
	@%p3 bra 	$Lt_149_4610;
	.loc	17	8936	0
	mov.f32 	%f59, %f39;
	mov.f32 	%f60, 0fbf800000;    	// -1
	mov.f32 	%f61, %f60;
	mov.f32 	%f62, 0f00000000;    	// 0
	mov.f32 	%f63, %f62;
	mad.f32 %f64, %f59, %f61, %f63;
	mov.f32 	%f65, %f64;
	.loc	17	9496	0
	mov.f32 	%f39, %f65;
$Lt_149_4610:
	.loc	17	9637	0
	mov.f32 	%f66, %f39;
	cvt.rzi.f32.f32 	%f67, %f1;
	setp.eq.f32 	%p4, %f1, %f67;
	@!%p4 bra 	$Lt_149_5122;
	.loc	17	9639	0
	mov.f32 	%f68, 0f00000000;    	// 0
	mul.rn.f32 	%f66, %f1, %f68;
$Lt_149_5122:
	.loc	15	185	0
	ld.param.u64 	%rd5, [__cudaparm_esinpi_mf_B];
	ld.param.s32 	%r23, [__cudaparm_esinpi_mf_ldb];
	mul.lo.s32 	%r24, %r23, %r4;
	add.s32 	%r25, %r6, %r24;
	cvt.s64.s32 	%rd6, %r25;
	mul.wide.s32 	%rd7, %r25, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f66;
$Lt_149_3586:
	exit;
$LDWend_esinpi_mf:
	} // esinpi_mf

	.entry eerfc_vf (
		.param .u64 __cudaparm_eerfc_vf_n,
		.param .u64 __cudaparm_eerfc_vf_x,
		.param .s32 __cudaparm_eerfc_vf_lx,
		.param .u64 __cudaparm_eerfc_vf_result,
		.param .s32 __cudaparm_eerfc_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<15>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<174>;
	.reg .pred %p<7>;
	.loc	15	187	0
$LDWbegin_eerfc_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eerfc_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_150_4098;
	ld.param.u64 	%rd3, [__cudaparm_eerfc_vf_x];
	ld.param.s32 	%r4, [__cudaparm_eerfc_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	mov.f32 	%f2, 0f3f5020c5;     	// 0.813
	setp.le.f32 	%p2, %f1, %f2;
	@!%p2 bra 	$Lt_150_4866;
	.loc	17	10660	0
	abs.f32 	%f3, %f1;
	mov.f32 	%f4, 0f3f800000;     	// 1
	setp.ge.f32 	%p3, %f3, %f4;
	@!%p3 bra 	$Lt_150_5378;
	.loc	17	8936	0
	mov.f32 	%f5, 0fb7b730fb;     	// -2.18381e-05
	mov.f32 	%f6, %f5;
	mov.f32 	%f7, %f3;
	mov.f32 	%f8, 0f3a03bb71;     	// 0.000502518
	mov.f32 	%f9, %f8;
	mad.f32 %f10, %f6, %f7, %f9;
	mov.f32 	%f11, %f10;
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f3;
	mov.f32 	%f14, 0fbbaca3b3;    	// -0.00526854
	mov.f32 	%f15, %f14;
	mad.f32 %f16, %f12, %f13, %f15;
	mov.f32 	%f11, %f16;
	mov.f32 	%f17, %f11;
	mov.f32 	%f18, %f3;
	mov.f32 	%f19, 0f3d0a7445;    	// 0.0338023
	mov.f32 	%f20, %f19;
	mad.f32 %f21, %f17, %f18, %f20;
	mov.f32 	%f11, %f21;
	mov.f32 	%f22, %f11;
	mov.f32 	%f23, %f3;
	mov.f32 	%f24, 0fbe1b3b75;    	// -0.151594
	mov.f32 	%f25, %f24;
	mad.f32 %f26, %f22, %f23, %f25;
	mov.f32 	%f11, %f26;
	mov.f32 	%f27, %f11;
	mov.f32 	%f28, %f3;
	mov.f32 	%f29, 0fbf6b385a;    	// -0.918829
	mov.f32 	%f30, %f29;
	mad.f32 %f31, %f27, %f28, %f30;
	mov.f32 	%f11, %f31;
	mov.f32 	%f32, %f11;
	mov.f32 	%f33, %f3;
	mov.f32 	%f34, 0fbfd0316e;    	// -1.62651
	mov.f32 	%f35, %f34;
	mad.f32 %f36, %f32, %f33, %f35;
	mov.f32 	%f11, %f36;
	mov.f32 	%f37, %f11;
	mov.f32 	%f38, %f3;
	mov.f32 	%f39, 0fba031cce;    	// -0.000500155
	mov.f32 	%f40, %f39;
	mad.f32 %f41, %f37, %f38, %f40;
	mov.f32 	%f11, %f41;
	.loc	17	8965	0
	mov.f32 	%f42, %f11;
	ex2.approx.ftz.f32 %f43,%f42;
	mov.f32 	%f44, %f43;
	.loc	17	10498	0
	mov.f32 	%f45, 0f3f800000;    	// 1
	mov.f32 	%f46, 0f3f800000;    	// 1
	sub.f32 	%f47, %f46, %f44;
	mov.f32 	%f48, 0f407ad445;    	// 3.91921
	setp.ge.f32 	%p4, %f3, %f48;
	selp.f32 	%f49, %f45, %f47, %p4;
	mov.b32 	%r6, %f49;
	mov.b32 	%r7, %f1;
	and.b32 	%r8, %r7, -2147483648;
	or.b32 	%r9, %r6, %r8;
	mov.b32 	%f50, %r9;
	bra.uni 	$Lt_150_5122;
$Lt_150_5378:
	.loc	17	8936	0
	mul.f32 	%f51, %f1, %f1;
	mov.f32 	%f52, 0fba1268fb;    	// -0.00055851
	mov.f32 	%f53, %f52;
	mov.f32 	%f54, %f51;
	mov.f32 	%f55, 0f3ba0c9f8;    	// 0.00490689
	mov.f32 	%f56, %f55;
	mad.f32 %f57, %f53, %f54, %f56;
	mov.f32 	%f11, %f57;
	mov.f32 	%f58, %f11;
	mov.f32 	%f59, %f51;
	mov.f32 	%f60, 0fbcdabfd4;    	// -0.0267028
	mov.f32 	%f61, %f60;
	mad.f32 %f62, %f58, %f59, %f61;
	mov.f32 	%f11, %f62;
	mov.f32 	%f63, %f11;
	mov.f32 	%f64, %f51;
	mov.f32 	%f65, 0f3de70331;    	// 0.112799
	mov.f32 	%f66, %f65;
	mad.f32 %f67, %f63, %f64, %f66;
	mov.f32 	%f11, %f67;
	mov.f32 	%f68, %f11;
	mov.f32 	%f69, %f51;
	mov.f32 	%f70, 0fbec09330;    	// -0.376123
	mov.f32 	%f71, %f70;
	mad.f32 %f72, %f68, %f69, %f71;
	mov.f32 	%f11, %f72;
	mov.f32 	%f73, %f11;
	mov.f32 	%f74, %f51;
	mov.f32 	%f75, 0f3f906eba;    	// 1.12838
	mov.f32 	%f76, %f75;
	mad.f32 %f77, %f73, %f74, %f76;
	mov.f32 	%f11, %f77;
	.loc	17	10507	0
	mul.f32 	%f50, %f1, %f11;
$Lt_150_5122:
	.loc	17	10660	0
	mov.f32 	%f78, 0f3f800000;    	// 1
	sub.f32 	%f79, %f78, %f50;
	bra.uni 	$Lt_150_4610;
$Lt_150_4866:
	.loc	17	8944	0
	mov.f32 	%f80, %f1;
	rcp.approx.ftz.f32 %f81,%f80;
	mov.f32 	%f82, %f81;
	.loc	17	8936	0
	mov.f32 	%f83, 0fbf7fc509;    	// -0.9991
	mov.f32 	%f84, %f83;
	mov.f32 	%f85, %f82;
	mov.f32 	%f86, 0fbe85acdf;    	// -0.261085
	mov.f32 	%f87, %f86;
	mad.f32 %f88, %f84, %f85, %f87;
	mov.f32 	%f89, %f88;
	mov.f32 	%f90, %f89;
	mov.f32 	%f91, %f82;
	mov.f32 	%f92, 0f3dff301b;    	// 0.124603
	mov.f32 	%f93, %f92;
	mad.f32 %f94, %f90, %f91, %f93;
	mov.f32 	%f89, %f94;
	mov.f32 	%f95, %f89;
	mov.f32 	%f96, %f82;
	mov.f32 	%f97, 0f3e079e1d;    	// 0.132439
	mov.f32 	%f98, %f97;
	mad.f32 %f99, %f95, %f96, %f98;
	mov.f32 	%f89, %f99;
	mov.f32 	%f100, %f89;
	mov.f32 	%f101, %f82;
	mov.f32 	%f102, 0f3d091fcf;   	// 0.0334776
	mov.f32 	%f103, %f102;
	mad.f32 %f104, %f100, %f101, %f103;
	mov.f32 	%f105, %f104;
	mov.f32 	%f106, 0f401045e9;   	// 2.25427
	add.f32 	%f107, %f82, %f106;
	mov.f32 	%f108, %f107;
	mov.f32 	%f109, %f82;
	mov.f32 	%f110, 0f4009b13f;   	// 2.15144
	mov.f32 	%f111, %f110;
	mad.f32 %f112, %f108, %f109, %f111;
	mov.f32 	%f89, %f112;
	mov.f32 	%f113, %f89;
	mov.f32 	%f114, %f82;
	mov.f32 	%f115, 0f3f83a2f6;   	// 1.02841
	mov.f32 	%f116, %f115;
	mad.f32 %f117, %f113, %f114, %f116;
	mov.f32 	%f89, %f117;
	mov.f32 	%f118, %f89;
	mov.f32 	%f119, %f82;
	mov.f32 	%f120, 0f3e859a52;   	// 0.260943
	mov.f32 	%f121, %f120;
	mad.f32 %f122, %f118, %f119, %f121;
	mov.f32 	%f89, %f122;
	mov.f32 	%f123, %f89;
	mov.f32 	%f124, %f82;
	mov.f32 	%f125, 0fb6860e0b;   	// -3.99515e-06
	mov.f32 	%f126, %f125;
	mad.f32 %f127, %f123, %f124, %f126;
	mov.f32 	%f89, %f127;
	.loc	17	10638	0
	div.approx.f32 	%f128, %f105, %f89;
	.loc	17	8936	0
	mov.b32 	%r10, %f1;
	and.b32 	%r11, %r10, -4096;
	mov.b32 	%f129, %r11;
	mul.f32 	%f130, %f129, %f129;
	neg.f32 	%f131, %f130;
	mov.f32 	%f132, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f133, %f131, %f132;
	cvt.rzi.f32.f32 	%f134, %f133;
	mov.f32 	%f135, %f134;
	mov.f32 	%f136, 0fbf317200;   	// -0.693146
	mov.f32 	%f137, %f136;
	mov.f32 	%f138, %f131;
	mad.f32 %f139, %f135, %f137, %f138;
	mov.f32 	%f140, %f139;
	mov.f32 	%f141, %f134;
	mov.f32 	%f142, 0fb5bfbe8e;   	// -1.42861e-06
	mov.f32 	%f143, %f142;
	mov.f32 	%f144, %f140;
	mad.f32 %f145, %f141, %f143, %f144;
	mov.f32 	%f146, %f145;
	.loc	17	8965	0
	mov.f32 	%f147, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f148, %f146, %f147;
	mov.f32 	%f149, %f148;
	ex2.approx.ftz.f32 %f150,%f149;
	mov.f32 	%f151, %f150;
	.loc	17	8936	0
	mul.f32 	%f152, %f82, %f128;
	mov.f32 	%f153, %f152;
	mov.f32 	%f154, %f82;
	mov.f32 	%f155, %f82;
	mad.f32 %f156, %f153, %f154, %f155;
	mov.f32 	%f157, %f156;
	.loc	17	10674	0
	ex2.approx.f32 	%f158, %f134;
	mul.f32 	%f159, %f151, %f158;
	add.f32 	%f160, %f129, %f1;
	sub.f32 	%f161, %f1, %f129;
	mul.f32 	%f162, %f160, %f161;
	neg.f32 	%f163, %f162;
	mov.f32 	%f164, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f165, %f163, %f164;
	ex2.approx.f32 	%f166, %f165;
	mov.f32 	%f167, 0f3f000000;   	// 0.5
	mul.f32 	%f168, %f166, %f167;
	mul.f32 	%f169, %f159, %f168;
	mul.f32 	%f170, %f157, %f169;
	.loc	17	10662	0
	mov.f32 	%f171, 0f00000000;   	// 0
	mov.f32 	%f172, 0f4120e148;   	// 10.055
	setp.gt.f32 	%p5, %f1, %f172;
	selp.f32 	%f79, %f171, %f170, %p5;
$Lt_150_4610:
	.loc	15	187	0
	ld.param.u64 	%rd7, [__cudaparm_eerfc_vf_result];
	ld.param.s32 	%r12, [__cudaparm_eerfc_vf_lr];
	mul.lo.s32 	%r13, %r12, %r3;
	cvt.s64.s32 	%rd8, %r13;
	mul.wide.s32 	%rd9, %r13, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f79;
$Lt_150_4098:
	exit;
$LDWend_eerfc_vf:
	} // eerfc_vf

	.entry eerfc_mf (
		.param .s32 __cudaparm_eerfc_mf_rs,
		.param .s32 __cudaparm_eerfc_mf_cs,
		.param .u64 __cudaparm_eerfc_mf_A,
		.param .s32 __cudaparm_eerfc_mf_lda,
		.param .u64 __cudaparm_eerfc_mf_B,
		.param .s32 __cudaparm_eerfc_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<28>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<174>;
	.reg .pred %p<7>;
$LDWbegin_eerfc_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eerfc_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eerfc_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_151_4354;
	ld.param.u64 	%rd1, [__cudaparm_eerfc_mf_A];
	ld.param.s32 	%r15, [__cudaparm_eerfc_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	mov.f32 	%f2, 0f3f5020c5;     	// 0.813
	setp.le.f32 	%p2, %f1, %f2;
	@!%p2 bra 	$Lt_151_5122;
	.loc	17	10660	0
	abs.f32 	%f3, %f1;
	mov.f32 	%f4, 0f3f800000;     	// 1
	setp.ge.f32 	%p3, %f3, %f4;
	@!%p3 bra 	$Lt_151_5634;
	.loc	17	8936	0
	mov.f32 	%f5, 0fb7b730fb;     	// -2.18381e-05
	mov.f32 	%f6, %f5;
	mov.f32 	%f7, %f3;
	mov.f32 	%f8, 0f3a03bb71;     	// 0.000502518
	mov.f32 	%f9, %f8;
	mad.f32 %f10, %f6, %f7, %f9;
	mov.f32 	%f11, %f10;
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f3;
	mov.f32 	%f14, 0fbbaca3b3;    	// -0.00526854
	mov.f32 	%f15, %f14;
	mad.f32 %f16, %f12, %f13, %f15;
	mov.f32 	%f11, %f16;
	mov.f32 	%f17, %f11;
	mov.f32 	%f18, %f3;
	mov.f32 	%f19, 0f3d0a7445;    	// 0.0338023
	mov.f32 	%f20, %f19;
	mad.f32 %f21, %f17, %f18, %f20;
	mov.f32 	%f11, %f21;
	mov.f32 	%f22, %f11;
	mov.f32 	%f23, %f3;
	mov.f32 	%f24, 0fbe1b3b75;    	// -0.151594
	mov.f32 	%f25, %f24;
	mad.f32 %f26, %f22, %f23, %f25;
	mov.f32 	%f11, %f26;
	mov.f32 	%f27, %f11;
	mov.f32 	%f28, %f3;
	mov.f32 	%f29, 0fbf6b385a;    	// -0.918829
	mov.f32 	%f30, %f29;
	mad.f32 %f31, %f27, %f28, %f30;
	mov.f32 	%f11, %f31;
	mov.f32 	%f32, %f11;
	mov.f32 	%f33, %f3;
	mov.f32 	%f34, 0fbfd0316e;    	// -1.62651
	mov.f32 	%f35, %f34;
	mad.f32 %f36, %f32, %f33, %f35;
	mov.f32 	%f11, %f36;
	mov.f32 	%f37, %f11;
	mov.f32 	%f38, %f3;
	mov.f32 	%f39, 0fba031cce;    	// -0.000500155
	mov.f32 	%f40, %f39;
	mad.f32 %f41, %f37, %f38, %f40;
	mov.f32 	%f11, %f41;
	.loc	17	8965	0
	mov.f32 	%f42, %f11;
	ex2.approx.ftz.f32 %f43,%f42;
	mov.f32 	%f44, %f43;
	.loc	17	10498	0
	mov.f32 	%f45, 0f3f800000;    	// 1
	mov.f32 	%f46, 0f3f800000;    	// 1
	sub.f32 	%f47, %f46, %f44;
	mov.f32 	%f48, 0f407ad445;    	// 3.91921
	setp.ge.f32 	%p4, %f3, %f48;
	selp.f32 	%f49, %f45, %f47, %p4;
	mov.b32 	%r18, %f49;
	mov.b32 	%r19, %f1;
	and.b32 	%r20, %r19, -2147483648;
	or.b32 	%r21, %r18, %r20;
	mov.b32 	%f50, %r21;
	bra.uni 	$Lt_151_5378;
$Lt_151_5634:
	.loc	17	8936	0
	mul.f32 	%f51, %f1, %f1;
	mov.f32 	%f52, 0fba1268fb;    	// -0.00055851
	mov.f32 	%f53, %f52;
	mov.f32 	%f54, %f51;
	mov.f32 	%f55, 0f3ba0c9f8;    	// 0.00490689
	mov.f32 	%f56, %f55;
	mad.f32 %f57, %f53, %f54, %f56;
	mov.f32 	%f11, %f57;
	mov.f32 	%f58, %f11;
	mov.f32 	%f59, %f51;
	mov.f32 	%f60, 0fbcdabfd4;    	// -0.0267028
	mov.f32 	%f61, %f60;
	mad.f32 %f62, %f58, %f59, %f61;
	mov.f32 	%f11, %f62;
	mov.f32 	%f63, %f11;
	mov.f32 	%f64, %f51;
	mov.f32 	%f65, 0f3de70331;    	// 0.112799
	mov.f32 	%f66, %f65;
	mad.f32 %f67, %f63, %f64, %f66;
	mov.f32 	%f11, %f67;
	mov.f32 	%f68, %f11;
	mov.f32 	%f69, %f51;
	mov.f32 	%f70, 0fbec09330;    	// -0.376123
	mov.f32 	%f71, %f70;
	mad.f32 %f72, %f68, %f69, %f71;
	mov.f32 	%f11, %f72;
	mov.f32 	%f73, %f11;
	mov.f32 	%f74, %f51;
	mov.f32 	%f75, 0f3f906eba;    	// 1.12838
	mov.f32 	%f76, %f75;
	mad.f32 %f77, %f73, %f74, %f76;
	mov.f32 	%f11, %f77;
	.loc	17	10507	0
	mul.f32 	%f50, %f1, %f11;
$Lt_151_5378:
	.loc	17	10660	0
	mov.f32 	%f78, 0f3f800000;    	// 1
	sub.f32 	%f79, %f78, %f50;
	bra.uni 	$Lt_151_4866;
$Lt_151_5122:
	.loc	17	8944	0
	mov.f32 	%f80, %f1;
	rcp.approx.ftz.f32 %f81,%f80;
	mov.f32 	%f82, %f81;
	.loc	17	8936	0
	mov.f32 	%f83, 0fbf7fc509;    	// -0.9991
	mov.f32 	%f84, %f83;
	mov.f32 	%f85, %f82;
	mov.f32 	%f86, 0fbe85acdf;    	// -0.261085
	mov.f32 	%f87, %f86;
	mad.f32 %f88, %f84, %f85, %f87;
	mov.f32 	%f89, %f88;
	mov.f32 	%f90, %f89;
	mov.f32 	%f91, %f82;
	mov.f32 	%f92, 0f3dff301b;    	// 0.124603
	mov.f32 	%f93, %f92;
	mad.f32 %f94, %f90, %f91, %f93;
	mov.f32 	%f89, %f94;
	mov.f32 	%f95, %f89;
	mov.f32 	%f96, %f82;
	mov.f32 	%f97, 0f3e079e1d;    	// 0.132439
	mov.f32 	%f98, %f97;
	mad.f32 %f99, %f95, %f96, %f98;
	mov.f32 	%f89, %f99;
	mov.f32 	%f100, %f89;
	mov.f32 	%f101, %f82;
	mov.f32 	%f102, 0f3d091fcf;   	// 0.0334776
	mov.f32 	%f103, %f102;
	mad.f32 %f104, %f100, %f101, %f103;
	mov.f32 	%f105, %f104;
	mov.f32 	%f106, 0f401045e9;   	// 2.25427
	add.f32 	%f107, %f82, %f106;
	mov.f32 	%f108, %f107;
	mov.f32 	%f109, %f82;
	mov.f32 	%f110, 0f4009b13f;   	// 2.15144
	mov.f32 	%f111, %f110;
	mad.f32 %f112, %f108, %f109, %f111;
	mov.f32 	%f89, %f112;
	mov.f32 	%f113, %f89;
	mov.f32 	%f114, %f82;
	mov.f32 	%f115, 0f3f83a2f6;   	// 1.02841
	mov.f32 	%f116, %f115;
	mad.f32 %f117, %f113, %f114, %f116;
	mov.f32 	%f89, %f117;
	mov.f32 	%f118, %f89;
	mov.f32 	%f119, %f82;
	mov.f32 	%f120, 0f3e859a52;   	// 0.260943
	mov.f32 	%f121, %f120;
	mad.f32 %f122, %f118, %f119, %f121;
	mov.f32 	%f89, %f122;
	mov.f32 	%f123, %f89;
	mov.f32 	%f124, %f82;
	mov.f32 	%f125, 0fb6860e0b;   	// -3.99515e-06
	mov.f32 	%f126, %f125;
	mad.f32 %f127, %f123, %f124, %f126;
	mov.f32 	%f89, %f127;
	.loc	17	10638	0
	div.approx.f32 	%f128, %f105, %f89;
	.loc	17	8936	0
	mov.b32 	%r22, %f1;
	and.b32 	%r23, %r22, -4096;
	mov.b32 	%f129, %r23;
	mul.f32 	%f130, %f129, %f129;
	neg.f32 	%f131, %f130;
	mov.f32 	%f132, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f133, %f131, %f132;
	cvt.rzi.f32.f32 	%f134, %f133;
	mov.f32 	%f135, %f134;
	mov.f32 	%f136, 0fbf317200;   	// -0.693146
	mov.f32 	%f137, %f136;
	mov.f32 	%f138, %f131;
	mad.f32 %f139, %f135, %f137, %f138;
	mov.f32 	%f140, %f139;
	mov.f32 	%f141, %f134;
	mov.f32 	%f142, 0fb5bfbe8e;   	// -1.42861e-06
	mov.f32 	%f143, %f142;
	mov.f32 	%f144, %f140;
	mad.f32 %f145, %f141, %f143, %f144;
	mov.f32 	%f146, %f145;
	.loc	17	8965	0
	mov.f32 	%f147, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f148, %f146, %f147;
	mov.f32 	%f149, %f148;
	ex2.approx.ftz.f32 %f150,%f149;
	mov.f32 	%f151, %f150;
	.loc	17	8936	0
	mul.f32 	%f152, %f82, %f128;
	mov.f32 	%f153, %f152;
	mov.f32 	%f154, %f82;
	mov.f32 	%f155, %f82;
	mad.f32 %f156, %f153, %f154, %f155;
	mov.f32 	%f157, %f156;
	.loc	17	10674	0
	ex2.approx.f32 	%f158, %f134;
	mul.f32 	%f159, %f151, %f158;
	add.f32 	%f160, %f129, %f1;
	sub.f32 	%f161, %f1, %f129;
	mul.f32 	%f162, %f160, %f161;
	neg.f32 	%f163, %f162;
	mov.f32 	%f164, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f165, %f163, %f164;
	ex2.approx.f32 	%f166, %f165;
	mov.f32 	%f167, 0f3f000000;   	// 0.5
	mul.f32 	%f168, %f166, %f167;
	mul.f32 	%f169, %f159, %f168;
	mul.f32 	%f170, %f157, %f169;
	.loc	17	10662	0
	mov.f32 	%f171, 0f00000000;   	// 0
	mov.f32 	%f172, 0f4120e148;   	// 10.055
	setp.gt.f32 	%p5, %f1, %f172;
	selp.f32 	%f79, %f171, %f170, %p5;
$Lt_151_4866:
	.loc	15	187	0
	ld.param.u64 	%rd5, [__cudaparm_eerfc_mf_B];
	ld.param.s32 	%r24, [__cudaparm_eerfc_mf_ldb];
	mul.lo.s32 	%r25, %r24, %r4;
	add.s32 	%r26, %r6, %r25;
	cvt.s64.s32 	%rd6, %r26;
	mul.wide.s32 	%rd7, %r26, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f79;
$Lt_151_4354:
	exit;
$LDWend_eerfc_mf:
	} // eerfc_mf

	.entry eerfcinv_vf (
		.param .u64 __cudaparm_eerfcinv_vf_n,
		.param .u64 __cudaparm_eerfcinv_vf_x,
		.param .s32 __cudaparm_eerfcinv_vf_lx,
		.param .u64 __cudaparm_eerfcinv_vf_result,
		.param .s32 __cudaparm_eerfcinv_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<15>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<119>;
	.reg .pred %p<5>;
	.loc	15	188	0
$LDWbegin_eerfcinv_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eerfcinv_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_152_3586;
	ld.param.u64 	%rd3, [__cudaparm_eerfcinv_vf_x];
	ld.param.s32 	%r4, [__cudaparm_eerfcinv_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	neg.f32 	%f2, %f1;
	mov.f32 	%f3, 0f3b5ed289;     	// 0.0034
	set.ge.u32.f32 	%r6, %f1, %f3;
	neg.s32 	%r7, %r6;
	mov.f32 	%f4, 0f3fff9097;     	// 1.9966
	set.le.u32.f32 	%r8, %f1, %f4;
	neg.s32 	%r9, %r8;
	and.b32 	%r10, %r7, %r9;
	mov.u32 	%r11, 0;
	setp.eq.s32 	%p2, %r10, %r11;
	@%p2 bra 	$Lt_152_4354;
	.loc	17	8958	0
	mov.f32 	%f5, 0f40000000;     	// 2
	add.rn.f32 	%f6, %f5, %f2;
	mul.rn.f32 	%f7, %f6, %f1;
	mov.f32 	%f8, %f7;
	lg2.approx.ftz.f32 %f9,%f8;
	mov.f32 	%f10, %f9;
	.loc	17	8936	0
	neg.f32 	%f11, %f10;
	mov.f32 	%f12, 0faf8a6370;    	// -2.51727e-10
	mov.f32 	%f13, %f12;
	mov.f32 	%f14, %f11;
	mov.f32 	%f15, 0f3221f645;    	// 9.42743e-09
	mov.f32 	%f16, %f15;
	mad.f32 %f17, %f13, %f14, %f16;
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f18;
	mov.f32 	%f20, %f11;
	mov.f32 	%f21, 0fb4016fda;    	// -1.20548e-07
	mov.f32 	%f22, %f21;
	mad.f32 %f23, %f19, %f20, %f22;
	mov.f32 	%f18, %f23;
	mov.f32 	%f24, %f18;
	mov.f32 	%f25, %f11;
	mov.f32 	%f26, 0f3468f846;    	// 2.1697e-07
	mov.f32 	%f27, %f26;
	mad.f32 %f28, %f24, %f25, %f27;
	mov.f32 	%f18, %f28;
	mov.f32 	%f29, %f18;
	mov.f32 	%f30, %f11;
	mov.f32 	%f31, 0f370742aa;    	// 8.06215e-06
	mov.f32 	%f32, %f31;
	mad.f32 %f33, %f29, %f30, %f32;
	mov.f32 	%f18, %f33;
	mov.f32 	%f34, %f18;
	mov.f32 	%f35, %f11;
	mov.f32 	%f36, 0fb804db4d;    	// -3.16755e-05
	mov.f32 	%f37, %f36;
	mad.f32 %f38, %f34, %f35, %f37;
	mov.f32 	%f18, %f38;
	mov.f32 	%f39, %f18;
	mov.f32 	%f40, %f11;
	mov.f32 	%f41, 0fba4afea1;    	// -0.000774363
	mov.f32 	%f42, %f41;
	mad.f32 %f43, %f39, %f40, %f42;
	mov.f32 	%f18, %f43;
	mov.f32 	%f44, %f18;
	mov.f32 	%f45, %f11;
	mov.f32 	%f46, 0f3bb5c027;    	// 0.00554659
	mov.f32 	%f47, %f46;
	mad.f32 %f48, %f44, %f45, %f47;
	mov.f32 	%f18, %f48;
	mov.f32 	%f49, %f18;
	mov.f32 	%f50, %f11;
	mov.f32 	%f51, 0f3e24ae0f;    	// 0.16082
	mov.f32 	%f52, %f51;
	mad.f32 %f53, %f49, %f50, %f52;
	mov.f32 	%f18, %f53;
	mov.f32 	%f54, %f18;
	mov.f32 	%f55, %f11;
	mov.f32 	%f56, 0f3f62dfc4;    	// 0.886227
	mov.f32 	%f57, %f56;
	mad.f32 %f58, %f54, %f55, %f57;
	mov.f32 	%f18, %f58;
	.loc	17	10773	0
	mov.f32 	%f59, 0f3f800000;    	// 1
	add.rn.f32 	%f60, %f59, %f2;
	mul.rn.f32 	%f61, %f60, %f18;
	bra.uni 	$Lt_152_4098;
$Lt_152_4354:
	.loc	17	8951	0
	mov.f32 	%f62, 0f3f800000;    	// 1
	setp.gt.f32 	%p3, %f1, %f62;
	mov.f32 	%f63, 0f40000000;    	// 2
	add.rn.f32 	%f64, %f63, %f2;
	selp.f32 	%f65, %f64, %f1, %p3;
	lg2.approx.f32 	%f66, %f65;
	neg.f32 	%f67, %f66;
	mov.f32 	%f68, %f67;
	rsqrt.approx.ftz.f32 %f69,%f68;
	mov.f32 	%f70, %f69;
	.loc	17	8936	0
	mov.f32 	%f71, 0fc27c73f1;    	// -63.1132
	mov.f32 	%f72, %f71;
	mov.f32 	%f73, %f70;
	mov.f32 	%f74, 0f42fef829;    	// 127.485
	mov.f32 	%f75, %f74;
	mad.f32 %f76, %f72, %f73, %f75;
	mov.f32 	%f77, %f76;
	mov.f32 	%f78, %f77;
	mov.f32 	%f79, %f70;
	mov.f32 	%f80, 0fc2e4361c;    	// -114.106
	mov.f32 	%f81, %f80;
	mad.f32 %f82, %f78, %f79, %f81;
	mov.f32 	%f77, %f82;
	mov.f32 	%f83, %f77;
	mov.f32 	%f84, %f70;
	mov.f32 	%f85, 0f42714d9b;    	// 60.3258
	mov.f32 	%f86, %f85;
	mad.f32 %f87, %f83, %f84, %f86;
	mov.f32 	%f77, %f87;
	mov.f32 	%f88, %f77;
	mov.f32 	%f89, %f70;
	mov.f32 	%f90, 0fc1ae51b3;    	// -21.7899
	mov.f32 	%f91, %f90;
	mad.f32 %f92, %f88, %f89, %f91;
	mov.f32 	%f77, %f92;
	mov.f32 	%f93, %f77;
	mov.f32 	%f94, %f70;
	mov.f32 	%f95, 0f40cef504;    	// 6.46741
	mov.f32 	%f96, %f95;
	mad.f32 %f97, %f93, %f94, %f96;
	mov.f32 	%f77, %f97;
	mov.f32 	%f98, %f77;
	mov.f32 	%f99, %f70;
	mov.f32 	%f100, 0fbfea9e05;   	// -1.83295
	mov.f32 	%f101, %f100;
	mad.f32 %f102, %f98, %f99, %f101;
	mov.f32 	%f77, %f102;
	mov.f32 	%f103, %f77;
	mov.f32 	%f104, %f70;
	mov.f32 	%f105, 0fbcf871f4;   	// -0.0303278
	mov.f32 	%f106, %f105;
	mad.f32 %f107, %f103, %f104, %f106;
	mov.f32 	%f77, %f107;
	mov.f32 	%f108, %f77;
	mov.f32 	%f109, %f70;
	mov.f32 	%f110, 0f3f553775;   	// 0.832877
	mov.f32 	%f111, %f110;
	mad.f32 %f112, %f108, %f109, %f111;
	mov.f32 	%f77, %f112;
	.loc	17	8944	0
	mov.f32 	%f113, %f70;
	rcp.approx.ftz.f32 %f114,%f113;
	mov.f32 	%f115, %f114;
	.loc	17	10778	0
	mul.rn.f32 	%f116, %f77, %f115;
	neg.f32 	%f117, %f116;
	selp.f32 	%f61, %f117, %f116, %p3;
$Lt_152_4098:
	.loc	15	188	0
	ld.param.u64 	%rd7, [__cudaparm_eerfcinv_vf_result];
	ld.param.s32 	%r12, [__cudaparm_eerfcinv_vf_lr];
	mul.lo.s32 	%r13, %r12, %r3;
	cvt.s64.s32 	%rd8, %r13;
	mul.wide.s32 	%rd9, %r13, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f61;
$Lt_152_3586:
	exit;
$LDWend_eerfcinv_vf:
	} // eerfcinv_vf

	.entry eerfcinv_mf (
		.param .s32 __cudaparm_eerfcinv_mf_rs,
		.param .s32 __cudaparm_eerfcinv_mf_cs,
		.param .u64 __cudaparm_eerfcinv_mf_A,
		.param .s32 __cudaparm_eerfcinv_mf_lda,
		.param .u64 __cudaparm_eerfcinv_mf_B,
		.param .s32 __cudaparm_eerfcinv_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<28>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<119>;
	.reg .pred %p<5>;
$LDWbegin_eerfcinv_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eerfcinv_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eerfcinv_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_153_3842;
	ld.param.u64 	%rd1, [__cudaparm_eerfcinv_mf_A];
	ld.param.s32 	%r15, [__cudaparm_eerfcinv_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	neg.f32 	%f2, %f1;
	mov.f32 	%f3, 0f3b5ed289;     	// 0.0034
	set.ge.u32.f32 	%r18, %f1, %f3;
	neg.s32 	%r19, %r18;
	mov.f32 	%f4, 0f3fff9097;     	// 1.9966
	set.le.u32.f32 	%r20, %f1, %f4;
	neg.s32 	%r21, %r20;
	and.b32 	%r22, %r19, %r21;
	mov.u32 	%r23, 0;
	setp.eq.s32 	%p2, %r22, %r23;
	@%p2 bra 	$Lt_153_4610;
	.loc	17	8958	0
	mov.f32 	%f5, 0f40000000;     	// 2
	add.rn.f32 	%f6, %f5, %f2;
	mul.rn.f32 	%f7, %f6, %f1;
	mov.f32 	%f8, %f7;
	lg2.approx.ftz.f32 %f9,%f8;
	mov.f32 	%f10, %f9;
	.loc	17	8936	0
	neg.f32 	%f11, %f10;
	mov.f32 	%f12, 0faf8a6370;    	// -2.51727e-10
	mov.f32 	%f13, %f12;
	mov.f32 	%f14, %f11;
	mov.f32 	%f15, 0f3221f645;    	// 9.42743e-09
	mov.f32 	%f16, %f15;
	mad.f32 %f17, %f13, %f14, %f16;
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f18;
	mov.f32 	%f20, %f11;
	mov.f32 	%f21, 0fb4016fda;    	// -1.20548e-07
	mov.f32 	%f22, %f21;
	mad.f32 %f23, %f19, %f20, %f22;
	mov.f32 	%f18, %f23;
	mov.f32 	%f24, %f18;
	mov.f32 	%f25, %f11;
	mov.f32 	%f26, 0f3468f846;    	// 2.1697e-07
	mov.f32 	%f27, %f26;
	mad.f32 %f28, %f24, %f25, %f27;
	mov.f32 	%f18, %f28;
	mov.f32 	%f29, %f18;
	mov.f32 	%f30, %f11;
	mov.f32 	%f31, 0f370742aa;    	// 8.06215e-06
	mov.f32 	%f32, %f31;
	mad.f32 %f33, %f29, %f30, %f32;
	mov.f32 	%f18, %f33;
	mov.f32 	%f34, %f18;
	mov.f32 	%f35, %f11;
	mov.f32 	%f36, 0fb804db4d;    	// -3.16755e-05
	mov.f32 	%f37, %f36;
	mad.f32 %f38, %f34, %f35, %f37;
	mov.f32 	%f18, %f38;
	mov.f32 	%f39, %f18;
	mov.f32 	%f40, %f11;
	mov.f32 	%f41, 0fba4afea1;    	// -0.000774363
	mov.f32 	%f42, %f41;
	mad.f32 %f43, %f39, %f40, %f42;
	mov.f32 	%f18, %f43;
	mov.f32 	%f44, %f18;
	mov.f32 	%f45, %f11;
	mov.f32 	%f46, 0f3bb5c027;    	// 0.00554659
	mov.f32 	%f47, %f46;
	mad.f32 %f48, %f44, %f45, %f47;
	mov.f32 	%f18, %f48;
	mov.f32 	%f49, %f18;
	mov.f32 	%f50, %f11;
	mov.f32 	%f51, 0f3e24ae0f;    	// 0.16082
	mov.f32 	%f52, %f51;
	mad.f32 %f53, %f49, %f50, %f52;
	mov.f32 	%f18, %f53;
	mov.f32 	%f54, %f18;
	mov.f32 	%f55, %f11;
	mov.f32 	%f56, 0f3f62dfc4;    	// 0.886227
	mov.f32 	%f57, %f56;
	mad.f32 %f58, %f54, %f55, %f57;
	mov.f32 	%f18, %f58;
	.loc	17	10773	0
	mov.f32 	%f59, 0f3f800000;    	// 1
	add.rn.f32 	%f60, %f59, %f2;
	mul.rn.f32 	%f61, %f60, %f18;
	bra.uni 	$Lt_153_4354;
$Lt_153_4610:
	.loc	17	8951	0
	mov.f32 	%f62, 0f3f800000;    	// 1
	setp.gt.f32 	%p3, %f1, %f62;
	mov.f32 	%f63, 0f40000000;    	// 2
	add.rn.f32 	%f64, %f63, %f2;
	selp.f32 	%f65, %f64, %f1, %p3;
	lg2.approx.f32 	%f66, %f65;
	neg.f32 	%f67, %f66;
	mov.f32 	%f68, %f67;
	rsqrt.approx.ftz.f32 %f69,%f68;
	mov.f32 	%f70, %f69;
	.loc	17	8936	0
	mov.f32 	%f71, 0fc27c73f1;    	// -63.1132
	mov.f32 	%f72, %f71;
	mov.f32 	%f73, %f70;
	mov.f32 	%f74, 0f42fef829;    	// 127.485
	mov.f32 	%f75, %f74;
	mad.f32 %f76, %f72, %f73, %f75;
	mov.f32 	%f77, %f76;
	mov.f32 	%f78, %f77;
	mov.f32 	%f79, %f70;
	mov.f32 	%f80, 0fc2e4361c;    	// -114.106
	mov.f32 	%f81, %f80;
	mad.f32 %f82, %f78, %f79, %f81;
	mov.f32 	%f77, %f82;
	mov.f32 	%f83, %f77;
	mov.f32 	%f84, %f70;
	mov.f32 	%f85, 0f42714d9b;    	// 60.3258
	mov.f32 	%f86, %f85;
	mad.f32 %f87, %f83, %f84, %f86;
	mov.f32 	%f77, %f87;
	mov.f32 	%f88, %f77;
	mov.f32 	%f89, %f70;
	mov.f32 	%f90, 0fc1ae51b3;    	// -21.7899
	mov.f32 	%f91, %f90;
	mad.f32 %f92, %f88, %f89, %f91;
	mov.f32 	%f77, %f92;
	mov.f32 	%f93, %f77;
	mov.f32 	%f94, %f70;
	mov.f32 	%f95, 0f40cef504;    	// 6.46741
	mov.f32 	%f96, %f95;
	mad.f32 %f97, %f93, %f94, %f96;
	mov.f32 	%f77, %f97;
	mov.f32 	%f98, %f77;
	mov.f32 	%f99, %f70;
	mov.f32 	%f100, 0fbfea9e05;   	// -1.83295
	mov.f32 	%f101, %f100;
	mad.f32 %f102, %f98, %f99, %f101;
	mov.f32 	%f77, %f102;
	mov.f32 	%f103, %f77;
	mov.f32 	%f104, %f70;
	mov.f32 	%f105, 0fbcf871f4;   	// -0.0303278
	mov.f32 	%f106, %f105;
	mad.f32 %f107, %f103, %f104, %f106;
	mov.f32 	%f77, %f107;
	mov.f32 	%f108, %f77;
	mov.f32 	%f109, %f70;
	mov.f32 	%f110, 0f3f553775;   	// 0.832877
	mov.f32 	%f111, %f110;
	mad.f32 %f112, %f108, %f109, %f111;
	mov.f32 	%f77, %f112;
	.loc	17	8944	0
	mov.f32 	%f113, %f70;
	rcp.approx.ftz.f32 %f114,%f113;
	mov.f32 	%f115, %f114;
	.loc	17	10778	0
	mul.rn.f32 	%f116, %f77, %f115;
	neg.f32 	%f117, %f116;
	selp.f32 	%f61, %f117, %f116, %p3;
$Lt_153_4354:
	.loc	15	188	0
	ld.param.u64 	%rd5, [__cudaparm_eerfcinv_mf_B];
	ld.param.s32 	%r24, [__cudaparm_eerfcinv_mf_ldb];
	mul.lo.s32 	%r25, %r24, %r4;
	add.s32 	%r26, %r6, %r25;
	cvt.s64.s32 	%rd6, %r26;
	mul.wide.s32 	%rd7, %r26, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f61;
$Lt_153_3842:
	exit;
$LDWend_eerfcinv_mf:
	} // eerfcinv_mf

	.entry eerfcx_vf (
		.param .u64 __cudaparm_eerfcx_vf_n,
		.param .u64 __cudaparm_eerfcx_vf_x,
		.param .s32 __cudaparm_eerfcx_vf_lx,
		.param .u64 __cudaparm_eerfcx_vf_result,
		.param .s32 __cudaparm_eerfcx_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<11>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<173>;
	.reg .pred %p<9>;
	.loc	15	189	0
$LDWbegin_eerfcx_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eerfcx_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_154_5634;
	ld.param.u64 	%rd3, [__cudaparm_eerfcx_vf_x];
	ld.param.s32 	%r4, [__cudaparm_eerfcx_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f4120e148;     	// 10.055
	setp.lt.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_154_6402;
	mov.f32 	%f4, 0f3f5020c5;     	// 0.813
	setp.le.f32 	%p3, %f2, %f4;
	@!%p3 bra 	$Lt_154_6914;
	.loc	17	8936	0
	mov.f32 	%f5, 0f3c2d0a8f;     	// 0.0105616
	mov.f32 	%f6, %f5;
	mov.f32 	%f7, %f2;
	mov.f32 	%f8, 0fbd606a09;     	// -0.0547886
	mov.f32 	%f9, %f8;
	mad.f32 %f10, %f6, %f7, %f9;
	mov.f32 	%f11, %f10;
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f2;
	mov.f32 	%f14, 0f3e176f6c;    	// 0.147886
	mov.f32 	%f15, %f14;
	mad.f32 %f16, %f12, %f13, %f15;
	mov.f32 	%f11, %f16;
	mov.f32 	%f17, %f11;
	mov.f32 	%f18, %f2;
	mov.f32 	%f19, 0fbe96a3e8;    	// -0.294219
	mov.f32 	%f20, %f19;
	mad.f32 %f21, %f17, %f18, %f20;
	mov.f32 	%f11, %f21;
	mov.f32 	%f22, %f11;
	mov.f32 	%f23, %f2;
	mov.f32 	%f24, 0f3eff50b0;    	// 0.498662
	mov.f32 	%f25, %f24;
	mad.f32 %f26, %f22, %f23, %f25;
	mov.f32 	%f11, %f26;
	mov.f32 	%f27, %f11;
	mov.f32 	%f28, %f2;
	mov.f32 	%f29, 0fbf408ad0;    	// -0.752118
	mov.f32 	%f30, %f29;
	mad.f32 %f31, %f27, %f28, %f30;
	mov.f32 	%f11, %f31;
	mov.f32 	%f32, %f11;
	mov.f32 	%f33, %f2;
	mov.f32 	%f34, 0f3f7fffa8;    	// 0.999995
	mov.f32 	%f35, %f34;
	mad.f32 %f36, %f32, %f33, %f35;
	mov.f32 	%f11, %f36;
	mov.f32 	%f37, %f11;
	mov.f32 	%f38, %f2;
	mov.f32 	%f39, 0fbf906eba;    	// -1.12838
	mov.f32 	%f40, %f39;
	mad.f32 %f41, %f37, %f38, %f40;
	mov.f32 	%f11, %f41;
	mov.f32 	%f42, %f11;
	mov.f32 	%f43, %f2;
	mov.f32 	%f44, 0f3f800000;    	// 1
	mov.f32 	%f45, %f44;
	mad.f32 %f46, %f42, %f43, %f45;
	mov.f32 	%f11, %f46;
	.loc	17	10726	0
	mov.f32 	%f47, %f11;
	bra.uni 	$Lt_154_6146;
$Lt_154_6914:
	.loc	17	8944	0
	mov.f32 	%f48, %f2;
	rcp.approx.ftz.f32 %f49,%f48;
	mov.f32 	%f50, %f49;
	.loc	17	8936	0
	mov.f32 	%f51, 0fbf7fc509;    	// -0.9991
	mov.f32 	%f52, %f51;
	mov.f32 	%f53, %f50;
	mov.f32 	%f54, 0fbe85acdf;    	// -0.261085
	mov.f32 	%f55, %f54;
	mad.f32 %f56, %f52, %f53, %f55;
	mov.f32 	%f57, %f56;
	mov.f32 	%f58, %f57;
	mov.f32 	%f59, %f50;
	mov.f32 	%f60, 0f3dff301b;    	// 0.124603
	mov.f32 	%f61, %f60;
	mad.f32 %f62, %f58, %f59, %f61;
	mov.f32 	%f57, %f62;
	mov.f32 	%f63, %f57;
	mov.f32 	%f64, %f50;
	mov.f32 	%f65, 0f3e079e1d;    	// 0.132439
	mov.f32 	%f66, %f65;
	mad.f32 %f67, %f63, %f64, %f66;
	mov.f32 	%f57, %f67;
	mov.f32 	%f68, %f57;
	mov.f32 	%f69, %f50;
	mov.f32 	%f70, 0f3d091fcf;    	// 0.0334776
	mov.f32 	%f71, %f70;
	mad.f32 %f72, %f68, %f69, %f71;
	mov.f32 	%f73, %f72;
	mov.f32 	%f74, 0f401045e9;    	// 2.25427
	add.f32 	%f75, %f50, %f74;
	mov.f32 	%f76, %f75;
	mov.f32 	%f77, %f50;
	mov.f32 	%f78, 0f4009b13f;    	// 2.15144
	mov.f32 	%f79, %f78;
	mad.f32 %f80, %f76, %f77, %f79;
	mov.f32 	%f57, %f80;
	mov.f32 	%f81, %f57;
	mov.f32 	%f82, %f50;
	mov.f32 	%f83, 0f3f83a2f6;    	// 1.02841
	mov.f32 	%f84, %f83;
	mad.f32 %f85, %f81, %f82, %f84;
	mov.f32 	%f57, %f85;
	mov.f32 	%f86, %f57;
	mov.f32 	%f87, %f50;
	mov.f32 	%f88, 0f3e859a52;    	// 0.260943
	mov.f32 	%f89, %f88;
	mad.f32 %f90, %f86, %f87, %f89;
	mov.f32 	%f57, %f90;
	mov.f32 	%f91, %f57;
	mov.f32 	%f92, %f50;
	mov.f32 	%f93, 0fb6860e0b;    	// -3.99515e-06
	mov.f32 	%f94, %f93;
	mad.f32 %f95, %f91, %f92, %f94;
	mov.f32 	%f57, %f95;
	.loc	17	10638	0
	div.approx.f32 	%f96, %f73, %f57;
	.loc	17	8936	0
	mov.f32 	%f97, %f96;
	mov.f32 	%f98, %f50;
	mov.f32 	%f99, 0f3f800000;    	// 1
	mov.f32 	%f100, %f99;
	mad.f32 %f101, %f97, %f98, %f100;
	mov.f32 	%f11, %f101;
	.loc	17	10731	0
	mul.f32 	%f102, %f11, %f50;
	mov.f32 	%f103, 0f3f000000;   	// 0.5
	mul.f32 	%f47, %f102, %f103;
	bra.uni 	$Lt_154_6146;
$Lt_154_6402:
	.loc	17	8944	0
	mov.f32 	%f104, %f2;
	rcp.approx.ftz.f32 %f105,%f104;
	mov.f32 	%f106, %f105;
	.loc	17	8936	0
	mul.f32 	%f107, %f106, %f106;
	mov.f32 	%f108, 0f40d20000;   	// 6.5625
	mov.f32 	%f109, %f108;
	mov.f32 	%f110, %f107;
	mov.f32 	%f111, 0fbff00000;   	// -1.875
	mov.f32 	%f112, %f111;
	mad.f32 %f113, %f109, %f110, %f112;
	mov.f32 	%f11, %f113;
	mov.f32 	%f114, %f11;
	mov.f32 	%f115, %f107;
	mov.f32 	%f116, 0f3f400000;   	// 0.75
	mov.f32 	%f117, %f116;
	mad.f32 %f118, %f114, %f115, %f117;
	mov.f32 	%f11, %f118;
	mov.f32 	%f119, %f11;
	mov.f32 	%f120, %f107;
	mov.f32 	%f121, 0fbf000000;   	// -0.5
	mov.f32 	%f122, %f121;
	mad.f32 %f123, %f119, %f120, %f122;
	mov.f32 	%f11, %f123;
	mov.f32 	%f124, %f11;
	mov.f32 	%f125, %f107;
	mov.f32 	%f126, 0f3f800000;   	// 1
	mov.f32 	%f127, %f126;
	mad.f32 %f128, %f124, %f125, %f127;
	mov.f32 	%f11, %f128;
	.loc	17	10743	0
	mov.f32 	%f129, 0f3f106ebb;   	// 0.56419
	mul.f32 	%f130, %f106, %f129;
	mul.f32 	%f47, %f11, %f130;
$Lt_154_6146:
	mov.f32 	%f131, 0f00000000;   	// 0
	setp.le.f32 	%p4, %f1, %f131;
	@!%p4 bra 	$Lt_154_7170;
	.loc	17	8936	0
	mov.b32 	%r6, %f2;
	and.b32 	%r7, %r6, -4096;
	mov.b32 	%f132, %r7;
	mul.f32 	%f133, %f132, %f132;
	mov.f32 	%f134, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f135, %f133, %f134;
	cvt.rzi.f32.f32 	%f136, %f135;
	mov.f32 	%f137, %f136;
	mov.f32 	%f138, 0fbf317200;   	// -0.693146
	mov.f32 	%f139, %f138;
	mov.f32 	%f140, %f133;
	mad.f32 %f141, %f137, %f139, %f140;
	mov.f32 	%f142, %f141;
	mov.f32 	%f143, %f136;
	mov.f32 	%f144, 0fb5bfbe8e;   	// -1.42861e-06
	mov.f32 	%f145, %f144;
	mov.f32 	%f146, %f142;
	mad.f32 %f147, %f143, %f145, %f146;
	mov.f32 	%f148, %f147;
	.loc	17	8965	0
	mov.f32 	%f149, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f150, %f148, %f149;
	mov.f32 	%f151, %f150;
	ex2.approx.ftz.f32 %f152,%f151;
	mov.f32 	%f153, %f152;
	.loc	17	9336	0
	mov.f32 	%f154, 0f7f800000;   	// ((1.0F)/(0.0F))
	mov.f32 	%f155, 0f00000000;   	// 0
	ex2.approx.f32 	%f156, %f136;
	mul.f32 	%f157, %f153, %f156;
	mov.f32 	%f158, 0fc2d20000;   	// -105
	setp.lt.f32 	%p5, %f133, %f158;
	selp.f32 	%f159, %f155, %f157, %p5;
	mov.f32 	%f160, 0f42d20000;   	// 105
	setp.gt.f32 	%p6, %f133, %f160;
	selp.f32 	%f161, %f154, %f159, %p6;
	.loc	17	10755	0
	add.f32 	%f162, %f2, %f132;
	sub.f32 	%f163, %f2, %f132;
	mul.f32 	%f164, %f162, %f163;
	mov.f32 	%f165, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f166, %f164, %f165;
	ex2.approx.f32 	%f167, %f166;
	mul.rn.f32 	%f168, %f161, %f167;
	add.f32 	%f169, %f168, %f168;
	.loc	17	10756	0
	sub.f32 	%f170, %f169, %f47;
	.loc	17	9337	0
	mov.f32 	%f171, 0f7f800000;   	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p7, %f161, %f171;
	selp.f32 	%f47, %f161, %f170, %p7;
$Lt_154_7170:
	.loc	15	189	0
	ld.param.u64 	%rd7, [__cudaparm_eerfcx_vf_result];
	ld.param.s32 	%r8, [__cudaparm_eerfcx_vf_lr];
	mul.lo.s32 	%r9, %r8, %r3;
	cvt.s64.s32 	%rd8, %r9;
	mul.wide.s32 	%rd9, %r9, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f47;
$Lt_154_5634:
	exit;
$LDWend_eerfcx_vf:
	} // eerfcx_vf

	.entry eerfcx_mf (
		.param .s32 __cudaparm_eerfcx_mf_rs,
		.param .s32 __cudaparm_eerfcx_mf_cs,
		.param .u64 __cudaparm_eerfcx_mf_A,
		.param .s32 __cudaparm_eerfcx_mf_lda,
		.param .u64 __cudaparm_eerfcx_mf_B,
		.param .s32 __cudaparm_eerfcx_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<173>;
	.reg .pred %p<9>;
$LDWbegin_eerfcx_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eerfcx_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eerfcx_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_155_5890;
	ld.param.u64 	%rd1, [__cudaparm_eerfcx_mf_A];
	ld.param.s32 	%r15, [__cudaparm_eerfcx_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f4120e148;     	// 10.055
	setp.lt.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_155_6658;
	mov.f32 	%f4, 0f3f5020c5;     	// 0.813
	setp.le.f32 	%p3, %f2, %f4;
	@!%p3 bra 	$Lt_155_7170;
	.loc	17	8936	0
	mov.f32 	%f5, 0f3c2d0a8f;     	// 0.0105616
	mov.f32 	%f6, %f5;
	mov.f32 	%f7, %f2;
	mov.f32 	%f8, 0fbd606a09;     	// -0.0547886
	mov.f32 	%f9, %f8;
	mad.f32 %f10, %f6, %f7, %f9;
	mov.f32 	%f11, %f10;
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f2;
	mov.f32 	%f14, 0f3e176f6c;    	// 0.147886
	mov.f32 	%f15, %f14;
	mad.f32 %f16, %f12, %f13, %f15;
	mov.f32 	%f11, %f16;
	mov.f32 	%f17, %f11;
	mov.f32 	%f18, %f2;
	mov.f32 	%f19, 0fbe96a3e8;    	// -0.294219
	mov.f32 	%f20, %f19;
	mad.f32 %f21, %f17, %f18, %f20;
	mov.f32 	%f11, %f21;
	mov.f32 	%f22, %f11;
	mov.f32 	%f23, %f2;
	mov.f32 	%f24, 0f3eff50b0;    	// 0.498662
	mov.f32 	%f25, %f24;
	mad.f32 %f26, %f22, %f23, %f25;
	mov.f32 	%f11, %f26;
	mov.f32 	%f27, %f11;
	mov.f32 	%f28, %f2;
	mov.f32 	%f29, 0fbf408ad0;    	// -0.752118
	mov.f32 	%f30, %f29;
	mad.f32 %f31, %f27, %f28, %f30;
	mov.f32 	%f11, %f31;
	mov.f32 	%f32, %f11;
	mov.f32 	%f33, %f2;
	mov.f32 	%f34, 0f3f7fffa8;    	// 0.999995
	mov.f32 	%f35, %f34;
	mad.f32 %f36, %f32, %f33, %f35;
	mov.f32 	%f11, %f36;
	mov.f32 	%f37, %f11;
	mov.f32 	%f38, %f2;
	mov.f32 	%f39, 0fbf906eba;    	// -1.12838
	mov.f32 	%f40, %f39;
	mad.f32 %f41, %f37, %f38, %f40;
	mov.f32 	%f11, %f41;
	mov.f32 	%f42, %f11;
	mov.f32 	%f43, %f2;
	mov.f32 	%f44, 0f3f800000;    	// 1
	mov.f32 	%f45, %f44;
	mad.f32 %f46, %f42, %f43, %f45;
	mov.f32 	%f11, %f46;
	.loc	17	10726	0
	mov.f32 	%f47, %f11;
	bra.uni 	$Lt_155_6402;
$Lt_155_7170:
	.loc	17	8944	0
	mov.f32 	%f48, %f2;
	rcp.approx.ftz.f32 %f49,%f48;
	mov.f32 	%f50, %f49;
	.loc	17	8936	0
	mov.f32 	%f51, 0fbf7fc509;    	// -0.9991
	mov.f32 	%f52, %f51;
	mov.f32 	%f53, %f50;
	mov.f32 	%f54, 0fbe85acdf;    	// -0.261085
	mov.f32 	%f55, %f54;
	mad.f32 %f56, %f52, %f53, %f55;
	mov.f32 	%f57, %f56;
	mov.f32 	%f58, %f57;
	mov.f32 	%f59, %f50;
	mov.f32 	%f60, 0f3dff301b;    	// 0.124603
	mov.f32 	%f61, %f60;
	mad.f32 %f62, %f58, %f59, %f61;
	mov.f32 	%f57, %f62;
	mov.f32 	%f63, %f57;
	mov.f32 	%f64, %f50;
	mov.f32 	%f65, 0f3e079e1d;    	// 0.132439
	mov.f32 	%f66, %f65;
	mad.f32 %f67, %f63, %f64, %f66;
	mov.f32 	%f57, %f67;
	mov.f32 	%f68, %f57;
	mov.f32 	%f69, %f50;
	mov.f32 	%f70, 0f3d091fcf;    	// 0.0334776
	mov.f32 	%f71, %f70;
	mad.f32 %f72, %f68, %f69, %f71;
	mov.f32 	%f73, %f72;
	mov.f32 	%f74, 0f401045e9;    	// 2.25427
	add.f32 	%f75, %f50, %f74;
	mov.f32 	%f76, %f75;
	mov.f32 	%f77, %f50;
	mov.f32 	%f78, 0f4009b13f;    	// 2.15144
	mov.f32 	%f79, %f78;
	mad.f32 %f80, %f76, %f77, %f79;
	mov.f32 	%f57, %f80;
	mov.f32 	%f81, %f57;
	mov.f32 	%f82, %f50;
	mov.f32 	%f83, 0f3f83a2f6;    	// 1.02841
	mov.f32 	%f84, %f83;
	mad.f32 %f85, %f81, %f82, %f84;
	mov.f32 	%f57, %f85;
	mov.f32 	%f86, %f57;
	mov.f32 	%f87, %f50;
	mov.f32 	%f88, 0f3e859a52;    	// 0.260943
	mov.f32 	%f89, %f88;
	mad.f32 %f90, %f86, %f87, %f89;
	mov.f32 	%f57, %f90;
	mov.f32 	%f91, %f57;
	mov.f32 	%f92, %f50;
	mov.f32 	%f93, 0fb6860e0b;    	// -3.99515e-06
	mov.f32 	%f94, %f93;
	mad.f32 %f95, %f91, %f92, %f94;
	mov.f32 	%f57, %f95;
	.loc	17	10638	0
	div.approx.f32 	%f96, %f73, %f57;
	.loc	17	8936	0
	mov.f32 	%f97, %f96;
	mov.f32 	%f98, %f50;
	mov.f32 	%f99, 0f3f800000;    	// 1
	mov.f32 	%f100, %f99;
	mad.f32 %f101, %f97, %f98, %f100;
	mov.f32 	%f11, %f101;
	.loc	17	10731	0
	mul.f32 	%f102, %f11, %f50;
	mov.f32 	%f103, 0f3f000000;   	// 0.5
	mul.f32 	%f47, %f102, %f103;
	bra.uni 	$Lt_155_6402;
$Lt_155_6658:
	.loc	17	8944	0
	mov.f32 	%f104, %f2;
	rcp.approx.ftz.f32 %f105,%f104;
	mov.f32 	%f106, %f105;
	.loc	17	8936	0
	mul.f32 	%f107, %f106, %f106;
	mov.f32 	%f108, 0f40d20000;   	// 6.5625
	mov.f32 	%f109, %f108;
	mov.f32 	%f110, %f107;
	mov.f32 	%f111, 0fbff00000;   	// -1.875
	mov.f32 	%f112, %f111;
	mad.f32 %f113, %f109, %f110, %f112;
	mov.f32 	%f11, %f113;
	mov.f32 	%f114, %f11;
	mov.f32 	%f115, %f107;
	mov.f32 	%f116, 0f3f400000;   	// 0.75
	mov.f32 	%f117, %f116;
	mad.f32 %f118, %f114, %f115, %f117;
	mov.f32 	%f11, %f118;
	mov.f32 	%f119, %f11;
	mov.f32 	%f120, %f107;
	mov.f32 	%f121, 0fbf000000;   	// -0.5
	mov.f32 	%f122, %f121;
	mad.f32 %f123, %f119, %f120, %f122;
	mov.f32 	%f11, %f123;
	mov.f32 	%f124, %f11;
	mov.f32 	%f125, %f107;
	mov.f32 	%f126, 0f3f800000;   	// 1
	mov.f32 	%f127, %f126;
	mad.f32 %f128, %f124, %f125, %f127;
	mov.f32 	%f11, %f128;
	.loc	17	10743	0
	mov.f32 	%f129, 0f3f106ebb;   	// 0.56419
	mul.f32 	%f130, %f106, %f129;
	mul.f32 	%f47, %f11, %f130;
$Lt_155_6402:
	mov.f32 	%f131, 0f00000000;   	// 0
	setp.le.f32 	%p4, %f1, %f131;
	@!%p4 bra 	$Lt_155_7426;
	.loc	17	8936	0
	mov.b32 	%r18, %f2;
	and.b32 	%r19, %r18, -4096;
	mov.b32 	%f132, %r19;
	mul.f32 	%f133, %f132, %f132;
	mov.f32 	%f134, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f135, %f133, %f134;
	cvt.rzi.f32.f32 	%f136, %f135;
	mov.f32 	%f137, %f136;
	mov.f32 	%f138, 0fbf317200;   	// -0.693146
	mov.f32 	%f139, %f138;
	mov.f32 	%f140, %f133;
	mad.f32 %f141, %f137, %f139, %f140;
	mov.f32 	%f142, %f141;
	mov.f32 	%f143, %f136;
	mov.f32 	%f144, 0fb5bfbe8e;   	// -1.42861e-06
	mov.f32 	%f145, %f144;
	mov.f32 	%f146, %f142;
	mad.f32 %f147, %f143, %f145, %f146;
	mov.f32 	%f148, %f147;
	.loc	17	8965	0
	mov.f32 	%f149, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f150, %f148, %f149;
	mov.f32 	%f151, %f150;
	ex2.approx.ftz.f32 %f152,%f151;
	mov.f32 	%f153, %f152;
	.loc	17	9336	0
	mov.f32 	%f154, 0f7f800000;   	// ((1.0F)/(0.0F))
	mov.f32 	%f155, 0f00000000;   	// 0
	ex2.approx.f32 	%f156, %f136;
	mul.f32 	%f157, %f153, %f156;
	mov.f32 	%f158, 0fc2d20000;   	// -105
	setp.lt.f32 	%p5, %f133, %f158;
	selp.f32 	%f159, %f155, %f157, %p5;
	mov.f32 	%f160, 0f42d20000;   	// 105
	setp.gt.f32 	%p6, %f133, %f160;
	selp.f32 	%f161, %f154, %f159, %p6;
	.loc	17	10755	0
	add.f32 	%f162, %f2, %f132;
	sub.f32 	%f163, %f2, %f132;
	mul.f32 	%f164, %f162, %f163;
	mov.f32 	%f165, 0f3fb8aa3b;   	// 1.4427
	mul.f32 	%f166, %f164, %f165;
	ex2.approx.f32 	%f167, %f166;
	mul.rn.f32 	%f168, %f161, %f167;
	add.f32 	%f169, %f168, %f168;
	.loc	17	10756	0
	sub.f32 	%f170, %f169, %f47;
	.loc	17	9337	0
	mov.f32 	%f171, 0f7f800000;   	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p7, %f161, %f171;
	selp.f32 	%f47, %f161, %f170, %p7;
$Lt_155_7426:
	.loc	15	189	0
	ld.param.u64 	%rd5, [__cudaparm_eerfcx_mf_B];
	ld.param.s32 	%r20, [__cudaparm_eerfcx_mf_ldb];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd6, %r22;
	mul.wide.s32 	%rd7, %r22, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f47;
$Lt_155_5890:
	exit;
$LDWend_eerfcx_mf:
	} // eerfcx_mf

	.entry eerf_vf (
		.param .u64 __cudaparm_eerf_vf_n,
		.param .u64 __cudaparm_eerf_vf_x,
		.param .s32 __cudaparm_eerf_vf_lx,
		.param .u64 __cudaparm_eerf_vf_result,
		.param .s32 __cudaparm_eerf_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<13>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<77>;
	.reg .pred %p<5>;
	.loc	15	190	0
$LDWbegin_eerf_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eerf_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_156_2562;
	ld.param.u64 	%rd3, [__cudaparm_eerf_vf_x];
	ld.param.s32 	%r4, [__cudaparm_eerf_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f3f800000;     	// 1
	setp.ge.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_156_3330;
	.loc	17	8936	0
	mov.f32 	%f4, 0fb7b730fb;     	// -2.18381e-05
	mov.f32 	%f5, %f4;
	mov.f32 	%f6, %f2;
	mov.f32 	%f7, 0f3a03bb71;     	// 0.000502518
	mov.f32 	%f8, %f7;
	mad.f32 %f9, %f5, %f6, %f8;
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, %f10;
	mov.f32 	%f12, %f2;
	mov.f32 	%f13, 0fbbaca3b3;    	// -0.00526854
	mov.f32 	%f14, %f13;
	mad.f32 %f15, %f11, %f12, %f14;
	mov.f32 	%f10, %f15;
	mov.f32 	%f16, %f10;
	mov.f32 	%f17, %f2;
	mov.f32 	%f18, 0f3d0a7445;    	// 0.0338023
	mov.f32 	%f19, %f18;
	mad.f32 %f20, %f16, %f17, %f19;
	mov.f32 	%f10, %f20;
	mov.f32 	%f21, %f10;
	mov.f32 	%f22, %f2;
	mov.f32 	%f23, 0fbe1b3b75;    	// -0.151594
	mov.f32 	%f24, %f23;
	mad.f32 %f25, %f21, %f22, %f24;
	mov.f32 	%f10, %f25;
	mov.f32 	%f26, %f10;
	mov.f32 	%f27, %f2;
	mov.f32 	%f28, 0fbf6b385a;    	// -0.918829
	mov.f32 	%f29, %f28;
	mad.f32 %f30, %f26, %f27, %f29;
	mov.f32 	%f10, %f30;
	mov.f32 	%f31, %f10;
	mov.f32 	%f32, %f2;
	mov.f32 	%f33, 0fbfd0316e;    	// -1.62651
	mov.f32 	%f34, %f33;
	mad.f32 %f35, %f31, %f32, %f34;
	mov.f32 	%f10, %f35;
	mov.f32 	%f36, %f10;
	mov.f32 	%f37, %f2;
	mov.f32 	%f38, 0fba031cce;    	// -0.000500155
	mov.f32 	%f39, %f38;
	mad.f32 %f40, %f36, %f37, %f39;
	mov.f32 	%f10, %f40;
	.loc	17	8965	0
	mov.f32 	%f41, %f10;
	ex2.approx.ftz.f32 %f42,%f41;
	mov.f32 	%f43, %f42;
	.loc	17	10498	0
	mov.f32 	%f44, 0f3f800000;    	// 1
	mov.f32 	%f45, 0f3f800000;    	// 1
	sub.f32 	%f46, %f45, %f43;
	mov.f32 	%f47, 0f407ad445;    	// 3.91921
	setp.ge.f32 	%p3, %f2, %f47;
	selp.f32 	%f48, %f44, %f46, %p3;
	mov.b32 	%r6, %f48;
	mov.b32 	%r7, %f1;
	and.b32 	%r8, %r7, -2147483648;
	or.b32 	%r9, %r6, %r8;
	mov.b32 	%f1, %r9;
	bra.uni 	$Lt_156_3074;
$Lt_156_3330:
	.loc	17	8936	0
	mul.f32 	%f49, %f1, %f1;
	mov.f32 	%f50, 0fba1268fb;    	// -0.00055851
	mov.f32 	%f51, %f50;
	mov.f32 	%f52, %f49;
	mov.f32 	%f53, 0f3ba0c9f8;    	// 0.00490689
	mov.f32 	%f54, %f53;
	mad.f32 %f55, %f51, %f52, %f54;
	mov.f32 	%f10, %f55;
	mov.f32 	%f56, %f10;
	mov.f32 	%f57, %f49;
	mov.f32 	%f58, 0fbcdabfd4;    	// -0.0267028
	mov.f32 	%f59, %f58;
	mad.f32 %f60, %f56, %f57, %f59;
	mov.f32 	%f10, %f60;
	mov.f32 	%f61, %f10;
	mov.f32 	%f62, %f49;
	mov.f32 	%f63, 0f3de70331;    	// 0.112799
	mov.f32 	%f64, %f63;
	mad.f32 %f65, %f61, %f62, %f64;
	mov.f32 	%f10, %f65;
	mov.f32 	%f66, %f10;
	mov.f32 	%f67, %f49;
	mov.f32 	%f68, 0fbec09330;    	// -0.376123
	mov.f32 	%f69, %f68;
	mad.f32 %f70, %f66, %f67, %f69;
	mov.f32 	%f10, %f70;
	mov.f32 	%f71, %f10;
	mov.f32 	%f72, %f49;
	mov.f32 	%f73, 0f3f906eba;    	// 1.12838
	mov.f32 	%f74, %f73;
	mad.f32 %f75, %f71, %f72, %f74;
	mov.f32 	%f10, %f75;
	.loc	17	10507	0
	mul.f32 	%f1, %f1, %f10;
$Lt_156_3074:
	.loc	15	190	0
	ld.param.u64 	%rd7, [__cudaparm_eerf_vf_result];
	ld.param.s32 	%r10, [__cudaparm_eerf_vf_lr];
	mul.lo.s32 	%r11, %r10, %r3;
	cvt.s64.s32 	%rd8, %r11;
	mul.wide.s32 	%rd9, %r11, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f1;
$Lt_156_2562:
	exit;
$LDWend_eerf_vf:
	} // eerf_vf

	.entry eerf_mf (
		.param .s32 __cudaparm_eerf_mf_rs,
		.param .s32 __cudaparm_eerf_mf_cs,
		.param .u64 __cudaparm_eerf_mf_A,
		.param .s32 __cudaparm_eerf_mf_lda,
		.param .u64 __cudaparm_eerf_mf_B,
		.param .s32 __cudaparm_eerf_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<26>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<77>;
	.reg .pred %p<5>;
$LDWbegin_eerf_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eerf_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eerf_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_157_2818;
	ld.param.u64 	%rd1, [__cudaparm_eerf_mf_A];
	ld.param.s32 	%r15, [__cudaparm_eerf_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f3f800000;     	// 1
	setp.ge.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_157_3586;
	.loc	17	8936	0
	mov.f32 	%f4, 0fb7b730fb;     	// -2.18381e-05
	mov.f32 	%f5, %f4;
	mov.f32 	%f6, %f2;
	mov.f32 	%f7, 0f3a03bb71;     	// 0.000502518
	mov.f32 	%f8, %f7;
	mad.f32 %f9, %f5, %f6, %f8;
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, %f10;
	mov.f32 	%f12, %f2;
	mov.f32 	%f13, 0fbbaca3b3;    	// -0.00526854
	mov.f32 	%f14, %f13;
	mad.f32 %f15, %f11, %f12, %f14;
	mov.f32 	%f10, %f15;
	mov.f32 	%f16, %f10;
	mov.f32 	%f17, %f2;
	mov.f32 	%f18, 0f3d0a7445;    	// 0.0338023
	mov.f32 	%f19, %f18;
	mad.f32 %f20, %f16, %f17, %f19;
	mov.f32 	%f10, %f20;
	mov.f32 	%f21, %f10;
	mov.f32 	%f22, %f2;
	mov.f32 	%f23, 0fbe1b3b75;    	// -0.151594
	mov.f32 	%f24, %f23;
	mad.f32 %f25, %f21, %f22, %f24;
	mov.f32 	%f10, %f25;
	mov.f32 	%f26, %f10;
	mov.f32 	%f27, %f2;
	mov.f32 	%f28, 0fbf6b385a;    	// -0.918829
	mov.f32 	%f29, %f28;
	mad.f32 %f30, %f26, %f27, %f29;
	mov.f32 	%f10, %f30;
	mov.f32 	%f31, %f10;
	mov.f32 	%f32, %f2;
	mov.f32 	%f33, 0fbfd0316e;    	// -1.62651
	mov.f32 	%f34, %f33;
	mad.f32 %f35, %f31, %f32, %f34;
	mov.f32 	%f10, %f35;
	mov.f32 	%f36, %f10;
	mov.f32 	%f37, %f2;
	mov.f32 	%f38, 0fba031cce;    	// -0.000500155
	mov.f32 	%f39, %f38;
	mad.f32 %f40, %f36, %f37, %f39;
	mov.f32 	%f10, %f40;
	.loc	17	8965	0
	mov.f32 	%f41, %f10;
	ex2.approx.ftz.f32 %f42,%f41;
	mov.f32 	%f43, %f42;
	.loc	17	10498	0
	mov.f32 	%f44, 0f3f800000;    	// 1
	mov.f32 	%f45, 0f3f800000;    	// 1
	sub.f32 	%f46, %f45, %f43;
	mov.f32 	%f47, 0f407ad445;    	// 3.91921
	setp.ge.f32 	%p3, %f2, %f47;
	selp.f32 	%f48, %f44, %f46, %p3;
	mov.b32 	%r18, %f48;
	mov.b32 	%r19, %f1;
	and.b32 	%r20, %r19, -2147483648;
	or.b32 	%r21, %r18, %r20;
	mov.b32 	%f1, %r21;
	bra.uni 	$Lt_157_3330;
$Lt_157_3586:
	.loc	17	8936	0
	mul.f32 	%f49, %f1, %f1;
	mov.f32 	%f50, 0fba1268fb;    	// -0.00055851
	mov.f32 	%f51, %f50;
	mov.f32 	%f52, %f49;
	mov.f32 	%f53, 0f3ba0c9f8;    	// 0.00490689
	mov.f32 	%f54, %f53;
	mad.f32 %f55, %f51, %f52, %f54;
	mov.f32 	%f10, %f55;
	mov.f32 	%f56, %f10;
	mov.f32 	%f57, %f49;
	mov.f32 	%f58, 0fbcdabfd4;    	// -0.0267028
	mov.f32 	%f59, %f58;
	mad.f32 %f60, %f56, %f57, %f59;
	mov.f32 	%f10, %f60;
	mov.f32 	%f61, %f10;
	mov.f32 	%f62, %f49;
	mov.f32 	%f63, 0f3de70331;    	// 0.112799
	mov.f32 	%f64, %f63;
	mad.f32 %f65, %f61, %f62, %f64;
	mov.f32 	%f10, %f65;
	mov.f32 	%f66, %f10;
	mov.f32 	%f67, %f49;
	mov.f32 	%f68, 0fbec09330;    	// -0.376123
	mov.f32 	%f69, %f68;
	mad.f32 %f70, %f66, %f67, %f69;
	mov.f32 	%f10, %f70;
	mov.f32 	%f71, %f10;
	mov.f32 	%f72, %f49;
	mov.f32 	%f73, 0f3f906eba;    	// 1.12838
	mov.f32 	%f74, %f73;
	mad.f32 %f75, %f71, %f72, %f74;
	mov.f32 	%f10, %f75;
	.loc	17	10507	0
	mul.f32 	%f1, %f1, %f10;
$Lt_157_3330:
	.loc	15	190	0
	ld.param.u64 	%rd5, [__cudaparm_eerf_mf_B];
	ld.param.s32 	%r22, [__cudaparm_eerf_mf_ldb];
	mul.lo.s32 	%r23, %r22, %r4;
	add.s32 	%r24, %r6, %r23;
	cvt.s64.s32 	%rd6, %r24;
	mul.wide.s32 	%rd7, %r24, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f1;
$Lt_157_2818:
	exit;
$LDWend_eerf_mf:
	} // eerf_mf

	.entry eerfinv_vf (
		.param .u64 __cudaparm_eerfinv_vf_n,
		.param .u64 __cudaparm_eerfinv_vf_x,
		.param .s32 __cudaparm_eerfinv_vf_lx,
		.param .u64 __cudaparm_eerfinv_vf_result,
		.param .s32 __cudaparm_eerfinv_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<95>;
	.reg .pred %p<5>;
	.loc	15	191	0
$LDWbegin_eerfinv_vf:
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r1, %rh1, %rh2;
	cvt.u32.u16 	%r2, %tid.x;
	add.u32 	%r3, %r2, %r1;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eerfinv_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_158_2562;
	ld.param.u64 	%rd3, [__cudaparm_eerfinv_vf_x];
	ld.param.s32 	%r4, [__cudaparm_eerfinv_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	8958	0
	mov.f32 	%f2, 0f3f800000;     	// 1
	add.f32 	%f3, %f1, %f2;
	mov.f32 	%f4, 0f3f800000;     	// 1
	sub.f32 	%f5, %f4, %f1;
	mul.f32 	%f6, %f3, %f5;
	mov.f32 	%f7, %f6;
	lg2.approx.ftz.f32 %f8,%f7;
	mov.f32 	%f9, %f8;
	.loc	17	10557	0
	neg.f32 	%f10, %f9;
	mov.f32 	%f11, 0f41033333;    	// 8.2
	setp.gt.f32 	%p2, %f10, %f11;
	@!%p2 bra 	$Lt_158_3330;
	.loc	17	8951	0
	mov.f32 	%f12, %f10;
	rsqrt.approx.ftz.f32 %f13,%f12;
	mov.f32 	%f14, %f13;
	.loc	17	8936	0
	mov.f32 	%f15, 0fbf1704a1;    	// -0.589914
	mov.f32 	%f16, %f15;
	mov.f32 	%f17, %f14;
	mov.f32 	%f18, 0fbf29baa5;    	// -0.663004
	mov.f32 	%f19, %f18;
	mad.f32 %f20, %f16, %f17, %f19;
	mov.f32 	%f21, %f20;
	mov.f32 	%f22, %f21;
	mov.f32 	%f23, %f14;
	mov.f32 	%f24, 0f3fcc6adc;    	// 1.59701
	mov.f32 	%f25, %f24;
	mad.f32 %f26, %f22, %f23, %f25;
	mov.f32 	%f21, %f26;
	mov.f32 	%f27, %f21;
	mov.f32 	%f28, %f14;
	mov.f32 	%f29, 0fbf2cdaed;    	// -0.675216
	mov.f32 	%f30, %f29;
	mad.f32 %f31, %f27, %f28, %f30;
	mov.f32 	%f21, %f31;
	mov.f32 	%f32, %f21;
	mov.f32 	%f33, %f14;
	mov.f32 	%f34, 0fbdc30537;    	// -0.0952248
	mov.f32 	%f35, %f34;
	mad.f32 %f36, %f32, %f33, %f35;
	mov.f32 	%f21, %f36;
	mov.f32 	%f37, %f21;
	mov.f32 	%f38, %f14;
	mov.f32 	%f39, 0f3f55d9b9;    	// 0.835353
	mov.f32 	%f40, %f39;
	mad.f32 %f41, %f37, %f38, %f40;
	mov.f32 	%f21, %f41;
	.loc	17	10559	0
	rcp.approx.f32 	%f42, %f14;
	mul.f32 	%f43, %f42, %f21;
	neg.f32 	%f44, %f43;
	mov.f32 	%f45, 0f00000000;    	// 0
	setp.lt.f32 	%p3, %f1, %f45;
	selp.f32 	%f46, %f44, %f43, %p3;
	bra.uni 	$Lt_158_3074;
$Lt_158_3330:
	.loc	17	8936	0
	mov.f32 	%f47, 0faf8a6370;    	// -2.51727e-10
	mov.f32 	%f48, %f47;
	mov.f32 	%f49, %f10;
	mov.f32 	%f50, 0f3221f645;    	// 9.42743e-09
	mov.f32 	%f51, %f50;
	mad.f32 %f52, %f48, %f49, %f51;
	mov.f32 	%f53, %f52;
	mov.f32 	%f54, %f53;
	mov.f32 	%f55, %f10;
	mov.f32 	%f56, 0fb4016fda;    	// -1.20548e-07
	mov.f32 	%f57, %f56;
	mad.f32 %f58, %f54, %f55, %f57;
	mov.f32 	%f53, %f58;
	mov.f32 	%f59, %f53;
	mov.f32 	%f60, %f10;
	mov.f32 	%f61, 0f3468f846;    	// 2.1697e-07
	mov.f32 	%f62, %f61;
	mad.f32 %f63, %f59, %f60, %f62;
	mov.f32 	%f53, %f63;
	mov.f32 	%f64, %f53;
	mov.f32 	%f65, %f10;
	mov.f32 	%f66, 0f370742aa;    	// 8.06215e-06
	mov.f32 	%f67, %f66;
	mad.f32 %f68, %f64, %f65, %f67;
	mov.f32 	%f53, %f68;
	mov.f32 	%f69, %f53;
	mov.f32 	%f70, %f10;
	mov.f32 	%f71, 0fb804db4d;    	// -3.16755e-05
	mov.f32 	%f72, %f71;
	mad.f32 %f73, %f69, %f70, %f72;
	mov.f32 	%f53, %f73;
	mov.f32 	%f74, %f53;
	mov.f32 	%f75, %f10;
	mov.f32 	%f76, 0fba4afea1;    	// -0.000774363
	mov.f32 	%f77, %f76;
	mad.f32 %f78, %f74, %f75, %f77;
	mov.f32 	%f53, %f78;
	mov.f32 	%f79, %f53;
	mov.f32 	%f80, %f10;
	mov.f32 	%f81, 0f3bb5c027;    	// 0.00554659
	mov.f32 	%f82, %f81;
	mad.f32 %f83, %f79, %f80, %f82;
	mov.f32 	%f53, %f83;
	mov.f32 	%f84, %f53;
	mov.f32 	%f85, %f10;
	mov.f32 	%f86, 0f3e24ae0f;    	// 0.16082
	mov.f32 	%f87, %f86;
	mad.f32 %f88, %f84, %f85, %f87;
	mov.f32 	%f53, %f88;
	mov.f32 	%f89, %f53;
	mov.f32 	%f90, %f10;
	mov.f32 	%f91, 0f3f62dfc4;    	// 0.886227
	mov.f32 	%f92, %f91;
	mad.f32 %f93, %f89, %f90, %f92;
	mov.f32 	%f53, %f93;
	.loc	17	10570	0
	mul.f32 	%f46, %f1, %f53;
$Lt_158_3074:
	.loc	15	191	0
	ld.param.u64 	%rd7, [__cudaparm_eerfinv_vf_result];
	ld.param.s32 	%r6, [__cudaparm_eerfinv_vf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f46;
$Lt_158_2562:
	exit;
$LDWend_eerfinv_vf:
	} // eerfinv_vf

	.entry eerfinv_mf (
		.param .s32 __cudaparm_eerfinv_mf_rs,
		.param .s32 __cudaparm_eerfinv_mf_cs,
		.param .u64 __cudaparm_eerfinv_mf_A,
		.param .s32 __cudaparm_eerfinv_mf_lda,
		.param .u64 __cudaparm_eerfinv_mf_B,
		.param .s32 __cudaparm_eerfinv_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<95>;
	.reg .pred %p<5>;
$LDWbegin_eerfinv_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eerfinv_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eerfinv_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_159_2818;
	ld.param.u64 	%rd1, [__cudaparm_eerfinv_mf_A];
	ld.param.s32 	%r15, [__cudaparm_eerfinv_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	8958	0
	mov.f32 	%f2, 0f3f800000;     	// 1
	add.f32 	%f3, %f1, %f2;
	mov.f32 	%f4, 0f3f800000;     	// 1
	sub.f32 	%f5, %f4, %f1;
	mul.f32 	%f6, %f3, %f5;
	mov.f32 	%f7, %f6;
	lg2.approx.ftz.f32 %f8,%f7;
	mov.f32 	%f9, %f8;
	.loc	17	10557	0
	neg.f32 	%f10, %f9;
	mov.f32 	%f11, 0f41033333;    	// 8.2
	setp.gt.f32 	%p2, %f10, %f11;
	@!%p2 bra 	$Lt_159_3586;
	.loc	17	8951	0
	mov.f32 	%f12, %f10;
	rsqrt.approx.ftz.f32 %f13,%f12;
	mov.f32 	%f14, %f13;
	.loc	17	8936	0
	mov.f32 	%f15, 0fbf1704a1;    	// -0.589914
	mov.f32 	%f16, %f15;
	mov.f32 	%f17, %f14;
	mov.f32 	%f18, 0fbf29baa5;    	// -0.663004
	mov.f32 	%f19, %f18;
	mad.f32 %f20, %f16, %f17, %f19;
	mov.f32 	%f21, %f20;
	mov.f32 	%f22, %f21;
	mov.f32 	%f23, %f14;
	mov.f32 	%f24, 0f3fcc6adc;    	// 1.59701
	mov.f32 	%f25, %f24;
	mad.f32 %f26, %f22, %f23, %f25;
	mov.f32 	%f21, %f26;
	mov.f32 	%f27, %f21;
	mov.f32 	%f28, %f14;
	mov.f32 	%f29, 0fbf2cdaed;    	// -0.675216
	mov.f32 	%f30, %f29;
	mad.f32 %f31, %f27, %f28, %f30;
	mov.f32 	%f21, %f31;
	mov.f32 	%f32, %f21;
	mov.f32 	%f33, %f14;
	mov.f32 	%f34, 0fbdc30537;    	// -0.0952248
	mov.f32 	%f35, %f34;
	mad.f32 %f36, %f32, %f33, %f35;
	mov.f32 	%f21, %f36;
	mov.f32 	%f37, %f21;
	mov.f32 	%f38, %f14;
	mov.f32 	%f39, 0f3f55d9b9;    	// 0.835353
	mov.f32 	%f40, %f39;
	mad.f32 %f41, %f37, %f38, %f40;
	mov.f32 	%f21, %f41;
	.loc	17	10559	0
	rcp.approx.f32 	%f42, %f14;
	mul.f32 	%f43, %f42, %f21;
	neg.f32 	%f44, %f43;
	mov.f32 	%f45, 0f00000000;    	// 0
	setp.lt.f32 	%p3, %f1, %f45;
	selp.f32 	%f46, %f44, %f43, %p3;
	bra.uni 	$Lt_159_3330;
$Lt_159_3586:
	.loc	17	8936	0
	mov.f32 	%f47, 0faf8a6370;    	// -2.51727e-10
	mov.f32 	%f48, %f47;
	mov.f32 	%f49, %f10;
	mov.f32 	%f50, 0f3221f645;    	// 9.42743e-09
	mov.f32 	%f51, %f50;
	mad.f32 %f52, %f48, %f49, %f51;
	mov.f32 	%f53, %f52;
	mov.f32 	%f54, %f53;
	mov.f32 	%f55, %f10;
	mov.f32 	%f56, 0fb4016fda;    	// -1.20548e-07
	mov.f32 	%f57, %f56;
	mad.f32 %f58, %f54, %f55, %f57;
	mov.f32 	%f53, %f58;
	mov.f32 	%f59, %f53;
	mov.f32 	%f60, %f10;
	mov.f32 	%f61, 0f3468f846;    	// 2.1697e-07
	mov.f32 	%f62, %f61;
	mad.f32 %f63, %f59, %f60, %f62;
	mov.f32 	%f53, %f63;
	mov.f32 	%f64, %f53;
	mov.f32 	%f65, %f10;
	mov.f32 	%f66, 0f370742aa;    	// 8.06215e-06
	mov.f32 	%f67, %f66;
	mad.f32 %f68, %f64, %f65, %f67;
	mov.f32 	%f53, %f68;
	mov.f32 	%f69, %f53;
	mov.f32 	%f70, %f10;
	mov.f32 	%f71, 0fb804db4d;    	// -3.16755e-05
	mov.f32 	%f72, %f71;
	mad.f32 %f73, %f69, %f70, %f72;
	mov.f32 	%f53, %f73;
	mov.f32 	%f74, %f53;
	mov.f32 	%f75, %f10;
	mov.f32 	%f76, 0fba4afea1;    	// -0.000774363
	mov.f32 	%f77, %f76;
	mad.f32 %f78, %f74, %f75, %f77;
	mov.f32 	%f53, %f78;
	mov.f32 	%f79, %f53;
	mov.f32 	%f80, %f10;
	mov.f32 	%f81, 0f3bb5c027;    	// 0.00554659
	mov.f32 	%f82, %f81;
	mad.f32 %f83, %f79, %f80, %f82;
	mov.f32 	%f53, %f83;
	mov.f32 	%f84, %f53;
	mov.f32 	%f85, %f10;
	mov.f32 	%f86, 0f3e24ae0f;    	// 0.16082
	mov.f32 	%f87, %f86;
	mad.f32 %f88, %f84, %f85, %f87;
	mov.f32 	%f53, %f88;
	mov.f32 	%f89, %f53;
	mov.f32 	%f90, %f10;
	mov.f32 	%f91, 0f3f62dfc4;    	// 0.886227
	mov.f32 	%f92, %f91;
	mad.f32 %f93, %f89, %f90, %f92;
	mov.f32 	%f53, %f93;
	.loc	17	10570	0
	mul.f32 	%f46, %f1, %f53;
$Lt_159_3330:
	.loc	15	191	0
	ld.param.u64 	%rd5, [__cudaparm_eerfinv_mf_B];
	ld.param.s32 	%r18, [__cudaparm_eerfinv_mf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f46;
$Lt_159_2818:
	exit;
$LDWend_eerfinv_mf:
	} // eerfinv_mf

	.entry eceil_vf (
		.param .u64 __cudaparm_eceil_vf_n,
		.param .u64 __cudaparm_eceil_vf_x,
		.param .s32 __cudaparm_eceil_vf_lx,
		.param .u64 __cudaparm_eceil_vf_result,
		.param .s32 __cudaparm_eceil_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
	.loc	15	193	0
$LDWbegin_eceil_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eceil_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_160_1026;
	ld.param.u64 	%rd3, [__cudaparm_eceil_vf_x];
	ld.param.s32 	%r4, [__cudaparm_eceil_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	cvt.rpi.f32.f32 	%f2, %f1;
	ld.param.u64 	%rd7, [__cudaparm_eceil_vf_result];
	ld.param.s32 	%r6, [__cudaparm_eceil_vf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f2;
$Lt_160_1026:
	exit;
$LDWend_eceil_vf:
	} // eceil_vf

	.entry eceil_mf (
		.param .s32 __cudaparm_eceil_mf_rs,
		.param .s32 __cudaparm_eceil_mf_cs,
		.param .u64 __cudaparm_eceil_mf_A,
		.param .s32 __cudaparm_eceil_mf_lda,
		.param .u64 __cudaparm_eceil_mf_B,
		.param .s32 __cudaparm_eceil_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
$LDWbegin_eceil_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eceil_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eceil_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_161_1282;
	ld.param.u64 	%rd1, [__cudaparm_eceil_mf_A];
	ld.param.s32 	%r15, [__cudaparm_eceil_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	cvt.rpi.f32.f32 	%f2, %f1;
	ld.param.u64 	%rd5, [__cudaparm_eceil_mf_B];
	ld.param.s32 	%r18, [__cudaparm_eceil_mf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f2;
$Lt_161_1282:
	exit;
$LDWend_eceil_mf:
	} // eceil_mf

	.entry efloor_vf (
		.param .u64 __cudaparm_efloor_vf_n,
		.param .u64 __cudaparm_efloor_vf_x,
		.param .s32 __cudaparm_efloor_vf_lx,
		.param .u64 __cudaparm_efloor_vf_result,
		.param .s32 __cudaparm_efloor_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
	.loc	15	194	0
$LDWbegin_efloor_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_efloor_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_162_1026;
	ld.param.u64 	%rd3, [__cudaparm_efloor_vf_x];
	ld.param.s32 	%r4, [__cudaparm_efloor_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	cvt.rmi.f32.f32 	%f2, %f1;
	ld.param.u64 	%rd7, [__cudaparm_efloor_vf_result];
	ld.param.s32 	%r6, [__cudaparm_efloor_vf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f2;
$Lt_162_1026:
	exit;
$LDWend_efloor_vf:
	} // efloor_vf

	.entry efloor_mf (
		.param .s32 __cudaparm_efloor_mf_rs,
		.param .s32 __cudaparm_efloor_mf_cs,
		.param .u64 __cudaparm_efloor_mf_A,
		.param .s32 __cudaparm_efloor_mf_lda,
		.param .u64 __cudaparm_efloor_mf_B,
		.param .s32 __cudaparm_efloor_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
$LDWbegin_efloor_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_efloor_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_efloor_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_163_1282;
	ld.param.u64 	%rd1, [__cudaparm_efloor_mf_A];
	ld.param.s32 	%r15, [__cudaparm_efloor_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	cvt.rmi.f32.f32 	%f2, %f1;
	ld.param.u64 	%rd5, [__cudaparm_efloor_mf_B];
	ld.param.s32 	%r18, [__cudaparm_efloor_mf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f2;
$Lt_163_1282:
	exit;
$LDWend_efloor_mf:
	} // efloor_mf

	.entry eround_vf (
		.param .u64 __cudaparm_eround_vf_n,
		.param .u64 __cudaparm_eround_vf_x,
		.param .s32 __cudaparm_eround_vf_lx,
		.param .u64 __cudaparm_eround_vf_result,
		.param .s32 __cudaparm_eround_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<12>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<10>;
	.reg .pred %p<5>;
	.loc	15	195	0
$LDWbegin_eround_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eround_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_164_2562;
	ld.param.u64 	%rd3, [__cudaparm_eround_vf_x];
	ld.param.s32 	%r4, [__cudaparm_eround_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	abs.f32 	%f2, %f1;
	mov.b32 	%r6, %f1;
	and.b32 	%r7, %r6, -2147483648;
	or.b32 	%r8, %r7, 1056964608;
	mov.b32 	%f3, %r8;
	add.f32 	%f4, %f1, %f3;
	cvt.rzi.f32.f32 	%f5, %f4;
	mov.f32 	%f6, 0f4b000000;     	// 8.38861e+06
	setp.gt.f32 	%p2, %f2, %f6;
	selp.f32 	%f7, %f1, %f5, %p2;
	mov.f32 	%f8, 0f3f000000;     	// 0.5
	setp.lt.f32 	%p3, %f2, %f8;
	@!%p3 bra 	$Lt_164_3074;
	.loc	17	11341	0
	cvt.rzi.f32.f32 	%f7, %f1;
$Lt_164_3074:
	.loc	15	195	0
	ld.param.u64 	%rd7, [__cudaparm_eround_vf_result];
	ld.param.s32 	%r9, [__cudaparm_eround_vf_lr];
	mul.lo.s32 	%r10, %r9, %r3;
	cvt.s64.s32 	%rd8, %r10;
	mul.wide.s32 	%rd9, %r10, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f7;
$Lt_164_2562:
	exit;
$LDWend_eround_vf:
	} // eround_vf

	.entry eround_mf (
		.param .s32 __cudaparm_eround_mf_rs,
		.param .s32 __cudaparm_eround_mf_cs,
		.param .u64 __cudaparm_eround_mf_A,
		.param .s32 __cudaparm_eround_mf_lda,
		.param .u64 __cudaparm_eround_mf_B,
		.param .s32 __cudaparm_eround_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<25>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<10>;
	.reg .pred %p<5>;
$LDWbegin_eround_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eround_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eround_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_165_2818;
	ld.param.u64 	%rd1, [__cudaparm_eround_mf_A];
	ld.param.s32 	%r15, [__cudaparm_eround_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	abs.f32 	%f2, %f1;
	mov.b32 	%r18, %f1;
	and.b32 	%r19, %r18, -2147483648;
	or.b32 	%r20, %r19, 1056964608;
	mov.b32 	%f3, %r20;
	add.f32 	%f4, %f1, %f3;
	cvt.rzi.f32.f32 	%f5, %f4;
	mov.f32 	%f6, 0f4b000000;     	// 8.38861e+06
	setp.gt.f32 	%p2, %f2, %f6;
	selp.f32 	%f7, %f1, %f5, %p2;
	mov.f32 	%f8, 0f3f000000;     	// 0.5
	setp.lt.f32 	%p3, %f2, %f8;
	@!%p3 bra 	$Lt_165_3330;
	.loc	17	11341	0
	cvt.rzi.f32.f32 	%f7, %f1;
$Lt_165_3330:
	.loc	15	195	0
	ld.param.u64 	%rd5, [__cudaparm_eround_mf_B];
	ld.param.s32 	%r21, [__cudaparm_eround_mf_ldb];
	mul.lo.s32 	%r22, %r21, %r4;
	add.s32 	%r23, %r6, %r22;
	cvt.s64.s32 	%rd6, %r23;
	mul.wide.s32 	%rd7, %r23, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f7;
$Lt_165_2818:
	exit;
$LDWend_eround_mf:
	} // eround_mf

	.entry erint_vf (
		.param .u64 __cudaparm_erint_vf_n,
		.param .u64 __cudaparm_erint_vf_x,
		.param .s32 __cudaparm_erint_vf_lx,
		.param .u64 __cudaparm_erint_vf_result,
		.param .s32 __cudaparm_erint_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
	.loc	15	196	0
$LDWbegin_erint_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_erint_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_166_1026;
	ld.param.u64 	%rd3, [__cudaparm_erint_vf_x];
	ld.param.s32 	%r4, [__cudaparm_erint_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	cvt.rni.f32.f32 	%f2, %f1;
	ld.param.u64 	%rd7, [__cudaparm_erint_vf_result];
	ld.param.s32 	%r6, [__cudaparm_erint_vf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f2;
$Lt_166_1026:
	exit;
$LDWend_erint_vf:
	} // erint_vf

	.entry erint_mf (
		.param .s32 __cudaparm_erint_mf_rs,
		.param .s32 __cudaparm_erint_mf_cs,
		.param .u64 __cudaparm_erint_mf_A,
		.param .s32 __cudaparm_erint_mf_lda,
		.param .u64 __cudaparm_erint_mf_B,
		.param .s32 __cudaparm_erint_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
$LDWbegin_erint_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_erint_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_erint_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_167_1282;
	ld.param.u64 	%rd1, [__cudaparm_erint_mf_A];
	ld.param.s32 	%r15, [__cudaparm_erint_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	cvt.rni.f32.f32 	%f2, %f1;
	ld.param.u64 	%rd5, [__cudaparm_erint_mf_B];
	ld.param.s32 	%r18, [__cudaparm_erint_mf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f2;
$Lt_167_1282:
	exit;
$LDWend_erint_mf:
	} // erint_mf

	.entry etrunc_vf (
		.param .u64 __cudaparm_etrunc_vf_n,
		.param .u64 __cudaparm_etrunc_vf_x,
		.param .s32 __cudaparm_etrunc_vf_lx,
		.param .u64 __cudaparm_etrunc_vf_result,
		.param .s32 __cudaparm_etrunc_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
	.loc	15	197	0
$LDWbegin_etrunc_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_etrunc_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_168_1026;
	ld.param.u64 	%rd3, [__cudaparm_etrunc_vf_x];
	ld.param.s32 	%r4, [__cudaparm_etrunc_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	cvt.rzi.f32.f32 	%f2, %f1;
	ld.param.u64 	%rd7, [__cudaparm_etrunc_vf_result];
	ld.param.s32 	%r6, [__cudaparm_etrunc_vf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f2;
$Lt_168_1026:
	exit;
$LDWend_etrunc_vf:
	} // etrunc_vf

	.entry etrunc_mf (
		.param .s32 __cudaparm_etrunc_mf_rs,
		.param .s32 __cudaparm_etrunc_mf_cs,
		.param .u64 __cudaparm_etrunc_mf_A,
		.param .s32 __cudaparm_etrunc_mf_lda,
		.param .u64 __cudaparm_etrunc_mf_B,
		.param .s32 __cudaparm_etrunc_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
$LDWbegin_etrunc_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_etrunc_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_etrunc_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_169_1282;
	ld.param.u64 	%rd1, [__cudaparm_etrunc_mf_A];
	ld.param.s32 	%r15, [__cudaparm_etrunc_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	cvt.rzi.f32.f32 	%f2, %f1;
	ld.param.u64 	%rd5, [__cudaparm_etrunc_mf_B];
	ld.param.s32 	%r18, [__cudaparm_etrunc_mf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f2;
$Lt_169_1282:
	exit;
$LDWend_etrunc_mf:
	} // etrunc_mf

	.entry eexp10_vf (
		.param .u64 __cudaparm_eexp10_vf_n,
		.param .u64 __cudaparm_eexp10_vf_x,
		.param .s32 __cudaparm_eexp10_vf_lx,
		.param .u64 __cudaparm_eexp10_vf_result,
		.param .s32 __cudaparm_eexp10_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<31>;
	.reg .pred %p<5>;
	.loc	15	199	0
$LDWbegin_eexp10_vf:
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r1, %rh1, %rh2;
	cvt.u32.u16 	%r2, %tid.x;
	add.u32 	%r3, %r2, %r1;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eexp10_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_170_2562;
	ld.param.u64 	%rd3, [__cudaparm_eexp10_vf_x];
	ld.param.s32 	%r4, [__cudaparm_eexp10_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	8936	0
	mov.f32 	%f2, 0f40549a78;     	// 3.32193
	mul.f32 	%f3, %f1, %f2;
	cvt.rzi.f32.f32 	%f4, %f3;
	mov.f32 	%f5, %f4;
	mov.f32 	%f6, 0fbe9a2080;     	// -0.301029
	mov.f32 	%f7, %f6;
	mov.f32 	%f8, %f1;
	mad.f32 %f9, %f5, %f7, %f8;
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, %f4;
	mov.f32 	%f12, 0fb55427de;    	// -7.90342e-07
	mov.f32 	%f13, %f12;
	mov.f32 	%f14, %f10;
	mad.f32 %f15, %f11, %f13, %f14;
	mov.f32 	%f16, %f15;
	.loc	17	8965	0
	mov.f32 	%f17, 0f40549a78;    	// 3.32193
	mul.f32 	%f18, %f16, %f17;
	mov.f32 	%f19, %f18;
	ex2.approx.ftz.f32 %f20,%f19;
	mov.f32 	%f21, %f20;
	.loc	15	199	0
	mov.f32 	%f22, 0f7f800000;    	// ((1.0F)/(0.0F))
	mov.f32 	%f23, 0f00000000;    	// 0
	ex2.approx.f32 	%f24, %f4;
	mul.f32 	%f25, %f21, %f24;
	mov.f32 	%f26, 0fc2380000;    	// -46
	setp.lt.f32 	%p2, %f1, %f26;
	selp.f32 	%f27, %f23, %f25, %p2;
	mov.f32 	%f28, 0f42380000;    	// 46
	setp.gt.f32 	%p3, %f1, %f28;
	selp.f32 	%f29, %f22, %f27, %p3;
	ld.param.u64 	%rd7, [__cudaparm_eexp10_vf_result];
	ld.param.s32 	%r6, [__cudaparm_eexp10_vf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f29;
$Lt_170_2562:
	exit;
$LDWend_eexp10_vf:
	} // eexp10_vf

	.entry eexp10_mf (
		.param .s32 __cudaparm_eexp10_mf_rs,
		.param .s32 __cudaparm_eexp10_mf_cs,
		.param .u64 __cudaparm_eexp10_mf_A,
		.param .s32 __cudaparm_eexp10_mf_lda,
		.param .u64 __cudaparm_eexp10_mf_B,
		.param .s32 __cudaparm_eexp10_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<31>;
	.reg .pred %p<5>;
$LDWbegin_eexp10_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eexp10_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eexp10_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_171_2818;
	ld.param.u64 	%rd1, [__cudaparm_eexp10_mf_A];
	ld.param.s32 	%r15, [__cudaparm_eexp10_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	8936	0
	mov.f32 	%f2, 0f40549a78;     	// 3.32193
	mul.f32 	%f3, %f1, %f2;
	cvt.rzi.f32.f32 	%f4, %f3;
	mov.f32 	%f5, %f4;
	mov.f32 	%f6, 0fbe9a2080;     	// -0.301029
	mov.f32 	%f7, %f6;
	mov.f32 	%f8, %f1;
	mad.f32 %f9, %f5, %f7, %f8;
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, %f4;
	mov.f32 	%f12, 0fb55427de;    	// -7.90342e-07
	mov.f32 	%f13, %f12;
	mov.f32 	%f14, %f10;
	mad.f32 %f15, %f11, %f13, %f14;
	mov.f32 	%f16, %f15;
	.loc	17	8965	0
	mov.f32 	%f17, 0f40549a78;    	// 3.32193
	mul.f32 	%f18, %f16, %f17;
	mov.f32 	%f19, %f18;
	ex2.approx.ftz.f32 %f20,%f19;
	mov.f32 	%f21, %f20;
	.loc	15	199	0
	mov.f32 	%f22, 0f7f800000;    	// ((1.0F)/(0.0F))
	mov.f32 	%f23, 0f00000000;    	// 0
	ex2.approx.f32 	%f24, %f4;
	mul.f32 	%f25, %f21, %f24;
	mov.f32 	%f26, 0fc2380000;    	// -46
	setp.lt.f32 	%p2, %f1, %f26;
	selp.f32 	%f27, %f23, %f25, %p2;
	mov.f32 	%f28, 0f42380000;    	// 46
	setp.gt.f32 	%p3, %f1, %f28;
	selp.f32 	%f29, %f22, %f27, %p3;
	ld.param.u64 	%rd5, [__cudaparm_eexp10_mf_B];
	ld.param.s32 	%r18, [__cudaparm_eexp10_mf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f29;
$Lt_171_2818:
	exit;
$LDWend_eexp10_mf:
	} // eexp10_mf

	.entry eexp2_vf (
		.param .u64 __cudaparm_eexp2_vf_n,
		.param .u64 __cudaparm_eexp2_vf_x,
		.param .s32 __cudaparm_eexp2_vf_lx,
		.param .u64 __cudaparm_eexp2_vf_result,
		.param .s32 __cudaparm_eexp2_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
	.loc	15	200	0
$LDWbegin_eexp2_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eexp2_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_172_1026;
	ld.param.u64 	%rd3, [__cudaparm_eexp2_vf_x];
	ld.param.s32 	%r4, [__cudaparm_eexp2_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	ex2.approx.f32 	%f2, %f1;
	ld.param.u64 	%rd7, [__cudaparm_eexp2_vf_result];
	ld.param.s32 	%r6, [__cudaparm_eexp2_vf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f2;
$Lt_172_1026:
	exit;
$LDWend_eexp2_vf:
	} // eexp2_vf

	.entry eexp2_mf (
		.param .s32 __cudaparm_eexp2_mf_rs,
		.param .s32 __cudaparm_eexp2_mf_cs,
		.param .u64 __cudaparm_eexp2_mf_A,
		.param .s32 __cudaparm_eexp2_mf_lda,
		.param .u64 __cudaparm_eexp2_mf_B,
		.param .s32 __cudaparm_eexp2_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
$LDWbegin_eexp2_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eexp2_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eexp2_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_173_1282;
	ld.param.u64 	%rd1, [__cudaparm_eexp2_mf_A];
	ld.param.s32 	%r15, [__cudaparm_eexp2_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	ex2.approx.f32 	%f2, %f1;
	ld.param.u64 	%rd5, [__cudaparm_eexp2_mf_B];
	ld.param.s32 	%r18, [__cudaparm_eexp2_mf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f2;
$Lt_173_1282:
	exit;
$LDWend_eexp2_mf:
	} // eexp2_mf

	.entry eexp_vf (
		.param .u64 __cudaparm_eexp_vf_n,
		.param .u64 __cudaparm_eexp_vf_x,
		.param .s32 __cudaparm_eexp_vf_lx,
		.param .u64 __cudaparm_eexp_vf_result,
		.param .s32 __cudaparm_eexp_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<31>;
	.reg .pred %p<5>;
	.loc	15	201	0
$LDWbegin_eexp_vf:
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r1, %rh1, %rh2;
	cvt.u32.u16 	%r2, %tid.x;
	add.u32 	%r3, %r2, %r1;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eexp_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_174_2562;
	ld.param.u64 	%rd3, [__cudaparm_eexp_vf_x];
	ld.param.s32 	%r4, [__cudaparm_eexp_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	8936	0
	mov.f32 	%f2, 0f3fb8aa3b;     	// 1.4427
	mul.f32 	%f3, %f1, %f2;
	cvt.rzi.f32.f32 	%f4, %f3;
	mov.f32 	%f5, %f4;
	mov.f32 	%f6, 0fbf317200;     	// -0.693146
	mov.f32 	%f7, %f6;
	mov.f32 	%f8, %f1;
	mad.f32 %f9, %f5, %f7, %f8;
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, %f4;
	mov.f32 	%f12, 0fb5bfbe8e;    	// -1.42861e-06
	mov.f32 	%f13, %f12;
	mov.f32 	%f14, %f10;
	mad.f32 %f15, %f11, %f13, %f14;
	mov.f32 	%f16, %f15;
	.loc	17	8965	0
	mov.f32 	%f17, 0f3fb8aa3b;    	// 1.4427
	mul.f32 	%f18, %f16, %f17;
	mov.f32 	%f19, %f18;
	ex2.approx.ftz.f32 %f20,%f19;
	mov.f32 	%f21, %f20;
	.loc	15	201	0
	mov.f32 	%f22, 0f7f800000;    	// ((1.0F)/(0.0F))
	mov.f32 	%f23, 0f00000000;    	// 0
	ex2.approx.f32 	%f24, %f4;
	mul.f32 	%f25, %f21, %f24;
	mov.f32 	%f26, 0fc2d20000;    	// -105
	setp.lt.f32 	%p2, %f1, %f26;
	selp.f32 	%f27, %f23, %f25, %p2;
	mov.f32 	%f28, 0f42d20000;    	// 105
	setp.gt.f32 	%p3, %f1, %f28;
	selp.f32 	%f29, %f22, %f27, %p3;
	ld.param.u64 	%rd7, [__cudaparm_eexp_vf_result];
	ld.param.s32 	%r6, [__cudaparm_eexp_vf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f29;
$Lt_174_2562:
	exit;
$LDWend_eexp_vf:
	} // eexp_vf

	.entry eexp_mf (
		.param .s32 __cudaparm_eexp_mf_rs,
		.param .s32 __cudaparm_eexp_mf_cs,
		.param .u64 __cudaparm_eexp_mf_A,
		.param .s32 __cudaparm_eexp_mf_lda,
		.param .u64 __cudaparm_eexp_mf_B,
		.param .s32 __cudaparm_eexp_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<31>;
	.reg .pred %p<5>;
$LDWbegin_eexp_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eexp_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eexp_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_175_2818;
	ld.param.u64 	%rd1, [__cudaparm_eexp_mf_A];
	ld.param.s32 	%r15, [__cudaparm_eexp_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	8936	0
	mov.f32 	%f2, 0f3fb8aa3b;     	// 1.4427
	mul.f32 	%f3, %f1, %f2;
	cvt.rzi.f32.f32 	%f4, %f3;
	mov.f32 	%f5, %f4;
	mov.f32 	%f6, 0fbf317200;     	// -0.693146
	mov.f32 	%f7, %f6;
	mov.f32 	%f8, %f1;
	mad.f32 %f9, %f5, %f7, %f8;
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, %f4;
	mov.f32 	%f12, 0fb5bfbe8e;    	// -1.42861e-06
	mov.f32 	%f13, %f12;
	mov.f32 	%f14, %f10;
	mad.f32 %f15, %f11, %f13, %f14;
	mov.f32 	%f16, %f15;
	.loc	17	8965	0
	mov.f32 	%f17, 0f3fb8aa3b;    	// 1.4427
	mul.f32 	%f18, %f16, %f17;
	mov.f32 	%f19, %f18;
	ex2.approx.ftz.f32 %f20,%f19;
	mov.f32 	%f21, %f20;
	.loc	15	201	0
	mov.f32 	%f22, 0f7f800000;    	// ((1.0F)/(0.0F))
	mov.f32 	%f23, 0f00000000;    	// 0
	ex2.approx.f32 	%f24, %f4;
	mul.f32 	%f25, %f21, %f24;
	mov.f32 	%f26, 0fc2d20000;    	// -105
	setp.lt.f32 	%p2, %f1, %f26;
	selp.f32 	%f27, %f23, %f25, %p2;
	mov.f32 	%f28, 0f42d20000;    	// 105
	setp.gt.f32 	%p3, %f1, %f28;
	selp.f32 	%f29, %f22, %f27, %p3;
	ld.param.u64 	%rd5, [__cudaparm_eexp_mf_B];
	ld.param.s32 	%r18, [__cudaparm_eexp_mf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f29;
$Lt_175_2818:
	exit;
$LDWend_eexp_mf:
	} // eexp_mf

	.entry eexpm1_vf (
		.param .u64 __cudaparm_eexpm1_vf_n,
		.param .u64 __cudaparm_eexpm1_vf_x,
		.param .s32 __cudaparm_eexpm1_vf_lx,
		.param .u64 __cudaparm_eexpm1_vf_result,
		.param .s32 __cudaparm_eexpm1_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<71>;
	.reg .pred %p<8>;
	.loc	15	202	0
$LDWbegin_eexpm1_vf:
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r1, %rh1, %rh2;
	cvt.u32.u16 	%r2, %tid.x;
	add.u32 	%r3, %r2, %r1;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_eexpm1_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_176_5634;
	ld.param.u64 	%rd3, [__cudaparm_eexpm1_vf_x];
	ld.param.s32 	%r4, [__cudaparm_eexpm1_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	8936	0
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f3fb8aa3b;     	// 1.4427
	mul.f32 	%f4, %f1, %f3;
	mov.f32 	%f5, 0f3ed1eb85;     	// 0.41
	setp.lt.f32 	%p2, %f2, %f5;
	cvt.rni.f32.f32 	%f6, %f4;
	mov.f32 	%f7, 0f00000000;     	// 0
	selp.f32 	%f8, %f7, %f6, %p2;
	neg.f32 	%f9, %f8;
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, 0f3f317200;    	// 0.693146
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f1;
	mad.f32 %f14, %f10, %f12, %f13;
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f9;
	mov.f32 	%f17, 0f35bfbe8e;    	// 1.42861e-06
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f15;
	mad.f32 %f20, %f16, %f18, %f19;
	mov.f32 	%f15, %f20;
	.loc	17	10012	0
	mov.f32 	%f21, %f15;
	.loc	17	8936	0
	mov.f32 	%f22, 0f3ab5ebe6;    	// 0.00138795
	mov.f32 	%f23, %f22;
	mov.f32 	%f24, %f15;
	mov.f32 	%f25, 0f3c095663;    	// 0.00838241
	mov.f32 	%f26, %f25;
	mad.f32 %f27, %f23, %f24, %f26;
	mov.f32 	%f15, %f27;
	mov.f32 	%f28, %f15;
	mov.f32 	%f29, %f21;
	mov.f32 	%f30, 0f3d2aabe3;    	// 0.0416678
	mov.f32 	%f31, %f30;
	mad.f32 %f32, %f28, %f29, %f31;
	mov.f32 	%f15, %f32;
	mov.f32 	%f33, %f15;
	mov.f32 	%f34, %f21;
	mov.f32 	%f35, 0f3e2aa9f6;    	// 0.166664
	mov.f32 	%f36, %f35;
	mad.f32 %f37, %f33, %f34, %f36;
	mov.f32 	%f15, %f37;
	mov.f32 	%f38, %f15;
	mov.f32 	%f39, %f21;
	mov.f32 	%f40, 0f3efffffe;    	// 0.5
	mov.f32 	%f41, %f40;
	mad.f32 %f42, %f38, %f39, %f41;
	mov.f32 	%f15, %f42;
	mul.f32 	%f43, %f15, %f21;
	mov.f32 	%f44, %f43;
	mov.f32 	%f45, %f21;
	mov.f32 	%f46, %f21;
	mad.f32 %f47, %f44, %f45, %f46;
	mov.f32 	%f15, %f47;
	mov.f32 	%f48, 0f43000000;    	// 128
	setp.eq.f32 	%p3, %f8, %f48;
	mov.f32 	%f49, 0fbf800000;    	// -1
	add.f32 	%f50, %f8, %f49;
	selp.f32 	%f51, %f50, %f8, %p3;
	ex2.approx.f32 	%f52, %f51;
	mov.f32 	%f53, %f15;
	mov.f32 	%f54, %f52;
	mov.f32 	%f55, 0fbf800000;    	// -1
	add.f32 	%f56, %f52, %f55;
	mov.f32 	%f57, %f56;
	mad.f32 %f58, %f53, %f54, %f57;
	mov.f32 	%f15, %f58;
	.loc	15	202	0
	add.f32 	%f59, %f1, %f1;
	mov.f32 	%f60, 0fbf800000;    	// -1
	mov.f32 	%f61, 0f7f800000;    	// ((1.0F)/(0.0F))
	add.f32 	%f62, %f15, %f15;
	selp.f32 	%f63, %f62, %f15, %p3;
	mov.f32 	%f64, 0f43000000;    	// 128
	setp.gt.f32 	%p4, %f51, %f64;
	selp.f32 	%f65, %f61, %f63, %p4;
	mov.f32 	%f66, 0fc1c80000;    	// -25
	setp.lt.f32 	%p5, %f51, %f66;
	selp.f32 	%f67, %f60, %f65, %p5;
	mov.f32 	%f68, 0f00000000;    	// 0
	setp.eq.f32 	%p6, %f1, %f68;
	selp.f32 	%f69, %f59, %f67, %p6;
	ld.param.u64 	%rd7, [__cudaparm_eexpm1_vf_result];
	ld.param.s32 	%r6, [__cudaparm_eexpm1_vf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f69;
$Lt_176_5634:
	exit;
$LDWend_eexpm1_vf:
	} // eexpm1_vf

	.entry eexpm1_mf (
		.param .s32 __cudaparm_eexpm1_mf_rs,
		.param .s32 __cudaparm_eexpm1_mf_cs,
		.param .u64 __cudaparm_eexpm1_mf_A,
		.param .s32 __cudaparm_eexpm1_mf_lda,
		.param .u64 __cudaparm_eexpm1_mf_B,
		.param .s32 __cudaparm_eexpm1_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<71>;
	.reg .pred %p<8>;
$LDWbegin_eexpm1_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_eexpm1_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_eexpm1_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_177_5890;
	ld.param.u64 	%rd1, [__cudaparm_eexpm1_mf_A];
	ld.param.s32 	%r15, [__cudaparm_eexpm1_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	8936	0
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f3fb8aa3b;     	// 1.4427
	mul.f32 	%f4, %f1, %f3;
	mov.f32 	%f5, 0f3ed1eb85;     	// 0.41
	setp.lt.f32 	%p2, %f2, %f5;
	cvt.rni.f32.f32 	%f6, %f4;
	mov.f32 	%f7, 0f00000000;     	// 0
	selp.f32 	%f8, %f7, %f6, %p2;
	neg.f32 	%f9, %f8;
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, 0f3f317200;    	// 0.693146
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f1;
	mad.f32 %f14, %f10, %f12, %f13;
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f9;
	mov.f32 	%f17, 0f35bfbe8e;    	// 1.42861e-06
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f15;
	mad.f32 %f20, %f16, %f18, %f19;
	mov.f32 	%f15, %f20;
	.loc	17	10012	0
	mov.f32 	%f21, %f15;
	.loc	17	8936	0
	mov.f32 	%f22, 0f3ab5ebe6;    	// 0.00138795
	mov.f32 	%f23, %f22;
	mov.f32 	%f24, %f15;
	mov.f32 	%f25, 0f3c095663;    	// 0.00838241
	mov.f32 	%f26, %f25;
	mad.f32 %f27, %f23, %f24, %f26;
	mov.f32 	%f15, %f27;
	mov.f32 	%f28, %f15;
	mov.f32 	%f29, %f21;
	mov.f32 	%f30, 0f3d2aabe3;    	// 0.0416678
	mov.f32 	%f31, %f30;
	mad.f32 %f32, %f28, %f29, %f31;
	mov.f32 	%f15, %f32;
	mov.f32 	%f33, %f15;
	mov.f32 	%f34, %f21;
	mov.f32 	%f35, 0f3e2aa9f6;    	// 0.166664
	mov.f32 	%f36, %f35;
	mad.f32 %f37, %f33, %f34, %f36;
	mov.f32 	%f15, %f37;
	mov.f32 	%f38, %f15;
	mov.f32 	%f39, %f21;
	mov.f32 	%f40, 0f3efffffe;    	// 0.5
	mov.f32 	%f41, %f40;
	mad.f32 %f42, %f38, %f39, %f41;
	mov.f32 	%f15, %f42;
	mul.f32 	%f43, %f15, %f21;
	mov.f32 	%f44, %f43;
	mov.f32 	%f45, %f21;
	mov.f32 	%f46, %f21;
	mad.f32 %f47, %f44, %f45, %f46;
	mov.f32 	%f15, %f47;
	mov.f32 	%f48, 0f43000000;    	// 128
	setp.eq.f32 	%p3, %f8, %f48;
	mov.f32 	%f49, 0fbf800000;    	// -1
	add.f32 	%f50, %f8, %f49;
	selp.f32 	%f51, %f50, %f8, %p3;
	ex2.approx.f32 	%f52, %f51;
	mov.f32 	%f53, %f15;
	mov.f32 	%f54, %f52;
	mov.f32 	%f55, 0fbf800000;    	// -1
	add.f32 	%f56, %f52, %f55;
	mov.f32 	%f57, %f56;
	mad.f32 %f58, %f53, %f54, %f57;
	mov.f32 	%f15, %f58;
	.loc	15	202	0
	add.f32 	%f59, %f1, %f1;
	mov.f32 	%f60, 0fbf800000;    	// -1
	mov.f32 	%f61, 0f7f800000;    	// ((1.0F)/(0.0F))
	add.f32 	%f62, %f15, %f15;
	selp.f32 	%f63, %f62, %f15, %p3;
	mov.f32 	%f64, 0f43000000;    	// 128
	setp.gt.f32 	%p4, %f51, %f64;
	selp.f32 	%f65, %f61, %f63, %p4;
	mov.f32 	%f66, 0fc1c80000;    	// -25
	setp.lt.f32 	%p5, %f51, %f66;
	selp.f32 	%f67, %f60, %f65, %p5;
	mov.f32 	%f68, 0f00000000;    	// 0
	setp.eq.f32 	%p6, %f1, %f68;
	selp.f32 	%f69, %f59, %f67, %p6;
	ld.param.u64 	%rd5, [__cudaparm_eexpm1_mf_B];
	ld.param.s32 	%r18, [__cudaparm_eexpm1_mf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f69;
$Lt_177_5890:
	exit;
$LDWend_eexpm1_mf:
	} // eexpm1_mf

	.entry elog10_vf (
		.param .u64 __cudaparm_elog10_vf_n,
		.param .u64 __cudaparm_elog10_vf_x,
		.param .s32 __cudaparm_elog10_vf_lx,
		.param .u64 __cudaparm_elog10_vf_result,
		.param .s32 __cudaparm_elog10_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<19>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<54>;
	.reg .pred %p<5>;
	.loc	15	204	0
$LDWbegin_elog10_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_elog10_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_178_2818;
	ld.param.u64 	%rd3, [__cudaparm_elog10_vf_x];
	ld.param.s32 	%r4, [__cudaparm_elog10_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	9936	0
	mov.f32 	%f2, 0f00000000;     	// 0
	set.gt.u32.f32 	%r6, %f1, %f2;
	neg.s32 	%r7, %r6;
	mov.f32 	%f3, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r8, %f1, %f3;
	neg.s32 	%r9, %r8;
	and.b32 	%r10, %r7, %r9;
	mov.u32 	%r11, 0;
	setp.eq.s32 	%p2, %r10, %r11;
	@%p2 bra 	$Lt_178_3586;
	.loc	17	9039	0
	mov.b32 	%r12, %f1;
	and.b32 	%r13, %r12, 8388607;
	or.b32 	%r14, %r13, 1065353216;
	mov.b32 	%f4, %r14;
	mov.f32 	%f5, %f4;
	.loc	17	9040	0
	shr.u32 	%r15, %r12, 23;
	cvt.rn.f32.u32 	%f6, %r15;
	mov.f32 	%f7, 0fc2fe0000;     	// -127
	add.f32 	%f8, %f6, %f7;
	mov.f32 	%f9, 0f3fb504f3;     	// 1.41421
	setp.gt.f32 	%p3, %f4, %f9;
	@!%p3 bra 	$Lt_178_3842;
	.loc	17	9042	0
	mov.f32 	%f10, 0f3f000000;    	// 0.5
	mul.f32 	%f5, %f4, %f10;
	.loc	17	9043	0
	mov.f32 	%f11, 0f3f800000;    	// 1
	add.f32 	%f8, %f8, %f11;
$Lt_178_3842:
	.loc	17	8944	0
	mov.f32 	%f12, 0f3f800000;    	// 1
	add.f32 	%f13, %f5, %f12;
	mov.f32 	%f14, %f13;
	rcp.approx.ftz.f32 %f15,%f14;
	mov.f32 	%f16, %f15;
	.loc	17	8936	0
	mov.f32 	%f17, 0fbf800000;    	// -1
	add.f32 	%f18, %f5, %f17;
	mul.f32 	%f19, %f18, %f18;
	neg.f32 	%f20, %f19;
	mul.rn.f32 	%f21, %f16, %f20;
	add.rn.f32 	%f22, %f18, %f21;
	mul.f32 	%f23, %f22, %f22;
	mov.f32 	%f24, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f25, %f24;
	mov.f32 	%f26, %f23;
	mov.f32 	%f27, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f28, %f27;
	mad.f32 %f29, %f25, %f26, %f28;
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f30;
	mov.f32 	%f32, %f23;
	mov.f32 	%f33, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f34, %f33;
	mad.f32 %f35, %f31, %f32, %f34;
	mov.f32 	%f36, %f35;
	mul.f32 	%f37, %f23, %f36;
	mov.f32 	%f38, %f37;
	mov.f32 	%f39, %f22;
	mov.f32 	%f40, %f21;
	mad.f32 %f41, %f38, %f39, %f40;
	mov.f32 	%f42, %f41;
	mov.f32 	%f43, %f8;
	mov.f32 	%f44, 0f3f317218;    	// 0.693147
	mov.f32 	%f45, %f44;
	add.f32 	%f46, %f18, %f42;
	mov.f32 	%f47, %f46;
	mad.f32 %f48, %f43, %f45, %f47;
	mov.f32 	%f49, %f48;
	.loc	17	9050	0
	mov.f32 	%f50, %f49;
	bra.uni 	$Lt_178_3330;
$Lt_178_3586:
	.loc	17	9053	0
	lg2.approx.f32 	%f50, %f1;
$Lt_178_3330:
	.loc	15	204	0
	mov.f32 	%f51, 0f3ede5bd9;    	// 0.434294
	mul.f32 	%f52, %f50, %f51;
	ld.param.u64 	%rd7, [__cudaparm_elog10_vf_result];
	ld.param.s32 	%r16, [__cudaparm_elog10_vf_lr];
	mul.lo.s32 	%r17, %r16, %r3;
	cvt.s64.s32 	%rd8, %r17;
	mul.wide.s32 	%rd9, %r17, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f52;
$Lt_178_2818:
	exit;
$LDWend_elog10_vf:
	} // elog10_vf

	.entry elog10_mf (
		.param .s32 __cudaparm_elog10_mf_rs,
		.param .s32 __cudaparm_elog10_mf_cs,
		.param .u64 __cudaparm_elog10_mf_A,
		.param .s32 __cudaparm_elog10_mf_lda,
		.param .u64 __cudaparm_elog10_mf_B,
		.param .s32 __cudaparm_elog10_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<32>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<54>;
	.reg .pred %p<5>;
$LDWbegin_elog10_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_elog10_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_elog10_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_179_3074;
	ld.param.u64 	%rd1, [__cudaparm_elog10_mf_A];
	ld.param.s32 	%r15, [__cudaparm_elog10_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	9936	0
	mov.f32 	%f2, 0f00000000;     	// 0
	set.gt.u32.f32 	%r18, %f1, %f2;
	neg.s32 	%r19, %r18;
	mov.f32 	%f3, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r20, %f1, %f3;
	neg.s32 	%r21, %r20;
	and.b32 	%r22, %r19, %r21;
	mov.u32 	%r23, 0;
	setp.eq.s32 	%p2, %r22, %r23;
	@%p2 bra 	$Lt_179_3842;
	.loc	17	9039	0
	mov.b32 	%r24, %f1;
	and.b32 	%r25, %r24, 8388607;
	or.b32 	%r26, %r25, 1065353216;
	mov.b32 	%f4, %r26;
	mov.f32 	%f5, %f4;
	.loc	17	9040	0
	shr.u32 	%r27, %r24, 23;
	cvt.rn.f32.u32 	%f6, %r27;
	mov.f32 	%f7, 0fc2fe0000;     	// -127
	add.f32 	%f8, %f6, %f7;
	mov.f32 	%f9, 0f3fb504f3;     	// 1.41421
	setp.gt.f32 	%p3, %f4, %f9;
	@!%p3 bra 	$Lt_179_4098;
	.loc	17	9042	0
	mov.f32 	%f10, 0f3f000000;    	// 0.5
	mul.f32 	%f5, %f4, %f10;
	.loc	17	9043	0
	mov.f32 	%f11, 0f3f800000;    	// 1
	add.f32 	%f8, %f8, %f11;
$Lt_179_4098:
	.loc	17	8944	0
	mov.f32 	%f12, 0f3f800000;    	// 1
	add.f32 	%f13, %f5, %f12;
	mov.f32 	%f14, %f13;
	rcp.approx.ftz.f32 %f15,%f14;
	mov.f32 	%f16, %f15;
	.loc	17	8936	0
	mov.f32 	%f17, 0fbf800000;    	// -1
	add.f32 	%f18, %f5, %f17;
	mul.f32 	%f19, %f18, %f18;
	neg.f32 	%f20, %f19;
	mul.rn.f32 	%f21, %f16, %f20;
	add.rn.f32 	%f22, %f18, %f21;
	mul.f32 	%f23, %f22, %f22;
	mov.f32 	%f24, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f25, %f24;
	mov.f32 	%f26, %f23;
	mov.f32 	%f27, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f28, %f27;
	mad.f32 %f29, %f25, %f26, %f28;
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f30;
	mov.f32 	%f32, %f23;
	mov.f32 	%f33, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f34, %f33;
	mad.f32 %f35, %f31, %f32, %f34;
	mov.f32 	%f36, %f35;
	mul.f32 	%f37, %f23, %f36;
	mov.f32 	%f38, %f37;
	mov.f32 	%f39, %f22;
	mov.f32 	%f40, %f21;
	mad.f32 %f41, %f38, %f39, %f40;
	mov.f32 	%f42, %f41;
	mov.f32 	%f43, %f8;
	mov.f32 	%f44, 0f3f317218;    	// 0.693147
	mov.f32 	%f45, %f44;
	add.f32 	%f46, %f18, %f42;
	mov.f32 	%f47, %f46;
	mad.f32 %f48, %f43, %f45, %f47;
	mov.f32 	%f49, %f48;
	.loc	17	9050	0
	mov.f32 	%f50, %f49;
	bra.uni 	$Lt_179_3586;
$Lt_179_3842:
	.loc	17	9053	0
	lg2.approx.f32 	%f50, %f1;
$Lt_179_3586:
	.loc	15	204	0
	mov.f32 	%f51, 0f3ede5bd9;    	// 0.434294
	mul.f32 	%f52, %f50, %f51;
	ld.param.u64 	%rd5, [__cudaparm_elog10_mf_B];
	ld.param.s32 	%r28, [__cudaparm_elog10_mf_ldb];
	mul.lo.s32 	%r29, %r28, %r4;
	add.s32 	%r30, %r6, %r29;
	cvt.s64.s32 	%rd6, %r30;
	mul.wide.s32 	%rd7, %r30, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f52;
$Lt_179_3074:
	exit;
$LDWend_elog10_mf:
	} // elog10_mf

	.entry elog2_vf (
		.param .u64 __cudaparm_elog2_vf_n,
		.param .u64 __cudaparm_elog2_vf_x,
		.param .s32 __cudaparm_elog2_vf_lx,
		.param .u64 __cudaparm_elog2_vf_result,
		.param .s32 __cudaparm_elog2_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<19>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<54>;
	.reg .pred %p<5>;
	.loc	15	205	0
$LDWbegin_elog2_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_elog2_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_180_2818;
	ld.param.u64 	%rd3, [__cudaparm_elog2_vf_x];
	ld.param.s32 	%r4, [__cudaparm_elog2_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	9139	0
	mov.f32 	%f2, 0f00000000;     	// 0
	set.gt.u32.f32 	%r6, %f1, %f2;
	neg.s32 	%r7, %r6;
	mov.f32 	%f3, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r8, %f1, %f3;
	neg.s32 	%r9, %r8;
	and.b32 	%r10, %r7, %r9;
	mov.u32 	%r11, 0;
	setp.eq.s32 	%p2, %r10, %r11;
	@%p2 bra 	$Lt_180_3586;
	.loc	17	9039	0
	mov.b32 	%r12, %f1;
	and.b32 	%r13, %r12, 8388607;
	or.b32 	%r14, %r13, 1065353216;
	mov.b32 	%f4, %r14;
	mov.f32 	%f5, %f4;
	.loc	17	9040	0
	shr.u32 	%r15, %r12, 23;
	cvt.rn.f32.u32 	%f6, %r15;
	mov.f32 	%f7, 0fc2fe0000;     	// -127
	add.f32 	%f8, %f6, %f7;
	mov.f32 	%f9, 0f3fb504f3;     	// 1.41421
	setp.gt.f32 	%p3, %f4, %f9;
	@!%p3 bra 	$Lt_180_3842;
	.loc	17	9042	0
	mov.f32 	%f10, 0f3f000000;    	// 0.5
	mul.f32 	%f5, %f4, %f10;
	.loc	17	9043	0
	mov.f32 	%f11, 0f3f800000;    	// 1
	add.f32 	%f8, %f8, %f11;
$Lt_180_3842:
	.loc	17	8944	0
	mov.f32 	%f12, 0f3f800000;    	// 1
	add.f32 	%f13, %f5, %f12;
	mov.f32 	%f14, %f13;
	rcp.approx.ftz.f32 %f15,%f14;
	mov.f32 	%f16, %f15;
	.loc	17	8936	0
	mov.f32 	%f17, 0fbf800000;    	// -1
	add.f32 	%f18, %f5, %f17;
	mul.f32 	%f19, %f18, %f18;
	neg.f32 	%f20, %f19;
	mul.rn.f32 	%f21, %f16, %f20;
	add.rn.f32 	%f22, %f18, %f21;
	mul.f32 	%f23, %f22, %f22;
	mov.f32 	%f24, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f25, %f24;
	mov.f32 	%f26, %f23;
	mov.f32 	%f27, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f28, %f27;
	mad.f32 %f29, %f25, %f26, %f28;
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f30;
	mov.f32 	%f32, %f23;
	mov.f32 	%f33, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f34, %f33;
	mad.f32 %f35, %f31, %f32, %f34;
	mov.f32 	%f36, %f35;
	mul.f32 	%f37, %f23, %f36;
	mov.f32 	%f38, %f37;
	mov.f32 	%f39, %f22;
	mov.f32 	%f40, %f21;
	mad.f32 %f41, %f38, %f39, %f40;
	mov.f32 	%f42, %f41;
	mov.f32 	%f43, %f8;
	mov.f32 	%f44, 0f3f317218;    	// 0.693147
	mov.f32 	%f45, %f44;
	add.f32 	%f46, %f18, %f42;
	mov.f32 	%f47, %f46;
	mad.f32 %f48, %f43, %f45, %f47;
	mov.f32 	%f49, %f48;
	.loc	17	9050	0
	mov.f32 	%f50, %f49;
	bra.uni 	$Lt_180_3330;
$Lt_180_3586:
	.loc	17	9053	0
	lg2.approx.f32 	%f50, %f1;
$Lt_180_3330:
	.loc	15	205	0
	mov.f32 	%f51, 0f3fb8aa3b;    	// 1.4427
	mul.f32 	%f52, %f50, %f51;
	ld.param.u64 	%rd7, [__cudaparm_elog2_vf_result];
	ld.param.s32 	%r16, [__cudaparm_elog2_vf_lr];
	mul.lo.s32 	%r17, %r16, %r3;
	cvt.s64.s32 	%rd8, %r17;
	mul.wide.s32 	%rd9, %r17, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f52;
$Lt_180_2818:
	exit;
$LDWend_elog2_vf:
	} // elog2_vf

	.entry elog2_mf (
		.param .s32 __cudaparm_elog2_mf_rs,
		.param .s32 __cudaparm_elog2_mf_cs,
		.param .u64 __cudaparm_elog2_mf_A,
		.param .s32 __cudaparm_elog2_mf_lda,
		.param .u64 __cudaparm_elog2_mf_B,
		.param .s32 __cudaparm_elog2_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<32>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<54>;
	.reg .pred %p<5>;
$LDWbegin_elog2_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_elog2_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_elog2_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_181_3074;
	ld.param.u64 	%rd1, [__cudaparm_elog2_mf_A];
	ld.param.s32 	%r15, [__cudaparm_elog2_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	9139	0
	mov.f32 	%f2, 0f00000000;     	// 0
	set.gt.u32.f32 	%r18, %f1, %f2;
	neg.s32 	%r19, %r18;
	mov.f32 	%f3, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r20, %f1, %f3;
	neg.s32 	%r21, %r20;
	and.b32 	%r22, %r19, %r21;
	mov.u32 	%r23, 0;
	setp.eq.s32 	%p2, %r22, %r23;
	@%p2 bra 	$Lt_181_3842;
	.loc	17	9039	0
	mov.b32 	%r24, %f1;
	and.b32 	%r25, %r24, 8388607;
	or.b32 	%r26, %r25, 1065353216;
	mov.b32 	%f4, %r26;
	mov.f32 	%f5, %f4;
	.loc	17	9040	0
	shr.u32 	%r27, %r24, 23;
	cvt.rn.f32.u32 	%f6, %r27;
	mov.f32 	%f7, 0fc2fe0000;     	// -127
	add.f32 	%f8, %f6, %f7;
	mov.f32 	%f9, 0f3fb504f3;     	// 1.41421
	setp.gt.f32 	%p3, %f4, %f9;
	@!%p3 bra 	$Lt_181_4098;
	.loc	17	9042	0
	mov.f32 	%f10, 0f3f000000;    	// 0.5
	mul.f32 	%f5, %f4, %f10;
	.loc	17	9043	0
	mov.f32 	%f11, 0f3f800000;    	// 1
	add.f32 	%f8, %f8, %f11;
$Lt_181_4098:
	.loc	17	8944	0
	mov.f32 	%f12, 0f3f800000;    	// 1
	add.f32 	%f13, %f5, %f12;
	mov.f32 	%f14, %f13;
	rcp.approx.ftz.f32 %f15,%f14;
	mov.f32 	%f16, %f15;
	.loc	17	8936	0
	mov.f32 	%f17, 0fbf800000;    	// -1
	add.f32 	%f18, %f5, %f17;
	mul.f32 	%f19, %f18, %f18;
	neg.f32 	%f20, %f19;
	mul.rn.f32 	%f21, %f16, %f20;
	add.rn.f32 	%f22, %f18, %f21;
	mul.f32 	%f23, %f22, %f22;
	mov.f32 	%f24, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f25, %f24;
	mov.f32 	%f26, %f23;
	mov.f32 	%f27, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f28, %f27;
	mad.f32 %f29, %f25, %f26, %f28;
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f30;
	mov.f32 	%f32, %f23;
	mov.f32 	%f33, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f34, %f33;
	mad.f32 %f35, %f31, %f32, %f34;
	mov.f32 	%f36, %f35;
	mul.f32 	%f37, %f23, %f36;
	mov.f32 	%f38, %f37;
	mov.f32 	%f39, %f22;
	mov.f32 	%f40, %f21;
	mad.f32 %f41, %f38, %f39, %f40;
	mov.f32 	%f42, %f41;
	mov.f32 	%f43, %f8;
	mov.f32 	%f44, 0f3f317218;    	// 0.693147
	mov.f32 	%f45, %f44;
	add.f32 	%f46, %f18, %f42;
	mov.f32 	%f47, %f46;
	mad.f32 %f48, %f43, %f45, %f47;
	mov.f32 	%f49, %f48;
	.loc	17	9050	0
	mov.f32 	%f50, %f49;
	bra.uni 	$Lt_181_3586;
$Lt_181_3842:
	.loc	17	9053	0
	lg2.approx.f32 	%f50, %f1;
$Lt_181_3586:
	.loc	15	205	0
	mov.f32 	%f51, 0f3fb8aa3b;    	// 1.4427
	mul.f32 	%f52, %f50, %f51;
	ld.param.u64 	%rd5, [__cudaparm_elog2_mf_B];
	ld.param.s32 	%r28, [__cudaparm_elog2_mf_ldb];
	mul.lo.s32 	%r29, %r28, %r4;
	add.s32 	%r30, %r6, %r29;
	cvt.s64.s32 	%rd6, %r30;
	mul.wide.s32 	%rd7, %r30, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f52;
$Lt_181_3074:
	exit;
$LDWend_elog2_mf:
	} // elog2_mf

	.entry elog_vf (
		.param .u64 __cudaparm_elog_vf_n,
		.param .u64 __cudaparm_elog_vf_x,
		.param .s32 __cudaparm_elog_vf_lx,
		.param .u64 __cudaparm_elog_vf_result,
		.param .s32 __cudaparm_elog_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<19>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<52>;
	.reg .pred %p<5>;
	.loc	15	206	0
$LDWbegin_elog_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_elog_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_182_2818;
	ld.param.u64 	%rd3, [__cudaparm_elog_vf_x];
	ld.param.s32 	%r4, [__cudaparm_elog_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	9927	0
	mov.f32 	%f2, 0f00000000;     	// 0
	set.gt.u32.f32 	%r6, %f1, %f2;
	neg.s32 	%r7, %r6;
	mov.f32 	%f3, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r8, %f1, %f3;
	neg.s32 	%r9, %r8;
	and.b32 	%r10, %r7, %r9;
	mov.u32 	%r11, 0;
	setp.eq.s32 	%p2, %r10, %r11;
	@%p2 bra 	$Lt_182_3586;
	.loc	17	9039	0
	mov.b32 	%r12, %f1;
	and.b32 	%r13, %r12, 8388607;
	or.b32 	%r14, %r13, 1065353216;
	mov.b32 	%f4, %r14;
	mov.f32 	%f5, %f4;
	.loc	17	9040	0
	shr.u32 	%r15, %r12, 23;
	cvt.rn.f32.u32 	%f6, %r15;
	mov.f32 	%f7, 0fc2fe0000;     	// -127
	add.f32 	%f8, %f6, %f7;
	mov.f32 	%f9, 0f3fb504f3;     	// 1.41421
	setp.gt.f32 	%p3, %f4, %f9;
	@!%p3 bra 	$Lt_182_3842;
	.loc	17	9042	0
	mov.f32 	%f10, 0f3f000000;    	// 0.5
	mul.f32 	%f5, %f4, %f10;
	.loc	17	9043	0
	mov.f32 	%f11, 0f3f800000;    	// 1
	add.f32 	%f8, %f8, %f11;
$Lt_182_3842:
	.loc	17	8944	0
	mov.f32 	%f12, 0f3f800000;    	// 1
	add.f32 	%f13, %f5, %f12;
	mov.f32 	%f14, %f13;
	rcp.approx.ftz.f32 %f15,%f14;
	mov.f32 	%f16, %f15;
	.loc	17	8936	0
	mov.f32 	%f17, 0fbf800000;    	// -1
	add.f32 	%f18, %f5, %f17;
	mul.f32 	%f19, %f18, %f18;
	neg.f32 	%f20, %f19;
	mul.rn.f32 	%f21, %f16, %f20;
	add.rn.f32 	%f22, %f18, %f21;
	mul.f32 	%f23, %f22, %f22;
	mov.f32 	%f24, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f25, %f24;
	mov.f32 	%f26, %f23;
	mov.f32 	%f27, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f28, %f27;
	mad.f32 %f29, %f25, %f26, %f28;
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f30;
	mov.f32 	%f32, %f23;
	mov.f32 	%f33, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f34, %f33;
	mad.f32 %f35, %f31, %f32, %f34;
	mov.f32 	%f36, %f35;
	mul.f32 	%f37, %f23, %f36;
	mov.f32 	%f38, %f37;
	mov.f32 	%f39, %f22;
	mov.f32 	%f40, %f21;
	mad.f32 %f41, %f38, %f39, %f40;
	mov.f32 	%f42, %f41;
	mov.f32 	%f43, %f8;
	mov.f32 	%f44, 0f3f317218;    	// 0.693147
	mov.f32 	%f45, %f44;
	add.f32 	%f46, %f18, %f42;
	mov.f32 	%f47, %f46;
	mad.f32 %f48, %f43, %f45, %f47;
	mov.f32 	%f49, %f48;
	.loc	17	9050	0
	mov.f32 	%f50, %f49;
	bra.uni 	$Lt_182_3330;
$Lt_182_3586:
	.loc	17	9053	0
	lg2.approx.f32 	%f50, %f1;
$Lt_182_3330:
	.loc	15	206	0
	ld.param.u64 	%rd7, [__cudaparm_elog_vf_result];
	ld.param.s32 	%r16, [__cudaparm_elog_vf_lr];
	mul.lo.s32 	%r17, %r16, %r3;
	cvt.s64.s32 	%rd8, %r17;
	mul.wide.s32 	%rd9, %r17, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f50;
$Lt_182_2818:
	exit;
$LDWend_elog_vf:
	} // elog_vf

	.entry elog_mf (
		.param .s32 __cudaparm_elog_mf_rs,
		.param .s32 __cudaparm_elog_mf_cs,
		.param .u64 __cudaparm_elog_mf_A,
		.param .s32 __cudaparm_elog_mf_lda,
		.param .u64 __cudaparm_elog_mf_B,
		.param .s32 __cudaparm_elog_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<32>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<52>;
	.reg .pred %p<5>;
$LDWbegin_elog_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_elog_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_elog_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_183_3074;
	ld.param.u64 	%rd1, [__cudaparm_elog_mf_A];
	ld.param.s32 	%r15, [__cudaparm_elog_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	9927	0
	mov.f32 	%f2, 0f00000000;     	// 0
	set.gt.u32.f32 	%r18, %f1, %f2;
	neg.s32 	%r19, %r18;
	mov.f32 	%f3, 0f7f800000;     	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r20, %f1, %f3;
	neg.s32 	%r21, %r20;
	and.b32 	%r22, %r19, %r21;
	mov.u32 	%r23, 0;
	setp.eq.s32 	%p2, %r22, %r23;
	@%p2 bra 	$Lt_183_3842;
	.loc	17	9039	0
	mov.b32 	%r24, %f1;
	and.b32 	%r25, %r24, 8388607;
	or.b32 	%r26, %r25, 1065353216;
	mov.b32 	%f4, %r26;
	mov.f32 	%f5, %f4;
	.loc	17	9040	0
	shr.u32 	%r27, %r24, 23;
	cvt.rn.f32.u32 	%f6, %r27;
	mov.f32 	%f7, 0fc2fe0000;     	// -127
	add.f32 	%f8, %f6, %f7;
	mov.f32 	%f9, 0f3fb504f3;     	// 1.41421
	setp.gt.f32 	%p3, %f4, %f9;
	@!%p3 bra 	$Lt_183_4098;
	.loc	17	9042	0
	mov.f32 	%f10, 0f3f000000;    	// 0.5
	mul.f32 	%f5, %f4, %f10;
	.loc	17	9043	0
	mov.f32 	%f11, 0f3f800000;    	// 1
	add.f32 	%f8, %f8, %f11;
$Lt_183_4098:
	.loc	17	8944	0
	mov.f32 	%f12, 0f3f800000;    	// 1
	add.f32 	%f13, %f5, %f12;
	mov.f32 	%f14, %f13;
	rcp.approx.ftz.f32 %f15,%f14;
	mov.f32 	%f16, %f15;
	.loc	17	8936	0
	mov.f32 	%f17, 0fbf800000;    	// -1
	add.f32 	%f18, %f5, %f17;
	mul.f32 	%f19, %f18, %f18;
	neg.f32 	%f20, %f19;
	mul.rn.f32 	%f21, %f16, %f20;
	add.rn.f32 	%f22, %f18, %f21;
	mul.f32 	%f23, %f22, %f22;
	mov.f32 	%f24, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f25, %f24;
	mov.f32 	%f26, %f23;
	mov.f32 	%f27, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f28, %f27;
	mad.f32 %f29, %f25, %f26, %f28;
	mov.f32 	%f30, %f29;
	mov.f32 	%f31, %f30;
	mov.f32 	%f32, %f23;
	mov.f32 	%f33, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f34, %f33;
	mad.f32 %f35, %f31, %f32, %f34;
	mov.f32 	%f36, %f35;
	mul.f32 	%f37, %f23, %f36;
	mov.f32 	%f38, %f37;
	mov.f32 	%f39, %f22;
	mov.f32 	%f40, %f21;
	mad.f32 %f41, %f38, %f39, %f40;
	mov.f32 	%f42, %f41;
	mov.f32 	%f43, %f8;
	mov.f32 	%f44, 0f3f317218;    	// 0.693147
	mov.f32 	%f45, %f44;
	add.f32 	%f46, %f18, %f42;
	mov.f32 	%f47, %f46;
	mad.f32 %f48, %f43, %f45, %f47;
	mov.f32 	%f49, %f48;
	.loc	17	9050	0
	mov.f32 	%f50, %f49;
	bra.uni 	$Lt_183_3586;
$Lt_183_3842:
	.loc	17	9053	0
	lg2.approx.f32 	%f50, %f1;
$Lt_183_3586:
	.loc	15	206	0
	ld.param.u64 	%rd5, [__cudaparm_elog_mf_B];
	ld.param.s32 	%r28, [__cudaparm_elog_mf_ldb];
	mul.lo.s32 	%r29, %r28, %r4;
	add.s32 	%r30, %r6, %r29;
	cvt.s64.s32 	%rd6, %r30;
	mul.wide.s32 	%rd7, %r30, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f50;
$Lt_183_3074:
	exit;
$LDWend_elog_mf:
	} // elog_mf

	.entry elog1p_vf (
		.param .u64 __cudaparm_elog1p_vf_n,
		.param .u64 __cudaparm_elog1p_vf_x,
		.param .s32 __cudaparm_elog1p_vf_lx,
		.param .u64 __cudaparm_elog1p_vf_result,
		.param .s32 __cudaparm_elog1p_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<25>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<83>;
	.reg .pred %p<6>;
	.loc	15	207	0
$LDWbegin_elog1p_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_elog1p_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_184_3842;
	ld.param.u64 	%rd3, [__cudaparm_elog1p_vf_x];
	ld.param.s32 	%r4, [__cudaparm_elog1p_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	mov.f32 	%f2, 0fbec9ba5e;     	// -0.394
	set.ge.u32.f32 	%r6, %f1, %f2;
	neg.s32 	%r7, %r6;
	mov.f32 	%f3, 0f3f266666;     	// 0.65
	set.le.u32.f32 	%r8, %f1, %f3;
	neg.s32 	%r9, %r8;
	and.b32 	%r10, %r7, %r9;
	mov.u32 	%r11, 0;
	setp.eq.s32 	%p2, %r10, %r11;
	@%p2 bra 	$Lt_184_4610;
	.loc	17	8936	0
	neg.f32 	%f4, %f1;
	mov.f32 	%f5, 0f40000000;     	// 2
	add.f32 	%f6, %f1, %f5;
	div.approx.f32 	%f7, %f1, %f6;
	mul.rn.f32 	%f8, %f4, %f7;
	add.rn.f32 	%f9, %f1, %f8;
	mul.f32 	%f10, %f9, %f9;
	mov.f32 	%f11, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f10;
	mov.f32 	%f14, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f15, %f14;
	mad.f32 %f16, %f12, %f13, %f15;
	mov.f32 	%f17, %f16;
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f10;
	mov.f32 	%f20, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f21, %f20;
	mad.f32 %f22, %f18, %f19, %f21;
	mov.f32 	%f23, %f22;
	mul.f32 	%f24, %f10, %f23;
	mov.f32 	%f25, %f24;
	mov.f32 	%f26, %f9;
	mov.f32 	%f27, %f8;
	mad.f32 %f28, %f25, %f26, %f27;
	mov.f32 	%f29, %f28;
	.loc	17	9948	0
	add.f32 	%f30, %f1, %f29;
	bra.uni 	$Lt_184_4354;
$Lt_184_4610:
	.loc	17	9950	0
	mov.f32 	%f31, 0f3f800000;    	// 1
	add.f32 	%f32, %f1, %f31;
	mov.f32 	%f33, 0f00000000;    	// 0
	set.gt.u32.f32 	%r12, %f32, %f33;
	neg.s32 	%r13, %r12;
	mov.f32 	%f34, 0f7f800000;    	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r14, %f32, %f34;
	neg.s32 	%r15, %r14;
	and.b32 	%r16, %r13, %r15;
	mov.u32 	%r17, 0;
	setp.eq.s32 	%p3, %r16, %r17;
	@%p3 bra 	$Lt_184_5122;
	.loc	17	9039	0
	mov.b32 	%r18, %f32;
	and.b32 	%r19, %r18, 8388607;
	or.b32 	%r20, %r19, 1065353216;
	mov.b32 	%f35, %r20;
	mov.f32 	%f36, %f35;
	.loc	17	9040	0
	shr.u32 	%r21, %r18, 23;
	cvt.rn.f32.u32 	%f37, %r21;
	mov.f32 	%f38, 0fc2fe0000;    	// -127
	add.f32 	%f39, %f37, %f38;
	mov.f32 	%f40, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p4, %f35, %f40;
	@!%p4 bra 	$Lt_184_5378;
	.loc	17	9042	0
	mov.f32 	%f41, 0f3f000000;    	// 0.5
	mul.f32 	%f36, %f35, %f41;
	.loc	17	9043	0
	mov.f32 	%f42, 0f3f800000;    	// 1
	add.f32 	%f39, %f39, %f42;
$Lt_184_5378:
	.loc	17	8944	0
	mov.f32 	%f43, 0f3f800000;    	// 1
	add.f32 	%f44, %f36, %f43;
	mov.f32 	%f45, %f44;
	rcp.approx.ftz.f32 %f46,%f45;
	mov.f32 	%f47, %f46;
	.loc	17	8936	0
	mov.f32 	%f48, 0fbf800000;    	// -1
	add.f32 	%f49, %f36, %f48;
	mul.f32 	%f50, %f49, %f49;
	neg.f32 	%f51, %f50;
	mul.rn.f32 	%f52, %f47, %f51;
	add.rn.f32 	%f53, %f49, %f52;
	mul.f32 	%f54, %f53, %f53;
	mov.f32 	%f55, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f56, %f55;
	mov.f32 	%f57, %f54;
	mov.f32 	%f58, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f59, %f58;
	mad.f32 %f60, %f56, %f57, %f59;
	mov.f32 	%f61, %f60;
	mov.f32 	%f62, %f61;
	mov.f32 	%f63, %f54;
	mov.f32 	%f64, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f65, %f64;
	mad.f32 %f66, %f62, %f63, %f65;
	mov.f32 	%f67, %f66;
	mul.f32 	%f68, %f54, %f67;
	mov.f32 	%f69, %f68;
	mov.f32 	%f70, %f53;
	mov.f32 	%f71, %f52;
	mad.f32 %f72, %f69, %f70, %f71;
	mov.f32 	%f73, %f72;
	mov.f32 	%f74, %f39;
	mov.f32 	%f75, 0f3f317218;    	// 0.693147
	mov.f32 	%f76, %f75;
	add.f32 	%f77, %f49, %f73;
	mov.f32 	%f78, %f77;
	mad.f32 %f79, %f74, %f76, %f78;
	mov.f32 	%f80, %f79;
	.loc	17	9050	0
	mov.f32 	%f81, %f80;
	bra.uni 	$Lt_184_4866;
$Lt_184_5122:
	.loc	17	9053	0
	lg2.approx.f32 	%f81, %f32;
$Lt_184_4866:
	.loc	17	9950	0
	mov.f32 	%f30, %f81;
$Lt_184_4354:
	.loc	15	207	0
	ld.param.u64 	%rd7, [__cudaparm_elog1p_vf_result];
	ld.param.s32 	%r22, [__cudaparm_elog1p_vf_lr];
	mul.lo.s32 	%r23, %r22, %r3;
	cvt.s64.s32 	%rd8, %r23;
	mul.wide.s32 	%rd9, %r23, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f30;
$Lt_184_3842:
	exit;
$LDWend_elog1p_vf:
	} // elog1p_vf

	.entry elog1p_mf (
		.param .s32 __cudaparm_elog1p_mf_rs,
		.param .s32 __cudaparm_elog1p_mf_cs,
		.param .u64 __cudaparm_elog1p_mf_A,
		.param .s32 __cudaparm_elog1p_mf_lda,
		.param .u64 __cudaparm_elog1p_mf_B,
		.param .s32 __cudaparm_elog1p_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<38>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<83>;
	.reg .pred %p<6>;
$LDWbegin_elog1p_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_elog1p_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_elog1p_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_185_4098;
	ld.param.u64 	%rd1, [__cudaparm_elog1p_mf_A];
	ld.param.s32 	%r15, [__cudaparm_elog1p_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	mov.f32 	%f2, 0fbec9ba5e;     	// -0.394
	set.ge.u32.f32 	%r18, %f1, %f2;
	neg.s32 	%r19, %r18;
	mov.f32 	%f3, 0f3f266666;     	// 0.65
	set.le.u32.f32 	%r20, %f1, %f3;
	neg.s32 	%r21, %r20;
	and.b32 	%r22, %r19, %r21;
	mov.u32 	%r23, 0;
	setp.eq.s32 	%p2, %r22, %r23;
	@%p2 bra 	$Lt_185_4866;
	.loc	17	8936	0
	neg.f32 	%f4, %f1;
	mov.f32 	%f5, 0f40000000;     	// 2
	add.f32 	%f6, %f1, %f5;
	div.approx.f32 	%f7, %f1, %f6;
	mul.rn.f32 	%f8, %f4, %f7;
	add.rn.f32 	%f9, %f1, %f8;
	mul.f32 	%f10, %f9, %f9;
	mov.f32 	%f11, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f12, %f11;
	mov.f32 	%f13, %f10;
	mov.f32 	%f14, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f15, %f14;
	mad.f32 %f16, %f12, %f13, %f15;
	mov.f32 	%f17, %f16;
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f10;
	mov.f32 	%f20, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f21, %f20;
	mad.f32 %f22, %f18, %f19, %f21;
	mov.f32 	%f23, %f22;
	mul.f32 	%f24, %f10, %f23;
	mov.f32 	%f25, %f24;
	mov.f32 	%f26, %f9;
	mov.f32 	%f27, %f8;
	mad.f32 %f28, %f25, %f26, %f27;
	mov.f32 	%f29, %f28;
	.loc	17	9948	0
	add.f32 	%f30, %f1, %f29;
	bra.uni 	$Lt_185_4610;
$Lt_185_4866:
	.loc	17	9950	0
	mov.f32 	%f31, 0f3f800000;    	// 1
	add.f32 	%f32, %f1, %f31;
	mov.f32 	%f33, 0f00000000;    	// 0
	set.gt.u32.f32 	%r24, %f32, %f33;
	neg.s32 	%r25, %r24;
	mov.f32 	%f34, 0f7f800000;    	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r26, %f32, %f34;
	neg.s32 	%r27, %r26;
	and.b32 	%r28, %r25, %r27;
	mov.u32 	%r29, 0;
	setp.eq.s32 	%p3, %r28, %r29;
	@%p3 bra 	$Lt_185_5378;
	.loc	17	9039	0
	mov.b32 	%r30, %f32;
	and.b32 	%r31, %r30, 8388607;
	or.b32 	%r32, %r31, 1065353216;
	mov.b32 	%f35, %r32;
	mov.f32 	%f36, %f35;
	.loc	17	9040	0
	shr.u32 	%r33, %r30, 23;
	cvt.rn.f32.u32 	%f37, %r33;
	mov.f32 	%f38, 0fc2fe0000;    	// -127
	add.f32 	%f39, %f37, %f38;
	mov.f32 	%f40, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p4, %f35, %f40;
	@!%p4 bra 	$Lt_185_5634;
	.loc	17	9042	0
	mov.f32 	%f41, 0f3f000000;    	// 0.5
	mul.f32 	%f36, %f35, %f41;
	.loc	17	9043	0
	mov.f32 	%f42, 0f3f800000;    	// 1
	add.f32 	%f39, %f39, %f42;
$Lt_185_5634:
	.loc	17	8944	0
	mov.f32 	%f43, 0f3f800000;    	// 1
	add.f32 	%f44, %f36, %f43;
	mov.f32 	%f45, %f44;
	rcp.approx.ftz.f32 %f46,%f45;
	mov.f32 	%f47, %f46;
	.loc	17	8936	0
	mov.f32 	%f48, 0fbf800000;    	// -1
	add.f32 	%f49, %f36, %f48;
	mul.f32 	%f50, %f49, %f49;
	neg.f32 	%f51, %f50;
	mul.rn.f32 	%f52, %f47, %f51;
	add.rn.f32 	%f53, %f49, %f52;
	mul.f32 	%f54, %f53, %f53;
	mov.f32 	%f55, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f56, %f55;
	mov.f32 	%f57, %f54;
	mov.f32 	%f58, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f59, %f58;
	mad.f32 %f60, %f56, %f57, %f59;
	mov.f32 	%f61, %f60;
	mov.f32 	%f62, %f61;
	mov.f32 	%f63, %f54;
	mov.f32 	%f64, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f65, %f64;
	mad.f32 %f66, %f62, %f63, %f65;
	mov.f32 	%f67, %f66;
	mul.f32 	%f68, %f54, %f67;
	mov.f32 	%f69, %f68;
	mov.f32 	%f70, %f53;
	mov.f32 	%f71, %f52;
	mad.f32 %f72, %f69, %f70, %f71;
	mov.f32 	%f73, %f72;
	mov.f32 	%f74, %f39;
	mov.f32 	%f75, 0f3f317218;    	// 0.693147
	mov.f32 	%f76, %f75;
	add.f32 	%f77, %f49, %f73;
	mov.f32 	%f78, %f77;
	mad.f32 %f79, %f74, %f76, %f78;
	mov.f32 	%f80, %f79;
	.loc	17	9050	0
	mov.f32 	%f81, %f80;
	bra.uni 	$Lt_185_5122;
$Lt_185_5378:
	.loc	17	9053	0
	lg2.approx.f32 	%f81, %f32;
$Lt_185_5122:
	.loc	17	9950	0
	mov.f32 	%f30, %f81;
$Lt_185_4610:
	.loc	15	207	0
	ld.param.u64 	%rd5, [__cudaparm_elog1p_mf_B];
	ld.param.s32 	%r34, [__cudaparm_elog1p_mf_ldb];
	mul.lo.s32 	%r35, %r34, %r4;
	add.s32 	%r36, %r6, %r35;
	cvt.s64.s32 	%rd6, %r36;
	mul.wide.s32 	%rd7, %r36, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f30;
$Lt_185_4098:
	exit;
$LDWend_elog1p_mf:
	} // elog1p_mf

	.entry ecbrt_vf (
		.param .u64 __cudaparm_ecbrt_vf_n,
		.param .u64 __cudaparm_ecbrt_vf_x,
		.param .s32 __cudaparm_ecbrt_vf_lx,
		.param .u64 __cudaparm_ecbrt_vf_result,
		.param .s32 __cudaparm_ecbrt_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<11>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<30>;
	.reg .pred %p<5>;
	.loc	15	209	0
$LDWbegin_ecbrt_vf:
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r1, %rh1, %rh2;
	cvt.u32.u16 	%r2, %tid.x;
	add.u32 	%r3, %r2, %r1;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_ecbrt_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_186_2562;
	ld.param.u64 	%rd3, [__cudaparm_ecbrt_vf_x];
	ld.param.s32 	%r4, [__cudaparm_ecbrt_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	8965	0
	abs.f32 	%f2, %f1;
	lg2.approx.f32 	%f3, %f2;
	mov.f32 	%f4, 0f3eaaaaab;     	// 0.333333
	mul.f32 	%f5, %f3, %f4;
	mov.f32 	%f6, %f5;
	ex2.approx.ftz.f32 %f7,%f6;
	mov.f32 	%f8, %f7;
	.loc	17	8944	0
	mul.f32 	%f9, %f8, %f8;
	mov.f32 	%f10, %f9;
	rcp.approx.ftz.f32 %f11,%f10;
	mov.f32 	%f12, %f11;
	.loc	17	8936	0
	mov.f32 	%f13, %f12;
	neg.f32 	%f14, %f2;
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f8;
	mad.f32 %f17, %f13, %f15, %f16;
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f18;
	mov.f32 	%f20, 0fbeaaaaab;    	// -0.333333
	mov.f32 	%f21, %f20;
	mov.f32 	%f22, %f8;
	mad.f32 %f23, %f19, %f21, %f22;
	mov.f32 	%f24, %f23;
	.loc	15	209	0
	add.f32 	%f25, %f1, %f1;
	neg.f32 	%f26, %f24;
	mov.b32 	%r6, %f1;
	mov.s32 	%r7, 0;
	setp.lt.s32 	%p2, %r6, %r7;
	selp.f32 	%f27, %f26, %f24, %p2;
	setp.eq.f32 	%p3, %f25, %f1;
	selp.f32 	%f28, %f25, %f27, %p3;
	ld.param.u64 	%rd7, [__cudaparm_ecbrt_vf_result];
	ld.param.s32 	%r8, [__cudaparm_ecbrt_vf_lr];
	mul.lo.s32 	%r9, %r8, %r3;
	cvt.s64.s32 	%rd8, %r9;
	mul.wide.s32 	%rd9, %r9, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f28;
$Lt_186_2562:
	exit;
$LDWend_ecbrt_vf:
	} // ecbrt_vf

	.entry ecbrt_mf (
		.param .s32 __cudaparm_ecbrt_mf_rs,
		.param .s32 __cudaparm_ecbrt_mf_cs,
		.param .u64 __cudaparm_ecbrt_mf_A,
		.param .s32 __cudaparm_ecbrt_mf_lda,
		.param .u64 __cudaparm_ecbrt_mf_B,
		.param .s32 __cudaparm_ecbrt_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<30>;
	.reg .pred %p<5>;
$LDWbegin_ecbrt_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_ecbrt_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_ecbrt_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_187_2818;
	ld.param.u64 	%rd1, [__cudaparm_ecbrt_mf_A];
	ld.param.s32 	%r15, [__cudaparm_ecbrt_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	8965	0
	abs.f32 	%f2, %f1;
	lg2.approx.f32 	%f3, %f2;
	mov.f32 	%f4, 0f3eaaaaab;     	// 0.333333
	mul.f32 	%f5, %f3, %f4;
	mov.f32 	%f6, %f5;
	ex2.approx.ftz.f32 %f7,%f6;
	mov.f32 	%f8, %f7;
	.loc	17	8944	0
	mul.f32 	%f9, %f8, %f8;
	mov.f32 	%f10, %f9;
	rcp.approx.ftz.f32 %f11,%f10;
	mov.f32 	%f12, %f11;
	.loc	17	8936	0
	mov.f32 	%f13, %f12;
	neg.f32 	%f14, %f2;
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f8;
	mad.f32 %f17, %f13, %f15, %f16;
	mov.f32 	%f18, %f17;
	mov.f32 	%f19, %f18;
	mov.f32 	%f20, 0fbeaaaaab;    	// -0.333333
	mov.f32 	%f21, %f20;
	mov.f32 	%f22, %f8;
	mad.f32 %f23, %f19, %f21, %f22;
	mov.f32 	%f24, %f23;
	.loc	15	209	0
	add.f32 	%f25, %f1, %f1;
	neg.f32 	%f26, %f24;
	mov.b32 	%r18, %f1;
	mov.s32 	%r19, 0;
	setp.lt.s32 	%p2, %r18, %r19;
	selp.f32 	%f27, %f26, %f24, %p2;
	setp.eq.f32 	%p3, %f25, %f1;
	selp.f32 	%f28, %f25, %f27, %p3;
	ld.param.u64 	%rd5, [__cudaparm_ecbrt_mf_B];
	ld.param.s32 	%r20, [__cudaparm_ecbrt_mf_ldb];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd6, %r22;
	mul.wide.s32 	%rd7, %r22, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f28;
$Lt_187_2818:
	exit;
$LDWend_ecbrt_mf:
	} // ecbrt_mf

	.entry esqrt_vf (
		.param .u64 __cudaparm_esqrt_vf_n,
		.param .u64 __cudaparm_esqrt_vf_x,
		.param .s32 __cudaparm_esqrt_vf_lx,
		.param .u64 __cudaparm_esqrt_vf_result,
		.param .s32 __cudaparm_esqrt_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
	.loc	15	210	0
$LDWbegin_esqrt_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_esqrt_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_188_1026;
	ld.param.u64 	%rd3, [__cudaparm_esqrt_vf_x];
	ld.param.s32 	%r4, [__cudaparm_esqrt_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	sqrt.approx.f32 	%f2, %f1;
	ld.param.u64 	%rd7, [__cudaparm_esqrt_vf_result];
	ld.param.s32 	%r6, [__cudaparm_esqrt_vf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f2;
$Lt_188_1026:
	exit;
$LDWend_esqrt_vf:
	} // esqrt_vf

	.entry esqrt_mf (
		.param .s32 __cudaparm_esqrt_mf_rs,
		.param .s32 __cudaparm_esqrt_mf_cs,
		.param .u64 __cudaparm_esqrt_mf_A,
		.param .s32 __cudaparm_esqrt_mf_lda,
		.param .u64 __cudaparm_esqrt_mf_B,
		.param .s32 __cudaparm_esqrt_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
$LDWbegin_esqrt_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_esqrt_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_esqrt_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_189_1282;
	ld.param.u64 	%rd1, [__cudaparm_esqrt_mf_A];
	ld.param.s32 	%r15, [__cudaparm_esqrt_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	sqrt.approx.f32 	%f2, %f1;
	ld.param.u64 	%rd5, [__cudaparm_esqrt_mf_B];
	ld.param.s32 	%r18, [__cudaparm_esqrt_mf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f2;
$Lt_189_1282:
	exit;
$LDWend_esqrt_mf:
	} // esqrt_mf

	.entry efabs_vf (
		.param .u64 __cudaparm_efabs_vf_n,
		.param .u64 __cudaparm_efabs_vf_x,
		.param .s32 __cudaparm_efabs_vf_lx,
		.param .u64 __cudaparm_efabs_vf_result,
		.param .s32 __cudaparm_efabs_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
	.loc	15	211	0
$LDWbegin_efabs_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_efabs_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_190_1026;
	ld.param.u64 	%rd3, [__cudaparm_efabs_vf_x];
	ld.param.s32 	%r4, [__cudaparm_efabs_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	abs.f32 	%f2, %f1;
	ld.param.u64 	%rd7, [__cudaparm_efabs_vf_result];
	ld.param.s32 	%r6, [__cudaparm_efabs_vf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f2;
$Lt_190_1026:
	exit;
$LDWend_efabs_vf:
	} // efabs_vf

	.entry efabs_mf (
		.param .s32 __cudaparm_efabs_mf_rs,
		.param .s32 __cudaparm_efabs_mf_cs,
		.param .u64 __cudaparm_efabs_mf_A,
		.param .s32 __cudaparm_efabs_mf_lda,
		.param .u64 __cudaparm_efabs_mf_B,
		.param .s32 __cudaparm_efabs_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
$LDWbegin_efabs_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_efabs_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_efabs_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_191_1282;
	ld.param.u64 	%rd1, [__cudaparm_efabs_mf_A];
	ld.param.s32 	%r15, [__cudaparm_efabs_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	abs.f32 	%f2, %f1;
	ld.param.u64 	%rd5, [__cudaparm_efabs_mf_B];
	ld.param.s32 	%r18, [__cudaparm_efabs_mf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f2;
$Lt_191_1282:
	exit;
$LDWend_efabs_mf:
	} // efabs_mf

	.entry ej0_vf (
		.param .u64 __cudaparm_ej0_vf_n,
		.param .u64 __cudaparm_ej0_vf_x,
		.param .s32 __cudaparm_ej0_vf_lx,
		.param .u64 __cudaparm_ej0_vf_result,
		.param .s32 __cudaparm_ej0_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<163>;
	.reg .u64 %rd<25>;
	.reg .f32 %f<269>;
	.reg .pred %p<26>;
	.local .align 4 .b8 __cuda___cuda_result_169028[28];
	.local .align 4 .b8 __cuda___cuda_result_449056[28];
	.loc	15	212	0
$LDWbegin_ej0_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_ej0_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_192_19202;
	ld.param.u64 	%rd3, [__cudaparm_ej0_vf_x];
	ld.param.s32 	%r4, [__cudaparm_ej0_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f41000000;     	// 8
	setp.le.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_192_19970;
	.loc	17	8936	0
	mov.f32 	%f4, 0fc019e8a9;     	// -2.40483
	add.f32 	%f5, %f2, %f4;
	mov.f32 	%f6, 0fb3e971b3;     	// -1.08706e-07
	add.f32 	%f7, %f5, %f6;
	mov.f32 	%f8, 0fa6b3b8e7;     	// -1.24707e-15
	mov.f32 	%f9, %f8;
	mov.f32 	%f10, %f7;
	mov.f32 	%f11, 0fa9aca9b3;    	// -7.66777e-14
	mov.f32 	%f12, %f11;
	mad.f32 %f13, %f9, %f10, %f12;
	mov.f32 	%f14, %f13;
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f7;
	mov.f32 	%f17, 0f2c3f0e18;    	// 2.71506e-12
	mov.f32 	%f18, %f17;
	mad.f32 %f19, %f15, %f16, %f18;
	mov.f32 	%f14, %f19;
	mov.f32 	%f20, %f14;
	mov.f32 	%f21, %f7;
	mov.f32 	%f22, 0facd41781;    	// -6.02801e-12
	mov.f32 	%f23, %f22;
	mad.f32 %f24, %f20, %f21, %f23;
	mov.f32 	%f14, %f24;
	mov.f32 	%f25, %f14;
	mov.f32 	%f26, %f7;
	mov.f32 	%f27, 0fafe90f38;    	// -4.23933e-10
	mov.f32 	%f28, %f27;
	mad.f32 %f29, %f25, %f26, %f28;
	mov.f32 	%f14, %f29;
	mov.f32 	%f30, %f14;
	mov.f32 	%f31, %f7;
	mov.f32 	%f32, 0f3020305b;    	// 5.82764e-10
	mov.f32 	%f33, %f32;
	mad.f32 %f34, %f30, %f31, %f33;
	mov.f32 	%f14, %f34;
	mov.f32 	%f35, %f14;
	mov.f32 	%f36, %f7;
	mov.f32 	%f37, 0f33797143;    	// 5.80778e-08
	mov.f32 	%f38, %f37;
	mad.f32 %f39, %f35, %f36, %f38;
	mov.f32 	%f14, %f39;
	mov.f32 	%f40, %f14;
	mov.f32 	%f41, %f7;
	mov.f32 	%f42, 0f30f76f85;    	// 1.80033e-09
	mov.f32 	%f43, %f42;
	mad.f32 %f44, %f40, %f41, %f43;
	mov.f32 	%f14, %f44;
	mov.f32 	%f45, %f14;
	mov.f32 	%f46, %f7;
	mov.f32 	%f47, 0fb6b6dfc6;    	// -5.45007e-06
	mov.f32 	%f48, %f47;
	mad.f32 %f49, %f45, %f46, %f48;
	mov.f32 	%f14, %f49;
	mov.f32 	%f50, %f14;
	mov.f32 	%f51, %f7;
	mov.f32 	%f52, 0fb6f665c9;    	// -7.34322e-06
	mov.f32 	%f53, %f52;
	mad.f32 %f54, %f50, %f51, %f53;
	mov.f32 	%f14, %f54;
	mov.f32 	%f55, %f14;
	mov.f32 	%f56, %f7;
	mov.f32 	%f57, 0f399e2deb;    	// 0.000301703
	mov.f32 	%f58, %f57;
	mad.f32 %f59, %f55, %f56, %f58;
	mov.f32 	%f14, %f59;
	mov.f32 	%f60, %f14;
	mov.f32 	%f61, %f7;
	mov.f32 	%f62, 0f3a4ae334;    	// 0.000773954
	mov.f32 	%f63, %f62;
	mad.f32 %f64, %f60, %f61, %f63;
	mov.f32 	%f14, %f64;
	mov.f32 	%f65, %f14;
	mov.f32 	%f66, %f7;
	mov.f32 	%f67, 0fbbeeaa1b;    	// -0.00728346
	mov.f32 	%f68, %f67;
	mad.f32 %f69, %f65, %f66, %f68;
	mov.f32 	%f14, %f69;
	mov.f32 	%f70, %f14;
	mov.f32 	%f71, %f7;
	mov.f32 	%f72, 0fbcda7747;    	// -0.0266682
	mov.f32 	%f73, %f72;
	mad.f32 %f74, %f70, %f71, %f73;
	mov.f32 	%f14, %f74;
	.loc	17	10124	0
	mov.f32 	%f75, 0fc10a75ab;    	// -8.65373
	add.f32 	%f76, %f2, %f75;
	mov.f32 	%f77, 0fb4cccded;    	// -3.81478e-07
	add.f32 	%f78, %f76, %f77;
	mov.f32 	%f79, 0fc0b0a47b;    	// -5.52008
	add.f32 	%f80, %f2, %f79;
	mov.f32 	%f81, 0f339a7a37;    	// 7.19341e-08
	add.f32 	%f82, %f80, %f81;
	mul.f32 	%f83, %f7, %f14;
	mul.f32 	%f84, %f82, %f83;
	mul.f32 	%f85, %f78, %f84;
	bra.uni 	$Lt_192_19714;
$Lt_192_19970:
	.loc	17	10125	0
	mov.f32 	%f86, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p3, %f2, %f86;
	@%p3 bra 	$Lt_192_20482;
	.loc	17	8944	0
	mov.f32 	%f87, %f2;
	rcp.approx.ftz.f32 %f88,%f87;
	mov.f32 	%f89, %f88;
	.loc	17	8936	0
	mul.f32 	%f90, %f89, %f89;
	mov.f32 	%f91, 0f4056fe93;    	// 3.35929
	mov.f32 	%f92, %f91;
	mov.f32 	%f93, %f90;
	mov.f32 	%f94, 0fbf03b7c2;    	// -0.514523
	mov.f32 	%f95, %f94;
	mad.f32 %f96, %f92, %f93, %f95;
	mov.f32 	%f14, %f96;
	mov.f32 	%f97, %f14;
	mov.f32 	%f98, %f90;
	mov.f32 	%f99, 0f3dd3b3f3;    	// 0.103371
	mov.f32 	%f100, %f99;
	mad.f32 %f101, %f97, %f98, %f100;
	mov.f32 	%f14, %f101;
	mov.f32 	%f102, %f14;
	mov.f32 	%f103, %f90;
	mov.f32 	%f104, 0fbd7fffb6;   	// -0.0624997
	mov.f32 	%f105, %f104;
	mad.f32 %f106, %f102, %f103, %f105;
	mov.f32 	%f14, %f106;
	mov.f32 	%f107, %f14;
	mov.f32 	%f108, %f90;
	mov.f32 	%f109, 0f3f800000;   	// 1
	mov.f32 	%f110, %f109;
	mad.f32 %f111, %f107, %f108, %f110;
	mov.f32 	%f112, %f111;
	mov.f32 	%f113, 0f3f91e009;   	// 1.13965
	mov.f32 	%f114, %f113;
	mov.f32 	%f115, %f90;
	mov.f32 	%f116, 0fbe52412d;   	// -0.205327
	mov.f32 	%f117, %f116;
	mad.f32 %f118, %f114, %f115, %f117;
	mov.f32 	%f14, %f118;
	mov.f32 	%f119, %f14;
	mov.f32 	%f120, %f90;
	mov.f32 	%f121, 0f3d854ed1;   	// 0.0650917
	mov.f32 	%f122, %f121;
	mad.f32 %f123, %f119, %f120, %f122;
	mov.f32 	%f14, %f123;
	mov.f32 	%f124, %f14;
	mov.f32 	%f125, %f90;
	mov.f32 	%f126, 0fbdffffff;   	// -0.125
	mov.f32 	%f127, %f126;
	mad.f32 %f128, %f124, %f125, %f127;
	mov.f32 	%f14, %f128;
	mov.f32 	%f129, %f14;
	mov.f32 	%f130, %f89;
	mov.f32 	%f131, %f2;
	mad.f32 %f132, %f129, %f130, %f131;
	mov.f32 	%f14, %f132;
	.loc	17	9280	0
	mov.f32 	%f133, 0f3f22f983;   	// 0.63662
	mul.f32 	%f134, %f14, %f133;
	cvt.rni.s32.f32 	%r6, %f134;
	mov.s32 	%r7, %r6;
	.loc	17	8936	0
	cvt.rn.f32.s32 	%f135, %r6;
	neg.f32 	%f136, %f135;
	mov.f32 	%f137, %f136;
	mov.f32 	%f138, 0f3fc90000;   	// 1.57031
	mov.f32 	%f139, %f138;
	mov.f32 	%f140, %f14;
	mad.f32 %f141, %f137, %f139, %f140;
	mov.f32 	%f142, %f141;
	mov.f32 	%f143, %f136;
	mov.f32 	%f144, 0f39fd8000;   	// 0.000483513
	mov.f32 	%f145, %f144;
	mov.f32 	%f146, %f142;
	mad.f32 %f147, %f143, %f145, %f146;
	mov.f32 	%f148, %f147;
	mov.f32 	%f149, %f136;
	mov.f32 	%f150, 0f34a88000;   	// 3.13856e-07
	mov.f32 	%f151, %f150;
	mov.f32 	%f152, %f148;
	mad.f32 %f153, %f149, %f151, %f152;
	mov.f32 	%f154, %f153;
	mov.f32 	%f155, %f136;
	mov.f32 	%f156, 0f2e85a309;   	// 6.0771e-11
	mov.f32 	%f157, %f156;
	mov.f32 	%f158, %f154;
	mad.f32 %f159, %f155, %f157, %f158;
	mov.f32 	%f160, %f159;
	.loc	17	9291	0
	mov.f32 	%f161, %f160;
	abs.f32 	%f162, %f14;
	mov.f32 	%f163, 0f473ba700;   	// 48039
	setp.gt.f32 	%p4, %f162, %f163;
	@!%p4 bra 	$Lt_192_20738;
	.loc	17	9294	0
	mov.u64 	%rd7, __cudart_i2opi_f;
	.loc	17	9215	0
	mov.b32 	%r8, %f14;
	and.b32 	%r9, %r8, -2147483648;
	mov.s32 	%r10, %r9;
	.loc	17	24	0
	shl.b32 	%r11, %r8, 8;
	or.b32 	%r12, %r11, -2147483648;
	mov.s64 	%rd8, %rd7;
	mov.u64 	%rd9, __cuda___cuda_result_169028;
	mov.s32 	%r13, 0;
	mov.u32 	%r14, 0;
$Lt_192_21762:
 //<loop> Loop body line 24, nesting depth: 1, iterations: 6
	.loc	17	9187	0
	ld.const.u32 	%r15, [%rd8+0];
	mov.u32 	%r16, %r15;
	mov.u32 	%r17, %r12;
	mov.u32 	%r18, %r14;
	{
	.reg .u64 tmp;
	mul.wide.u32 tmp, %r16, %r17;
	mov.b64         {%r19,%r20}, tmp;
	add.cc.u32      %r19, %r19, %r18;
	addc.u32        %r20, %r20, 0;
	}
	mov.s32 	%r21, %r19;
	mov.s32 	%r22, %r20;
	.loc	17	9229	0
	mov.s32 	%r14, %r22;
	.loc	17	9230	0
	st.local.u32 	[%rd9+0], %r21;
	add.s32 	%r13, %r13, 1;
	add.u64 	%rd9, %rd9, 4;
	add.u64 	%rd8, %rd8, 4;
	mov.u32 	%r23, 6;
	setp.ne.s32 	%p5, %r13, %r23;
	@%p5 bra 	$Lt_192_21762;
	.loc	17	9232	0
	st.local.u32 	[__cuda___cuda_result_169028+24], %r22;
	.loc	17	9237	0
	shl.b32 	%r24, %r8, 1;
	shr.u32 	%r25, %r24, 24;
	sub.u32 	%r26, %r25, 128;
	mov.u64 	%rd10, __cuda___cuda_result_169028;
	shr.u32 	%r27, %r26, 5;
	mov.s32 	%r28, 4;
	sub.s32 	%r29, %r28, %r27;
	cvt.s64.s32 	%rd11, %r29;
	mul.wide.s32 	%rd12, %r29, 4;
	add.u64 	%rd13, %rd10, %rd12;
	ld.local.u32 	%r14, [%rd13+8];
	.loc	17	9238	0
	ld.local.u32 	%r30, [%rd13+4];
	and.b32 	%r31, %r26, 31;
	mov.u32 	%r32, 0;
	setp.eq.u32 	%p6, %r31, %r32;
	@%p6 bra 	$Lt_192_22274;
	.loc	17	9241	0
	mov.s32 	%r33, 32;
	sub.s32 	%r34, %r33, %r31;
	shr.u32 	%r35, %r30, %r34;
	shl.b32 	%r36, %r14, %r31;
	add.u32 	%r14, %r35, %r36;
	.loc	17	9242	0
	ld.local.u32 	%r37, [%rd13+0];
	shr.u32 	%r38, %r37, %r34;
	shl.b32 	%r39, %r30, %r31;
	add.u32 	%r30, %r38, %r39;
$Lt_192_22274:
	.loc	17	9244	0
	shr.u32 	%r40, %r14, 30;
	.loc	17	9246	0
	shr.u32 	%r41, %r30, 30;
	shl.b32 	%r42, %r14, 2;
	add.u32 	%r14, %r41, %r42;
	.loc	17	9247	0
	shl.b32 	%r30, %r30, 2;
	.loc	17	9249	0
	shr.u32 	%r43, %r14, 31;
	add.u32 	%r44, %r40, %r43;
	.loc	17	9244	0
	neg.s32 	%r45, %r44;
	mov.u32 	%r46, 0;
	setp.ne.u32 	%p7, %r9, %r46;
	selp.s32 	%r13, %r45, %r44, %p7;
	.loc	17	9251	0
	mov.s32 	%r7, %r13;
	mov.u32 	%r47, 0;
	setp.eq.u32 	%p8, %r43, %r47;
	@%p8 bra 	$Lt_192_22786;
	.loc	17	9255	0
	neg.s32 	%r30, %r30;
	.loc	17	9257	0
	mov.u32 	%r48, 0;
	set.eq.u32.u32 	%r49, %r30, %r48;
	neg.s32 	%r50, %r49;
	not.b32 	%r51, %r14;
	add.u32 	%r14, %r50, %r51;
	.loc	17	9258	0
	xor.b32 	%r10, %r9, -2147483648;
$Lt_192_22786:
	.loc	17	9261	0
	mov.u32 	%r52, 0;
	setp.eq.s32 	%p9, %r14, %r52;
	@%p9 bra 	$Lt_192_23554;
	.loc	19	6283	0
	cvt.rz.f32.u32 	%f164, %r14;
	mov.b32 	%r53, %f164;
	shr.s32 	%r54, %r53, 23;
	mov.s32 	%r55, 158;
	sub.s32 	%r56, %r55, %r54;
	bra.uni 	$Lt_192_23298;
$Lt_192_23554:
	mov.s32 	%r56, 32;
$Lt_192_23298:
	.loc	17	9261	0
	mov.s32 	%r57, %r56;
	mov.s32 	%r58, %r57;
	.loc	19	6283	0
	mov.s32 	%r59, 32;
	sub.s32 	%r60, %r59, %r57;
	shr.u32 	%r61, %r30, %r60;
	shl.b32 	%r62, %r14, %r57;
	add.u32 	%r63, %r61, %r62;
	mov.u32 	%r64, 0;
	setp.ne.u32 	%p10, %r57, %r64;
	selp.u32 	%r65, %r63, %r14, %p10;
	.loc	17	9265	0
	mul.lo.u32 	%r30, %r65, -921707870;
	.loc	17	9266	0
	mov.u32 	%r66, -921707870;
	mul.hi.u32 	%r14, %r65, %r66;
	mov.u32 	%r67, 0;
	setp.le.s32 	%p11, %r14, %r67;
	@%p11 bra 	$Lt_192_23810;
	.loc	17	9268	0
	shr.u32 	%r68, %r30, 31;
	shl.b32 	%r69, %r14, 1;
	add.u32 	%r14, %r68, %r69;
	.loc	17	9269	0
	add.u32 	%r58, %r57, 1;
$Lt_192_23810:
	.loc	17	9294	0
	add.u32 	%r70, %r14, 1;
	shr.u32 	%r71, %r70, 7;
	add.u32 	%r72, %r71, 1;
	shr.u32 	%r73, %r72, 1;
	mov.s32 	%r74, 126;
	sub.s32 	%r75, %r74, %r58;
	shl.b32 	%r76, %r75, 23;
	add.u32 	%r77, %r73, %r76;
	or.b32 	%r78, %r10, %r77;
	mov.b32 	%f161, %r78;
$Lt_192_20738:
	.loc	17	9561	0
	mov.u64 	%rd7, __cudart_i2opi_f;
	mov.f32 	%f165, 0fbf490fdb;   	// -0.785398
	add.f32 	%f166, %f161, %f165;
	and.b32 	%r79, %r7, 3;
	cvt.rn.f32.s32 	%f167, %r79;
	mov.f32 	%f168, 0f3fc90fdb;   	// 1.5708
	mad.f32 	%f169, %f167, %f168, %f166;
	mov.f32 	%f170, %f169;
	.loc	17	9511	0
	abs.f32 	%f171, %f169;
	mov.f32 	%f172, 0f7f800000;   	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p12, %f171, %f172;
	@!%p12 bra 	$Lt_192_24322;
	.loc	17	9512	0
	mov.f32 	%f173, 0f00000000;   	// 0
	mul.rn.f32 	%f170, %f169, %f173;
$Lt_192_24322:
	.loc	17	9280	0
	mov.f32 	%f174, 0f3f22f983;   	// 0.63662
	mul.f32 	%f175, %f170, %f174;
	cvt.rni.s32.f32 	%r80, %f175;
	mov.s32 	%r81, %r80;
	.loc	17	8936	0
	cvt.rn.f32.s32 	%f176, %r80;
	neg.f32 	%f177, %f176;
	mov.f32 	%f178, %f177;
	mov.f32 	%f179, 0f3fc90000;   	// 1.57031
	mov.f32 	%f180, %f179;
	mov.f32 	%f181, %f170;
	mad.f32 %f182, %f178, %f180, %f181;
	mov.f32 	%f183, %f182;
	mov.f32 	%f184, %f177;
	mov.f32 	%f185, 0f39fd8000;   	// 0.000483513
	mov.f32 	%f186, %f185;
	mov.f32 	%f187, %f183;
	mad.f32 %f188, %f184, %f186, %f187;
	mov.f32 	%f189, %f188;
	mov.f32 	%f190, %f177;
	mov.f32 	%f191, 0f34a88000;   	// 3.13856e-07
	mov.f32 	%f192, %f191;
	mov.f32 	%f193, %f189;
	mad.f32 %f194, %f190, %f192, %f193;
	mov.f32 	%f195, %f194;
	mov.f32 	%f196, %f177;
	mov.f32 	%f197, 0f2e85a309;   	// 6.0771e-11
	mov.f32 	%f198, %f197;
	mov.f32 	%f199, %f195;
	mad.f32 %f200, %f196, %f198, %f199;
	mov.f32 	%f201, %f200;
	.loc	17	9291	0
	mov.f32 	%f202, %f201;
	abs.f32 	%f203, %f170;
	mov.f32 	%f204, 0f473ba700;   	// 48039
	setp.gt.f32 	%p13, %f203, %f204;
	@!%p13 bra 	$Lt_192_24834;
	.loc	17	9215	0
	mov.b32 	%r82, %f170;
	and.b32 	%r83, %r82, -2147483648;
	mov.s32 	%r84, %r83;
	.loc	17	24	0
	shl.b32 	%r85, %r82, 8;
	or.b32 	%r86, %r85, -2147483648;
	mov.s64 	%rd14, %rd7;
	mov.u64 	%rd15, __cuda___cuda_result_449056;
	mov.s32 	%r87, 0;
	mov.u32 	%r88, 0;
$Lt_192_25858:
 //<loop> Loop body line 24, nesting depth: 1, iterations: 6
	.loc	17	9187	0
	ld.const.u32 	%r89, [%rd14+0];
	mov.u32 	%r90, %r89;
	mov.u32 	%r91, %r86;
	mov.u32 	%r92, %r88;
	{
	.reg .u64 tmp;
	mul.wide.u32 tmp, %r90, %r91;
	mov.b64         {%r93,%r94}, tmp;
	add.cc.u32      %r93, %r93, %r92;
	addc.u32        %r94, %r94, 0;
	}
	mov.s32 	%r95, %r93;
	mov.s32 	%r96, %r94;
	.loc	17	9229	0
	mov.s32 	%r88, %r96;
	.loc	17	9230	0
	st.local.u32 	[%rd15+0], %r95;
	add.s32 	%r87, %r87, 1;
	add.u64 	%rd15, %rd15, 4;
	add.u64 	%rd14, %rd14, 4;
	mov.u32 	%r97, 6;
	setp.ne.s32 	%p14, %r87, %r97;
	@%p14 bra 	$Lt_192_25858;
	.loc	17	9232	0
	st.local.u32 	[__cuda___cuda_result_449056+24], %r96;
	.loc	17	9237	0
	shl.b32 	%r98, %r82, 1;
	shr.u32 	%r99, %r98, 24;
	sub.u32 	%r100, %r99, 128;
	mov.u64 	%rd16, __cuda___cuda_result_449056;
	shr.u32 	%r101, %r100, 5;
	mov.s32 	%r102, 4;
	sub.s32 	%r103, %r102, %r101;
	cvt.s64.s32 	%rd17, %r103;
	mul.wide.s32 	%rd18, %r103, 4;
	add.u64 	%rd19, %rd16, %rd18;
	ld.local.u32 	%r88, [%rd19+8];
	.loc	17	9238	0
	ld.local.u32 	%r104, [%rd19+4];
	and.b32 	%r105, %r100, 31;
	mov.u32 	%r106, 0;
	setp.eq.u32 	%p15, %r105, %r106;
	@%p15 bra 	$Lt_192_26370;
	.loc	17	9241	0
	mov.s32 	%r107, 32;
	sub.s32 	%r108, %r107, %r105;
	shr.u32 	%r109, %r104, %r108;
	shl.b32 	%r110, %r88, %r105;
	add.u32 	%r88, %r109, %r110;
	.loc	17	9242	0
	ld.local.u32 	%r111, [%rd19+0];
	shr.u32 	%r112, %r111, %r108;
	shl.b32 	%r113, %r104, %r105;
	add.u32 	%r104, %r112, %r113;
$Lt_192_26370:
	.loc	17	9244	0
	shr.u32 	%r114, %r88, 30;
	.loc	17	9246	0
	shr.u32 	%r115, %r104, 30;
	shl.b32 	%r116, %r88, 2;
	add.u32 	%r88, %r115, %r116;
	.loc	17	9247	0
	shl.b32 	%r104, %r104, 2;
	.loc	17	9249	0
	shr.u32 	%r117, %r88, 31;
	add.u32 	%r118, %r114, %r117;
	.loc	17	9244	0
	neg.s32 	%r119, %r118;
	mov.u32 	%r120, 0;
	setp.ne.u32 	%p16, %r83, %r120;
	selp.s32 	%r87, %r119, %r118, %p16;
	.loc	17	9251	0
	mov.s32 	%r81, %r87;
	mov.u32 	%r121, 0;
	setp.eq.u32 	%p17, %r117, %r121;
	@%p17 bra 	$Lt_192_26882;
	.loc	17	9255	0
	neg.s32 	%r104, %r104;
	.loc	17	9257	0
	mov.u32 	%r122, 0;
	set.eq.u32.u32 	%r123, %r104, %r122;
	neg.s32 	%r124, %r123;
	not.b32 	%r125, %r88;
	add.u32 	%r88, %r124, %r125;
	.loc	17	9258	0
	xor.b32 	%r84, %r83, -2147483648;
$Lt_192_26882:
	.loc	17	9261	0
	mov.u32 	%r126, 0;
	setp.eq.s32 	%p18, %r88, %r126;
	@%p18 bra 	$Lt_192_27650;
	.loc	19	6283	0
	cvt.rz.f32.u32 	%f205, %r88;
	mov.b32 	%r127, %f205;
	shr.s32 	%r128, %r127, 23;
	mov.s32 	%r129, 158;
	sub.s32 	%r130, %r129, %r128;
	bra.uni 	$Lt_192_27394;
$Lt_192_27650:
	mov.s32 	%r130, 32;
$Lt_192_27394:
	.loc	17	9261	0
	mov.s32 	%r131, %r130;
	mov.s32 	%r132, %r131;
	.loc	19	6283	0
	mov.s32 	%r133, 32;
	sub.s32 	%r134, %r133, %r131;
	shr.u32 	%r135, %r104, %r134;
	shl.b32 	%r136, %r88, %r131;
	add.u32 	%r137, %r135, %r136;
	mov.u32 	%r138, 0;
	setp.ne.u32 	%p19, %r131, %r138;
	selp.u32 	%r139, %r137, %r88, %p19;
	.loc	17	9265	0
	mul.lo.u32 	%r104, %r139, -921707870;
	.loc	17	9266	0
	mov.u32 	%r140, -921707870;
	mul.hi.u32 	%r88, %r139, %r140;
	mov.u32 	%r141, 0;
	setp.le.s32 	%p20, %r88, %r141;
	@%p20 bra 	$Lt_192_27906;
	.loc	17	9268	0
	shr.u32 	%r142, %r104, 31;
	shl.b32 	%r143, %r88, 1;
	add.u32 	%r88, %r142, %r143;
	.loc	17	9269	0
	add.u32 	%r132, %r131, 1;
$Lt_192_27906:
	.loc	17	9294	0
	add.u32 	%r144, %r88, 1;
	shr.u32 	%r145, %r144, 7;
	add.u32 	%r146, %r145, 1;
	shr.u32 	%r147, %r146, 1;
	mov.s32 	%r148, 126;
	sub.s32 	%r149, %r148, %r132;
	shl.b32 	%r150, %r149, 23;
	add.u32 	%r151, %r147, %r150;
	or.b32 	%r152, %r84, %r151;
	mov.b32 	%f202, %r152;
$Lt_192_24834:
	.loc	17	8936	0
	mul.f32 	%f206, %f202, %f202;
	mov.f32 	%f207, 0f37ccf5ce;   	// 2.44332e-05
	mov.f32 	%f208, %f207;
	mov.f32 	%f209, %f206;
	mov.f32 	%f210, 0fbab6061a;   	// -0.00138873
	mov.f32 	%f211, %f210;
	mad.f32 %f212, %f208, %f209, %f211;
	mov.f32 	%f213, %f212;
	mov.f32 	%f214, %f213;
	mov.f32 	%f215, %f206;
	mov.f32 	%f216, 0f3d2aaaa5;   	// 0.0416666
	mov.f32 	%f217, %f216;
	mad.f32 %f218, %f214, %f215, %f217;
	mov.f32 	%f219, %f218;
	mov.f32 	%f220, %f219;
	mov.f32 	%f221, %f206;
	mov.f32 	%f222, 0fbf000000;   	// -0.5
	mov.f32 	%f223, %f222;
	mad.f32 %f224, %f220, %f221, %f223;
	mov.f32 	%f225, %f224;
	mov.f32 	%f226, %f225;
	mov.f32 	%f227, %f206;
	mov.f32 	%f228, 0f3f800000;   	// 1
	mov.f32 	%f229, %f228;
	mad.f32 %f230, %f226, %f227, %f229;
	mov.f32 	%f231, %f230;
	.loc	17	9515	0
	mov.f32 	%f232, %f231;
	.loc	17	8936	0
	mov.f32 	%f233, 0fb94ca1f9;   	// -0.000195153
	mov.f32 	%f234, %f233;
	mov.f32 	%f235, %f206;
	mov.f32 	%f236, 0f3c08839e;   	// 0.00833216
	mov.f32 	%f237, %f236;
	mad.f32 %f238, %f234, %f235, %f237;
	mov.f32 	%f239, %f238;
	mov.f32 	%f240, %f239;
	mov.f32 	%f241, %f206;
	mov.f32 	%f242, 0fbe2aaaa3;   	// -0.166667
	mov.f32 	%f243, %f242;
	mad.f32 %f244, %f240, %f241, %f243;
	mov.f32 	%f245, %f244;
	mul.f32 	%f246, %f206, %f245;
	mov.f32 	%f247, %f246;
	mov.f32 	%f248, %f202;
	mov.f32 	%f249, %f202;
	mad.f32 %f250, %f247, %f248, %f249;
	mov.f32 	%f251, %f250;
	.loc	17	9516	0
	mov.f32 	%f252, %f251;
	.loc	17	9517	0
	mov.f32 	%f253, %f252;
	and.b32 	%r153, %r81, 1;
	mov.u32 	%r154, 0;
	setp.eq.s32 	%p21, %r153, %r154;
	@%p21 bra 	$Lt_192_28418;
	.loc	17	9519	0
	mov.f32 	%f254, %f232;
	mov.f32 	%f252, %f254;
	.loc	17	9520	0
	mov.f32 	%f232, %f253;
$Lt_192_28418:
	and.b32 	%r155, %r81, 2;
	mov.u32 	%r156, 0;
	setp.eq.s32 	%p22, %r155, %r156;
	@%p22 bra 	$Lt_192_28930;
	.loc	17	9523	0
	mov.f32 	%f255, %f252;
	neg.f32 	%f256, %f255;
	mov.f32 	%f252, %f256;
$Lt_192_28930:
	add.s32 	%r157, %r81, 1;
	and.b32 	%r158, %r157, 2;
	mov.u32 	%r159, 0;
	setp.eq.s32 	%p23, %r158, %r159;
	@%p23 bra 	$Lt_192_29442;
	.loc	17	9527	0
	mov.f32 	%f257, %f232;
	neg.f32 	%f258, %f257;
	mov.f32 	%f232, %f258;
$Lt_192_29442:
	mov.f32 	%f259, 0f00000000;   	// 0
	setp.eq.f32 	%p24, %f202, %f259;
	@!%p24 bra 	$Lt_192_29954;
	.loc	17	9531	0
	mov.f32 	%f260, 0f00000000;   	// 0
	mul.rn.f32 	%f261, %f202, %f260;
	mov.f32 	%f252, %f261;
$Lt_192_29954:
	.loc	17	9534	0
	mov.f32 	%f262, %f252;
	.loc	17	9535	0
	mov.f32 	%f263, %f232;
	.loc	17	10143	0
	rsqrt.approx.f32 	%f264, %f2;
	mov.f32 	%f265, 0f3f4c422a;   	// 0.797885
	mul.f32 	%f266, %f264, %f265;
	mul.f32 	%f267, %f112, %f266;
	mul.f32 	%f85, %f263, %f267;
	bra.uni 	$Lt_192_20226;
$Lt_192_20482:
	.loc	17	10147	0
	mov.f32 	%f85, 0f00000000;    	// 0
$Lt_192_20226:
$Lt_192_19714:
	.loc	15	212	0
	ld.param.u64 	%rd20, [__cudaparm_ej0_vf_result];
	ld.param.s32 	%r160, [__cudaparm_ej0_vf_lr];
	mul.lo.s32 	%r161, %r160, %r3;
	cvt.s64.s32 	%rd21, %r161;
	mul.wide.s32 	%rd22, %r161, 4;
	add.u64 	%rd23, %rd20, %rd22;
	st.global.f32 	[%rd23+0], %f85;
$Lt_192_19202:
	exit;
$LDWend_ej0_vf:
	} // ej0_vf

	.entry ej0_mf (
		.param .s32 __cudaparm_ej0_mf_rs,
		.param .s32 __cudaparm_ej0_mf_cs,
		.param .u64 __cudaparm_ej0_mf_A,
		.param .s32 __cudaparm_ej0_mf_lda,
		.param .u64 __cudaparm_ej0_mf_B,
		.param .s32 __cudaparm_ej0_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<176>;
	.reg .u64 %rd<23>;
	.reg .f32 %f<269>;
	.reg .pred %p<26>;
	.local .align 4 .b8 __cuda___cuda_result_169124[28];
	.local .align 4 .b8 __cuda___cuda_result_449152[28];
$LDWbegin_ej0_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_ej0_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_ej0_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_193_19458;
	ld.param.u64 	%rd1, [__cudaparm_ej0_mf_A];
	ld.param.s32 	%r15, [__cudaparm_ej0_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f41000000;     	// 8
	setp.le.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_193_20226;
	.loc	17	8936	0
	mov.f32 	%f4, 0fc019e8a9;     	// -2.40483
	add.f32 	%f5, %f2, %f4;
	mov.f32 	%f6, 0fb3e971b3;     	// -1.08706e-07
	add.f32 	%f7, %f5, %f6;
	mov.f32 	%f8, 0fa6b3b8e7;     	// -1.24707e-15
	mov.f32 	%f9, %f8;
	mov.f32 	%f10, %f7;
	mov.f32 	%f11, 0fa9aca9b3;    	// -7.66777e-14
	mov.f32 	%f12, %f11;
	mad.f32 %f13, %f9, %f10, %f12;
	mov.f32 	%f14, %f13;
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f7;
	mov.f32 	%f17, 0f2c3f0e18;    	// 2.71506e-12
	mov.f32 	%f18, %f17;
	mad.f32 %f19, %f15, %f16, %f18;
	mov.f32 	%f14, %f19;
	mov.f32 	%f20, %f14;
	mov.f32 	%f21, %f7;
	mov.f32 	%f22, 0facd41781;    	// -6.02801e-12
	mov.f32 	%f23, %f22;
	mad.f32 %f24, %f20, %f21, %f23;
	mov.f32 	%f14, %f24;
	mov.f32 	%f25, %f14;
	mov.f32 	%f26, %f7;
	mov.f32 	%f27, 0fafe90f38;    	// -4.23933e-10
	mov.f32 	%f28, %f27;
	mad.f32 %f29, %f25, %f26, %f28;
	mov.f32 	%f14, %f29;
	mov.f32 	%f30, %f14;
	mov.f32 	%f31, %f7;
	mov.f32 	%f32, 0f3020305b;    	// 5.82764e-10
	mov.f32 	%f33, %f32;
	mad.f32 %f34, %f30, %f31, %f33;
	mov.f32 	%f14, %f34;
	mov.f32 	%f35, %f14;
	mov.f32 	%f36, %f7;
	mov.f32 	%f37, 0f33797143;    	// 5.80778e-08
	mov.f32 	%f38, %f37;
	mad.f32 %f39, %f35, %f36, %f38;
	mov.f32 	%f14, %f39;
	mov.f32 	%f40, %f14;
	mov.f32 	%f41, %f7;
	mov.f32 	%f42, 0f30f76f85;    	// 1.80033e-09
	mov.f32 	%f43, %f42;
	mad.f32 %f44, %f40, %f41, %f43;
	mov.f32 	%f14, %f44;
	mov.f32 	%f45, %f14;
	mov.f32 	%f46, %f7;
	mov.f32 	%f47, 0fb6b6dfc6;    	// -5.45007e-06
	mov.f32 	%f48, %f47;
	mad.f32 %f49, %f45, %f46, %f48;
	mov.f32 	%f14, %f49;
	mov.f32 	%f50, %f14;
	mov.f32 	%f51, %f7;
	mov.f32 	%f52, 0fb6f665c9;    	// -7.34322e-06
	mov.f32 	%f53, %f52;
	mad.f32 %f54, %f50, %f51, %f53;
	mov.f32 	%f14, %f54;
	mov.f32 	%f55, %f14;
	mov.f32 	%f56, %f7;
	mov.f32 	%f57, 0f399e2deb;    	// 0.000301703
	mov.f32 	%f58, %f57;
	mad.f32 %f59, %f55, %f56, %f58;
	mov.f32 	%f14, %f59;
	mov.f32 	%f60, %f14;
	mov.f32 	%f61, %f7;
	mov.f32 	%f62, 0f3a4ae334;    	// 0.000773954
	mov.f32 	%f63, %f62;
	mad.f32 %f64, %f60, %f61, %f63;
	mov.f32 	%f14, %f64;
	mov.f32 	%f65, %f14;
	mov.f32 	%f66, %f7;
	mov.f32 	%f67, 0fbbeeaa1b;    	// -0.00728346
	mov.f32 	%f68, %f67;
	mad.f32 %f69, %f65, %f66, %f68;
	mov.f32 	%f14, %f69;
	mov.f32 	%f70, %f14;
	mov.f32 	%f71, %f7;
	mov.f32 	%f72, 0fbcda7747;    	// -0.0266682
	mov.f32 	%f73, %f72;
	mad.f32 %f74, %f70, %f71, %f73;
	mov.f32 	%f14, %f74;
	.loc	17	10124	0
	mov.f32 	%f75, 0fc10a75ab;    	// -8.65373
	add.f32 	%f76, %f2, %f75;
	mov.f32 	%f77, 0fb4cccded;    	// -3.81478e-07
	add.f32 	%f78, %f76, %f77;
	mov.f32 	%f79, 0fc0b0a47b;    	// -5.52008
	add.f32 	%f80, %f2, %f79;
	mov.f32 	%f81, 0f339a7a37;    	// 7.19341e-08
	add.f32 	%f82, %f80, %f81;
	mul.f32 	%f83, %f7, %f14;
	mul.f32 	%f84, %f82, %f83;
	mul.f32 	%f85, %f78, %f84;
	bra.uni 	$Lt_193_19970;
$Lt_193_20226:
	.loc	17	10125	0
	mov.f32 	%f86, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p3, %f2, %f86;
	@%p3 bra 	$Lt_193_20738;
	.loc	17	8944	0
	mov.f32 	%f87, %f2;
	rcp.approx.ftz.f32 %f88,%f87;
	mov.f32 	%f89, %f88;
	.loc	17	8936	0
	mul.f32 	%f90, %f89, %f89;
	mov.f32 	%f91, 0f4056fe93;    	// 3.35929
	mov.f32 	%f92, %f91;
	mov.f32 	%f93, %f90;
	mov.f32 	%f94, 0fbf03b7c2;    	// -0.514523
	mov.f32 	%f95, %f94;
	mad.f32 %f96, %f92, %f93, %f95;
	mov.f32 	%f14, %f96;
	mov.f32 	%f97, %f14;
	mov.f32 	%f98, %f90;
	mov.f32 	%f99, 0f3dd3b3f3;    	// 0.103371
	mov.f32 	%f100, %f99;
	mad.f32 %f101, %f97, %f98, %f100;
	mov.f32 	%f14, %f101;
	mov.f32 	%f102, %f14;
	mov.f32 	%f103, %f90;
	mov.f32 	%f104, 0fbd7fffb6;   	// -0.0624997
	mov.f32 	%f105, %f104;
	mad.f32 %f106, %f102, %f103, %f105;
	mov.f32 	%f14, %f106;
	mov.f32 	%f107, %f14;
	mov.f32 	%f108, %f90;
	mov.f32 	%f109, 0f3f800000;   	// 1
	mov.f32 	%f110, %f109;
	mad.f32 %f111, %f107, %f108, %f110;
	mov.f32 	%f112, %f111;
	mov.f32 	%f113, 0f3f91e009;   	// 1.13965
	mov.f32 	%f114, %f113;
	mov.f32 	%f115, %f90;
	mov.f32 	%f116, 0fbe52412d;   	// -0.205327
	mov.f32 	%f117, %f116;
	mad.f32 %f118, %f114, %f115, %f117;
	mov.f32 	%f14, %f118;
	mov.f32 	%f119, %f14;
	mov.f32 	%f120, %f90;
	mov.f32 	%f121, 0f3d854ed1;   	// 0.0650917
	mov.f32 	%f122, %f121;
	mad.f32 %f123, %f119, %f120, %f122;
	mov.f32 	%f14, %f123;
	mov.f32 	%f124, %f14;
	mov.f32 	%f125, %f90;
	mov.f32 	%f126, 0fbdffffff;   	// -0.125
	mov.f32 	%f127, %f126;
	mad.f32 %f128, %f124, %f125, %f127;
	mov.f32 	%f14, %f128;
	mov.f32 	%f129, %f14;
	mov.f32 	%f130, %f89;
	mov.f32 	%f131, %f2;
	mad.f32 %f132, %f129, %f130, %f131;
	mov.f32 	%f14, %f132;
	.loc	17	9280	0
	mov.f32 	%f133, 0f3f22f983;   	// 0.63662
	mul.f32 	%f134, %f14, %f133;
	cvt.rni.s32.f32 	%r18, %f134;
	mov.s32 	%r19, %r18;
	.loc	17	8936	0
	cvt.rn.f32.s32 	%f135, %r18;
	neg.f32 	%f136, %f135;
	mov.f32 	%f137, %f136;
	mov.f32 	%f138, 0f3fc90000;   	// 1.57031
	mov.f32 	%f139, %f138;
	mov.f32 	%f140, %f14;
	mad.f32 %f141, %f137, %f139, %f140;
	mov.f32 	%f142, %f141;
	mov.f32 	%f143, %f136;
	mov.f32 	%f144, 0f39fd8000;   	// 0.000483513
	mov.f32 	%f145, %f144;
	mov.f32 	%f146, %f142;
	mad.f32 %f147, %f143, %f145, %f146;
	mov.f32 	%f148, %f147;
	mov.f32 	%f149, %f136;
	mov.f32 	%f150, 0f34a88000;   	// 3.13856e-07
	mov.f32 	%f151, %f150;
	mov.f32 	%f152, %f148;
	mad.f32 %f153, %f149, %f151, %f152;
	mov.f32 	%f154, %f153;
	mov.f32 	%f155, %f136;
	mov.f32 	%f156, 0f2e85a309;   	// 6.0771e-11
	mov.f32 	%f157, %f156;
	mov.f32 	%f158, %f154;
	mad.f32 %f159, %f155, %f157, %f158;
	mov.f32 	%f160, %f159;
	.loc	17	9291	0
	mov.f32 	%f161, %f160;
	abs.f32 	%f162, %f14;
	mov.f32 	%f163, 0f473ba700;   	// 48039
	setp.gt.f32 	%p4, %f162, %f163;
	@!%p4 bra 	$Lt_193_20994;
	.loc	17	9294	0
	mov.u64 	%rd5, __cudart_i2opi_f;
	.loc	17	9215	0
	mov.b32 	%r20, %f14;
	and.b32 	%r21, %r20, -2147483648;
	mov.s32 	%r22, %r21;
	.loc	17	24	0
	shl.b32 	%r23, %r20, 8;
	or.b32 	%r24, %r23, -2147483648;
	mov.s64 	%rd6, %rd5;
	mov.u64 	%rd7, __cuda___cuda_result_169124;
	mov.s32 	%r25, 0;
	mov.u32 	%r26, 0;
$Lt_193_22018:
 //<loop> Loop body line 24, nesting depth: 1, iterations: 6
	.loc	17	9187	0
	ld.const.u32 	%r27, [%rd6+0];
	mov.u32 	%r28, %r27;
	mov.u32 	%r29, %r24;
	mov.u32 	%r30, %r26;
	{
	.reg .u64 tmp;
	mul.wide.u32 tmp, %r28, %r29;
	mov.b64         {%r31,%r32}, tmp;
	add.cc.u32      %r31, %r31, %r30;
	addc.u32        %r32, %r32, 0;
	}
	mov.s32 	%r33, %r31;
	mov.s32 	%r34, %r32;
	.loc	17	9229	0
	mov.s32 	%r26, %r34;
	.loc	17	9230	0
	st.local.u32 	[%rd7+0], %r33;
	add.s32 	%r25, %r25, 1;
	add.u64 	%rd7, %rd7, 4;
	add.u64 	%rd6, %rd6, 4;
	mov.u32 	%r35, 6;
	setp.ne.s32 	%p5, %r25, %r35;
	@%p5 bra 	$Lt_193_22018;
	.loc	17	9232	0
	st.local.u32 	[__cuda___cuda_result_169124+24], %r34;
	.loc	17	9237	0
	shl.b32 	%r36, %r20, 1;
	shr.u32 	%r37, %r36, 24;
	sub.u32 	%r38, %r37, 128;
	mov.u64 	%rd8, __cuda___cuda_result_169124;
	shr.u32 	%r39, %r38, 5;
	mov.s32 	%r40, 4;
	sub.s32 	%r41, %r40, %r39;
	cvt.s64.s32 	%rd9, %r41;
	mul.wide.s32 	%rd10, %r41, 4;
	add.u64 	%rd11, %rd8, %rd10;
	ld.local.u32 	%r26, [%rd11+8];
	.loc	17	9238	0
	ld.local.u32 	%r42, [%rd11+4];
	and.b32 	%r43, %r38, 31;
	mov.u32 	%r44, 0;
	setp.eq.u32 	%p6, %r43, %r44;
	@%p6 bra 	$Lt_193_22530;
	.loc	17	9241	0
	mov.s32 	%r45, 32;
	sub.s32 	%r46, %r45, %r43;
	shr.u32 	%r47, %r42, %r46;
	shl.b32 	%r48, %r26, %r43;
	add.u32 	%r26, %r47, %r48;
	.loc	17	9242	0
	ld.local.u32 	%r49, [%rd11+0];
	shr.u32 	%r50, %r49, %r46;
	shl.b32 	%r51, %r42, %r43;
	add.u32 	%r42, %r50, %r51;
$Lt_193_22530:
	.loc	17	9244	0
	shr.u32 	%r52, %r26, 30;
	.loc	17	9246	0
	shr.u32 	%r53, %r42, 30;
	shl.b32 	%r54, %r26, 2;
	add.u32 	%r26, %r53, %r54;
	.loc	17	9247	0
	shl.b32 	%r42, %r42, 2;
	.loc	17	9249	0
	shr.u32 	%r55, %r26, 31;
	add.u32 	%r56, %r52, %r55;
	.loc	17	9244	0
	neg.s32 	%r57, %r56;
	mov.u32 	%r58, 0;
	setp.ne.u32 	%p7, %r21, %r58;
	selp.s32 	%r25, %r57, %r56, %p7;
	.loc	17	9251	0
	mov.s32 	%r19, %r25;
	mov.u32 	%r59, 0;
	setp.eq.u32 	%p8, %r55, %r59;
	@%p8 bra 	$Lt_193_23042;
	.loc	17	9255	0
	neg.s32 	%r42, %r42;
	.loc	17	9257	0
	mov.u32 	%r60, 0;
	set.eq.u32.u32 	%r61, %r42, %r60;
	neg.s32 	%r62, %r61;
	not.b32 	%r63, %r26;
	add.u32 	%r26, %r62, %r63;
	.loc	17	9258	0
	xor.b32 	%r22, %r21, -2147483648;
$Lt_193_23042:
	.loc	17	9261	0
	mov.u32 	%r64, 0;
	setp.eq.s32 	%p9, %r26, %r64;
	@%p9 bra 	$Lt_193_23810;
	.loc	19	6283	0
	cvt.rz.f32.u32 	%f164, %r26;
	mov.b32 	%r65, %f164;
	shr.s32 	%r66, %r65, 23;
	mov.s32 	%r67, 158;
	sub.s32 	%r68, %r67, %r66;
	bra.uni 	$Lt_193_23554;
$Lt_193_23810:
	mov.s32 	%r68, 32;
$Lt_193_23554:
	.loc	17	9261	0
	mov.s32 	%r69, %r68;
	mov.s32 	%r70, %r69;
	.loc	19	6283	0
	mov.s32 	%r71, 32;
	sub.s32 	%r72, %r71, %r69;
	shr.u32 	%r73, %r42, %r72;
	shl.b32 	%r74, %r26, %r69;
	add.u32 	%r75, %r73, %r74;
	mov.u32 	%r76, 0;
	setp.ne.u32 	%p10, %r69, %r76;
	selp.u32 	%r77, %r75, %r26, %p10;
	.loc	17	9265	0
	mul.lo.u32 	%r42, %r77, -921707870;
	.loc	17	9266	0
	mov.u32 	%r78, -921707870;
	mul.hi.u32 	%r26, %r77, %r78;
	mov.u32 	%r79, 0;
	setp.le.s32 	%p11, %r26, %r79;
	@%p11 bra 	$Lt_193_24066;
	.loc	17	9268	0
	shr.u32 	%r80, %r42, 31;
	shl.b32 	%r81, %r26, 1;
	add.u32 	%r26, %r80, %r81;
	.loc	17	9269	0
	add.u32 	%r70, %r69, 1;
$Lt_193_24066:
	.loc	17	9294	0
	add.u32 	%r82, %r26, 1;
	shr.u32 	%r83, %r82, 7;
	add.u32 	%r84, %r83, 1;
	shr.u32 	%r85, %r84, 1;
	mov.s32 	%r86, 126;
	sub.s32 	%r87, %r86, %r70;
	shl.b32 	%r88, %r87, 23;
	add.u32 	%r89, %r85, %r88;
	or.b32 	%r90, %r22, %r89;
	mov.b32 	%f161, %r90;
$Lt_193_20994:
	.loc	17	9561	0
	mov.u64 	%rd5, __cudart_i2opi_f;
	mov.f32 	%f165, 0fbf490fdb;   	// -0.785398
	add.f32 	%f166, %f161, %f165;
	and.b32 	%r91, %r19, 3;
	cvt.rn.f32.s32 	%f167, %r91;
	mov.f32 	%f168, 0f3fc90fdb;   	// 1.5708
	mad.f32 	%f169, %f167, %f168, %f166;
	mov.f32 	%f170, %f169;
	.loc	17	9511	0
	abs.f32 	%f171, %f169;
	mov.f32 	%f172, 0f7f800000;   	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p12, %f171, %f172;
	@!%p12 bra 	$Lt_193_24578;
	.loc	17	9512	0
	mov.f32 	%f173, 0f00000000;   	// 0
	mul.rn.f32 	%f170, %f169, %f173;
$Lt_193_24578:
	.loc	17	9280	0
	mov.f32 	%f174, 0f3f22f983;   	// 0.63662
	mul.f32 	%f175, %f170, %f174;
	cvt.rni.s32.f32 	%r92, %f175;
	mov.s32 	%r93, %r92;
	.loc	17	8936	0
	cvt.rn.f32.s32 	%f176, %r92;
	neg.f32 	%f177, %f176;
	mov.f32 	%f178, %f177;
	mov.f32 	%f179, 0f3fc90000;   	// 1.57031
	mov.f32 	%f180, %f179;
	mov.f32 	%f181, %f170;
	mad.f32 %f182, %f178, %f180, %f181;
	mov.f32 	%f183, %f182;
	mov.f32 	%f184, %f177;
	mov.f32 	%f185, 0f39fd8000;   	// 0.000483513
	mov.f32 	%f186, %f185;
	mov.f32 	%f187, %f183;
	mad.f32 %f188, %f184, %f186, %f187;
	mov.f32 	%f189, %f188;
	mov.f32 	%f190, %f177;
	mov.f32 	%f191, 0f34a88000;   	// 3.13856e-07
	mov.f32 	%f192, %f191;
	mov.f32 	%f193, %f189;
	mad.f32 %f194, %f190, %f192, %f193;
	mov.f32 	%f195, %f194;
	mov.f32 	%f196, %f177;
	mov.f32 	%f197, 0f2e85a309;   	// 6.0771e-11
	mov.f32 	%f198, %f197;
	mov.f32 	%f199, %f195;
	mad.f32 %f200, %f196, %f198, %f199;
	mov.f32 	%f201, %f200;
	.loc	17	9291	0
	mov.f32 	%f202, %f201;
	abs.f32 	%f203, %f170;
	mov.f32 	%f204, 0f473ba700;   	// 48039
	setp.gt.f32 	%p13, %f203, %f204;
	@!%p13 bra 	$Lt_193_25090;
	.loc	17	9215	0
	mov.b32 	%r94, %f170;
	and.b32 	%r95, %r94, -2147483648;
	mov.s32 	%r96, %r95;
	.loc	17	24	0
	shl.b32 	%r97, %r94, 8;
	or.b32 	%r98, %r97, -2147483648;
	mov.s64 	%rd12, %rd5;
	mov.u64 	%rd13, __cuda___cuda_result_449152;
	mov.s32 	%r99, 0;
	mov.u32 	%r100, 0;
$Lt_193_26114:
 //<loop> Loop body line 24, nesting depth: 1, iterations: 6
	.loc	17	9187	0
	ld.const.u32 	%r101, [%rd12+0];
	mov.u32 	%r102, %r101;
	mov.u32 	%r103, %r98;
	mov.u32 	%r104, %r100;
	{
	.reg .u64 tmp;
	mul.wide.u32 tmp, %r102, %r103;
	mov.b64         {%r105,%r106}, tmp;
	add.cc.u32      %r105, %r105, %r104;
	addc.u32        %r106, %r106, 0;
	}
	mov.s32 	%r107, %r105;
	mov.s32 	%r108, %r106;
	.loc	17	9229	0
	mov.s32 	%r100, %r108;
	.loc	17	9230	0
	st.local.u32 	[%rd13+0], %r107;
	add.s32 	%r99, %r99, 1;
	add.u64 	%rd13, %rd13, 4;
	add.u64 	%rd12, %rd12, 4;
	mov.u32 	%r109, 6;
	setp.ne.s32 	%p14, %r99, %r109;
	@%p14 bra 	$Lt_193_26114;
	.loc	17	9232	0
	st.local.u32 	[__cuda___cuda_result_449152+24], %r108;
	.loc	17	9237	0
	shl.b32 	%r110, %r94, 1;
	shr.u32 	%r111, %r110, 24;
	sub.u32 	%r112, %r111, 128;
	mov.u64 	%rd14, __cuda___cuda_result_449152;
	shr.u32 	%r113, %r112, 5;
	mov.s32 	%r114, 4;
	sub.s32 	%r115, %r114, %r113;
	cvt.s64.s32 	%rd15, %r115;
	mul.wide.s32 	%rd16, %r115, 4;
	add.u64 	%rd17, %rd14, %rd16;
	ld.local.u32 	%r100, [%rd17+8];
	.loc	17	9238	0
	ld.local.u32 	%r116, [%rd17+4];
	and.b32 	%r117, %r112, 31;
	mov.u32 	%r118, 0;
	setp.eq.u32 	%p15, %r117, %r118;
	@%p15 bra 	$Lt_193_26626;
	.loc	17	9241	0
	mov.s32 	%r119, 32;
	sub.s32 	%r120, %r119, %r117;
	shr.u32 	%r121, %r116, %r120;
	shl.b32 	%r122, %r100, %r117;
	add.u32 	%r100, %r121, %r122;
	.loc	17	9242	0
	ld.local.u32 	%r123, [%rd17+0];
	shr.u32 	%r124, %r123, %r120;
	shl.b32 	%r125, %r116, %r117;
	add.u32 	%r116, %r124, %r125;
$Lt_193_26626:
	.loc	17	9244	0
	shr.u32 	%r126, %r100, 30;
	.loc	17	9246	0
	shr.u32 	%r127, %r116, 30;
	shl.b32 	%r128, %r100, 2;
	add.u32 	%r100, %r127, %r128;
	.loc	17	9247	0
	shl.b32 	%r116, %r116, 2;
	.loc	17	9249	0
	shr.u32 	%r129, %r100, 31;
	add.u32 	%r130, %r126, %r129;
	.loc	17	9244	0
	neg.s32 	%r131, %r130;
	mov.u32 	%r132, 0;
	setp.ne.u32 	%p16, %r95, %r132;
	selp.s32 	%r99, %r131, %r130, %p16;
	.loc	17	9251	0
	mov.s32 	%r93, %r99;
	mov.u32 	%r133, 0;
	setp.eq.u32 	%p17, %r129, %r133;
	@%p17 bra 	$Lt_193_27138;
	.loc	17	9255	0
	neg.s32 	%r116, %r116;
	.loc	17	9257	0
	mov.u32 	%r134, 0;
	set.eq.u32.u32 	%r135, %r116, %r134;
	neg.s32 	%r136, %r135;
	not.b32 	%r137, %r100;
	add.u32 	%r100, %r136, %r137;
	.loc	17	9258	0
	xor.b32 	%r96, %r95, -2147483648;
$Lt_193_27138:
	.loc	17	9261	0
	mov.u32 	%r138, 0;
	setp.eq.s32 	%p18, %r100, %r138;
	@%p18 bra 	$Lt_193_27906;
	.loc	19	6283	0
	cvt.rz.f32.u32 	%f205, %r100;
	mov.b32 	%r139, %f205;
	shr.s32 	%r140, %r139, 23;
	mov.s32 	%r141, 158;
	sub.s32 	%r142, %r141, %r140;
	bra.uni 	$Lt_193_27650;
$Lt_193_27906:
	mov.s32 	%r142, 32;
$Lt_193_27650:
	.loc	17	9261	0
	mov.s32 	%r143, %r142;
	mov.s32 	%r144, %r143;
	.loc	19	6283	0
	mov.s32 	%r145, 32;
	sub.s32 	%r146, %r145, %r143;
	shr.u32 	%r147, %r116, %r146;
	shl.b32 	%r148, %r100, %r143;
	add.u32 	%r149, %r147, %r148;
	mov.u32 	%r150, 0;
	setp.ne.u32 	%p19, %r143, %r150;
	selp.u32 	%r151, %r149, %r100, %p19;
	.loc	17	9265	0
	mul.lo.u32 	%r116, %r151, -921707870;
	.loc	17	9266	0
	mov.u32 	%r152, -921707870;
	mul.hi.u32 	%r100, %r151, %r152;
	mov.u32 	%r153, 0;
	setp.le.s32 	%p20, %r100, %r153;
	@%p20 bra 	$Lt_193_28162;
	.loc	17	9268	0
	shr.u32 	%r154, %r116, 31;
	shl.b32 	%r155, %r100, 1;
	add.u32 	%r100, %r154, %r155;
	.loc	17	9269	0
	add.u32 	%r144, %r143, 1;
$Lt_193_28162:
	.loc	17	9294	0
	add.u32 	%r156, %r100, 1;
	shr.u32 	%r157, %r156, 7;
	add.u32 	%r158, %r157, 1;
	shr.u32 	%r159, %r158, 1;
	mov.s32 	%r160, 126;
	sub.s32 	%r161, %r160, %r144;
	shl.b32 	%r162, %r161, 23;
	add.u32 	%r163, %r159, %r162;
	or.b32 	%r164, %r96, %r163;
	mov.b32 	%f202, %r164;
$Lt_193_25090:
	.loc	17	8936	0
	mul.f32 	%f206, %f202, %f202;
	mov.f32 	%f207, 0f37ccf5ce;   	// 2.44332e-05
	mov.f32 	%f208, %f207;
	mov.f32 	%f209, %f206;
	mov.f32 	%f210, 0fbab6061a;   	// -0.00138873
	mov.f32 	%f211, %f210;
	mad.f32 %f212, %f208, %f209, %f211;
	mov.f32 	%f213, %f212;
	mov.f32 	%f214, %f213;
	mov.f32 	%f215, %f206;
	mov.f32 	%f216, 0f3d2aaaa5;   	// 0.0416666
	mov.f32 	%f217, %f216;
	mad.f32 %f218, %f214, %f215, %f217;
	mov.f32 	%f219, %f218;
	mov.f32 	%f220, %f219;
	mov.f32 	%f221, %f206;
	mov.f32 	%f222, 0fbf000000;   	// -0.5
	mov.f32 	%f223, %f222;
	mad.f32 %f224, %f220, %f221, %f223;
	mov.f32 	%f225, %f224;
	mov.f32 	%f226, %f225;
	mov.f32 	%f227, %f206;
	mov.f32 	%f228, 0f3f800000;   	// 1
	mov.f32 	%f229, %f228;
	mad.f32 %f230, %f226, %f227, %f229;
	mov.f32 	%f231, %f230;
	.loc	17	9515	0
	mov.f32 	%f232, %f231;
	.loc	17	8936	0
	mov.f32 	%f233, 0fb94ca1f9;   	// -0.000195153
	mov.f32 	%f234, %f233;
	mov.f32 	%f235, %f206;
	mov.f32 	%f236, 0f3c08839e;   	// 0.00833216
	mov.f32 	%f237, %f236;
	mad.f32 %f238, %f234, %f235, %f237;
	mov.f32 	%f239, %f238;
	mov.f32 	%f240, %f239;
	mov.f32 	%f241, %f206;
	mov.f32 	%f242, 0fbe2aaaa3;   	// -0.166667
	mov.f32 	%f243, %f242;
	mad.f32 %f244, %f240, %f241, %f243;
	mov.f32 	%f245, %f244;
	mul.f32 	%f246, %f206, %f245;
	mov.f32 	%f247, %f246;
	mov.f32 	%f248, %f202;
	mov.f32 	%f249, %f202;
	mad.f32 %f250, %f247, %f248, %f249;
	mov.f32 	%f251, %f250;
	.loc	17	9516	0
	mov.f32 	%f252, %f251;
	.loc	17	9517	0
	mov.f32 	%f253, %f252;
	and.b32 	%r165, %r93, 1;
	mov.u32 	%r166, 0;
	setp.eq.s32 	%p21, %r165, %r166;
	@%p21 bra 	$Lt_193_28674;
	.loc	17	9519	0
	mov.f32 	%f254, %f232;
	mov.f32 	%f252, %f254;
	.loc	17	9520	0
	mov.f32 	%f232, %f253;
$Lt_193_28674:
	and.b32 	%r167, %r93, 2;
	mov.u32 	%r168, 0;
	setp.eq.s32 	%p22, %r167, %r168;
	@%p22 bra 	$Lt_193_29186;
	.loc	17	9523	0
	mov.f32 	%f255, %f252;
	neg.f32 	%f256, %f255;
	mov.f32 	%f252, %f256;
$Lt_193_29186:
	add.s32 	%r169, %r93, 1;
	and.b32 	%r170, %r169, 2;
	mov.u32 	%r171, 0;
	setp.eq.s32 	%p23, %r170, %r171;
	@%p23 bra 	$Lt_193_29698;
	.loc	17	9527	0
	mov.f32 	%f257, %f232;
	neg.f32 	%f258, %f257;
	mov.f32 	%f232, %f258;
$Lt_193_29698:
	mov.f32 	%f259, 0f00000000;   	// 0
	setp.eq.f32 	%p24, %f202, %f259;
	@!%p24 bra 	$Lt_193_30210;
	.loc	17	9531	0
	mov.f32 	%f260, 0f00000000;   	// 0
	mul.rn.f32 	%f261, %f202, %f260;
	mov.f32 	%f252, %f261;
$Lt_193_30210:
	.loc	17	9534	0
	mov.f32 	%f262, %f252;
	.loc	17	9535	0
	mov.f32 	%f263, %f232;
	.loc	17	10143	0
	rsqrt.approx.f32 	%f264, %f2;
	mov.f32 	%f265, 0f3f4c422a;   	// 0.797885
	mul.f32 	%f266, %f264, %f265;
	mul.f32 	%f267, %f112, %f266;
	mul.f32 	%f85, %f263, %f267;
	bra.uni 	$Lt_193_20482;
$Lt_193_20738:
	.loc	17	10147	0
	mov.f32 	%f85, 0f00000000;    	// 0
$Lt_193_20482:
$Lt_193_19970:
	.loc	15	212	0
	ld.param.u64 	%rd18, [__cudaparm_ej0_mf_B];
	ld.param.s32 	%r172, [__cudaparm_ej0_mf_ldb];
	mul.lo.s32 	%r173, %r172, %r4;
	add.s32 	%r174, %r6, %r173;
	cvt.s64.s32 	%rd19, %r174;
	mul.wide.s32 	%rd20, %r174, 4;
	add.u64 	%rd21, %rd18, %rd20;
	st.global.f32 	[%rd21+0], %f85;
$Lt_193_19458:
	exit;
$LDWend_ej0_mf:
	} // ej0_mf

	.entry ej1_vf (
		.param .u64 __cudaparm_ej1_vf_n,
		.param .u64 __cudaparm_ej1_vf_x,
		.param .s32 __cudaparm_ej1_vf_lx,
		.param .u64 __cudaparm_ej1_vf_result,
		.param .s32 __cudaparm_ej1_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<168>;
	.reg .u64 %rd<25>;
	.reg .f32 %f<263>;
	.reg .pred %p<28>;
	.local .align 4 .b8 __cuda___cuda_result_169220[28];
	.local .align 4 .b8 __cuda___cuda_result_449248[28];
	.loc	15	213	0
$LDWbegin_ej1_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_ej1_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_194_20738;
	ld.param.u64 	%rd3, [__cudaparm_ej1_vf_x];
	ld.param.s32 	%r4, [__cudaparm_ej1_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f40fb3333;     	// 7.85
	setp.le.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_194_21506;
	.loc	17	8936	0
	mov.f32 	%f4, 0fc0753aac;     	// -3.83171
	add.f32 	%f5, %f2, %f4;
	mov.f32 	%f6, 0f33a5090f;     	// 7.68506e-08
	add.f32 	%f7, %f5, %f6;
	mov.f32 	%f8, 0f29af3463;     	// 7.78065e-14
	mov.f32 	%f9, %f8;
	mov.f32 	%f10, %f7;
	mov.f32 	%f11, 0f2b81bf42;    	// 9.21909e-13
	mov.f32 	%f12, %f11;
	mad.f32 %f13, %f9, %f10, %f12;
	mov.f32 	%f14, %f13;
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f7;
	mov.f32 	%f17, 0fade21ec1;    	// -2.57069e-11
	mov.f32 	%f18, %f17;
	mad.f32 %f19, %f15, %f16, %f18;
	mov.f32 	%f14, %f19;
	mov.f32 	%f20, %f14;
	mov.f32 	%f21, %f7;
	mov.f32 	%f22, 0faf5ddeff;    	// -2.01791e-10
	mov.f32 	%f23, %f22;
	mad.f32 %f24, %f20, %f21, %f23;
	mov.f32 	%f14, %f24;
	mov.f32 	%f25, %f14;
	mov.f32 	%f26, %f7;
	mov.f32 	%f27, 0f319b0c9d;    	// 4.51253e-09
	mov.f32 	%f28, %f27;
	mad.f32 %f29, %f25, %f26, %f28;
	mov.f32 	%f14, %f29;
	mov.f32 	%f30, %f14;
	mov.f32 	%f31, %f7;
	mov.f32 	%f32, 0f32e81173;    	// 2.70163e-08
	mov.f32 	%f33, %f32;
	mad.f32 %f34, %f30, %f31, %f33;
	mov.f32 	%f14, %f34;
	mov.f32 	%f35, %f14;
	mov.f32 	%f36, %f7;
	mov.f32 	%f37, 0fb50f8dc8;    	// -5.3478e-07
	mov.f32 	%f38, %f37;
	mad.f32 %f39, %f35, %f36, %f38;
	mov.f32 	%f14, %f39;
	mov.f32 	%f40, %f14;
	mov.f32 	%f41, %f7;
	mov.f32 	%f42, 0fb61e653d;    	// -2.36028e-06
	mov.f32 	%f43, %f42;
	mad.f32 %f44, %f40, %f41, %f43;
	mov.f32 	%f14, %f44;
	mov.f32 	%f45, %f14;
	mov.f32 	%f46, %f7;
	mov.f32 	%f47, 0f382cd9c5;    	// 4.12108e-05
	mov.f32 	%f48, %f47;
	mad.f32 %f49, %f45, %f46, %f48;
	mov.f32 	%f14, %f49;
	mov.f32 	%f50, %f14;
	mov.f32 	%f51, %f7;
	mov.f32 	%f52, 0f38f9eb10;    	// 0.00011917
	mov.f32 	%f53, %f52;
	mad.f32 %f54, %f50, %f51, %f53;
	mov.f32 	%f14, %f54;
	mov.f32 	%f55, %f14;
	mov.f32 	%f56, %f7;
	mov.f32 	%f57, 0fbaeceb9c;    	// -0.00180756
	mov.f32 	%f58, %f57;
	mad.f32 %f59, %f55, %f56, %f58;
	mov.f32 	%f14, %f59;
	mov.f32 	%f60, %f14;
	mov.f32 	%f61, %f7;
	mov.f32 	%f62, 0fbb276ffd;    	// -0.00255489
	mov.f32 	%f63, %f62;
	mad.f32 %f64, %f60, %f61, %f63;
	mov.f32 	%f14, %f64;
	mov.f32 	%f65, %f14;
	mov.f32 	%f66, %f7;
	mov.f32 	%f67, 0f3d073993;    	// 0.0330139
	mov.f32 	%f68, %f67;
	mad.f32 %f69, %f65, %f66, %f68;
	mov.f32 	%f14, %f69;
	.loc	17	10179	0
	mov.f32 	%f70, 0fc0e07fb0;    	// -7.01559
	add.f32 	%f71, %f2, %f70;
	mov.f32 	%f72, 0f3444b8db;    	// 1.83212e-07
	add.f32 	%f73, %f71, %f72;
	mul.f32 	%f74, %f14, %f73;
	mul.f32 	%f75, %f7, %f74;
	mul.f32 	%f76, %f2, %f75;
	bra.uni 	$Lt_194_21250;
$Lt_194_21506:
	.loc	17	10180	0
	mov.f32 	%f77, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p3, %f2, %f77;
	@%p3 bra 	$Lt_194_22018;
	.loc	17	8944	0
	mov.f32 	%f78, %f2;
	rcp.approx.ftz.f32 %f79,%f78;
	mov.f32 	%f80, %f79;
	.loc	17	8936	0
	mul.f32 	%f81, %f80, %f80;
	mov.f32 	%f82, 0fc082cb37;    	// -4.08731
	mov.f32 	%f83, %f82;
	mov.f32 	%f84, %f81;
	mov.f32 	%f85, 0f3f3ff7e9;    	// 0.749877
	mov.f32 	%f86, %f85;
	mad.f32 %f87, %f83, %f84, %f86;
	mov.f32 	%f14, %f87;
	mov.f32 	%f88, %f14;
	mov.f32 	%f89, %f81;
	mov.f32 	%f90, 0fbe458bae;    	// -0.192916
	mov.f32 	%f91, %f90;
	mad.f32 %f92, %f88, %f89, %f91;
	mov.f32 	%f14, %f92;
	mov.f32 	%f93, %f14;
	mov.f32 	%f94, %f81;
	mov.f32 	%f95, 0f3e3fff8b;    	// 0.187498
	mov.f32 	%f96, %f95;
	mad.f32 %f97, %f93, %f94, %f96;
	mov.f32 	%f14, %f97;
	mov.f32 	%f98, %f14;
	mov.f32 	%f99, %f81;
	mov.f32 	%f100, 0f3f800000;   	// 1
	mov.f32 	%f101, %f100;
	mad.f32 %f102, %f98, %f99, %f101;
	mov.f32 	%f103, %f102;
	mov.f32 	%f104, 0fbfca3ba2;   	// -1.57994
	mov.f32 	%f105, %f104;
	mov.f32 	%f106, %f81;
	mov.f32 	%f107, 0f3eb914ad;   	// 0.361486
	mov.f32 	%f108, %f107;
	mad.f32 %f109, %f105, %f106, %f108;
	mov.f32 	%f14, %f109;
	mov.f32 	%f110, %f14;
	mov.f32 	%f111, %f81;
	mov.f32 	%f112, 0fbe27f2ec;   	// -0.164013
	mov.f32 	%f113, %f112;
	mad.f32 %f114, %f110, %f111, %f113;
	mov.f32 	%f14, %f114;
	mov.f32 	%f115, %f14;
	mov.f32 	%f116, %f81;
	mov.f32 	%f117, 0f3ebffffd;   	// 0.375
	mov.f32 	%f118, %f117;
	mad.f32 %f119, %f115, %f116, %f118;
	mov.f32 	%f14, %f119;
	mov.f32 	%f120, %f14;
	mov.f32 	%f121, %f80;
	mov.f32 	%f122, %f2;
	mad.f32 %f123, %f120, %f121, %f122;
	mov.f32 	%f14, %f123;
	.loc	17	9280	0
	mov.f32 	%f124, 0f3f22f983;   	// 0.63662
	mul.f32 	%f125, %f14, %f124;
	cvt.rni.s32.f32 	%r6, %f125;
	mov.s32 	%r7, %r6;
	.loc	17	8936	0
	cvt.rn.f32.s32 	%f126, %r6;
	neg.f32 	%f127, %f126;
	mov.f32 	%f128, %f127;
	mov.f32 	%f129, 0f3fc90000;   	// 1.57031
	mov.f32 	%f130, %f129;
	mov.f32 	%f131, %f14;
	mad.f32 %f132, %f128, %f130, %f131;
	mov.f32 	%f133, %f132;
	mov.f32 	%f134, %f127;
	mov.f32 	%f135, 0f39fd8000;   	// 0.000483513
	mov.f32 	%f136, %f135;
	mov.f32 	%f137, %f133;
	mad.f32 %f138, %f134, %f136, %f137;
	mov.f32 	%f139, %f138;
	mov.f32 	%f140, %f127;
	mov.f32 	%f141, 0f34a88000;   	// 3.13856e-07
	mov.f32 	%f142, %f141;
	mov.f32 	%f143, %f139;
	mad.f32 %f144, %f140, %f142, %f143;
	mov.f32 	%f145, %f144;
	mov.f32 	%f146, %f127;
	mov.f32 	%f147, 0f2e85a309;   	// 6.0771e-11
	mov.f32 	%f148, %f147;
	mov.f32 	%f149, %f145;
	mad.f32 %f150, %f146, %f148, %f149;
	mov.f32 	%f151, %f150;
	.loc	17	9291	0
	mov.f32 	%f152, %f151;
	abs.f32 	%f153, %f14;
	mov.f32 	%f154, 0f473ba700;   	// 48039
	setp.gt.f32 	%p4, %f153, %f154;
	@!%p4 bra 	$Lt_194_22274;
	.loc	17	9294	0
	mov.u64 	%rd7, __cudart_i2opi_f;
	.loc	17	9215	0
	mov.b32 	%r8, %f14;
	and.b32 	%r9, %r8, -2147483648;
	mov.s32 	%r10, %r9;
	.loc	17	24	0
	shl.b32 	%r11, %r8, 8;
	or.b32 	%r12, %r11, -2147483648;
	mov.s64 	%rd8, %rd7;
	mov.u64 	%rd9, __cuda___cuda_result_169220;
	mov.s32 	%r13, 0;
	mov.u32 	%r14, 0;
$Lt_194_23298:
 //<loop> Loop body line 24, nesting depth: 1, iterations: 6
	.loc	17	9187	0
	ld.const.u32 	%r15, [%rd8+0];
	mov.u32 	%r16, %r15;
	mov.u32 	%r17, %r12;
	mov.u32 	%r18, %r14;
	{
	.reg .u64 tmp;
	mul.wide.u32 tmp, %r16, %r17;
	mov.b64         {%r19,%r20}, tmp;
	add.cc.u32      %r19, %r19, %r18;
	addc.u32        %r20, %r20, 0;
	}
	mov.s32 	%r21, %r19;
	mov.s32 	%r22, %r20;
	.loc	17	9229	0
	mov.s32 	%r14, %r22;
	.loc	17	9230	0
	st.local.u32 	[%rd9+0], %r21;
	add.s32 	%r13, %r13, 1;
	add.u64 	%rd9, %rd9, 4;
	add.u64 	%rd8, %rd8, 4;
	mov.u32 	%r23, 6;
	setp.ne.s32 	%p5, %r13, %r23;
	@%p5 bra 	$Lt_194_23298;
	.loc	17	9232	0
	st.local.u32 	[__cuda___cuda_result_169220+24], %r22;
	.loc	17	9237	0
	shl.b32 	%r24, %r8, 1;
	shr.u32 	%r25, %r24, 24;
	sub.u32 	%r26, %r25, 128;
	mov.u64 	%rd10, __cuda___cuda_result_169220;
	shr.u32 	%r27, %r26, 5;
	mov.s32 	%r28, 4;
	sub.s32 	%r29, %r28, %r27;
	cvt.s64.s32 	%rd11, %r29;
	mul.wide.s32 	%rd12, %r29, 4;
	add.u64 	%rd13, %rd10, %rd12;
	ld.local.u32 	%r14, [%rd13+8];
	.loc	17	9238	0
	ld.local.u32 	%r30, [%rd13+4];
	and.b32 	%r31, %r26, 31;
	mov.u32 	%r32, 0;
	setp.eq.u32 	%p6, %r31, %r32;
	@%p6 bra 	$Lt_194_23810;
	.loc	17	9241	0
	mov.s32 	%r33, 32;
	sub.s32 	%r34, %r33, %r31;
	shr.u32 	%r35, %r30, %r34;
	shl.b32 	%r36, %r14, %r31;
	add.u32 	%r14, %r35, %r36;
	.loc	17	9242	0
	ld.local.u32 	%r37, [%rd13+0];
	shr.u32 	%r38, %r37, %r34;
	shl.b32 	%r39, %r30, %r31;
	add.u32 	%r30, %r38, %r39;
$Lt_194_23810:
	.loc	17	9244	0
	shr.u32 	%r40, %r14, 30;
	.loc	17	9246	0
	shr.u32 	%r41, %r30, 30;
	shl.b32 	%r42, %r14, 2;
	add.u32 	%r14, %r41, %r42;
	.loc	17	9247	0
	shl.b32 	%r30, %r30, 2;
	.loc	17	9249	0
	shr.u32 	%r43, %r14, 31;
	add.u32 	%r44, %r40, %r43;
	.loc	17	9244	0
	neg.s32 	%r45, %r44;
	mov.u32 	%r46, 0;
	setp.ne.u32 	%p7, %r9, %r46;
	selp.s32 	%r13, %r45, %r44, %p7;
	.loc	17	9251	0
	mov.s32 	%r7, %r13;
	mov.u32 	%r47, 0;
	setp.eq.u32 	%p8, %r43, %r47;
	@%p8 bra 	$Lt_194_24322;
	.loc	17	9255	0
	neg.s32 	%r30, %r30;
	.loc	17	9257	0
	mov.u32 	%r48, 0;
	set.eq.u32.u32 	%r49, %r30, %r48;
	neg.s32 	%r50, %r49;
	not.b32 	%r51, %r14;
	add.u32 	%r14, %r50, %r51;
	.loc	17	9258	0
	xor.b32 	%r10, %r9, -2147483648;
$Lt_194_24322:
	.loc	17	9261	0
	mov.u32 	%r52, 0;
	setp.eq.s32 	%p9, %r14, %r52;
	@%p9 bra 	$Lt_194_25090;
	.loc	19	6283	0
	cvt.rz.f32.u32 	%f155, %r14;
	mov.b32 	%r53, %f155;
	shr.s32 	%r54, %r53, 23;
	mov.s32 	%r55, 158;
	sub.s32 	%r56, %r55, %r54;
	bra.uni 	$Lt_194_24834;
$Lt_194_25090:
	mov.s32 	%r56, 32;
$Lt_194_24834:
	.loc	17	9261	0
	mov.s32 	%r57, %r56;
	mov.s32 	%r58, %r57;
	.loc	19	6283	0
	mov.s32 	%r59, 32;
	sub.s32 	%r60, %r59, %r57;
	shr.u32 	%r61, %r30, %r60;
	shl.b32 	%r62, %r14, %r57;
	add.u32 	%r63, %r61, %r62;
	mov.u32 	%r64, 0;
	setp.ne.u32 	%p10, %r57, %r64;
	selp.u32 	%r65, %r63, %r14, %p10;
	.loc	17	9265	0
	mul.lo.u32 	%r30, %r65, -921707870;
	.loc	17	9266	0
	mov.u32 	%r66, -921707870;
	mul.hi.u32 	%r14, %r65, %r66;
	mov.u32 	%r67, 0;
	setp.le.s32 	%p11, %r14, %r67;
	@%p11 bra 	$Lt_194_25346;
	.loc	17	9268	0
	shr.u32 	%r68, %r30, 31;
	shl.b32 	%r69, %r14, 1;
	add.u32 	%r14, %r68, %r69;
	.loc	17	9269	0
	add.u32 	%r58, %r57, 1;
$Lt_194_25346:
	.loc	17	9294	0
	add.u32 	%r70, %r14, 1;
	shr.u32 	%r71, %r70, 7;
	add.u32 	%r72, %r71, 1;
	shr.u32 	%r73, %r72, 1;
	mov.s32 	%r74, 126;
	sub.s32 	%r75, %r74, %r58;
	shl.b32 	%r76, %r75, 23;
	add.u32 	%r77, %r73, %r76;
	or.b32 	%r78, %r10, %r77;
	mov.b32 	%f152, %r78;
$Lt_194_22274:
	.loc	17	9561	0
	mov.u64 	%rd7, __cudart_i2opi_f;
	mov.f32 	%f156, 0fc016cbe4;   	// -2.35619
	add.f32 	%f157, %f152, %f156;
	and.b32 	%r79, %r7, 3;
	cvt.rn.f32.s32 	%f158, %r79;
	mov.f32 	%f159, 0f3fc90fdb;   	// 1.5708
	mad.f32 	%f160, %f158, %f159, %f157;
	mov.f32 	%f161, %f160;
	.loc	17	9511	0
	abs.f32 	%f162, %f160;
	mov.f32 	%f163, 0f7f800000;   	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p12, %f162, %f163;
	@!%p12 bra 	$Lt_194_25858;
	.loc	17	9512	0
	mov.f32 	%f164, 0f00000000;   	// 0
	mul.rn.f32 	%f161, %f160, %f164;
$Lt_194_25858:
	.loc	17	9280	0
	mov.f32 	%f165, 0f3f22f983;   	// 0.63662
	mul.f32 	%f166, %f161, %f165;
	cvt.rni.s32.f32 	%r80, %f166;
	mov.s32 	%r81, %r80;
	.loc	17	8936	0
	cvt.rn.f32.s32 	%f167, %r80;
	neg.f32 	%f168, %f167;
	mov.f32 	%f169, %f168;
	mov.f32 	%f170, 0f3fc90000;   	// 1.57031
	mov.f32 	%f171, %f170;
	mov.f32 	%f172, %f161;
	mad.f32 %f173, %f169, %f171, %f172;
	mov.f32 	%f174, %f173;
	mov.f32 	%f175, %f168;
	mov.f32 	%f176, 0f39fd8000;   	// 0.000483513
	mov.f32 	%f177, %f176;
	mov.f32 	%f178, %f174;
	mad.f32 %f179, %f175, %f177, %f178;
	mov.f32 	%f180, %f179;
	mov.f32 	%f181, %f168;
	mov.f32 	%f182, 0f34a88000;   	// 3.13856e-07
	mov.f32 	%f183, %f182;
	mov.f32 	%f184, %f180;
	mad.f32 %f185, %f181, %f183, %f184;
	mov.f32 	%f186, %f185;
	mov.f32 	%f187, %f168;
	mov.f32 	%f188, 0f2e85a309;   	// 6.0771e-11
	mov.f32 	%f189, %f188;
	mov.f32 	%f190, %f186;
	mad.f32 %f191, %f187, %f189, %f190;
	mov.f32 	%f192, %f191;
	.loc	17	9291	0
	mov.f32 	%f193, %f192;
	abs.f32 	%f194, %f161;
	mov.f32 	%f195, 0f473ba700;   	// 48039
	setp.gt.f32 	%p13, %f194, %f195;
	@!%p13 bra 	$Lt_194_26370;
	.loc	17	9215	0
	mov.b32 	%r82, %f161;
	and.b32 	%r83, %r82, -2147483648;
	mov.s32 	%r84, %r83;
	.loc	17	24	0
	shl.b32 	%r85, %r82, 8;
	or.b32 	%r86, %r85, -2147483648;
	mov.s64 	%rd14, %rd7;
	mov.u64 	%rd15, __cuda___cuda_result_449248;
	mov.s32 	%r87, 0;
	mov.u32 	%r88, 0;
$Lt_194_27394:
 //<loop> Loop body line 24, nesting depth: 1, iterations: 6
	.loc	17	9187	0
	ld.const.u32 	%r89, [%rd14+0];
	mov.u32 	%r90, %r89;
	mov.u32 	%r91, %r86;
	mov.u32 	%r92, %r88;
	{
	.reg .u64 tmp;
	mul.wide.u32 tmp, %r90, %r91;
	mov.b64         {%r93,%r94}, tmp;
	add.cc.u32      %r93, %r93, %r92;
	addc.u32        %r94, %r94, 0;
	}
	mov.s32 	%r95, %r93;
	mov.s32 	%r96, %r94;
	.loc	17	9229	0
	mov.s32 	%r88, %r96;
	.loc	17	9230	0
	st.local.u32 	[%rd15+0], %r95;
	add.s32 	%r87, %r87, 1;
	add.u64 	%rd15, %rd15, 4;
	add.u64 	%rd14, %rd14, 4;
	mov.u32 	%r97, 6;
	setp.ne.s32 	%p14, %r87, %r97;
	@%p14 bra 	$Lt_194_27394;
	.loc	17	9232	0
	st.local.u32 	[__cuda___cuda_result_449248+24], %r96;
	.loc	17	9237	0
	shl.b32 	%r98, %r82, 1;
	shr.u32 	%r99, %r98, 24;
	sub.u32 	%r100, %r99, 128;
	mov.u64 	%rd16, __cuda___cuda_result_449248;
	shr.u32 	%r101, %r100, 5;
	mov.s32 	%r102, 4;
	sub.s32 	%r103, %r102, %r101;
	cvt.s64.s32 	%rd17, %r103;
	mul.wide.s32 	%rd18, %r103, 4;
	add.u64 	%rd19, %rd16, %rd18;
	ld.local.u32 	%r88, [%rd19+8];
	.loc	17	9238	0
	ld.local.u32 	%r104, [%rd19+4];
	and.b32 	%r105, %r100, 31;
	mov.u32 	%r106, 0;
	setp.eq.u32 	%p15, %r105, %r106;
	@%p15 bra 	$Lt_194_27906;
	.loc	17	9241	0
	mov.s32 	%r107, 32;
	sub.s32 	%r108, %r107, %r105;
	shr.u32 	%r109, %r104, %r108;
	shl.b32 	%r110, %r88, %r105;
	add.u32 	%r88, %r109, %r110;
	.loc	17	9242	0
	ld.local.u32 	%r111, [%rd19+0];
	shr.u32 	%r112, %r111, %r108;
	shl.b32 	%r113, %r104, %r105;
	add.u32 	%r104, %r112, %r113;
$Lt_194_27906:
	.loc	17	9244	0
	shr.u32 	%r114, %r88, 30;
	.loc	17	9246	0
	shr.u32 	%r115, %r104, 30;
	shl.b32 	%r116, %r88, 2;
	add.u32 	%r88, %r115, %r116;
	.loc	17	9247	0
	shl.b32 	%r104, %r104, 2;
	.loc	17	9249	0
	shr.u32 	%r117, %r88, 31;
	add.u32 	%r118, %r114, %r117;
	.loc	17	9244	0
	neg.s32 	%r119, %r118;
	mov.u32 	%r120, 0;
	setp.ne.u32 	%p16, %r83, %r120;
	selp.s32 	%r87, %r119, %r118, %p16;
	.loc	17	9251	0
	mov.s32 	%r81, %r87;
	mov.u32 	%r121, 0;
	setp.eq.u32 	%p17, %r117, %r121;
	@%p17 bra 	$Lt_194_28418;
	.loc	17	9255	0
	neg.s32 	%r104, %r104;
	.loc	17	9257	0
	mov.u32 	%r122, 0;
	set.eq.u32.u32 	%r123, %r104, %r122;
	neg.s32 	%r124, %r123;
	not.b32 	%r125, %r88;
	add.u32 	%r88, %r124, %r125;
	.loc	17	9258	0
	xor.b32 	%r84, %r83, -2147483648;
$Lt_194_28418:
	.loc	17	9261	0
	mov.u32 	%r126, 0;
	setp.eq.s32 	%p18, %r88, %r126;
	@%p18 bra 	$Lt_194_29186;
	.loc	19	6283	0
	cvt.rz.f32.u32 	%f196, %r88;
	mov.b32 	%r127, %f196;
	shr.s32 	%r128, %r127, 23;
	mov.s32 	%r129, 158;
	sub.s32 	%r130, %r129, %r128;
	bra.uni 	$Lt_194_28930;
$Lt_194_29186:
	mov.s32 	%r130, 32;
$Lt_194_28930:
	.loc	17	9261	0
	mov.s32 	%r131, %r130;
	mov.s32 	%r132, %r131;
	.loc	19	6283	0
	mov.s32 	%r133, 32;
	sub.s32 	%r134, %r133, %r131;
	shr.u32 	%r135, %r104, %r134;
	shl.b32 	%r136, %r88, %r131;
	add.u32 	%r137, %r135, %r136;
	mov.u32 	%r138, 0;
	setp.ne.u32 	%p19, %r131, %r138;
	selp.u32 	%r139, %r137, %r88, %p19;
	.loc	17	9265	0
	mul.lo.u32 	%r104, %r139, -921707870;
	.loc	17	9266	0
	mov.u32 	%r140, -921707870;
	mul.hi.u32 	%r88, %r139, %r140;
	mov.u32 	%r141, 0;
	setp.le.s32 	%p20, %r88, %r141;
	@%p20 bra 	$Lt_194_29442;
	.loc	17	9268	0
	shr.u32 	%r142, %r104, 31;
	shl.b32 	%r143, %r88, 1;
	add.u32 	%r88, %r142, %r143;
	.loc	17	9269	0
	add.u32 	%r132, %r131, 1;
$Lt_194_29442:
	.loc	17	9294	0
	add.u32 	%r144, %r88, 1;
	shr.u32 	%r145, %r144, 7;
	add.u32 	%r146, %r145, 1;
	shr.u32 	%r147, %r146, 1;
	mov.s32 	%r148, 126;
	sub.s32 	%r149, %r148, %r132;
	shl.b32 	%r150, %r149, 23;
	add.u32 	%r151, %r147, %r150;
	or.b32 	%r152, %r84, %r151;
	mov.b32 	%f193, %r152;
$Lt_194_26370:
	.loc	17	8936	0
	mul.f32 	%f197, %f193, %f193;
	mov.f32 	%f198, 0f37ccf5ce;   	// 2.44332e-05
	mov.f32 	%f199, %f198;
	mov.f32 	%f200, %f197;
	mov.f32 	%f201, 0fbab6061a;   	// -0.00138873
	mov.f32 	%f202, %f201;
	mad.f32 %f203, %f199, %f200, %f202;
	mov.f32 	%f204, %f203;
	mov.f32 	%f205, %f204;
	mov.f32 	%f206, %f197;
	mov.f32 	%f207, 0f3d2aaaa5;   	// 0.0416666
	mov.f32 	%f208, %f207;
	mad.f32 %f209, %f205, %f206, %f208;
	mov.f32 	%f210, %f209;
	mov.f32 	%f211, %f210;
	mov.f32 	%f212, %f197;
	mov.f32 	%f213, 0fbf000000;   	// -0.5
	mov.f32 	%f214, %f213;
	mad.f32 %f215, %f211, %f212, %f214;
	mov.f32 	%f216, %f215;
	mov.f32 	%f217, %f216;
	mov.f32 	%f218, %f197;
	mov.f32 	%f219, 0f3f800000;   	// 1
	mov.f32 	%f220, %f219;
	mad.f32 %f221, %f217, %f218, %f220;
	mov.f32 	%f222, %f221;
	.loc	17	9515	0
	mov.f32 	%f223, %f222;
	.loc	17	8936	0
	mov.f32 	%f224, 0fb94ca1f9;   	// -0.000195153
	mov.f32 	%f225, %f224;
	mov.f32 	%f226, %f197;
	mov.f32 	%f227, 0f3c08839e;   	// 0.00833216
	mov.f32 	%f228, %f227;
	mad.f32 %f229, %f225, %f226, %f228;
	mov.f32 	%f230, %f229;
	mov.f32 	%f231, %f230;
	mov.f32 	%f232, %f197;
	mov.f32 	%f233, 0fbe2aaaa3;   	// -0.166667
	mov.f32 	%f234, %f233;
	mad.f32 %f235, %f231, %f232, %f234;
	mov.f32 	%f236, %f235;
	mul.f32 	%f237, %f197, %f236;
	mov.f32 	%f238, %f237;
	mov.f32 	%f239, %f193;
	mov.f32 	%f240, %f193;
	mad.f32 %f241, %f238, %f239, %f240;
	mov.f32 	%f242, %f241;
	.loc	17	9516	0
	mov.f32 	%f243, %f242;
	.loc	17	9517	0
	mov.f32 	%f244, %f243;
	and.b32 	%r153, %r81, 1;
	mov.u32 	%r154, 0;
	setp.eq.s32 	%p21, %r153, %r154;
	@%p21 bra 	$Lt_194_29954;
	.loc	17	9519	0
	mov.f32 	%f245, %f223;
	mov.f32 	%f243, %f245;
	.loc	17	9520	0
	mov.f32 	%f223, %f244;
$Lt_194_29954:
	and.b32 	%r155, %r81, 2;
	mov.u32 	%r156, 0;
	setp.eq.s32 	%p22, %r155, %r156;
	@%p22 bra 	$Lt_194_30466;
	.loc	17	9523	0
	mov.f32 	%f246, %f243;
	neg.f32 	%f247, %f246;
	mov.f32 	%f243, %f247;
$Lt_194_30466:
	add.s32 	%r157, %r81, 1;
	and.b32 	%r158, %r157, 2;
	mov.u32 	%r159, 0;
	setp.eq.s32 	%p23, %r158, %r159;
	@%p23 bra 	$Lt_194_30978;
	.loc	17	9527	0
	mov.f32 	%f248, %f223;
	neg.f32 	%f249, %f248;
	mov.f32 	%f223, %f249;
$Lt_194_30978:
	mov.f32 	%f250, 0f00000000;   	// 0
	setp.eq.f32 	%p24, %f193, %f250;
	@!%p24 bra 	$Lt_194_31490;
	.loc	17	9531	0
	mov.f32 	%f251, 0f00000000;   	// 0
	mul.rn.f32 	%f252, %f193, %f251;
	mov.f32 	%f243, %f252;
$Lt_194_31490:
	.loc	17	9534	0
	mov.f32 	%f253, %f243;
	.loc	17	9535	0
	mov.f32 	%f254, %f223;
	.loc	17	10194	0
	rsqrt.approx.f32 	%f255, %f2;
	mov.f32 	%f256, 0f3f4c422a;   	// 0.797885
	mul.f32 	%f257, %f255, %f256;
	mul.f32 	%f258, %f103, %f257;
	mul.f32 	%f76, %f254, %f258;
	bra.uni 	$Lt_194_21762;
$Lt_194_22018:
	.loc	17	10197	0
	mov.f32 	%f76, 0f00000000;    	// 0
$Lt_194_21762:
$Lt_194_21250:
	.loc	17	10199	0
	neg.f32 	%f259, %f76;
	mov.f32 	%f260, 0f00000000;   	// 0
	setp.lt.f32 	%p25, %f1, %f260;
	selp.f32 	%f76, %f259, %f76, %p25;
	mov.f32 	%f261, 0f0da24260;   	// 1e-30
	setp.lt.f32 	%p26, %f2, %f261;
	@!%p26 bra 	$Lt_194_32002;
	.loc	17	10203	0
	mov.b32 	%r160, %f1;
	and.b32 	%r161, %r160, -2147483648;
	mov.b32 	%r162, %f76;
	and.b32 	%r163, %r162, 2147483647;
	or.b32 	%r164, %r161, %r163;
	mov.b32 	%f76, %r164;
$Lt_194_32002:
	.loc	15	213	0
	ld.param.u64 	%rd20, [__cudaparm_ej1_vf_result];
	ld.param.s32 	%r165, [__cudaparm_ej1_vf_lr];
	mul.lo.s32 	%r166, %r165, %r3;
	cvt.s64.s32 	%rd21, %r166;
	mul.wide.s32 	%rd22, %r166, 4;
	add.u64 	%rd23, %rd20, %rd22;
	st.global.f32 	[%rd23+0], %f76;
$Lt_194_20738:
	exit;
$LDWend_ej1_vf:
	} // ej1_vf

	.entry ej1_mf (
		.param .s32 __cudaparm_ej1_mf_rs,
		.param .s32 __cudaparm_ej1_mf_cs,
		.param .u64 __cudaparm_ej1_mf_A,
		.param .s32 __cudaparm_ej1_mf_lda,
		.param .u64 __cudaparm_ej1_mf_B,
		.param .s32 __cudaparm_ej1_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<181>;
	.reg .u64 %rd<23>;
	.reg .f32 %f<263>;
	.reg .pred %p<28>;
	.local .align 4 .b8 __cuda___cuda_result_169316[28];
	.local .align 4 .b8 __cuda___cuda_result_449344[28];
$LDWbegin_ej1_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_ej1_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_ej1_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_195_20994;
	ld.param.u64 	%rd1, [__cudaparm_ej1_mf_A];
	ld.param.s32 	%r15, [__cudaparm_ej1_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f40fb3333;     	// 7.85
	setp.le.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_195_21762;
	.loc	17	8936	0
	mov.f32 	%f4, 0fc0753aac;     	// -3.83171
	add.f32 	%f5, %f2, %f4;
	mov.f32 	%f6, 0f33a5090f;     	// 7.68506e-08
	add.f32 	%f7, %f5, %f6;
	mov.f32 	%f8, 0f29af3463;     	// 7.78065e-14
	mov.f32 	%f9, %f8;
	mov.f32 	%f10, %f7;
	mov.f32 	%f11, 0f2b81bf42;    	// 9.21909e-13
	mov.f32 	%f12, %f11;
	mad.f32 %f13, %f9, %f10, %f12;
	mov.f32 	%f14, %f13;
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f7;
	mov.f32 	%f17, 0fade21ec1;    	// -2.57069e-11
	mov.f32 	%f18, %f17;
	mad.f32 %f19, %f15, %f16, %f18;
	mov.f32 	%f14, %f19;
	mov.f32 	%f20, %f14;
	mov.f32 	%f21, %f7;
	mov.f32 	%f22, 0faf5ddeff;    	// -2.01791e-10
	mov.f32 	%f23, %f22;
	mad.f32 %f24, %f20, %f21, %f23;
	mov.f32 	%f14, %f24;
	mov.f32 	%f25, %f14;
	mov.f32 	%f26, %f7;
	mov.f32 	%f27, 0f319b0c9d;    	// 4.51253e-09
	mov.f32 	%f28, %f27;
	mad.f32 %f29, %f25, %f26, %f28;
	mov.f32 	%f14, %f29;
	mov.f32 	%f30, %f14;
	mov.f32 	%f31, %f7;
	mov.f32 	%f32, 0f32e81173;    	// 2.70163e-08
	mov.f32 	%f33, %f32;
	mad.f32 %f34, %f30, %f31, %f33;
	mov.f32 	%f14, %f34;
	mov.f32 	%f35, %f14;
	mov.f32 	%f36, %f7;
	mov.f32 	%f37, 0fb50f8dc8;    	// -5.3478e-07
	mov.f32 	%f38, %f37;
	mad.f32 %f39, %f35, %f36, %f38;
	mov.f32 	%f14, %f39;
	mov.f32 	%f40, %f14;
	mov.f32 	%f41, %f7;
	mov.f32 	%f42, 0fb61e653d;    	// -2.36028e-06
	mov.f32 	%f43, %f42;
	mad.f32 %f44, %f40, %f41, %f43;
	mov.f32 	%f14, %f44;
	mov.f32 	%f45, %f14;
	mov.f32 	%f46, %f7;
	mov.f32 	%f47, 0f382cd9c5;    	// 4.12108e-05
	mov.f32 	%f48, %f47;
	mad.f32 %f49, %f45, %f46, %f48;
	mov.f32 	%f14, %f49;
	mov.f32 	%f50, %f14;
	mov.f32 	%f51, %f7;
	mov.f32 	%f52, 0f38f9eb10;    	// 0.00011917
	mov.f32 	%f53, %f52;
	mad.f32 %f54, %f50, %f51, %f53;
	mov.f32 	%f14, %f54;
	mov.f32 	%f55, %f14;
	mov.f32 	%f56, %f7;
	mov.f32 	%f57, 0fbaeceb9c;    	// -0.00180756
	mov.f32 	%f58, %f57;
	mad.f32 %f59, %f55, %f56, %f58;
	mov.f32 	%f14, %f59;
	mov.f32 	%f60, %f14;
	mov.f32 	%f61, %f7;
	mov.f32 	%f62, 0fbb276ffd;    	// -0.00255489
	mov.f32 	%f63, %f62;
	mad.f32 %f64, %f60, %f61, %f63;
	mov.f32 	%f14, %f64;
	mov.f32 	%f65, %f14;
	mov.f32 	%f66, %f7;
	mov.f32 	%f67, 0f3d073993;    	// 0.0330139
	mov.f32 	%f68, %f67;
	mad.f32 %f69, %f65, %f66, %f68;
	mov.f32 	%f14, %f69;
	.loc	17	10179	0
	mov.f32 	%f70, 0fc0e07fb0;    	// -7.01559
	add.f32 	%f71, %f2, %f70;
	mov.f32 	%f72, 0f3444b8db;    	// 1.83212e-07
	add.f32 	%f73, %f71, %f72;
	mul.f32 	%f74, %f14, %f73;
	mul.f32 	%f75, %f7, %f74;
	mul.f32 	%f76, %f2, %f75;
	bra.uni 	$Lt_195_21506;
$Lt_195_21762:
	.loc	17	10180	0
	mov.f32 	%f77, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p3, %f2, %f77;
	@%p3 bra 	$Lt_195_22274;
	.loc	17	8944	0
	mov.f32 	%f78, %f2;
	rcp.approx.ftz.f32 %f79,%f78;
	mov.f32 	%f80, %f79;
	.loc	17	8936	0
	mul.f32 	%f81, %f80, %f80;
	mov.f32 	%f82, 0fc082cb37;    	// -4.08731
	mov.f32 	%f83, %f82;
	mov.f32 	%f84, %f81;
	mov.f32 	%f85, 0f3f3ff7e9;    	// 0.749877
	mov.f32 	%f86, %f85;
	mad.f32 %f87, %f83, %f84, %f86;
	mov.f32 	%f14, %f87;
	mov.f32 	%f88, %f14;
	mov.f32 	%f89, %f81;
	mov.f32 	%f90, 0fbe458bae;    	// -0.192916
	mov.f32 	%f91, %f90;
	mad.f32 %f92, %f88, %f89, %f91;
	mov.f32 	%f14, %f92;
	mov.f32 	%f93, %f14;
	mov.f32 	%f94, %f81;
	mov.f32 	%f95, 0f3e3fff8b;    	// 0.187498
	mov.f32 	%f96, %f95;
	mad.f32 %f97, %f93, %f94, %f96;
	mov.f32 	%f14, %f97;
	mov.f32 	%f98, %f14;
	mov.f32 	%f99, %f81;
	mov.f32 	%f100, 0f3f800000;   	// 1
	mov.f32 	%f101, %f100;
	mad.f32 %f102, %f98, %f99, %f101;
	mov.f32 	%f103, %f102;
	mov.f32 	%f104, 0fbfca3ba2;   	// -1.57994
	mov.f32 	%f105, %f104;
	mov.f32 	%f106, %f81;
	mov.f32 	%f107, 0f3eb914ad;   	// 0.361486
	mov.f32 	%f108, %f107;
	mad.f32 %f109, %f105, %f106, %f108;
	mov.f32 	%f14, %f109;
	mov.f32 	%f110, %f14;
	mov.f32 	%f111, %f81;
	mov.f32 	%f112, 0fbe27f2ec;   	// -0.164013
	mov.f32 	%f113, %f112;
	mad.f32 %f114, %f110, %f111, %f113;
	mov.f32 	%f14, %f114;
	mov.f32 	%f115, %f14;
	mov.f32 	%f116, %f81;
	mov.f32 	%f117, 0f3ebffffd;   	// 0.375
	mov.f32 	%f118, %f117;
	mad.f32 %f119, %f115, %f116, %f118;
	mov.f32 	%f14, %f119;
	mov.f32 	%f120, %f14;
	mov.f32 	%f121, %f80;
	mov.f32 	%f122, %f2;
	mad.f32 %f123, %f120, %f121, %f122;
	mov.f32 	%f14, %f123;
	.loc	17	9280	0
	mov.f32 	%f124, 0f3f22f983;   	// 0.63662
	mul.f32 	%f125, %f14, %f124;
	cvt.rni.s32.f32 	%r18, %f125;
	mov.s32 	%r19, %r18;
	.loc	17	8936	0
	cvt.rn.f32.s32 	%f126, %r18;
	neg.f32 	%f127, %f126;
	mov.f32 	%f128, %f127;
	mov.f32 	%f129, 0f3fc90000;   	// 1.57031
	mov.f32 	%f130, %f129;
	mov.f32 	%f131, %f14;
	mad.f32 %f132, %f128, %f130, %f131;
	mov.f32 	%f133, %f132;
	mov.f32 	%f134, %f127;
	mov.f32 	%f135, 0f39fd8000;   	// 0.000483513
	mov.f32 	%f136, %f135;
	mov.f32 	%f137, %f133;
	mad.f32 %f138, %f134, %f136, %f137;
	mov.f32 	%f139, %f138;
	mov.f32 	%f140, %f127;
	mov.f32 	%f141, 0f34a88000;   	// 3.13856e-07
	mov.f32 	%f142, %f141;
	mov.f32 	%f143, %f139;
	mad.f32 %f144, %f140, %f142, %f143;
	mov.f32 	%f145, %f144;
	mov.f32 	%f146, %f127;
	mov.f32 	%f147, 0f2e85a309;   	// 6.0771e-11
	mov.f32 	%f148, %f147;
	mov.f32 	%f149, %f145;
	mad.f32 %f150, %f146, %f148, %f149;
	mov.f32 	%f151, %f150;
	.loc	17	9291	0
	mov.f32 	%f152, %f151;
	abs.f32 	%f153, %f14;
	mov.f32 	%f154, 0f473ba700;   	// 48039
	setp.gt.f32 	%p4, %f153, %f154;
	@!%p4 bra 	$Lt_195_22530;
	.loc	17	9294	0
	mov.u64 	%rd5, __cudart_i2opi_f;
	.loc	17	9215	0
	mov.b32 	%r20, %f14;
	and.b32 	%r21, %r20, -2147483648;
	mov.s32 	%r22, %r21;
	.loc	17	24	0
	shl.b32 	%r23, %r20, 8;
	or.b32 	%r24, %r23, -2147483648;
	mov.s64 	%rd6, %rd5;
	mov.u64 	%rd7, __cuda___cuda_result_169316;
	mov.s32 	%r25, 0;
	mov.u32 	%r26, 0;
$Lt_195_23554:
 //<loop> Loop body line 24, nesting depth: 1, iterations: 6
	.loc	17	9187	0
	ld.const.u32 	%r27, [%rd6+0];
	mov.u32 	%r28, %r27;
	mov.u32 	%r29, %r24;
	mov.u32 	%r30, %r26;
	{
	.reg .u64 tmp;
	mul.wide.u32 tmp, %r28, %r29;
	mov.b64         {%r31,%r32}, tmp;
	add.cc.u32      %r31, %r31, %r30;
	addc.u32        %r32, %r32, 0;
	}
	mov.s32 	%r33, %r31;
	mov.s32 	%r34, %r32;
	.loc	17	9229	0
	mov.s32 	%r26, %r34;
	.loc	17	9230	0
	st.local.u32 	[%rd7+0], %r33;
	add.s32 	%r25, %r25, 1;
	add.u64 	%rd7, %rd7, 4;
	add.u64 	%rd6, %rd6, 4;
	mov.u32 	%r35, 6;
	setp.ne.s32 	%p5, %r25, %r35;
	@%p5 bra 	$Lt_195_23554;
	.loc	17	9232	0
	st.local.u32 	[__cuda___cuda_result_169316+24], %r34;
	.loc	17	9237	0
	shl.b32 	%r36, %r20, 1;
	shr.u32 	%r37, %r36, 24;
	sub.u32 	%r38, %r37, 128;
	mov.u64 	%rd8, __cuda___cuda_result_169316;
	shr.u32 	%r39, %r38, 5;
	mov.s32 	%r40, 4;
	sub.s32 	%r41, %r40, %r39;
	cvt.s64.s32 	%rd9, %r41;
	mul.wide.s32 	%rd10, %r41, 4;
	add.u64 	%rd11, %rd8, %rd10;
	ld.local.u32 	%r26, [%rd11+8];
	.loc	17	9238	0
	ld.local.u32 	%r42, [%rd11+4];
	and.b32 	%r43, %r38, 31;
	mov.u32 	%r44, 0;
	setp.eq.u32 	%p6, %r43, %r44;
	@%p6 bra 	$Lt_195_24066;
	.loc	17	9241	0
	mov.s32 	%r45, 32;
	sub.s32 	%r46, %r45, %r43;
	shr.u32 	%r47, %r42, %r46;
	shl.b32 	%r48, %r26, %r43;
	add.u32 	%r26, %r47, %r48;
	.loc	17	9242	0
	ld.local.u32 	%r49, [%rd11+0];
	shr.u32 	%r50, %r49, %r46;
	shl.b32 	%r51, %r42, %r43;
	add.u32 	%r42, %r50, %r51;
$Lt_195_24066:
	.loc	17	9244	0
	shr.u32 	%r52, %r26, 30;
	.loc	17	9246	0
	shr.u32 	%r53, %r42, 30;
	shl.b32 	%r54, %r26, 2;
	add.u32 	%r26, %r53, %r54;
	.loc	17	9247	0
	shl.b32 	%r42, %r42, 2;
	.loc	17	9249	0
	shr.u32 	%r55, %r26, 31;
	add.u32 	%r56, %r52, %r55;
	.loc	17	9244	0
	neg.s32 	%r57, %r56;
	mov.u32 	%r58, 0;
	setp.ne.u32 	%p7, %r21, %r58;
	selp.s32 	%r25, %r57, %r56, %p7;
	.loc	17	9251	0
	mov.s32 	%r19, %r25;
	mov.u32 	%r59, 0;
	setp.eq.u32 	%p8, %r55, %r59;
	@%p8 bra 	$Lt_195_24578;
	.loc	17	9255	0
	neg.s32 	%r42, %r42;
	.loc	17	9257	0
	mov.u32 	%r60, 0;
	set.eq.u32.u32 	%r61, %r42, %r60;
	neg.s32 	%r62, %r61;
	not.b32 	%r63, %r26;
	add.u32 	%r26, %r62, %r63;
	.loc	17	9258	0
	xor.b32 	%r22, %r21, -2147483648;
$Lt_195_24578:
	.loc	17	9261	0
	mov.u32 	%r64, 0;
	setp.eq.s32 	%p9, %r26, %r64;
	@%p9 bra 	$Lt_195_25346;
	.loc	19	6283	0
	cvt.rz.f32.u32 	%f155, %r26;
	mov.b32 	%r65, %f155;
	shr.s32 	%r66, %r65, 23;
	mov.s32 	%r67, 158;
	sub.s32 	%r68, %r67, %r66;
	bra.uni 	$Lt_195_25090;
$Lt_195_25346:
	mov.s32 	%r68, 32;
$Lt_195_25090:
	.loc	17	9261	0
	mov.s32 	%r69, %r68;
	mov.s32 	%r70, %r69;
	.loc	19	6283	0
	mov.s32 	%r71, 32;
	sub.s32 	%r72, %r71, %r69;
	shr.u32 	%r73, %r42, %r72;
	shl.b32 	%r74, %r26, %r69;
	add.u32 	%r75, %r73, %r74;
	mov.u32 	%r76, 0;
	setp.ne.u32 	%p10, %r69, %r76;
	selp.u32 	%r77, %r75, %r26, %p10;
	.loc	17	9265	0
	mul.lo.u32 	%r42, %r77, -921707870;
	.loc	17	9266	0
	mov.u32 	%r78, -921707870;
	mul.hi.u32 	%r26, %r77, %r78;
	mov.u32 	%r79, 0;
	setp.le.s32 	%p11, %r26, %r79;
	@%p11 bra 	$Lt_195_25602;
	.loc	17	9268	0
	shr.u32 	%r80, %r42, 31;
	shl.b32 	%r81, %r26, 1;
	add.u32 	%r26, %r80, %r81;
	.loc	17	9269	0
	add.u32 	%r70, %r69, 1;
$Lt_195_25602:
	.loc	17	9294	0
	add.u32 	%r82, %r26, 1;
	shr.u32 	%r83, %r82, 7;
	add.u32 	%r84, %r83, 1;
	shr.u32 	%r85, %r84, 1;
	mov.s32 	%r86, 126;
	sub.s32 	%r87, %r86, %r70;
	shl.b32 	%r88, %r87, 23;
	add.u32 	%r89, %r85, %r88;
	or.b32 	%r90, %r22, %r89;
	mov.b32 	%f152, %r90;
$Lt_195_22530:
	.loc	17	9561	0
	mov.u64 	%rd5, __cudart_i2opi_f;
	mov.f32 	%f156, 0fc016cbe4;   	// -2.35619
	add.f32 	%f157, %f152, %f156;
	and.b32 	%r91, %r19, 3;
	cvt.rn.f32.s32 	%f158, %r91;
	mov.f32 	%f159, 0f3fc90fdb;   	// 1.5708
	mad.f32 	%f160, %f158, %f159, %f157;
	mov.f32 	%f161, %f160;
	.loc	17	9511	0
	abs.f32 	%f162, %f160;
	mov.f32 	%f163, 0f7f800000;   	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p12, %f162, %f163;
	@!%p12 bra 	$Lt_195_26114;
	.loc	17	9512	0
	mov.f32 	%f164, 0f00000000;   	// 0
	mul.rn.f32 	%f161, %f160, %f164;
$Lt_195_26114:
	.loc	17	9280	0
	mov.f32 	%f165, 0f3f22f983;   	// 0.63662
	mul.f32 	%f166, %f161, %f165;
	cvt.rni.s32.f32 	%r92, %f166;
	mov.s32 	%r93, %r92;
	.loc	17	8936	0
	cvt.rn.f32.s32 	%f167, %r92;
	neg.f32 	%f168, %f167;
	mov.f32 	%f169, %f168;
	mov.f32 	%f170, 0f3fc90000;   	// 1.57031
	mov.f32 	%f171, %f170;
	mov.f32 	%f172, %f161;
	mad.f32 %f173, %f169, %f171, %f172;
	mov.f32 	%f174, %f173;
	mov.f32 	%f175, %f168;
	mov.f32 	%f176, 0f39fd8000;   	// 0.000483513
	mov.f32 	%f177, %f176;
	mov.f32 	%f178, %f174;
	mad.f32 %f179, %f175, %f177, %f178;
	mov.f32 	%f180, %f179;
	mov.f32 	%f181, %f168;
	mov.f32 	%f182, 0f34a88000;   	// 3.13856e-07
	mov.f32 	%f183, %f182;
	mov.f32 	%f184, %f180;
	mad.f32 %f185, %f181, %f183, %f184;
	mov.f32 	%f186, %f185;
	mov.f32 	%f187, %f168;
	mov.f32 	%f188, 0f2e85a309;   	// 6.0771e-11
	mov.f32 	%f189, %f188;
	mov.f32 	%f190, %f186;
	mad.f32 %f191, %f187, %f189, %f190;
	mov.f32 	%f192, %f191;
	.loc	17	9291	0
	mov.f32 	%f193, %f192;
	abs.f32 	%f194, %f161;
	mov.f32 	%f195, 0f473ba700;   	// 48039
	setp.gt.f32 	%p13, %f194, %f195;
	@!%p13 bra 	$Lt_195_26626;
	.loc	17	9215	0
	mov.b32 	%r94, %f161;
	and.b32 	%r95, %r94, -2147483648;
	mov.s32 	%r96, %r95;
	.loc	17	24	0
	shl.b32 	%r97, %r94, 8;
	or.b32 	%r98, %r97, -2147483648;
	mov.s64 	%rd12, %rd5;
	mov.u64 	%rd13, __cuda___cuda_result_449344;
	mov.s32 	%r99, 0;
	mov.u32 	%r100, 0;
$Lt_195_27650:
 //<loop> Loop body line 24, nesting depth: 1, iterations: 6
	.loc	17	9187	0
	ld.const.u32 	%r101, [%rd12+0];
	mov.u32 	%r102, %r101;
	mov.u32 	%r103, %r98;
	mov.u32 	%r104, %r100;
	{
	.reg .u64 tmp;
	mul.wide.u32 tmp, %r102, %r103;
	mov.b64         {%r105,%r106}, tmp;
	add.cc.u32      %r105, %r105, %r104;
	addc.u32        %r106, %r106, 0;
	}
	mov.s32 	%r107, %r105;
	mov.s32 	%r108, %r106;
	.loc	17	9229	0
	mov.s32 	%r100, %r108;
	.loc	17	9230	0
	st.local.u32 	[%rd13+0], %r107;
	add.s32 	%r99, %r99, 1;
	add.u64 	%rd13, %rd13, 4;
	add.u64 	%rd12, %rd12, 4;
	mov.u32 	%r109, 6;
	setp.ne.s32 	%p14, %r99, %r109;
	@%p14 bra 	$Lt_195_27650;
	.loc	17	9232	0
	st.local.u32 	[__cuda___cuda_result_449344+24], %r108;
	.loc	17	9237	0
	shl.b32 	%r110, %r94, 1;
	shr.u32 	%r111, %r110, 24;
	sub.u32 	%r112, %r111, 128;
	mov.u64 	%rd14, __cuda___cuda_result_449344;
	shr.u32 	%r113, %r112, 5;
	mov.s32 	%r114, 4;
	sub.s32 	%r115, %r114, %r113;
	cvt.s64.s32 	%rd15, %r115;
	mul.wide.s32 	%rd16, %r115, 4;
	add.u64 	%rd17, %rd14, %rd16;
	ld.local.u32 	%r100, [%rd17+8];
	.loc	17	9238	0
	ld.local.u32 	%r116, [%rd17+4];
	and.b32 	%r117, %r112, 31;
	mov.u32 	%r118, 0;
	setp.eq.u32 	%p15, %r117, %r118;
	@%p15 bra 	$Lt_195_28162;
	.loc	17	9241	0
	mov.s32 	%r119, 32;
	sub.s32 	%r120, %r119, %r117;
	shr.u32 	%r121, %r116, %r120;
	shl.b32 	%r122, %r100, %r117;
	add.u32 	%r100, %r121, %r122;
	.loc	17	9242	0
	ld.local.u32 	%r123, [%rd17+0];
	shr.u32 	%r124, %r123, %r120;
	shl.b32 	%r125, %r116, %r117;
	add.u32 	%r116, %r124, %r125;
$Lt_195_28162:
	.loc	17	9244	0
	shr.u32 	%r126, %r100, 30;
	.loc	17	9246	0
	shr.u32 	%r127, %r116, 30;
	shl.b32 	%r128, %r100, 2;
	add.u32 	%r100, %r127, %r128;
	.loc	17	9247	0
	shl.b32 	%r116, %r116, 2;
	.loc	17	9249	0
	shr.u32 	%r129, %r100, 31;
	add.u32 	%r130, %r126, %r129;
	.loc	17	9244	0
	neg.s32 	%r131, %r130;
	mov.u32 	%r132, 0;
	setp.ne.u32 	%p16, %r95, %r132;
	selp.s32 	%r99, %r131, %r130, %p16;
	.loc	17	9251	0
	mov.s32 	%r93, %r99;
	mov.u32 	%r133, 0;
	setp.eq.u32 	%p17, %r129, %r133;
	@%p17 bra 	$Lt_195_28674;
	.loc	17	9255	0
	neg.s32 	%r116, %r116;
	.loc	17	9257	0
	mov.u32 	%r134, 0;
	set.eq.u32.u32 	%r135, %r116, %r134;
	neg.s32 	%r136, %r135;
	not.b32 	%r137, %r100;
	add.u32 	%r100, %r136, %r137;
	.loc	17	9258	0
	xor.b32 	%r96, %r95, -2147483648;
$Lt_195_28674:
	.loc	17	9261	0
	mov.u32 	%r138, 0;
	setp.eq.s32 	%p18, %r100, %r138;
	@%p18 bra 	$Lt_195_29442;
	.loc	19	6283	0
	cvt.rz.f32.u32 	%f196, %r100;
	mov.b32 	%r139, %f196;
	shr.s32 	%r140, %r139, 23;
	mov.s32 	%r141, 158;
	sub.s32 	%r142, %r141, %r140;
	bra.uni 	$Lt_195_29186;
$Lt_195_29442:
	mov.s32 	%r142, 32;
$Lt_195_29186:
	.loc	17	9261	0
	mov.s32 	%r143, %r142;
	mov.s32 	%r144, %r143;
	.loc	19	6283	0
	mov.s32 	%r145, 32;
	sub.s32 	%r146, %r145, %r143;
	shr.u32 	%r147, %r116, %r146;
	shl.b32 	%r148, %r100, %r143;
	add.u32 	%r149, %r147, %r148;
	mov.u32 	%r150, 0;
	setp.ne.u32 	%p19, %r143, %r150;
	selp.u32 	%r151, %r149, %r100, %p19;
	.loc	17	9265	0
	mul.lo.u32 	%r116, %r151, -921707870;
	.loc	17	9266	0
	mov.u32 	%r152, -921707870;
	mul.hi.u32 	%r100, %r151, %r152;
	mov.u32 	%r153, 0;
	setp.le.s32 	%p20, %r100, %r153;
	@%p20 bra 	$Lt_195_29698;
	.loc	17	9268	0
	shr.u32 	%r154, %r116, 31;
	shl.b32 	%r155, %r100, 1;
	add.u32 	%r100, %r154, %r155;
	.loc	17	9269	0
	add.u32 	%r144, %r143, 1;
$Lt_195_29698:
	.loc	17	9294	0
	add.u32 	%r156, %r100, 1;
	shr.u32 	%r157, %r156, 7;
	add.u32 	%r158, %r157, 1;
	shr.u32 	%r159, %r158, 1;
	mov.s32 	%r160, 126;
	sub.s32 	%r161, %r160, %r144;
	shl.b32 	%r162, %r161, 23;
	add.u32 	%r163, %r159, %r162;
	or.b32 	%r164, %r96, %r163;
	mov.b32 	%f193, %r164;
$Lt_195_26626:
	.loc	17	8936	0
	mul.f32 	%f197, %f193, %f193;
	mov.f32 	%f198, 0f37ccf5ce;   	// 2.44332e-05
	mov.f32 	%f199, %f198;
	mov.f32 	%f200, %f197;
	mov.f32 	%f201, 0fbab6061a;   	// -0.00138873
	mov.f32 	%f202, %f201;
	mad.f32 %f203, %f199, %f200, %f202;
	mov.f32 	%f204, %f203;
	mov.f32 	%f205, %f204;
	mov.f32 	%f206, %f197;
	mov.f32 	%f207, 0f3d2aaaa5;   	// 0.0416666
	mov.f32 	%f208, %f207;
	mad.f32 %f209, %f205, %f206, %f208;
	mov.f32 	%f210, %f209;
	mov.f32 	%f211, %f210;
	mov.f32 	%f212, %f197;
	mov.f32 	%f213, 0fbf000000;   	// -0.5
	mov.f32 	%f214, %f213;
	mad.f32 %f215, %f211, %f212, %f214;
	mov.f32 	%f216, %f215;
	mov.f32 	%f217, %f216;
	mov.f32 	%f218, %f197;
	mov.f32 	%f219, 0f3f800000;   	// 1
	mov.f32 	%f220, %f219;
	mad.f32 %f221, %f217, %f218, %f220;
	mov.f32 	%f222, %f221;
	.loc	17	9515	0
	mov.f32 	%f223, %f222;
	.loc	17	8936	0
	mov.f32 	%f224, 0fb94ca1f9;   	// -0.000195153
	mov.f32 	%f225, %f224;
	mov.f32 	%f226, %f197;
	mov.f32 	%f227, 0f3c08839e;   	// 0.00833216
	mov.f32 	%f228, %f227;
	mad.f32 %f229, %f225, %f226, %f228;
	mov.f32 	%f230, %f229;
	mov.f32 	%f231, %f230;
	mov.f32 	%f232, %f197;
	mov.f32 	%f233, 0fbe2aaaa3;   	// -0.166667
	mov.f32 	%f234, %f233;
	mad.f32 %f235, %f231, %f232, %f234;
	mov.f32 	%f236, %f235;
	mul.f32 	%f237, %f197, %f236;
	mov.f32 	%f238, %f237;
	mov.f32 	%f239, %f193;
	mov.f32 	%f240, %f193;
	mad.f32 %f241, %f238, %f239, %f240;
	mov.f32 	%f242, %f241;
	.loc	17	9516	0
	mov.f32 	%f243, %f242;
	.loc	17	9517	0
	mov.f32 	%f244, %f243;
	and.b32 	%r165, %r93, 1;
	mov.u32 	%r166, 0;
	setp.eq.s32 	%p21, %r165, %r166;
	@%p21 bra 	$Lt_195_30210;
	.loc	17	9519	0
	mov.f32 	%f245, %f223;
	mov.f32 	%f243, %f245;
	.loc	17	9520	0
	mov.f32 	%f223, %f244;
$Lt_195_30210:
	and.b32 	%r167, %r93, 2;
	mov.u32 	%r168, 0;
	setp.eq.s32 	%p22, %r167, %r168;
	@%p22 bra 	$Lt_195_30722;
	.loc	17	9523	0
	mov.f32 	%f246, %f243;
	neg.f32 	%f247, %f246;
	mov.f32 	%f243, %f247;
$Lt_195_30722:
	add.s32 	%r169, %r93, 1;
	and.b32 	%r170, %r169, 2;
	mov.u32 	%r171, 0;
	setp.eq.s32 	%p23, %r170, %r171;
	@%p23 bra 	$Lt_195_31234;
	.loc	17	9527	0
	mov.f32 	%f248, %f223;
	neg.f32 	%f249, %f248;
	mov.f32 	%f223, %f249;
$Lt_195_31234:
	mov.f32 	%f250, 0f00000000;   	// 0
	setp.eq.f32 	%p24, %f193, %f250;
	@!%p24 bra 	$Lt_195_31746;
	.loc	17	9531	0
	mov.f32 	%f251, 0f00000000;   	// 0
	mul.rn.f32 	%f252, %f193, %f251;
	mov.f32 	%f243, %f252;
$Lt_195_31746:
	.loc	17	9534	0
	mov.f32 	%f253, %f243;
	.loc	17	9535	0
	mov.f32 	%f254, %f223;
	.loc	17	10194	0
	rsqrt.approx.f32 	%f255, %f2;
	mov.f32 	%f256, 0f3f4c422a;   	// 0.797885
	mul.f32 	%f257, %f255, %f256;
	mul.f32 	%f258, %f103, %f257;
	mul.f32 	%f76, %f254, %f258;
	bra.uni 	$Lt_195_22018;
$Lt_195_22274:
	.loc	17	10197	0
	mov.f32 	%f76, 0f00000000;    	// 0
$Lt_195_22018:
$Lt_195_21506:
	.loc	17	10199	0
	neg.f32 	%f259, %f76;
	mov.f32 	%f260, 0f00000000;   	// 0
	setp.lt.f32 	%p25, %f1, %f260;
	selp.f32 	%f76, %f259, %f76, %p25;
	mov.f32 	%f261, 0f0da24260;   	// 1e-30
	setp.lt.f32 	%p26, %f2, %f261;
	@!%p26 bra 	$Lt_195_32258;
	.loc	17	10203	0
	mov.b32 	%r172, %f1;
	and.b32 	%r173, %r172, -2147483648;
	mov.b32 	%r174, %f76;
	and.b32 	%r175, %r174, 2147483647;
	or.b32 	%r176, %r173, %r175;
	mov.b32 	%f76, %r176;
$Lt_195_32258:
	.loc	15	213	0
	ld.param.u64 	%rd18, [__cudaparm_ej1_mf_B];
	ld.param.s32 	%r177, [__cudaparm_ej1_mf_ldb];
	mul.lo.s32 	%r178, %r177, %r4;
	add.s32 	%r179, %r6, %r178;
	cvt.s64.s32 	%rd19, %r179;
	mul.wide.s32 	%rd20, %r179, 4;
	add.u64 	%rd21, %rd18, %rd20;
	st.global.f32 	[%rd21+0], %f76;
$Lt_195_20994:
	exit;
$LDWend_ej1_mf:
	} // ej1_mf

	.entry elgamma_vf (
		.param .u64 __cudaparm_elgamma_vf_n,
		.param .u64 __cudaparm_elgamma_vf_x,
		.param .s32 __cudaparm_elgamma_vf_lx,
		.param .u64 __cudaparm_elgamma_vf_result,
		.param .s32 __cudaparm_elgamma_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<54>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<476>;
	.reg .pred %p<21>;
	.loc	15	214	0
$LDWbegin_elgamma_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_elgamma_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_196_16386;
	ld.param.u64 	%rd3, [__cudaparm_elgamma_vf_x];
	ld.param.s32 	%r4, [__cudaparm_elgamma_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	.loc	17	10838	0
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f40400000;     	// 3
	setp.ge.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_196_17154;
	mov.f32 	%f4, 0f40f9999a;     	// 7.8
	setp.ge.f32 	%p3, %f2, %f4;
	@!%p3 bra 	$Lt_196_17666;
	.loc	17	8944	0
	mov.f32 	%f5, %f2;
	rcp.approx.ftz.f32 %f6,%f5;
	mov.f32 	%f7, %f6;
	.loc	17	8936	0
	mul.f32 	%f8, %f7, %f7;
	mov.f32 	%f9, 0f3a4be755;     	// 0.000777831
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, %f8;
	mov.f32 	%f12, 0fbb360953;    	// -0.00277766
	mov.f32 	%f13, %f12;
	mad.f32 %f14, %f10, %f11, %f13;
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f15;
	mov.f32 	%f17, %f8;
	mov.f32 	%f18, 0f3daaaaa3;    	// 0.0833333
	mov.f32 	%f19, %f18;
	mad.f32 %f20, %f16, %f17, %f19;
	mov.f32 	%f15, %f20;
	mov.f32 	%f21, %f15;
	mov.f32 	%f22, %f7;
	mov.f32 	%f23, 0f3f6b3f8e;    	// 0.918939
	mov.f32 	%f24, %f23;
	mad.f32 %f25, %f21, %f22, %f24;
	mov.f32 	%f15, %f25;
	.loc	17	9370	0
	mov.f32 	%f26, 0f00000000;    	// 0
	set.gt.u32.f32 	%r6, %f2, %f26;
	neg.s32 	%r7, %r6;
	mov.f32 	%f27, 0f7f800000;    	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r8, %f2, %f27;
	neg.s32 	%r9, %r8;
	and.b32 	%r10, %r7, %r9;
	mov.u32 	%r11, 0;
	setp.eq.s32 	%p4, %r10, %r11;
	@%p4 bra 	$Lt_196_18178;
	.loc	17	9039	0
	mov.b32 	%r12, %f2;
	and.b32 	%r13, %r12, 8388607;
	or.b32 	%r14, %r13, 1065353216;
	mov.b32 	%f28, %r14;
	mov.f32 	%f29, %f28;
	.loc	17	9040	0
	shr.u32 	%r15, %r12, 23;
	cvt.rn.f32.u32 	%f30, %r15;
	mov.f32 	%f31, 0fc2fe0000;    	// -127
	add.f32 	%f32, %f30, %f31;
	mov.f32 	%f33, %f32;
	mov.f32 	%f34, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p5, %f28, %f34;
	@!%p5 bra 	$Lt_196_18434;
	.loc	17	9042	0
	mov.f32 	%f35, 0f3f000000;    	// 0.5
	mul.f32 	%f29, %f28, %f35;
	.loc	17	9043	0
	mov.f32 	%f36, 0f3f800000;    	// 1
	add.f32 	%f33, %f32, %f36;
$Lt_196_18434:
	.loc	17	8944	0
	mov.f32 	%f37, 0f3f800000;    	// 1
	add.f32 	%f38, %f29, %f37;
	mov.f32 	%f39, %f38;
	rcp.approx.ftz.f32 %f40,%f39;
	mov.f32 	%f41, %f40;
	.loc	17	8936	0
	mov.f32 	%f42, 0fbf800000;    	// -1
	add.f32 	%f43, %f29, %f42;
	mul.f32 	%f44, %f43, %f43;
	neg.f32 	%f45, %f44;
	mul.rn.f32 	%f46, %f41, %f45;
	add.rn.f32 	%f47, %f43, %f46;
	mul.f32 	%f48, %f47, %f47;
	mov.f32 	%f49, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f50, %f49;
	mov.f32 	%f51, %f48;
	mov.f32 	%f52, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f53, %f52;
	mad.f32 %f54, %f50, %f51, %f53;
	mov.f32 	%f55, %f54;
	mov.f32 	%f56, %f55;
	mov.f32 	%f57, %f48;
	mov.f32 	%f58, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f59, %f58;
	mad.f32 %f60, %f56, %f57, %f59;
	mov.f32 	%f55, %f60;
	mul.f32 	%f61, %f48, %f55;
	mov.f32 	%f62, %f61;
	mov.f32 	%f63, %f47;
	mov.f32 	%f64, %f46;
	mad.f32 %f65, %f62, %f63, %f64;
	mov.f32 	%f55, %f65;
	mov.f32 	%f66, %f33;
	mov.f32 	%f67, 0f3f317218;    	// 0.693147
	mov.f32 	%f68, %f67;
	add.f32 	%f69, %f43, %f55;
	mov.f32 	%f70, %f69;
	mad.f32 %f71, %f66, %f68, %f70;
	mov.f32 	%f72, %f71;
	.loc	17	9050	0
	mov.f32 	%f73, %f72;
	bra.uni 	$Lt_196_17922;
$Lt_196_18178:
	.loc	17	9053	0
	lg2.approx.f32 	%f73, %f2;
$Lt_196_17922:
	.loc	17	9055	0
	mov.f32 	%f74, 0f3f000000;    	// 0.5
	mul.f32 	%f75, %f73, %f74;
	mov.f32 	%f76, 0fbf000000;    	// -0.5
	add.f32 	%f77, %f2, %f76;
	mul.rn.f32 	%f78, %f75, %f77;
	add.rn.f32 	%f79, %f78, %f15;
	sub.f32 	%f80, %f78, %f2;
	add.f32 	%f81, %f79, %f80;
	mov.f32 	%f82, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p6, %f2, %f82;
	selp.f32 	%f83, %f2, %f81, %p6;
	bra.uni 	$Lt_196_19458;
$Lt_196_17666:
	.loc	17	8936	0
	mov.f32 	%f84, 0fc0400000;    	// -3
	add.f32 	%f85, %f2, %f84;
	mov.f32 	%f86, 0fc43b38fb;    	// -748.89
	mov.f32 	%f87, %f86;
	mov.f32 	%f88, %f85;
	mov.f32 	%f89, 0fc640f6f8;    	// -12349.7
	mov.f32 	%f90, %f89;
	mad.f32 %f91, %f87, %f88, %f90;
	mov.f32 	%f15, %f91;
	mov.f32 	%f92, %f15;
	mov.f32 	%f93, %f85;
	mov.f32 	%f94, 0fc7206560;    	// -41061.4
	mov.f32 	%f95, %f94;
	mad.f32 %f96, %f92, %f93, %f95;
	mov.f32 	%f15, %f96;
	mov.f32 	%f97, %f15;
	mov.f32 	%f98, %f85;
	mov.f32 	%f99, 0fc73cb6aa;    	// -48310.7
	mov.f32 	%f100, %f99;
	mad.f32 %f101, %f97, %f98, %f100;
	mov.f32 	%f15, %f101;
	mov.f32 	%f102, %f15;
	mov.f32 	%f103, %f85;
	mov.f32 	%f104, 0fc80bae5a;   	// -143033
	mov.f32 	%f105, %f104;
	mad.f32 %f106, %f102, %f103, %f105;
	mov.f32 	%f15, %f106;
	.loc	17	9385	0
	mov.f32 	%f107, %f15;
	.loc	17	8936	0
	mov.f32 	%f108, 0fc381a020;   	// -259.251
	add.f32 	%f109, %f85, %f108;
	mov.f32 	%f110, %f109;
	mov.f32 	%f111, %f85;
	mov.f32 	%f112, 0fc62864b8;   	// -10777.2
	mov.f32 	%f113, %f112;
	mad.f32 %f114, %f110, %f111, %f113;
	mov.f32 	%f15, %f114;
	mov.f32 	%f115, %f15;
	mov.f32 	%f116, %f85;
	mov.f32 	%f117, 0fc7b50686;   	// -92685
	mov.f32 	%f118, %f117;
	mad.f32 %f119, %f115, %f116, %f118;
	mov.f32 	%f15, %f119;
	mov.f32 	%f120, %f15;
	mov.f32 	%f121, %f85;
	mov.f32 	%f122, 0fc8498465;   	// -206354
	mov.f32 	%f123, %f122;
	mad.f32 %f124, %f120, %f121, %f123;
	mov.f32 	%f15, %f124;
	.loc	17	8944	0
	mov.f32 	%f125, %f15;
	rcp.approx.ftz.f32 %f126,%f125;
	mov.f32 	%f127, %f126;
	.loc	17	8936	0
	mov.f32 	%f128, %f107;
	mov.f32 	%f129, %f127;
	mov.f32 	%f130, %f85;
	mad.f32 %f131, %f128, %f129, %f130;
	mov.f32 	%f15, %f131;
	.loc	17	9390	0
	mov.f32 	%f83, %f15;
	bra.uni 	$Lt_196_19458;
$Lt_196_17154:
	mov.f32 	%f132, 0f3fc00000;   	// 1.5
	setp.ge.f32 	%p7, %f2, %f132;
	@!%p7 bra 	$Lt_196_19202;
	.loc	17	8936	0
	mov.f32 	%f133, 0fc0000000;   	// -2
	add.f32 	%f134, %f2, %f133;
	mov.f32 	%f135, 0f385007fa;   	// 4.95985e-05
	mov.f32 	%f136, %f135;
	mov.f32 	%f137, %f134;
	mov.f32 	%f138, 0fb967a002;   	// -0.000220895
	mov.f32 	%f139, %f138;
	mad.f32 %f140, %f136, %f137, %f139;
	mov.f32 	%f15, %f140;
	mov.f32 	%f141, %f15;
	mov.f32 	%f142, %f134;
	mov.f32 	%f143, 0f3a0de6fc;   	// 0.000541314
	mov.f32 	%f144, %f143;
	mad.f32 %f145, %f141, %f142, %f144;
	mov.f32 	%f15, %f145;
	mov.f32 	%f146, %f15;
	mov.f32 	%f147, %f134;
	mov.f32 	%f148, 0fba9de0e2;   	// -0.00120452
	mov.f32 	%f149, %f148;
	mad.f32 %f150, %f146, %f147, %f149;
	mov.f32 	%f15, %f150;
	mov.f32 	%f151, %f15;
	mov.f32 	%f152, %f134;
	mov.f32 	%f153, 0f3b3d05b7;   	// 0.00288425
	mov.f32 	%f154, %f153;
	mad.f32 %f155, %f151, %f152, %f154;
	mov.f32 	%f15, %f155;
	mov.f32 	%f156, %f15;
	mov.f32 	%f157, %f134;
	mov.f32 	%f158, 0fbbf1eb10;   	// -0.00738276
	mov.f32 	%f159, %f158;
	mad.f32 %f160, %f156, %f157, %f159;
	mov.f32 	%f15, %f160;
	mov.f32 	%f161, %f15;
	mov.f32 	%f162, %f134;
	mov.f32 	%f163, 0f3ca89a28;   	// 0.0205813
	mov.f32 	%f164, %f163;
	mad.f32 %f165, %f161, %f162, %f164;
	mov.f32 	%f15, %f165;
	mov.f32 	%f166, %f15;
	mov.f32 	%f167, %f134;
	mov.f32 	%f168, 0fbd89f01a;   	// -0.0673525
	mov.f32 	%f169, %f168;
	mad.f32 %f170, %f166, %f167, %f169;
	mov.f32 	%f15, %f170;
	mov.f32 	%f171, %f15;
	mov.f32 	%f172, %f134;
	mov.f32 	%f173, 0f3ea51a66;   	// 0.322467
	mov.f32 	%f174, %f173;
	mad.f32 %f175, %f171, %f172, %f174;
	mov.f32 	%f15, %f175;
	mov.f32 	%f176, %f15;
	mov.f32 	%f177, %f134;
	mov.f32 	%f178, 0f3ed87730;   	// 0.422784
	mov.f32 	%f179, %f178;
	mad.f32 %f180, %f176, %f177, %f179;
	mov.f32 	%f15, %f180;
	.loc	17	9404	0
	mul.f32 	%f83, %f134, %f15;
	bra.uni 	$Lt_196_19458;
$Lt_196_19202:
	mov.f32 	%f181, 0f3f333333;   	// 0.7
	setp.ge.f32 	%p8, %f2, %f181;
	@!%p8 bra 	$Lt_196_19714;
	.loc	17	8936	0
	mov.f32 	%f182, 0f3f800000;   	// 1
	sub.f32 	%f183, %f182, %f2;
	mov.f32 	%f184, 0f3d3bef76;   	// 0.0458827
	mov.f32 	%f185, %f184;
	mov.f32 	%f186, %f183;
	mov.f32 	%f187, 0f3dd47577;   	// 0.10374
	mov.f32 	%f188, %f187;
	mad.f32 %f189, %f185, %f186, %f188;
	mov.f32 	%f15, %f189;
	mov.f32 	%f190, %f15;
	mov.f32 	%f191, %f183;
	mov.f32 	%f192, 0f3dfb8079;   	// 0.122804
	mov.f32 	%f193, %f192;
	mad.f32 %f194, %f190, %f191, %f193;
	mov.f32 	%f15, %f194;
	mov.f32 	%f195, %f15;
	mov.f32 	%f196, %f183;
	mov.f32 	%f197, 0f3e0295b5;   	// 0.127524
	mov.f32 	%f198, %f197;
	mad.f32 %f199, %f195, %f196, %f198;
	mov.f32 	%f15, %f199;
	mov.f32 	%f200, %f15;
	mov.f32 	%f201, %f183;
	mov.f32 	%f202, 0f3e12a765;   	// 0.143217
	mov.f32 	%f203, %f202;
	mad.f32 %f204, %f200, %f201, %f203;
	mov.f32 	%f15, %f204;
	mov.f32 	%f205, %f15;
	mov.f32 	%f206, %f183;
	mov.f32 	%f207, 0f3e2d6867;   	// 0.169344
	mov.f32 	%f208, %f207;
	mad.f32 %f209, %f205, %f206, %f208;
	mov.f32 	%f15, %f209;
	mov.f32 	%f210, %f15;
	mov.f32 	%f211, %f183;
	mov.f32 	%f212, 0f3e5462bf;   	// 0.207408
	mov.f32 	%f213, %f212;
	mad.f32 %f214, %f210, %f211, %f213;
	mov.f32 	%f15, %f214;
	mov.f32 	%f215, %f15;
	mov.f32 	%f216, %f183;
	mov.f32 	%f217, 0f3e8a8a72;   	// 0.270588
	mov.f32 	%f218, %f217;
	mad.f32 %f219, %f215, %f216, %f218;
	mov.f32 	%f15, %f219;
	mov.f32 	%f220, %f15;
	mov.f32 	%f221, %f183;
	mov.f32 	%f222, 0f3ecd26a4;   	// 0.400685
	mov.f32 	%f223, %f222;
	mad.f32 %f224, %f220, %f221, %f223;
	mov.f32 	%f15, %f224;
	mov.f32 	%f225, %f15;
	mov.f32 	%f226, %f183;
	mov.f32 	%f227, 0f3f528d32;   	// 0.822467
	mov.f32 	%f228, %f227;
	mad.f32 %f229, %f225, %f226, %f228;
	mov.f32 	%f15, %f229;
	mov.f32 	%f230, %f15;
	mov.f32 	%f231, %f183;
	mov.f32 	%f232, 0f3f13c468;   	// 0.577216
	mov.f32 	%f233, %f232;
	mad.f32 %f234, %f230, %f231, %f233;
	mov.f32 	%f15, %f234;
	.loc	17	9418	0
	mul.f32 	%f83, %f183, %f15;
	bra.uni 	$Lt_196_19458;
$Lt_196_19714:
	.loc	17	8936	0
	mov.f32 	%f235, 0f3b6b1c86;   	// 0.00358752
	mov.f32 	%f236, %f235;
	mov.f32 	%f237, %f2;
	mov.f32 	%f238, 0fbbb34878;   	// -0.00547129
	mov.f32 	%f239, %f238;
	mad.f32 %f240, %f236, %f237, %f239;
	mov.f32 	%f15, %f240;
	mov.f32 	%f241, %f15;
	mov.f32 	%f242, %f2;
	mov.f32 	%f243, 0fbd36caef;   	// -0.0446271
	mov.f32 	%f244, %f243;
	mad.f32 %f245, %f241, %f242, %f244;
	mov.f32 	%f15, %f245;
	mov.f32 	%f246, %f15;
	mov.f32 	%f247, %f2;
	mov.f32 	%f248, 0f3e2b5555;   	// 0.167318
	mov.f32 	%f249, %f248;
	mad.f32 %f250, %f246, %f247, %f249;
	mov.f32 	%f15, %f250;
	mov.f32 	%f251, %f15;
	mov.f32 	%f252, %f2;
	mov.f32 	%f253, 0fbd2c96c7;   	// -0.042136
	mov.f32 	%f254, %f253;
	mad.f32 %f255, %f251, %f252, %f254;
	mov.f32 	%f15, %f255;
	mov.f32 	%f256, %f15;
	mov.f32 	%f257, %f2;
	mov.f32 	%f258, 0fbf27e6eb;   	// -0.655867
	mov.f32 	%f259, %f258;
	mad.f32 %f260, %f256, %f257, %f259;
	mov.f32 	%f15, %f260;
	mov.f32 	%f261, %f15;
	mov.f32 	%f262, %f2;
	mov.f32 	%f263, 0f3f13c463;   	// 0.577215
	mov.f32 	%f264, %f263;
	mad.f32 %f265, %f261, %f262, %f264;
	mov.f32 	%f15, %f265;
	mul.f32 	%f266, %f2, %f15;
	mov.f32 	%f267, %f266;
	mov.f32 	%f268, %f2;
	mov.f32 	%f269, %f2;
	mad.f32 %f270, %f267, %f268, %f269;
	mov.f32 	%f15, %f270;
	.loc	17	9429	0
	mov.f32 	%f271, 0f00000000;   	// 0
	set.gt.u32.f32 	%r16, %f15, %f271;
	neg.s32 	%r17, %r16;
	mov.f32 	%f272, 0f7f800000;   	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r18, %f15, %f272;
	neg.s32 	%r19, %r18;
	and.b32 	%r20, %r17, %r19;
	mov.u32 	%r21, 0;
	setp.eq.s32 	%p9, %r20, %r21;
	@%p9 bra 	$Lt_196_20226;
	.loc	17	9039	0
	mov.b32 	%r22, %f15;
	and.b32 	%r23, %r22, 8388607;
	or.b32 	%r24, %r23, 1065353216;
	mov.b32 	%f273, %r24;
	mov.f32 	%f29, %f273;
	.loc	17	9040	0
	shr.u32 	%r25, %r22, 23;
	cvt.rn.f32.u32 	%f274, %r25;
	mov.f32 	%f275, 0fc2fe0000;   	// -127
	add.f32 	%f33, %f274, %f275;
	mov.f32 	%f276, 0f3fb504f3;   	// 1.41421
	setp.gt.f32 	%p10, %f273, %f276;
	@!%p10 bra 	$Lt_196_20482;
	.loc	17	9042	0
	mov.f32 	%f277, 0f3f000000;   	// 0.5
	mul.f32 	%f29, %f273, %f277;
	.loc	17	9043	0
	mov.f32 	%f278, 0f3f800000;   	// 1
	add.f32 	%f33, %f33, %f278;
$Lt_196_20482:
	.loc	17	8944	0
	mov.f32 	%f279, 0f3f800000;   	// 1
	add.f32 	%f280, %f29, %f279;
	mov.f32 	%f281, %f280;
	rcp.approx.ftz.f32 %f282,%f281;
	mov.f32 	%f283, %f282;
	.loc	17	8936	0
	mov.f32 	%f284, 0fbf800000;   	// -1
	add.f32 	%f285, %f29, %f284;
	mul.f32 	%f286, %f285, %f285;
	neg.f32 	%f287, %f286;
	mul.rn.f32 	%f288, %f283, %f287;
	add.rn.f32 	%f289, %f285, %f288;
	mul.f32 	%f290, %f289, %f289;
	mov.f32 	%f291, 0f3b2063c3;   	// 0.00244735
	mov.f32 	%f292, %f291;
	mov.f32 	%f293, %f290;
	mov.f32 	%f294, 0f3c4c4be0;   	// 0.0124693
	mov.f32 	%f295, %f294;
	mad.f32 %f296, %f292, %f293, %f295;
	mov.f32 	%f55, %f296;
	mov.f32 	%f297, %f55;
	mov.f32 	%f298, %f290;
	mov.f32 	%f299, 0f3daaab50;   	// 0.0833346
	mov.f32 	%f300, %f299;
	mad.f32 %f301, %f297, %f298, %f300;
	mov.f32 	%f55, %f301;
	mul.f32 	%f302, %f290, %f55;
	mov.f32 	%f303, %f302;
	mov.f32 	%f304, %f289;
	mov.f32 	%f305, %f288;
	mad.f32 %f306, %f303, %f304, %f305;
	mov.f32 	%f55, %f306;
	mov.f32 	%f307, %f33;
	mov.f32 	%f308, 0f3f317218;   	// 0.693147
	mov.f32 	%f309, %f308;
	add.f32 	%f310, %f285, %f55;
	mov.f32 	%f311, %f310;
	mad.f32 %f312, %f307, %f309, %f311;
	mov.f32 	%f313, %f312;
	.loc	17	9050	0
	mov.f32 	%f73, %f313;
	bra.uni 	$Lt_196_19970;
$Lt_196_20226:
	.loc	17	9053	0
	lg2.approx.f32 	%f73, %f15;
$Lt_196_19970:
	.loc	17	9429	0
	neg.f32 	%f83, %f73;
$Lt_196_19458:
$Lt_196_18946:
$Lt_196_16898:
	.loc	17	10838	0
	mov.f32 	%f314, 0f00000000;   	// 0
	setp.ge.f32 	%p11, %f1, %f314;
	@!%p11 bra 	$Lt_196_20994;
	.loc	17	10839	0
	mov.f32 	%f315, %f83;
	bra.uni 	$LDWendi___internal_fast_rcpf_436_1;
$Lt_196_20994:
	cvt.rmi.f32.f32 	%f316, %f2;
	setp.eq.f32 	%p12, %f316, %f2;
	@!%p12 bra 	$Lt_196_21506;
	.loc	17	10842	0
	mov.f32 	%f315, 0f7f800000;   	// ((1.0F)/(0.0F))
	bra.uni 	$LDWendi___internal_fast_rcpf_436_1;
$Lt_196_21506:
	mov.f32 	%f317, 0f1fec1e4a;   	// 1e-19
	setp.lt.f32 	%p13, %f2, %f317;
	@!%p13 bra 	$Lt_196_22018;
	.loc	17	10843	0
	mov.f32 	%f318, 0f00000000;   	// 0
	set.gt.u32.f32 	%r26, %f2, %f318;
	neg.s32 	%r27, %r26;
	mov.f32 	%f319, 0f7f800000;   	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r28, %f2, %f319;
	neg.s32 	%r29, %r28;
	and.b32 	%r30, %r27, %r29;
	mov.u32 	%r31, 0;
	setp.eq.s32 	%p14, %r30, %r31;
	@%p14 bra 	$Lt_196_22786;
	.loc	17	9039	0
	mov.b32 	%r32, %f2;
	and.b32 	%r33, %r32, 8388607;
	or.b32 	%r34, %r33, 1065353216;
	mov.b32 	%f28, %r34;
	mov.f32 	%f320, %f28;
	.loc	17	9040	0
	shr.u32 	%r35, %r32, 23;
	cvt.rn.f32.u32 	%f321, %r35;
	mov.f32 	%f322, 0fc2fe0000;   	// -127
	add.f32 	%f32, %f321, %f322;
	mov.f32 	%f323, %f32;
	mov.f32 	%f324, 0f3fb504f3;   	// 1.41421
	setp.gt.f32 	%p15, %f28, %f324;
	@!%p15 bra 	$Lt_196_23042;
	.loc	17	9042	0
	mov.f32 	%f325, 0f3f000000;   	// 0.5
	mul.f32 	%f320, %f28, %f325;
	.loc	17	9043	0
	mov.f32 	%f326, 0f3f800000;   	// 1
	add.f32 	%f323, %f32, %f326;
$Lt_196_23042:
	.loc	17	8944	0
	mov.f32 	%f327, 0f3f800000;   	// 1
	add.f32 	%f328, %f320, %f327;
	mov.f32 	%f329, %f328;
	rcp.approx.ftz.f32 %f330,%f329;
	mov.f32 	%f331, %f330;
	.loc	17	8936	0
	mov.f32 	%f332, 0fbf800000;   	// -1
	add.f32 	%f333, %f320, %f332;
	mul.f32 	%f334, %f333, %f333;
	neg.f32 	%f335, %f334;
	mul.rn.f32 	%f336, %f331, %f335;
	add.rn.f32 	%f337, %f333, %f336;
	mul.f32 	%f338, %f337, %f337;
	mov.f32 	%f339, 0f3b2063c3;   	// 0.00244735
	mov.f32 	%f340, %f339;
	mov.f32 	%f341, %f338;
	mov.f32 	%f342, 0f3c4c4be0;   	// 0.0124693
	mov.f32 	%f343, %f342;
	mad.f32 %f344, %f340, %f341, %f343;
	mov.f32 	%f345, %f344;
	mov.f32 	%f346, %f345;
	mov.f32 	%f347, %f338;
	mov.f32 	%f348, 0f3daaab50;   	// 0.0833346
	mov.f32 	%f349, %f348;
	mad.f32 %f350, %f346, %f347, %f349;
	mov.f32 	%f345, %f350;
	mul.f32 	%f351, %f338, %f345;
	mov.f32 	%f352, %f351;
	mov.f32 	%f353, %f337;
	mov.f32 	%f354, %f336;
	mad.f32 %f355, %f352, %f353, %f354;
	mov.f32 	%f345, %f355;
	mov.f32 	%f356, %f323;
	mov.f32 	%f357, 0f3f317218;   	// 0.693147
	mov.f32 	%f358, %f357;
	add.f32 	%f359, %f333, %f345;
	mov.f32 	%f360, %f359;
	mad.f32 %f361, %f356, %f358, %f360;
	mov.f32 	%f362, %f361;
	.loc	17	9050	0
	mov.f32 	%f363, %f362;
	bra.uni 	$Lt_196_22530;
$Lt_196_22786:
	.loc	17	9053	0
	lg2.approx.f32 	%f363, %f2;
$Lt_196_22530:
	.loc	17	10843	0
	neg.f32 	%f315, %f363;
	bra.uni 	$LDWendi___internal_fast_rcpf_436_1;
$Lt_196_22018:
	.loc	17	8936	0
	add.f32 	%f364, %f2, %f2;
	cvt.rni.f32.f32 	%f365, %f364;
	neg.f32 	%f366, %f365;
	mov.f32 	%f367, %f366;
	mov.f32 	%f368, 0f3f000000;   	// 0.5
	mov.f32 	%f369, %f368;
	mov.f32 	%f370, %f2;
	mad.f32 %f371, %f367, %f369, %f370;
	mov.f32 	%f372, %f371;
	.loc	17	10848	0
	mov.f32 	%f373, 0f40490fdb;   	// 3.14159
	mul.f32 	%f374, %f372, %f373;
	mul.f32 	%f375, %f374, %f374;
	cvt.rzi.s32.f32 	%r36, %f365;
	and.b32 	%r37, %r36, 1;
	mov.u32 	%r38, 0;
	setp.eq.s32 	%p16, %r37, %r38;
	@%p16 bra 	$Lt_196_23810;
	.loc	17	8936	0
	mov.f32 	%f376, 0f37ccf5ce;   	// 2.44332e-05
	mov.f32 	%f377, %f376;
	mov.f32 	%f378, %f375;
	mov.f32 	%f379, 0fbab6061a;   	// -0.00138873
	mov.f32 	%f380, %f379;
	mad.f32 %f381, %f377, %f378, %f380;
	mov.f32 	%f382, %f381;
	mov.f32 	%f383, %f382;
	mov.f32 	%f384, %f375;
	mov.f32 	%f385, 0f3d2aaaa5;   	// 0.0416666
	mov.f32 	%f386, %f385;
	mad.f32 %f387, %f383, %f384, %f386;
	mov.f32 	%f388, %f387;
	mov.f32 	%f389, %f388;
	mov.f32 	%f390, %f375;
	mov.f32 	%f391, 0fbf000000;   	// -0.5
	mov.f32 	%f392, %f391;
	mad.f32 %f393, %f389, %f390, %f392;
	mov.f32 	%f394, %f393;
	mov.f32 	%f395, %f394;
	mov.f32 	%f396, %f375;
	mov.f32 	%f397, 0f3f800000;   	// 1
	mov.f32 	%f398, %f397;
	mad.f32 %f399, %f395, %f396, %f398;
	mov.f32 	%f400, %f399;
	.loc	17	9491	0
	mov.f32 	%f401, %f400;
	bra.uni 	$Lt_196_23554;
$Lt_196_23810:
	.loc	17	8936	0
	mov.f32 	%f402, 0fb94ca1f9;   	// -0.000195153
	mov.f32 	%f403, %f402;
	mov.f32 	%f404, %f375;
	mov.f32 	%f405, 0f3c08839e;   	// 0.00833216
	mov.f32 	%f406, %f405;
	mad.f32 %f407, %f403, %f404, %f406;
	mov.f32 	%f408, %f407;
	mov.f32 	%f409, %f408;
	mov.f32 	%f410, %f375;
	mov.f32 	%f411, 0fbe2aaaa3;   	// -0.166667
	mov.f32 	%f412, %f411;
	mad.f32 %f413, %f409, %f410, %f412;
	mov.f32 	%f414, %f413;
	mul.f32 	%f415, %f375, %f414;
	mov.f32 	%f416, %f415;
	mov.f32 	%f417, %f374;
	mov.f32 	%f418, %f374;
	mad.f32 %f419, %f416, %f417, %f418;
	mov.f32 	%f420, %f419;
	.loc	17	9493	0
	mov.f32 	%f401, %f420;
$Lt_196_23554:
	and.b32 	%r39, %r36, 2;
	mov.u32 	%r40, 0;
	setp.eq.s32 	%p17, %r39, %r40;
	@%p17 bra 	$Lt_196_24066;
	.loc	17	8936	0
	mov.f32 	%f421, %f401;
	mov.f32 	%f422, 0fbf800000;   	// -1
	mov.f32 	%f423, %f422;
	mov.f32 	%f424, 0f00000000;   	// 0
	mov.f32 	%f425, %f424;
	mad.f32 %f426, %f421, %f423, %f425;
	mov.f32 	%f427, %f426;
	.loc	17	9496	0
	mov.f32 	%f401, %f427;
$Lt_196_24066:
	.loc	17	10850	0
	abs.f32 	%f428, %f401;
	mul.f32 	%f429, %f2, %f428;
	mov.f32 	%f430, 0f00000000;   	// 0
	set.gt.u32.f32 	%r41, %f429, %f430;
	neg.s32 	%r42, %r41;
	mov.f32 	%f431, 0f7f800000;   	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r43, %f429, %f431;
	neg.s32 	%r44, %r43;
	and.b32 	%r45, %r42, %r44;
	mov.u32 	%r46, 0;
	setp.eq.s32 	%p18, %r45, %r46;
	@%p18 bra 	$Lt_196_24834;
	.loc	17	9039	0
	mov.b32 	%r47, %f429;
	and.b32 	%r48, %r47, 8388607;
	or.b32 	%r49, %r48, 1065353216;
	mov.b32 	%f432, %r49;
	mov.f32 	%f320, %f432;
	.loc	17	9040	0
	shr.u32 	%r50, %r47, 23;
	cvt.rn.f32.u32 	%f433, %r50;
	mov.f32 	%f434, 0fc2fe0000;   	// -127
	add.f32 	%f323, %f433, %f434;
	mov.f32 	%f435, 0f3fb504f3;   	// 1.41421
	setp.gt.f32 	%p19, %f432, %f435;
	@!%p19 bra 	$Lt_196_25090;
	.loc	17	9042	0
	mov.f32 	%f436, 0f3f000000;   	// 0.5
	mul.f32 	%f320, %f432, %f436;
	.loc	17	9043	0
	mov.f32 	%f437, 0f3f800000;   	// 1
	add.f32 	%f323, %f323, %f437;
$Lt_196_25090:
	.loc	17	8944	0
	mov.f32 	%f438, 0f3f800000;   	// 1
	add.f32 	%f439, %f320, %f438;
	mov.f32 	%f440, %f439;
	rcp.approx.ftz.f32 %f441,%f440;
	mov.f32 	%f442, %f441;
	.loc	17	8936	0
	mov.f32 	%f443, 0fbf800000;   	// -1
	add.f32 	%f444, %f320, %f443;
	mul.f32 	%f445, %f444, %f444;
	neg.f32 	%f446, %f445;
	mul.rn.f32 	%f447, %f442, %f446;
	add.rn.f32 	%f448, %f444, %f447;
	mul.f32 	%f449, %f448, %f448;
	mov.f32 	%f450, 0f3b2063c3;   	// 0.00244735
	mov.f32 	%f451, %f450;
	mov.f32 	%f452, %f449;
	mov.f32 	%f453, 0f3c4c4be0;   	// 0.0124693
	mov.f32 	%f454, %f453;
	mad.f32 %f455, %f451, %f452, %f454;
	mov.f32 	%f345, %f455;
	mov.f32 	%f456, %f345;
	mov.f32 	%f457, %f449;
	mov.f32 	%f458, 0f3daaab50;   	// 0.0833346
	mov.f32 	%f459, %f458;
	mad.f32 %f460, %f456, %f457, %f459;
	mov.f32 	%f345, %f460;
	mul.f32 	%f461, %f449, %f345;
	mov.f32 	%f462, %f461;
	mov.f32 	%f463, %f448;
	mov.f32 	%f464, %f447;
	mad.f32 %f465, %f462, %f463, %f464;
	mov.f32 	%f345, %f465;
	mov.f32 	%f466, %f323;
	mov.f32 	%f467, 0f3f317218;   	// 0.693147
	mov.f32 	%f468, %f467;
	add.f32 	%f469, %f444, %f345;
	mov.f32 	%f470, %f469;
	mad.f32 %f471, %f466, %f468, %f470;
	mov.f32 	%f472, %f471;
	.loc	17	9050	0
	mov.f32 	%f363, %f472;
	bra.uni 	$Lt_196_24578;
$Lt_196_24834:
	.loc	17	9053	0
	lg2.approx.f32 	%f363, %f429;
$Lt_196_24578:
	.loc	17	10851	0
	mov.f32 	%f473, 0f3f928682;   	// 1.14473
	sub.f32 	%f474, %f473, %f363;
	sub.f32 	%f315, %f474, %f83;
$LDWendi___internal_fast_rcpf_436_1:
	.loc	15	214	0
	ld.param.u64 	%rd7, [__cudaparm_elgamma_vf_result];
	ld.param.s32 	%r51, [__cudaparm_elgamma_vf_lr];
	mul.lo.s32 	%r52, %r51, %r3;
	cvt.s64.s32 	%rd8, %r52;
	mul.wide.s32 	%rd9, %r52, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f315;
$Lt_196_16386:
	exit;
$LDWend_elgamma_vf:
	} // elgamma_vf

	.entry elgamma_mf (
		.param .s32 __cudaparm_elgamma_mf_rs,
		.param .s32 __cudaparm_elgamma_mf_cs,
		.param .u64 __cudaparm_elgamma_mf_A,
		.param .s32 __cudaparm_elgamma_mf_lda,
		.param .u64 __cudaparm_elgamma_mf_B,
		.param .s32 __cudaparm_elgamma_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<67>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<476>;
	.reg .pred %p<21>;
$LDWbegin_elgamma_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_elgamma_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_elgamma_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_197_16642;
	ld.param.u64 	%rd1, [__cudaparm_elgamma_mf_A];
	ld.param.s32 	%r15, [__cudaparm_elgamma_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	.loc	17	10838	0
	abs.f32 	%f2, %f1;
	mov.f32 	%f3, 0f40400000;     	// 3
	setp.ge.f32 	%p2, %f2, %f3;
	@!%p2 bra 	$Lt_197_17410;
	mov.f32 	%f4, 0f40f9999a;     	// 7.8
	setp.ge.f32 	%p3, %f2, %f4;
	@!%p3 bra 	$Lt_197_17922;
	.loc	17	8944	0
	mov.f32 	%f5, %f2;
	rcp.approx.ftz.f32 %f6,%f5;
	mov.f32 	%f7, %f6;
	.loc	17	8936	0
	mul.f32 	%f8, %f7, %f7;
	mov.f32 	%f9, 0f3a4be755;     	// 0.000777831
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, %f8;
	mov.f32 	%f12, 0fbb360953;    	// -0.00277766
	mov.f32 	%f13, %f12;
	mad.f32 %f14, %f10, %f11, %f13;
	mov.f32 	%f15, %f14;
	mov.f32 	%f16, %f15;
	mov.f32 	%f17, %f8;
	mov.f32 	%f18, 0f3daaaaa3;    	// 0.0833333
	mov.f32 	%f19, %f18;
	mad.f32 %f20, %f16, %f17, %f19;
	mov.f32 	%f15, %f20;
	mov.f32 	%f21, %f15;
	mov.f32 	%f22, %f7;
	mov.f32 	%f23, 0f3f6b3f8e;    	// 0.918939
	mov.f32 	%f24, %f23;
	mad.f32 %f25, %f21, %f22, %f24;
	mov.f32 	%f15, %f25;
	.loc	17	9370	0
	mov.f32 	%f26, 0f00000000;    	// 0
	set.gt.u32.f32 	%r18, %f2, %f26;
	neg.s32 	%r19, %r18;
	mov.f32 	%f27, 0f7f800000;    	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r20, %f2, %f27;
	neg.s32 	%r21, %r20;
	and.b32 	%r22, %r19, %r21;
	mov.u32 	%r23, 0;
	setp.eq.s32 	%p4, %r22, %r23;
	@%p4 bra 	$Lt_197_18434;
	.loc	17	9039	0
	mov.b32 	%r24, %f2;
	and.b32 	%r25, %r24, 8388607;
	or.b32 	%r26, %r25, 1065353216;
	mov.b32 	%f28, %r26;
	mov.f32 	%f29, %f28;
	.loc	17	9040	0
	shr.u32 	%r27, %r24, 23;
	cvt.rn.f32.u32 	%f30, %r27;
	mov.f32 	%f31, 0fc2fe0000;    	// -127
	add.f32 	%f32, %f30, %f31;
	mov.f32 	%f33, %f32;
	mov.f32 	%f34, 0f3fb504f3;    	// 1.41421
	setp.gt.f32 	%p5, %f28, %f34;
	@!%p5 bra 	$Lt_197_18690;
	.loc	17	9042	0
	mov.f32 	%f35, 0f3f000000;    	// 0.5
	mul.f32 	%f29, %f28, %f35;
	.loc	17	9043	0
	mov.f32 	%f36, 0f3f800000;    	// 1
	add.f32 	%f33, %f32, %f36;
$Lt_197_18690:
	.loc	17	8944	0
	mov.f32 	%f37, 0f3f800000;    	// 1
	add.f32 	%f38, %f29, %f37;
	mov.f32 	%f39, %f38;
	rcp.approx.ftz.f32 %f40,%f39;
	mov.f32 	%f41, %f40;
	.loc	17	8936	0
	mov.f32 	%f42, 0fbf800000;    	// -1
	add.f32 	%f43, %f29, %f42;
	mul.f32 	%f44, %f43, %f43;
	neg.f32 	%f45, %f44;
	mul.rn.f32 	%f46, %f41, %f45;
	add.rn.f32 	%f47, %f43, %f46;
	mul.f32 	%f48, %f47, %f47;
	mov.f32 	%f49, 0f3b2063c3;    	// 0.00244735
	mov.f32 	%f50, %f49;
	mov.f32 	%f51, %f48;
	mov.f32 	%f52, 0f3c4c4be0;    	// 0.0124693
	mov.f32 	%f53, %f52;
	mad.f32 %f54, %f50, %f51, %f53;
	mov.f32 	%f55, %f54;
	mov.f32 	%f56, %f55;
	mov.f32 	%f57, %f48;
	mov.f32 	%f58, 0f3daaab50;    	// 0.0833346
	mov.f32 	%f59, %f58;
	mad.f32 %f60, %f56, %f57, %f59;
	mov.f32 	%f55, %f60;
	mul.f32 	%f61, %f48, %f55;
	mov.f32 	%f62, %f61;
	mov.f32 	%f63, %f47;
	mov.f32 	%f64, %f46;
	mad.f32 %f65, %f62, %f63, %f64;
	mov.f32 	%f55, %f65;
	mov.f32 	%f66, %f33;
	mov.f32 	%f67, 0f3f317218;    	// 0.693147
	mov.f32 	%f68, %f67;
	add.f32 	%f69, %f43, %f55;
	mov.f32 	%f70, %f69;
	mad.f32 %f71, %f66, %f68, %f70;
	mov.f32 	%f72, %f71;
	.loc	17	9050	0
	mov.f32 	%f73, %f72;
	bra.uni 	$Lt_197_18178;
$Lt_197_18434:
	.loc	17	9053	0
	lg2.approx.f32 	%f73, %f2;
$Lt_197_18178:
	.loc	17	9055	0
	mov.f32 	%f74, 0f3f000000;    	// 0.5
	mul.f32 	%f75, %f73, %f74;
	mov.f32 	%f76, 0fbf000000;    	// -0.5
	add.f32 	%f77, %f2, %f76;
	mul.rn.f32 	%f78, %f75, %f77;
	add.rn.f32 	%f79, %f78, %f15;
	sub.f32 	%f80, %f78, %f2;
	add.f32 	%f81, %f79, %f80;
	mov.f32 	%f82, 0f7f800000;    	// ((1.0F)/(0.0F))
	setp.eq.f32 	%p6, %f2, %f82;
	selp.f32 	%f83, %f2, %f81, %p6;
	bra.uni 	$Lt_197_19714;
$Lt_197_17922:
	.loc	17	8936	0
	mov.f32 	%f84, 0fc0400000;    	// -3
	add.f32 	%f85, %f2, %f84;
	mov.f32 	%f86, 0fc43b38fb;    	// -748.89
	mov.f32 	%f87, %f86;
	mov.f32 	%f88, %f85;
	mov.f32 	%f89, 0fc640f6f8;    	// -12349.7
	mov.f32 	%f90, %f89;
	mad.f32 %f91, %f87, %f88, %f90;
	mov.f32 	%f15, %f91;
	mov.f32 	%f92, %f15;
	mov.f32 	%f93, %f85;
	mov.f32 	%f94, 0fc7206560;    	// -41061.4
	mov.f32 	%f95, %f94;
	mad.f32 %f96, %f92, %f93, %f95;
	mov.f32 	%f15, %f96;
	mov.f32 	%f97, %f15;
	mov.f32 	%f98, %f85;
	mov.f32 	%f99, 0fc73cb6aa;    	// -48310.7
	mov.f32 	%f100, %f99;
	mad.f32 %f101, %f97, %f98, %f100;
	mov.f32 	%f15, %f101;
	mov.f32 	%f102, %f15;
	mov.f32 	%f103, %f85;
	mov.f32 	%f104, 0fc80bae5a;   	// -143033
	mov.f32 	%f105, %f104;
	mad.f32 %f106, %f102, %f103, %f105;
	mov.f32 	%f15, %f106;
	.loc	17	9385	0
	mov.f32 	%f107, %f15;
	.loc	17	8936	0
	mov.f32 	%f108, 0fc381a020;   	// -259.251
	add.f32 	%f109, %f85, %f108;
	mov.f32 	%f110, %f109;
	mov.f32 	%f111, %f85;
	mov.f32 	%f112, 0fc62864b8;   	// -10777.2
	mov.f32 	%f113, %f112;
	mad.f32 %f114, %f110, %f111, %f113;
	mov.f32 	%f15, %f114;
	mov.f32 	%f115, %f15;
	mov.f32 	%f116, %f85;
	mov.f32 	%f117, 0fc7b50686;   	// -92685
	mov.f32 	%f118, %f117;
	mad.f32 %f119, %f115, %f116, %f118;
	mov.f32 	%f15, %f119;
	mov.f32 	%f120, %f15;
	mov.f32 	%f121, %f85;
	mov.f32 	%f122, 0fc8498465;   	// -206354
	mov.f32 	%f123, %f122;
	mad.f32 %f124, %f120, %f121, %f123;
	mov.f32 	%f15, %f124;
	.loc	17	8944	0
	mov.f32 	%f125, %f15;
	rcp.approx.ftz.f32 %f126,%f125;
	mov.f32 	%f127, %f126;
	.loc	17	8936	0
	mov.f32 	%f128, %f107;
	mov.f32 	%f129, %f127;
	mov.f32 	%f130, %f85;
	mad.f32 %f131, %f128, %f129, %f130;
	mov.f32 	%f15, %f131;
	.loc	17	9390	0
	mov.f32 	%f83, %f15;
	bra.uni 	$Lt_197_19714;
$Lt_197_17410:
	mov.f32 	%f132, 0f3fc00000;   	// 1.5
	setp.ge.f32 	%p7, %f2, %f132;
	@!%p7 bra 	$Lt_197_19458;
	.loc	17	8936	0
	mov.f32 	%f133, 0fc0000000;   	// -2
	add.f32 	%f134, %f2, %f133;
	mov.f32 	%f135, 0f385007fa;   	// 4.95985e-05
	mov.f32 	%f136, %f135;
	mov.f32 	%f137, %f134;
	mov.f32 	%f138, 0fb967a002;   	// -0.000220895
	mov.f32 	%f139, %f138;
	mad.f32 %f140, %f136, %f137, %f139;
	mov.f32 	%f15, %f140;
	mov.f32 	%f141, %f15;
	mov.f32 	%f142, %f134;
	mov.f32 	%f143, 0f3a0de6fc;   	// 0.000541314
	mov.f32 	%f144, %f143;
	mad.f32 %f145, %f141, %f142, %f144;
	mov.f32 	%f15, %f145;
	mov.f32 	%f146, %f15;
	mov.f32 	%f147, %f134;
	mov.f32 	%f148, 0fba9de0e2;   	// -0.00120452
	mov.f32 	%f149, %f148;
	mad.f32 %f150, %f146, %f147, %f149;
	mov.f32 	%f15, %f150;
	mov.f32 	%f151, %f15;
	mov.f32 	%f152, %f134;
	mov.f32 	%f153, 0f3b3d05b7;   	// 0.00288425
	mov.f32 	%f154, %f153;
	mad.f32 %f155, %f151, %f152, %f154;
	mov.f32 	%f15, %f155;
	mov.f32 	%f156, %f15;
	mov.f32 	%f157, %f134;
	mov.f32 	%f158, 0fbbf1eb10;   	// -0.00738276
	mov.f32 	%f159, %f158;
	mad.f32 %f160, %f156, %f157, %f159;
	mov.f32 	%f15, %f160;
	mov.f32 	%f161, %f15;
	mov.f32 	%f162, %f134;
	mov.f32 	%f163, 0f3ca89a28;   	// 0.0205813
	mov.f32 	%f164, %f163;
	mad.f32 %f165, %f161, %f162, %f164;
	mov.f32 	%f15, %f165;
	mov.f32 	%f166, %f15;
	mov.f32 	%f167, %f134;
	mov.f32 	%f168, 0fbd89f01a;   	// -0.0673525
	mov.f32 	%f169, %f168;
	mad.f32 %f170, %f166, %f167, %f169;
	mov.f32 	%f15, %f170;
	mov.f32 	%f171, %f15;
	mov.f32 	%f172, %f134;
	mov.f32 	%f173, 0f3ea51a66;   	// 0.322467
	mov.f32 	%f174, %f173;
	mad.f32 %f175, %f171, %f172, %f174;
	mov.f32 	%f15, %f175;
	mov.f32 	%f176, %f15;
	mov.f32 	%f177, %f134;
	mov.f32 	%f178, 0f3ed87730;   	// 0.422784
	mov.f32 	%f179, %f178;
	mad.f32 %f180, %f176, %f177, %f179;
	mov.f32 	%f15, %f180;
	.loc	17	9404	0
	mul.f32 	%f83, %f134, %f15;
	bra.uni 	$Lt_197_19714;
$Lt_197_19458:
	mov.f32 	%f181, 0f3f333333;   	// 0.7
	setp.ge.f32 	%p8, %f2, %f181;
	@!%p8 bra 	$Lt_197_19970;
	.loc	17	8936	0
	mov.f32 	%f182, 0f3f800000;   	// 1
	sub.f32 	%f183, %f182, %f2;
	mov.f32 	%f184, 0f3d3bef76;   	// 0.0458827
	mov.f32 	%f185, %f184;
	mov.f32 	%f186, %f183;
	mov.f32 	%f187, 0f3dd47577;   	// 0.10374
	mov.f32 	%f188, %f187;
	mad.f32 %f189, %f185, %f186, %f188;
	mov.f32 	%f15, %f189;
	mov.f32 	%f190, %f15;
	mov.f32 	%f191, %f183;
	mov.f32 	%f192, 0f3dfb8079;   	// 0.122804
	mov.f32 	%f193, %f192;
	mad.f32 %f194, %f190, %f191, %f193;
	mov.f32 	%f15, %f194;
	mov.f32 	%f195, %f15;
	mov.f32 	%f196, %f183;
	mov.f32 	%f197, 0f3e0295b5;   	// 0.127524
	mov.f32 	%f198, %f197;
	mad.f32 %f199, %f195, %f196, %f198;
	mov.f32 	%f15, %f199;
	mov.f32 	%f200, %f15;
	mov.f32 	%f201, %f183;
	mov.f32 	%f202, 0f3e12a765;   	// 0.143217
	mov.f32 	%f203, %f202;
	mad.f32 %f204, %f200, %f201, %f203;
	mov.f32 	%f15, %f204;
	mov.f32 	%f205, %f15;
	mov.f32 	%f206, %f183;
	mov.f32 	%f207, 0f3e2d6867;   	// 0.169344
	mov.f32 	%f208, %f207;
	mad.f32 %f209, %f205, %f206, %f208;
	mov.f32 	%f15, %f209;
	mov.f32 	%f210, %f15;
	mov.f32 	%f211, %f183;
	mov.f32 	%f212, 0f3e5462bf;   	// 0.207408
	mov.f32 	%f213, %f212;
	mad.f32 %f214, %f210, %f211, %f213;
	mov.f32 	%f15, %f214;
	mov.f32 	%f215, %f15;
	mov.f32 	%f216, %f183;
	mov.f32 	%f217, 0f3e8a8a72;   	// 0.270588
	mov.f32 	%f218, %f217;
	mad.f32 %f219, %f215, %f216, %f218;
	mov.f32 	%f15, %f219;
	mov.f32 	%f220, %f15;
	mov.f32 	%f221, %f183;
	mov.f32 	%f222, 0f3ecd26a4;   	// 0.400685
	mov.f32 	%f223, %f222;
	mad.f32 %f224, %f220, %f221, %f223;
	mov.f32 	%f15, %f224;
	mov.f32 	%f225, %f15;
	mov.f32 	%f226, %f183;
	mov.f32 	%f227, 0f3f528d32;   	// 0.822467
	mov.f32 	%f228, %f227;
	mad.f32 %f229, %f225, %f226, %f228;
	mov.f32 	%f15, %f229;
	mov.f32 	%f230, %f15;
	mov.f32 	%f231, %f183;
	mov.f32 	%f232, 0f3f13c468;   	// 0.577216
	mov.f32 	%f233, %f232;
	mad.f32 %f234, %f230, %f231, %f233;
	mov.f32 	%f15, %f234;
	.loc	17	9418	0
	mul.f32 	%f83, %f183, %f15;
	bra.uni 	$Lt_197_19714;
$Lt_197_19970:
	.loc	17	8936	0
	mov.f32 	%f235, 0f3b6b1c86;   	// 0.00358752
	mov.f32 	%f236, %f235;
	mov.f32 	%f237, %f2;
	mov.f32 	%f238, 0fbbb34878;   	// -0.00547129
	mov.f32 	%f239, %f238;
	mad.f32 %f240, %f236, %f237, %f239;
	mov.f32 	%f15, %f240;
	mov.f32 	%f241, %f15;
	mov.f32 	%f242, %f2;
	mov.f32 	%f243, 0fbd36caef;   	// -0.0446271
	mov.f32 	%f244, %f243;
	mad.f32 %f245, %f241, %f242, %f244;
	mov.f32 	%f15, %f245;
	mov.f32 	%f246, %f15;
	mov.f32 	%f247, %f2;
	mov.f32 	%f248, 0f3e2b5555;   	// 0.167318
	mov.f32 	%f249, %f248;
	mad.f32 %f250, %f246, %f247, %f249;
	mov.f32 	%f15, %f250;
	mov.f32 	%f251, %f15;
	mov.f32 	%f252, %f2;
	mov.f32 	%f253, 0fbd2c96c7;   	// -0.042136
	mov.f32 	%f254, %f253;
	mad.f32 %f255, %f251, %f252, %f254;
	mov.f32 	%f15, %f255;
	mov.f32 	%f256, %f15;
	mov.f32 	%f257, %f2;
	mov.f32 	%f258, 0fbf27e6eb;   	// -0.655867
	mov.f32 	%f259, %f258;
	mad.f32 %f260, %f256, %f257, %f259;
	mov.f32 	%f15, %f260;
	mov.f32 	%f261, %f15;
	mov.f32 	%f262, %f2;
	mov.f32 	%f263, 0f3f13c463;   	// 0.577215
	mov.f32 	%f264, %f263;
	mad.f32 %f265, %f261, %f262, %f264;
	mov.f32 	%f15, %f265;
	mul.f32 	%f266, %f2, %f15;
	mov.f32 	%f267, %f266;
	mov.f32 	%f268, %f2;
	mov.f32 	%f269, %f2;
	mad.f32 %f270, %f267, %f268, %f269;
	mov.f32 	%f15, %f270;
	.loc	17	9429	0
	mov.f32 	%f271, 0f00000000;   	// 0
	set.gt.u32.f32 	%r28, %f15, %f271;
	neg.s32 	%r29, %r28;
	mov.f32 	%f272, 0f7f800000;   	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r30, %f15, %f272;
	neg.s32 	%r31, %r30;
	and.b32 	%r32, %r29, %r31;
	mov.u32 	%r33, 0;
	setp.eq.s32 	%p9, %r32, %r33;
	@%p9 bra 	$Lt_197_20482;
	.loc	17	9039	0
	mov.b32 	%r34, %f15;
	and.b32 	%r35, %r34, 8388607;
	or.b32 	%r36, %r35, 1065353216;
	mov.b32 	%f273, %r36;
	mov.f32 	%f29, %f273;
	.loc	17	9040	0
	shr.u32 	%r37, %r34, 23;
	cvt.rn.f32.u32 	%f274, %r37;
	mov.f32 	%f275, 0fc2fe0000;   	// -127
	add.f32 	%f33, %f274, %f275;
	mov.f32 	%f276, 0f3fb504f3;   	// 1.41421
	setp.gt.f32 	%p10, %f273, %f276;
	@!%p10 bra 	$Lt_197_20738;
	.loc	17	9042	0
	mov.f32 	%f277, 0f3f000000;   	// 0.5
	mul.f32 	%f29, %f273, %f277;
	.loc	17	9043	0
	mov.f32 	%f278, 0f3f800000;   	// 1
	add.f32 	%f33, %f33, %f278;
$Lt_197_20738:
	.loc	17	8944	0
	mov.f32 	%f279, 0f3f800000;   	// 1
	add.f32 	%f280, %f29, %f279;
	mov.f32 	%f281, %f280;
	rcp.approx.ftz.f32 %f282,%f281;
	mov.f32 	%f283, %f282;
	.loc	17	8936	0
	mov.f32 	%f284, 0fbf800000;   	// -1
	add.f32 	%f285, %f29, %f284;
	mul.f32 	%f286, %f285, %f285;
	neg.f32 	%f287, %f286;
	mul.rn.f32 	%f288, %f283, %f287;
	add.rn.f32 	%f289, %f285, %f288;
	mul.f32 	%f290, %f289, %f289;
	mov.f32 	%f291, 0f3b2063c3;   	// 0.00244735
	mov.f32 	%f292, %f291;
	mov.f32 	%f293, %f290;
	mov.f32 	%f294, 0f3c4c4be0;   	// 0.0124693
	mov.f32 	%f295, %f294;
	mad.f32 %f296, %f292, %f293, %f295;
	mov.f32 	%f55, %f296;
	mov.f32 	%f297, %f55;
	mov.f32 	%f298, %f290;
	mov.f32 	%f299, 0f3daaab50;   	// 0.0833346
	mov.f32 	%f300, %f299;
	mad.f32 %f301, %f297, %f298, %f300;
	mov.f32 	%f55, %f301;
	mul.f32 	%f302, %f290, %f55;
	mov.f32 	%f303, %f302;
	mov.f32 	%f304, %f289;
	mov.f32 	%f305, %f288;
	mad.f32 %f306, %f303, %f304, %f305;
	mov.f32 	%f55, %f306;
	mov.f32 	%f307, %f33;
	mov.f32 	%f308, 0f3f317218;   	// 0.693147
	mov.f32 	%f309, %f308;
	add.f32 	%f310, %f285, %f55;
	mov.f32 	%f311, %f310;
	mad.f32 %f312, %f307, %f309, %f311;
	mov.f32 	%f313, %f312;
	.loc	17	9050	0
	mov.f32 	%f73, %f313;
	bra.uni 	$Lt_197_20226;
$Lt_197_20482:
	.loc	17	9053	0
	lg2.approx.f32 	%f73, %f15;
$Lt_197_20226:
	.loc	17	9429	0
	neg.f32 	%f83, %f73;
$Lt_197_19714:
$Lt_197_19202:
$Lt_197_17154:
	.loc	17	10838	0
	mov.f32 	%f314, 0f00000000;   	// 0
	setp.ge.f32 	%p11, %f1, %f314;
	@!%p11 bra 	$Lt_197_21250;
	.loc	17	10839	0
	mov.f32 	%f315, %f83;
	bra.uni 	$LDWendi___internal_fast_rcpf_437_1;
$Lt_197_21250:
	cvt.rmi.f32.f32 	%f316, %f2;
	setp.eq.f32 	%p12, %f316, %f2;
	@!%p12 bra 	$Lt_197_21762;
	.loc	17	10842	0
	mov.f32 	%f315, 0f7f800000;   	// ((1.0F)/(0.0F))
	bra.uni 	$LDWendi___internal_fast_rcpf_437_1;
$Lt_197_21762:
	mov.f32 	%f317, 0f1fec1e4a;   	// 1e-19
	setp.lt.f32 	%p13, %f2, %f317;
	@!%p13 bra 	$Lt_197_22274;
	.loc	17	10843	0
	mov.f32 	%f318, 0f00000000;   	// 0
	set.gt.u32.f32 	%r38, %f2, %f318;
	neg.s32 	%r39, %r38;
	mov.f32 	%f319, 0f7f800000;   	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r40, %f2, %f319;
	neg.s32 	%r41, %r40;
	and.b32 	%r42, %r39, %r41;
	mov.u32 	%r43, 0;
	setp.eq.s32 	%p14, %r42, %r43;
	@%p14 bra 	$Lt_197_23042;
	.loc	17	9039	0
	mov.b32 	%r44, %f2;
	and.b32 	%r45, %r44, 8388607;
	or.b32 	%r46, %r45, 1065353216;
	mov.b32 	%f28, %r46;
	mov.f32 	%f320, %f28;
	.loc	17	9040	0
	shr.u32 	%r47, %r44, 23;
	cvt.rn.f32.u32 	%f321, %r47;
	mov.f32 	%f322, 0fc2fe0000;   	// -127
	add.f32 	%f32, %f321, %f322;
	mov.f32 	%f323, %f32;
	mov.f32 	%f324, 0f3fb504f3;   	// 1.41421
	setp.gt.f32 	%p15, %f28, %f324;
	@!%p15 bra 	$Lt_197_23298;
	.loc	17	9042	0
	mov.f32 	%f325, 0f3f000000;   	// 0.5
	mul.f32 	%f320, %f28, %f325;
	.loc	17	9043	0
	mov.f32 	%f326, 0f3f800000;   	// 1
	add.f32 	%f323, %f32, %f326;
$Lt_197_23298:
	.loc	17	8944	0
	mov.f32 	%f327, 0f3f800000;   	// 1
	add.f32 	%f328, %f320, %f327;
	mov.f32 	%f329, %f328;
	rcp.approx.ftz.f32 %f330,%f329;
	mov.f32 	%f331, %f330;
	.loc	17	8936	0
	mov.f32 	%f332, 0fbf800000;   	// -1
	add.f32 	%f333, %f320, %f332;
	mul.f32 	%f334, %f333, %f333;
	neg.f32 	%f335, %f334;
	mul.rn.f32 	%f336, %f331, %f335;
	add.rn.f32 	%f337, %f333, %f336;
	mul.f32 	%f338, %f337, %f337;
	mov.f32 	%f339, 0f3b2063c3;   	// 0.00244735
	mov.f32 	%f340, %f339;
	mov.f32 	%f341, %f338;
	mov.f32 	%f342, 0f3c4c4be0;   	// 0.0124693
	mov.f32 	%f343, %f342;
	mad.f32 %f344, %f340, %f341, %f343;
	mov.f32 	%f345, %f344;
	mov.f32 	%f346, %f345;
	mov.f32 	%f347, %f338;
	mov.f32 	%f348, 0f3daaab50;   	// 0.0833346
	mov.f32 	%f349, %f348;
	mad.f32 %f350, %f346, %f347, %f349;
	mov.f32 	%f345, %f350;
	mul.f32 	%f351, %f338, %f345;
	mov.f32 	%f352, %f351;
	mov.f32 	%f353, %f337;
	mov.f32 	%f354, %f336;
	mad.f32 %f355, %f352, %f353, %f354;
	mov.f32 	%f345, %f355;
	mov.f32 	%f356, %f323;
	mov.f32 	%f357, 0f3f317218;   	// 0.693147
	mov.f32 	%f358, %f357;
	add.f32 	%f359, %f333, %f345;
	mov.f32 	%f360, %f359;
	mad.f32 %f361, %f356, %f358, %f360;
	mov.f32 	%f362, %f361;
	.loc	17	9050	0
	mov.f32 	%f363, %f362;
	bra.uni 	$Lt_197_22786;
$Lt_197_23042:
	.loc	17	9053	0
	lg2.approx.f32 	%f363, %f2;
$Lt_197_22786:
	.loc	17	10843	0
	neg.f32 	%f315, %f363;
	bra.uni 	$LDWendi___internal_fast_rcpf_437_1;
$Lt_197_22274:
	.loc	17	8936	0
	add.f32 	%f364, %f2, %f2;
	cvt.rni.f32.f32 	%f365, %f364;
	neg.f32 	%f366, %f365;
	mov.f32 	%f367, %f366;
	mov.f32 	%f368, 0f3f000000;   	// 0.5
	mov.f32 	%f369, %f368;
	mov.f32 	%f370, %f2;
	mad.f32 %f371, %f367, %f369, %f370;
	mov.f32 	%f372, %f371;
	.loc	17	10848	0
	mov.f32 	%f373, 0f40490fdb;   	// 3.14159
	mul.f32 	%f374, %f372, %f373;
	mul.f32 	%f375, %f374, %f374;
	cvt.rzi.s32.f32 	%r48, %f365;
	and.b32 	%r49, %r48, 1;
	mov.u32 	%r50, 0;
	setp.eq.s32 	%p16, %r49, %r50;
	@%p16 bra 	$Lt_197_24066;
	.loc	17	8936	0
	mov.f32 	%f376, 0f37ccf5ce;   	// 2.44332e-05
	mov.f32 	%f377, %f376;
	mov.f32 	%f378, %f375;
	mov.f32 	%f379, 0fbab6061a;   	// -0.00138873
	mov.f32 	%f380, %f379;
	mad.f32 %f381, %f377, %f378, %f380;
	mov.f32 	%f382, %f381;
	mov.f32 	%f383, %f382;
	mov.f32 	%f384, %f375;
	mov.f32 	%f385, 0f3d2aaaa5;   	// 0.0416666
	mov.f32 	%f386, %f385;
	mad.f32 %f387, %f383, %f384, %f386;
	mov.f32 	%f388, %f387;
	mov.f32 	%f389, %f388;
	mov.f32 	%f390, %f375;
	mov.f32 	%f391, 0fbf000000;   	// -0.5
	mov.f32 	%f392, %f391;
	mad.f32 %f393, %f389, %f390, %f392;
	mov.f32 	%f394, %f393;
	mov.f32 	%f395, %f394;
	mov.f32 	%f396, %f375;
	mov.f32 	%f397, 0f3f800000;   	// 1
	mov.f32 	%f398, %f397;
	mad.f32 %f399, %f395, %f396, %f398;
	mov.f32 	%f400, %f399;
	.loc	17	9491	0
	mov.f32 	%f401, %f400;
	bra.uni 	$Lt_197_23810;
$Lt_197_24066:
	.loc	17	8936	0
	mov.f32 	%f402, 0fb94ca1f9;   	// -0.000195153
	mov.f32 	%f403, %f402;
	mov.f32 	%f404, %f375;
	mov.f32 	%f405, 0f3c08839e;   	// 0.00833216
	mov.f32 	%f406, %f405;
	mad.f32 %f407, %f403, %f404, %f406;
	mov.f32 	%f408, %f407;
	mov.f32 	%f409, %f408;
	mov.f32 	%f410, %f375;
	mov.f32 	%f411, 0fbe2aaaa3;   	// -0.166667
	mov.f32 	%f412, %f411;
	mad.f32 %f413, %f409, %f410, %f412;
	mov.f32 	%f414, %f413;
	mul.f32 	%f415, %f375, %f414;
	mov.f32 	%f416, %f415;
	mov.f32 	%f417, %f374;
	mov.f32 	%f418, %f374;
	mad.f32 %f419, %f416, %f417, %f418;
	mov.f32 	%f420, %f419;
	.loc	17	9493	0
	mov.f32 	%f401, %f420;
$Lt_197_23810:
	and.b32 	%r51, %r48, 2;
	mov.u32 	%r52, 0;
	setp.eq.s32 	%p17, %r51, %r52;
	@%p17 bra 	$Lt_197_24322;
	.loc	17	8936	0
	mov.f32 	%f421, %f401;
	mov.f32 	%f422, 0fbf800000;   	// -1
	mov.f32 	%f423, %f422;
	mov.f32 	%f424, 0f00000000;   	// 0
	mov.f32 	%f425, %f424;
	mad.f32 %f426, %f421, %f423, %f425;
	mov.f32 	%f427, %f426;
	.loc	17	9496	0
	mov.f32 	%f401, %f427;
$Lt_197_24322:
	.loc	17	10850	0
	abs.f32 	%f428, %f401;
	mul.f32 	%f429, %f2, %f428;
	mov.f32 	%f430, 0f00000000;   	// 0
	set.gt.u32.f32 	%r53, %f429, %f430;
	neg.s32 	%r54, %r53;
	mov.f32 	%f431, 0f7f800000;   	// ((1.0F)/(0.0F))
	set.lt.u32.f32 	%r55, %f429, %f431;
	neg.s32 	%r56, %r55;
	and.b32 	%r57, %r54, %r56;
	mov.u32 	%r58, 0;
	setp.eq.s32 	%p18, %r57, %r58;
	@%p18 bra 	$Lt_197_25090;
	.loc	17	9039	0
	mov.b32 	%r59, %f429;
	and.b32 	%r60, %r59, 8388607;
	or.b32 	%r61, %r60, 1065353216;
	mov.b32 	%f432, %r61;
	mov.f32 	%f320, %f432;
	.loc	17	9040	0
	shr.u32 	%r62, %r59, 23;
	cvt.rn.f32.u32 	%f433, %r62;
	mov.f32 	%f434, 0fc2fe0000;   	// -127
	add.f32 	%f323, %f433, %f434;
	mov.f32 	%f435, 0f3fb504f3;   	// 1.41421
	setp.gt.f32 	%p19, %f432, %f435;
	@!%p19 bra 	$Lt_197_25346;
	.loc	17	9042	0
	mov.f32 	%f436, 0f3f000000;   	// 0.5
	mul.f32 	%f320, %f432, %f436;
	.loc	17	9043	0
	mov.f32 	%f437, 0f3f800000;   	// 1
	add.f32 	%f323, %f323, %f437;
$Lt_197_25346:
	.loc	17	8944	0
	mov.f32 	%f438, 0f3f800000;   	// 1
	add.f32 	%f439, %f320, %f438;
	mov.f32 	%f440, %f439;
	rcp.approx.ftz.f32 %f441,%f440;
	mov.f32 	%f442, %f441;
	.loc	17	8936	0
	mov.f32 	%f443, 0fbf800000;   	// -1
	add.f32 	%f444, %f320, %f443;
	mul.f32 	%f445, %f444, %f444;
	neg.f32 	%f446, %f445;
	mul.rn.f32 	%f447, %f442, %f446;
	add.rn.f32 	%f448, %f444, %f447;
	mul.f32 	%f449, %f448, %f448;
	mov.f32 	%f450, 0f3b2063c3;   	// 0.00244735
	mov.f32 	%f451, %f450;
	mov.f32 	%f452, %f449;
	mov.f32 	%f453, 0f3c4c4be0;   	// 0.0124693
	mov.f32 	%f454, %f453;
	mad.f32 %f455, %f451, %f452, %f454;
	mov.f32 	%f345, %f455;
	mov.f32 	%f456, %f345;
	mov.f32 	%f457, %f449;
	mov.f32 	%f458, 0f3daaab50;   	// 0.0833346
	mov.f32 	%f459, %f458;
	mad.f32 %f460, %f456, %f457, %f459;
	mov.f32 	%f345, %f460;
	mul.f32 	%f461, %f449, %f345;
	mov.f32 	%f462, %f461;
	mov.f32 	%f463, %f448;
	mov.f32 	%f464, %f447;
	mad.f32 %f465, %f462, %f463, %f464;
	mov.f32 	%f345, %f465;
	mov.f32 	%f466, %f323;
	mov.f32 	%f467, 0f3f317218;   	// 0.693147
	mov.f32 	%f468, %f467;
	add.f32 	%f469, %f444, %f345;
	mov.f32 	%f470, %f469;
	mad.f32 %f471, %f466, %f468, %f470;
	mov.f32 	%f472, %f471;
	.loc	17	9050	0
	mov.f32 	%f363, %f472;
	bra.uni 	$Lt_197_24834;
$Lt_197_25090:
	.loc	17	9053	0
	lg2.approx.f32 	%f363, %f429;
$Lt_197_24834:
	.loc	17	10851	0
	mov.f32 	%f473, 0f3f928682;   	// 1.14473
	sub.f32 	%f474, %f473, %f363;
	sub.f32 	%f315, %f474, %f83;
$LDWendi___internal_fast_rcpf_437_1:
	.loc	15	214	0
	ld.param.u64 	%rd5, [__cudaparm_elgamma_mf_B];
	ld.param.s32 	%r63, [__cudaparm_elgamma_mf_ldb];
	mul.lo.s32 	%r64, %r63, %r4;
	add.s32 	%r65, %r6, %r64;
	cvt.s64.s32 	%rd6, %r65;
	mul.wide.s32 	%rd7, %r65, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f315;
$Lt_197_16642:
	exit;
$LDWend_elgamma_mf:
	} // elgamma_mf

	.entry etgamma_vf (
		.param .u64 __cudaparm_etgamma_vf_n,
		.param .u64 __cudaparm_etgamma_vf_x,
		.param .s32 __cudaparm_etgamma_vf_lx,
		.param .u64 __cudaparm_etgamma_vf_result,
		.param .s32 __cudaparm_etgamma_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<18>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<138>;
	.reg .pred %p<15>;
	.loc	15	215	0
$LDWbegin_etgamma_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_etgamma_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_198_11778;
	ld.param.u64 	%rd3, [__cudaparm_etgamma_vf_x];
	ld.param.s32 	%r4, [__cudaparm_etgamma_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	mov.f32 	%f2, 0f00000000;     	// 0
	setp.ge.f32 	%p2, %f1, %f2;
	@!%p2 bra 	$Lt_198_12546;
	.loc	17	11278	0
	mov.f32 	%f3, 0f42100000;     	// 36
	setp.gt.f32 	%p3, %f1, %f3;
	mov.f32 	%f4, 0f42100000;     	// 36
	selp.f32 	%f5, %f4, %f1, %p3;
	mov.f32 	%f6, 0f42081eb8;     	// 34.03
	setp.gt.f32 	%p4, %f5, %f6;
	mov.f32 	%f7, 0fbf800000;     	// -1
	add.f32 	%f8, %f5, %f7;
	selp.f32 	%f9, %f8, %f5, %p4;
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, 0f3fc00000;    	// 1.5
	setp.gt.f32 	%p5, %f9, %f11;
	@!%p5 bra 	$Lt_198_15874;
	mov.f32 	%f12, 0f3f800000;    	// 1
$Lt_198_13314:
	.loc	17	11284	0
	mov.f32 	%f13, 0fbf800000;    	// -1
	add.f32 	%f10, %f10, %f13;
	.loc	17	11285	0
	mul.f32 	%f12, %f10, %f12;
	mov.f32 	%f14, 0f3fc00000;    	// 1.5
	setp.gt.f32 	%p6, %f10, %f14;
	@%p6 bra 	$Lt_198_13314;
	bra.uni 	$Lt_198_12802;
$Lt_198_15874:
	mov.f32 	%f12, 0f3f800000;    	// 1
$Lt_198_12802:
	.loc	17	11287	0
	mov.f32 	%f15, 0fbf800000;    	// -1
	add.f32 	%f16, %f10, %f15;
	mov.f32 	%f17, 0f3f000000;    	// 0.5
	setp.ge.f32 	%p7, %f5, %f17;
	selp.f32 	%f10, %f16, %f10, %p7;
	.loc	17	8936	0
	mov.f32 	%f18, 0fba8aa19e;    	// -0.00105767
	mov.f32 	%f19, %f18;
	mov.f32 	%f20, %f10;
	mov.f32 	%f21, 0f3be86aa4;    	// 0.00709279
	mov.f32 	%f22, %f21;
	mad.f32 %f23, %f19, %f20, %f22;
	mov.f32 	%f24, %f23;
	mov.f32 	%f25, %f24;
	mov.f32 	%f26, %f10;
	mov.f32 	%f27, 0fbc1e2998;    	// -0.00965347
	mov.f32 	%f28, %f27;
	mad.f32 %f29, %f25, %f26, %f28;
	mov.f32 	%f24, %f29;
	mov.f32 	%f30, %f24;
	mov.f32 	%f31, %f10;
	mov.f32 	%f32, 0fbd2cbe4a;    	// -0.0421737
	mov.f32 	%f33, %f32;
	mad.f32 %f34, %f30, %f31, %f33;
	mov.f32 	%f24, %f34;
	mov.f32 	%f35, %f24;
	mov.f32 	%f36, %f10;
	mov.f32 	%f37, 0f3e2a8a17;    	// 0.166542
	mov.f32 	%f38, %f37;
	mad.f32 %f39, %f35, %f36, %f38;
	mov.f32 	%f24, %f39;
	mov.f32 	%f40, %f24;
	mov.f32 	%f41, %f10;
	mov.f32 	%f42, 0fbd2c0cbb;    	// -0.0420043
	mov.f32 	%f43, %f42;
	mad.f32 %f44, %f40, %f41, %f43;
	mov.f32 	%f24, %f44;
	mov.f32 	%f45, %f24;
	mov.f32 	%f46, %f10;
	mov.f32 	%f47, 0fbf27e7a3;    	// -0.655878
	mov.f32 	%f48, %f47;
	mad.f32 %f49, %f45, %f46, %f48;
	mov.f32 	%f24, %f49;
	mov.f32 	%f50, %f24;
	mov.f32 	%f51, %f10;
	mov.f32 	%f52, 0f3f13c468;    	// 0.577216
	mov.f32 	%f53, %f52;
	mad.f32 %f54, %f50, %f51, %f53;
	mov.f32 	%f24, %f54;
	mov.f32 	%f55, %f24;
	mov.f32 	%f56, %f10;
	mov.f32 	%f57, 0f3f800000;    	// 1
	mov.f32 	%f58, %f57;
	mad.f32 %f59, %f55, %f56, %f58;
	mov.f32 	%f24, %f59;
	.loc	17	11294	0
	mul.f32 	%f60, %f5, %f24;
	mov.f32 	%f61, 0f3f000000;    	// 0.5
	setp.lt.f32 	%p8, %f5, %f61;
	selp.f32 	%f62, %f60, %f24, %p8;
	div.approx.f32 	%f12, %f12, %f62;
	@!%p4 bra 	$Lt_198_13826;
	.loc	17	11298	0
	mul.f32 	%f12, %f8, %f12;
$Lt_198_13826:
	mov.f32 	%f63, %f12;
	bra.uni 	$Lt_198_12290;
$Lt_198_12546:
	.loc	17	11306	0
	cvt.rmi.f32.f32 	%f64, %f1;
	setp.eq.f32 	%p9, %f64, %f1;
	mov.f32 	%f65, 0f7fffffff;    	// nan
	selp.f32 	%f66, %f65, %f1, %p9;
	mov.f32 	%f67, 0fc2246666;    	// -41.1
	setp.lt.f32 	%p10, %f66, %f67;
	mov.f32 	%f68, 0fc2246666;    	// -41.1
	selp.f32 	%f69, %f68, %f66, %p10;
	mov.f32 	%f70, 0fc2081eb8;    	// -34.03
	setp.lt.f32 	%p11, %f69, %f70;
	mov.f32 	%f71, 0f40c00000;    	// 6
	add.f32 	%f72, %f69, %f71;
	selp.f32 	%f73, %f72, %f69, %p11;
	mov.f32 	%f10, %f73;
	.loc	17	11310	0
	mov.f32 	%f12, %f73;
	mov.f32 	%f74, 0fbf000000;    	// -0.5
	setp.lt.f32 	%p12, %f73, %f74;
	@!%p12 bra 	$Lt_198_14338;
$Lt_198_14850:
	.loc	17	11312	0
	mov.f32 	%f75, 0f3f800000;    	// 1
	add.f32 	%f10, %f10, %f75;
	.loc	17	11313	0
	mul.f32 	%f12, %f10, %f12;
	mov.f32 	%f76, 0fbf000000;    	// -0.5
	setp.lt.f32 	%p13, %f10, %f76;
	@%p13 bra 	$Lt_198_14850;
$Lt_198_14338:
	.loc	17	8936	0
	mov.f32 	%f77, 0fba8aa19e;    	// -0.00105767
	mov.f32 	%f78, %f77;
	mov.f32 	%f79, %f10;
	mov.f32 	%f80, 0f3be86aa4;    	// 0.00709279
	mov.f32 	%f81, %f80;
	mad.f32 %f82, %f78, %f79, %f81;
	mov.f32 	%f24, %f82;
	mov.f32 	%f83, %f24;
	mov.f32 	%f84, %f10;
	mov.f32 	%f85, 0fbc1e2998;    	// -0.00965347
	mov.f32 	%f86, %f85;
	mad.f32 %f87, %f83, %f84, %f86;
	mov.f32 	%f24, %f87;
	mov.f32 	%f88, %f24;
	mov.f32 	%f89, %f10;
	mov.f32 	%f90, 0fbd2cbe4a;    	// -0.0421737
	mov.f32 	%f91, %f90;
	mad.f32 %f92, %f88, %f89, %f91;
	mov.f32 	%f24, %f92;
	mov.f32 	%f93, %f24;
	mov.f32 	%f94, %f10;
	mov.f32 	%f95, 0f3e2a8a17;    	// 0.166542
	mov.f32 	%f96, %f95;
	mad.f32 %f97, %f93, %f94, %f96;
	mov.f32 	%f24, %f97;
	mov.f32 	%f98, %f24;
	mov.f32 	%f99, %f10;
	mov.f32 	%f100, 0fbd2c0cbb;   	// -0.0420043
	mov.f32 	%f101, %f100;
	mad.f32 %f102, %f98, %f99, %f101;
	mov.f32 	%f24, %f102;
	mov.f32 	%f103, %f24;
	mov.f32 	%f104, %f10;
	mov.f32 	%f105, 0fbf27e7a3;   	// -0.655878
	mov.f32 	%f106, %f105;
	mad.f32 %f107, %f103, %f104, %f106;
	mov.f32 	%f24, %f107;
	mov.f32 	%f108, %f24;
	mov.f32 	%f109, %f10;
	mov.f32 	%f110, 0f3f13c468;   	// 0.577216
	mov.f32 	%f111, %f110;
	mad.f32 %f112, %f108, %f109, %f111;
	mov.f32 	%f24, %f112;
	mov.f32 	%f113, %f24;
	mov.f32 	%f114, %f10;
	mov.f32 	%f115, 0f3f800000;   	// 1
	mov.f32 	%f116, %f115;
	mad.f32 %f117, %f113, %f114, %f116;
	mov.f32 	%f24, %f117;
	.loc	17	11316	0
	mul.f32 	%f118, %f24, %f12;
	.loc	17	11317	0
	rcp.approx.f32 	%f12, %f118;
	@!%p11 bra 	$Lt_198_15362;
	.loc	17	11325	0
	mov.f32 	%f119, 0f40a00000;   	// 5
	add.f32 	%f120, %f69, %f119;
	mov.f32 	%f121, 0f40800000;   	// 4
	add.f32 	%f122, %f69, %f121;
	mov.f32 	%f123, 0f40400000;   	// 3
	add.f32 	%f124, %f69, %f123;
	mov.f32 	%f125, 0f40000000;   	// 2
	add.f32 	%f126, %f69, %f125;
	mov.f32 	%f127, 0f3f800000;   	// 1
	add.f32 	%f128, %f69, %f127;
	mul.f32 	%f129, %f69, %f128;
	mul.f32 	%f130, %f126, %f129;
	mul.f32 	%f131, %f124, %f130;
	mul.f32 	%f132, %f122, %f131;
	mul.f32 	%f133, %f120, %f132;
	rcp.approx.f32 	%f10, %f133;
	.loc	17	11326	0
	mul.f32 	%f134, %f10, %f12;
	.loc	17	11319	0
	mov.f32 	%f135, 0f80000000;   	// -0
	cvt.rzi.s32.f32 	%r6, %f1;
	and.b32 	%r7, %r6, 1;
	mov.s32 	%r8, 0;
	set.eq.u32.s32 	%r9, %r7, %r8;
	neg.s32 	%r10, %r9;
	mov.f32 	%f136, 0fc2280000;   	// -42
	set.lt.u32.f32 	%r11, %f1, %f136;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r10, %r12;
	neg.s32 	%r14, %r13;
	slct.f32.s32 	%f12, %f134, %f135, %r14;
$Lt_198_15362:
	mov.f32 	%f63, %f12;
$Lt_198_12290:
	.loc	15	215	0
	ld.param.u64 	%rd7, [__cudaparm_etgamma_vf_result];
	ld.param.s32 	%r15, [__cudaparm_etgamma_vf_lr];
	mul.lo.s32 	%r16, %r15, %r3;
	cvt.s64.s32 	%rd8, %r16;
	mul.wide.s32 	%rd9, %r16, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f63;
$Lt_198_11778:
	exit;
$LDWend_etgamma_vf:
	} // etgamma_vf

	.entry etgamma_mf (
		.param .s32 __cudaparm_etgamma_mf_rs,
		.param .s32 __cudaparm_etgamma_mf_cs,
		.param .u64 __cudaparm_etgamma_mf_A,
		.param .s32 __cudaparm_etgamma_mf_lda,
		.param .u64 __cudaparm_etgamma_mf_B,
		.param .s32 __cudaparm_etgamma_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<31>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<138>;
	.reg .pred %p<15>;
$LDWbegin_etgamma_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_etgamma_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_etgamma_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_199_12034;
	ld.param.u64 	%rd1, [__cudaparm_etgamma_mf_A];
	ld.param.s32 	%r15, [__cudaparm_etgamma_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	mov.f32 	%f2, 0f00000000;     	// 0
	setp.ge.f32 	%p2, %f1, %f2;
	@!%p2 bra 	$Lt_199_12802;
	.loc	17	11278	0
	mov.f32 	%f3, 0f42100000;     	// 36
	setp.gt.f32 	%p3, %f1, %f3;
	mov.f32 	%f4, 0f42100000;     	// 36
	selp.f32 	%f5, %f4, %f1, %p3;
	mov.f32 	%f6, 0f42081eb8;     	// 34.03
	setp.gt.f32 	%p4, %f5, %f6;
	mov.f32 	%f7, 0fbf800000;     	// -1
	add.f32 	%f8, %f5, %f7;
	selp.f32 	%f9, %f8, %f5, %p4;
	mov.f32 	%f10, %f9;
	mov.f32 	%f11, 0f3fc00000;    	// 1.5
	setp.gt.f32 	%p5, %f9, %f11;
	@!%p5 bra 	$Lt_199_16130;
	mov.f32 	%f12, 0f3f800000;    	// 1
$Lt_199_13570:
	.loc	17	11284	0
	mov.f32 	%f13, 0fbf800000;    	// -1
	add.f32 	%f10, %f10, %f13;
	.loc	17	11285	0
	mul.f32 	%f12, %f10, %f12;
	mov.f32 	%f14, 0f3fc00000;    	// 1.5
	setp.gt.f32 	%p6, %f10, %f14;
	@%p6 bra 	$Lt_199_13570;
	bra.uni 	$Lt_199_13058;
$Lt_199_16130:
	mov.f32 	%f12, 0f3f800000;    	// 1
$Lt_199_13058:
	.loc	17	11287	0
	mov.f32 	%f15, 0fbf800000;    	// -1
	add.f32 	%f16, %f10, %f15;
	mov.f32 	%f17, 0f3f000000;    	// 0.5
	setp.ge.f32 	%p7, %f5, %f17;
	selp.f32 	%f10, %f16, %f10, %p7;
	.loc	17	8936	0
	mov.f32 	%f18, 0fba8aa19e;    	// -0.00105767
	mov.f32 	%f19, %f18;
	mov.f32 	%f20, %f10;
	mov.f32 	%f21, 0f3be86aa4;    	// 0.00709279
	mov.f32 	%f22, %f21;
	mad.f32 %f23, %f19, %f20, %f22;
	mov.f32 	%f24, %f23;
	mov.f32 	%f25, %f24;
	mov.f32 	%f26, %f10;
	mov.f32 	%f27, 0fbc1e2998;    	// -0.00965347
	mov.f32 	%f28, %f27;
	mad.f32 %f29, %f25, %f26, %f28;
	mov.f32 	%f24, %f29;
	mov.f32 	%f30, %f24;
	mov.f32 	%f31, %f10;
	mov.f32 	%f32, 0fbd2cbe4a;    	// -0.0421737
	mov.f32 	%f33, %f32;
	mad.f32 %f34, %f30, %f31, %f33;
	mov.f32 	%f24, %f34;
	mov.f32 	%f35, %f24;
	mov.f32 	%f36, %f10;
	mov.f32 	%f37, 0f3e2a8a17;    	// 0.166542
	mov.f32 	%f38, %f37;
	mad.f32 %f39, %f35, %f36, %f38;
	mov.f32 	%f24, %f39;
	mov.f32 	%f40, %f24;
	mov.f32 	%f41, %f10;
	mov.f32 	%f42, 0fbd2c0cbb;    	// -0.0420043
	mov.f32 	%f43, %f42;
	mad.f32 %f44, %f40, %f41, %f43;
	mov.f32 	%f24, %f44;
	mov.f32 	%f45, %f24;
	mov.f32 	%f46, %f10;
	mov.f32 	%f47, 0fbf27e7a3;    	// -0.655878
	mov.f32 	%f48, %f47;
	mad.f32 %f49, %f45, %f46, %f48;
	mov.f32 	%f24, %f49;
	mov.f32 	%f50, %f24;
	mov.f32 	%f51, %f10;
	mov.f32 	%f52, 0f3f13c468;    	// 0.577216
	mov.f32 	%f53, %f52;
	mad.f32 %f54, %f50, %f51, %f53;
	mov.f32 	%f24, %f54;
	mov.f32 	%f55, %f24;
	mov.f32 	%f56, %f10;
	mov.f32 	%f57, 0f3f800000;    	// 1
	mov.f32 	%f58, %f57;
	mad.f32 %f59, %f55, %f56, %f58;
	mov.f32 	%f24, %f59;
	.loc	17	11294	0
	mul.f32 	%f60, %f5, %f24;
	mov.f32 	%f61, 0f3f000000;    	// 0.5
	setp.lt.f32 	%p8, %f5, %f61;
	selp.f32 	%f62, %f60, %f24, %p8;
	div.approx.f32 	%f12, %f12, %f62;
	@!%p4 bra 	$Lt_199_14082;
	.loc	17	11298	0
	mul.f32 	%f12, %f8, %f12;
$Lt_199_14082:
	mov.f32 	%f63, %f12;
	bra.uni 	$Lt_199_12546;
$Lt_199_12802:
	.loc	17	11306	0
	cvt.rmi.f32.f32 	%f64, %f1;
	setp.eq.f32 	%p9, %f64, %f1;
	mov.f32 	%f65, 0f7fffffff;    	// nan
	selp.f32 	%f66, %f65, %f1, %p9;
	mov.f32 	%f67, 0fc2246666;    	// -41.1
	setp.lt.f32 	%p10, %f66, %f67;
	mov.f32 	%f68, 0fc2246666;    	// -41.1
	selp.f32 	%f69, %f68, %f66, %p10;
	mov.f32 	%f70, 0fc2081eb8;    	// -34.03
	setp.lt.f32 	%p11, %f69, %f70;
	mov.f32 	%f71, 0f40c00000;    	// 6
	add.f32 	%f72, %f69, %f71;
	selp.f32 	%f73, %f72, %f69, %p11;
	mov.f32 	%f10, %f73;
	.loc	17	11310	0
	mov.f32 	%f12, %f73;
	mov.f32 	%f74, 0fbf000000;    	// -0.5
	setp.lt.f32 	%p12, %f73, %f74;
	@!%p12 bra 	$Lt_199_14594;
$Lt_199_15106:
	.loc	17	11312	0
	mov.f32 	%f75, 0f3f800000;    	// 1
	add.f32 	%f10, %f10, %f75;
	.loc	17	11313	0
	mul.f32 	%f12, %f10, %f12;
	mov.f32 	%f76, 0fbf000000;    	// -0.5
	setp.lt.f32 	%p13, %f10, %f76;
	@%p13 bra 	$Lt_199_15106;
$Lt_199_14594:
	.loc	17	8936	0
	mov.f32 	%f77, 0fba8aa19e;    	// -0.00105767
	mov.f32 	%f78, %f77;
	mov.f32 	%f79, %f10;
	mov.f32 	%f80, 0f3be86aa4;    	// 0.00709279
	mov.f32 	%f81, %f80;
	mad.f32 %f82, %f78, %f79, %f81;
	mov.f32 	%f24, %f82;
	mov.f32 	%f83, %f24;
	mov.f32 	%f84, %f10;
	mov.f32 	%f85, 0fbc1e2998;    	// -0.00965347
	mov.f32 	%f86, %f85;
	mad.f32 %f87, %f83, %f84, %f86;
	mov.f32 	%f24, %f87;
	mov.f32 	%f88, %f24;
	mov.f32 	%f89, %f10;
	mov.f32 	%f90, 0fbd2cbe4a;    	// -0.0421737
	mov.f32 	%f91, %f90;
	mad.f32 %f92, %f88, %f89, %f91;
	mov.f32 	%f24, %f92;
	mov.f32 	%f93, %f24;
	mov.f32 	%f94, %f10;
	mov.f32 	%f95, 0f3e2a8a17;    	// 0.166542
	mov.f32 	%f96, %f95;
	mad.f32 %f97, %f93, %f94, %f96;
	mov.f32 	%f24, %f97;
	mov.f32 	%f98, %f24;
	mov.f32 	%f99, %f10;
	mov.f32 	%f100, 0fbd2c0cbb;   	// -0.0420043
	mov.f32 	%f101, %f100;
	mad.f32 %f102, %f98, %f99, %f101;
	mov.f32 	%f24, %f102;
	mov.f32 	%f103, %f24;
	mov.f32 	%f104, %f10;
	mov.f32 	%f105, 0fbf27e7a3;   	// -0.655878
	mov.f32 	%f106, %f105;
	mad.f32 %f107, %f103, %f104, %f106;
	mov.f32 	%f24, %f107;
	mov.f32 	%f108, %f24;
	mov.f32 	%f109, %f10;
	mov.f32 	%f110, 0f3f13c468;   	// 0.577216
	mov.f32 	%f111, %f110;
	mad.f32 %f112, %f108, %f109, %f111;
	mov.f32 	%f24, %f112;
	mov.f32 	%f113, %f24;
	mov.f32 	%f114, %f10;
	mov.f32 	%f115, 0f3f800000;   	// 1
	mov.f32 	%f116, %f115;
	mad.f32 %f117, %f113, %f114, %f116;
	mov.f32 	%f24, %f117;
	.loc	17	11316	0
	mul.f32 	%f118, %f24, %f12;
	.loc	17	11317	0
	rcp.approx.f32 	%f12, %f118;
	@!%p11 bra 	$Lt_199_15618;
	.loc	17	11325	0
	mov.f32 	%f119, 0f40a00000;   	// 5
	add.f32 	%f120, %f69, %f119;
	mov.f32 	%f121, 0f40800000;   	// 4
	add.f32 	%f122, %f69, %f121;
	mov.f32 	%f123, 0f40400000;   	// 3
	add.f32 	%f124, %f69, %f123;
	mov.f32 	%f125, 0f40000000;   	// 2
	add.f32 	%f126, %f69, %f125;
	mov.f32 	%f127, 0f3f800000;   	// 1
	add.f32 	%f128, %f69, %f127;
	mul.f32 	%f129, %f69, %f128;
	mul.f32 	%f130, %f126, %f129;
	mul.f32 	%f131, %f124, %f130;
	mul.f32 	%f132, %f122, %f131;
	mul.f32 	%f133, %f120, %f132;
	rcp.approx.f32 	%f10, %f133;
	.loc	17	11326	0
	mul.f32 	%f134, %f10, %f12;
	.loc	17	11319	0
	mov.f32 	%f135, 0f80000000;   	// -0
	cvt.rzi.s32.f32 	%r18, %f1;
	and.b32 	%r19, %r18, 1;
	mov.s32 	%r20, 0;
	set.eq.u32.s32 	%r21, %r19, %r20;
	neg.s32 	%r22, %r21;
	mov.f32 	%f136, 0fc2280000;   	// -42
	set.lt.u32.f32 	%r23, %f1, %f136;
	neg.s32 	%r24, %r23;
	and.b32 	%r25, %r22, %r24;
	neg.s32 	%r26, %r25;
	slct.f32.s32 	%f12, %f134, %f135, %r26;
$Lt_199_15618:
	mov.f32 	%f63, %f12;
$Lt_199_12546:
	.loc	15	215	0
	ld.param.u64 	%rd5, [__cudaparm_etgamma_mf_B];
	ld.param.s32 	%r27, [__cudaparm_etgamma_mf_ldb];
	mul.lo.s32 	%r28, %r27, %r4;
	add.s32 	%r29, %r6, %r28;
	cvt.s64.s32 	%rd6, %r29;
	mul.wide.s32 	%rd7, %r29, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f63;
$Lt_199_12034:
	exit;
$LDWend_etgamma_mf:
	} // etgamma_mf

	.entry esignum_vf (
		.param .u64 __cudaparm_esignum_vf_n,
		.param .u64 __cudaparm_esignum_vf_x,
		.param .s32 __cudaparm_esignum_vf_lx,
		.param .u64 __cudaparm_esignum_vf_result,
		.param .s32 __cudaparm_esignum_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<11>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
	.loc	15	217	0
$LDWbegin_esignum_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_esignum_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_200_1026;
	ld.param.u64 	%rd3, [__cudaparm_esignum_vf_x];
	ld.param.s32 	%r4, [__cudaparm_esignum_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	mov.b32 	%r6, %f1;
	shr.u32 	%r7, %r6, 31;
	cvt.rn.f32.s32 	%f2, %r7;
	ld.param.u64 	%rd7, [__cudaparm_esignum_vf_result];
	ld.param.s32 	%r8, [__cudaparm_esignum_vf_lr];
	mul.lo.s32 	%r9, %r8, %r3;
	cvt.s64.s32 	%rd8, %r9;
	mul.wide.s32 	%rd9, %r9, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f2;
$Lt_200_1026:
	exit;
$LDWend_esignum_vf:
	} // esignum_vf

	.entry esignum_mf (
		.param .s32 __cudaparm_esignum_mf_rs,
		.param .s32 __cudaparm_esignum_mf_cs,
		.param .u64 __cudaparm_esignum_mf_A,
		.param .s32 __cudaparm_esignum_mf_lda,
		.param .u64 __cudaparm_esignum_mf_B,
		.param .s32 __cudaparm_esignum_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<24>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<4>;
	.reg .pred %p<3>;
$LDWbegin_esignum_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_esignum_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_esignum_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_201_1282;
	ld.param.u64 	%rd1, [__cudaparm_esignum_mf_A];
	ld.param.s32 	%r15, [__cudaparm_esignum_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	mov.b32 	%r18, %f1;
	shr.u32 	%r19, %r18, 31;
	cvt.rn.f32.s32 	%f2, %r19;
	ld.param.u64 	%rd5, [__cudaparm_esignum_mf_B];
	ld.param.s32 	%r20, [__cudaparm_esignum_mf_ldb];
	mul.lo.s32 	%r21, %r20, %r4;
	add.s32 	%r22, %r6, %r21;
	cvt.s64.s32 	%rd6, %r22;
	mul.wide.s32 	%rd7, %r22, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f2;
$Lt_201_1282:
	exit;
$LDWend_esignum_mf:
	} // esignum_mf

	.entry edeg_to_rad_vf (
		.param .u64 __cudaparm_edeg_to_rad_vf_n,
		.param .u64 __cudaparm_edeg_to_rad_vf_x,
		.param .s32 __cudaparm_edeg_to_rad_vf_lx,
		.param .u64 __cudaparm_edeg_to_rad_vf_result,
		.param .s32 __cudaparm_edeg_to_rad_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
	.loc	15	219	0
$LDWbegin_edeg_to_rad_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_edeg_to_rad_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_202_1026;
	ld.param.u64 	%rd3, [__cudaparm_edeg_to_rad_vf_x];
	ld.param.s32 	%r4, [__cudaparm_edeg_to_rad_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	mov.f32 	%f2, 0f3c8efa35;     	// 0.0174533
	mul.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_edeg_to_rad_vf_result];
	ld.param.s32 	%r6, [__cudaparm_edeg_to_rad_vf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f3;
$Lt_202_1026:
	exit;
$LDWend_edeg_to_rad_vf:
	} // edeg_to_rad_vf

	.entry edeg_to_rad_mf (
		.param .s32 __cudaparm_edeg_to_rad_mf_rs,
		.param .s32 __cudaparm_edeg_to_rad_mf_cs,
		.param .u64 __cudaparm_edeg_to_rad_mf_A,
		.param .s32 __cudaparm_edeg_to_rad_mf_lda,
		.param .u64 __cudaparm_edeg_to_rad_mf_B,
		.param .s32 __cudaparm_edeg_to_rad_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_edeg_to_rad_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_edeg_to_rad_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_edeg_to_rad_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_203_1282;
	ld.param.u64 	%rd1, [__cudaparm_edeg_to_rad_mf_A];
	ld.param.s32 	%r15, [__cudaparm_edeg_to_rad_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	mov.f32 	%f2, 0f3c8efa35;     	// 0.0174533
	mul.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd5, [__cudaparm_edeg_to_rad_mf_B];
	ld.param.s32 	%r18, [__cudaparm_edeg_to_rad_mf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f3;
$Lt_203_1282:
	exit;
$LDWend_edeg_to_rad_mf:
	} // edeg_to_rad_mf

	.entry erad_to_deg_vf (
		.param .u64 __cudaparm_erad_to_deg_vf_n,
		.param .u64 __cudaparm_erad_to_deg_vf_x,
		.param .s32 __cudaparm_erad_to_deg_vf_lx,
		.param .u64 __cudaparm_erad_to_deg_vf_result,
		.param .s32 __cudaparm_erad_to_deg_vf_lr)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<9>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
	.loc	15	220	0
$LDWbegin_erad_to_deg_vf:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	ld.param.u64 	%rd2, [__cudaparm_erad_to_deg_vf_n];
	setp.ge.u64 	%p1, %rd1, %rd2;
	@%p1 bra 	$Lt_204_1026;
	ld.param.u64 	%rd3, [__cudaparm_erad_to_deg_vf_x];
	ld.param.s32 	%r4, [__cudaparm_erad_to_deg_vf_lx];
	mul.lo.s32 	%r5, %r4, %r3;
	cvt.s64.s32 	%rd4, %r5;
	mul.wide.s32 	%rd5, %r5, 4;
	add.u64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6+0];
	mov.f32 	%f2, 0f42652ee0;     	// 57.2958
	mul.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_erad_to_deg_vf_result];
	ld.param.s32 	%r6, [__cudaparm_erad_to_deg_vf_lr];
	mul.lo.s32 	%r7, %r6, %r3;
	cvt.s64.s32 	%rd8, %r7;
	mul.wide.s32 	%rd9, %r7, 4;
	add.u64 	%rd10, %rd7, %rd9;
	st.global.f32 	[%rd10+0], %f3;
$Lt_204_1026:
	exit;
$LDWend_erad_to_deg_vf:
	} // erad_to_deg_vf

	.entry erad_to_deg_mf (
		.param .s32 __cudaparm_erad_to_deg_mf_rs,
		.param .s32 __cudaparm_erad_to_deg_mf_cs,
		.param .u64 __cudaparm_erad_to_deg_mf_A,
		.param .s32 __cudaparm_erad_to_deg_mf_lda,
		.param .u64 __cudaparm_erad_to_deg_mf_B,
		.param .s32 __cudaparm_erad_to_deg_mf_ldb)
	{
	.reg .u16 %rh<6>;
	.reg .u32 %r<22>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.reg .pred %p<3>;
$LDWbegin_erad_to_deg_mf:
	mov.u16 	%rh1, %ctaid.y;
	mov.u16 	%rh2, %ntid.y;
	mul.wide.u16 	%r1, %rh1, %rh2;
	mov.u16 	%rh3, %ctaid.x;
	mov.u16 	%rh4, %ntid.x;
	mul.wide.u16 	%r2, %rh3, %rh4;
	cvt.u32.u16 	%r3, %tid.y;
	add.u32 	%r4, %r3, %r1;
	cvt.u32.u16 	%r5, %tid.x;
	add.u32 	%r6, %r5, %r2;
	ld.param.s32 	%r7, [__cudaparm_erad_to_deg_mf_rs];
	set.gt.u32.s32 	%r8, %r7, %r4;
	neg.s32 	%r9, %r8;
	ld.param.s32 	%r10, [__cudaparm_erad_to_deg_mf_cs];
	set.gt.u32.s32 	%r11, %r10, %r6;
	neg.s32 	%r12, %r11;
	and.b32 	%r13, %r9, %r12;
	mov.u32 	%r14, 0;
	setp.eq.s32 	%p1, %r13, %r14;
	@%p1 bra 	$Lt_205_1282;
	ld.param.u64 	%rd1, [__cudaparm_erad_to_deg_mf_A];
	ld.param.s32 	%r15, [__cudaparm_erad_to_deg_mf_lda];
	mul.lo.s32 	%r16, %r15, %r4;
	add.s32 	%r17, %r6, %r16;
	cvt.s64.s32 	%rd2, %r17;
	mul.wide.s32 	%rd3, %r17, 4;
	add.u64 	%rd4, %rd1, %rd3;
	ld.global.f32 	%f1, [%rd4+0];
	mov.f32 	%f2, 0f42652ee0;     	// 57.2958
	mul.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd5, [__cudaparm_erad_to_deg_mf_B];
	ld.param.s32 	%r18, [__cudaparm_erad_to_deg_mf_ldb];
	mul.lo.s32 	%r19, %r18, %r4;
	add.s32 	%r20, %r6, %r19;
	cvt.s64.s32 	%rd6, %r20;
	mul.wide.s32 	%rd7, %r20, 4;
	add.u64 	%rd8, %rd5, %rd7;
	st.global.f32 	[%rd8+0], %f3;
$Lt_205_1282:
	exit;
$LDWend_erad_to_deg_mf:
	} // erad_to_deg_mf

